{"body": "<p>I am working through this tutorial:  <a href=\"http://mesosphere.io/docs/getting-started/cloud-install/\" rel=\"nofollow\">http://mesosphere.io/docs/getting-started/cloud-install/</a></p>\n\n<p>Just learning on an Ubuntu instance on Digital Ocean, I let the master process bind to the public IP, and the Mesos and Marathon web interfaces became publicly accessible.  No surprises there.</p>\n\n<p>Do Mesos and Marathon rely on Zookeeper to create private IPs between instances?  Could you skip using Zookeeper by manually setting up a private network between instances?  Then the proper way to start the master and slave processes is to bind to the secondary, private IPs of each instance?</p>\n\n<p>Digital Ocean can set up private IPs automatically, but this is kind of a learning exercise for me.  I am aware of the broad rule that administrator access to a server shouldn't come through a public IP.  Another way of phrasing this posting is, does private networking provide the security for Mesos and Marathon?</p>\n\n<p>Only starting with one Ubuntu instance, running both master and slave, for now.  Binding to the loopback address would fix this issue for just one machine, I realize.</p>\n", "is_answered": true, "title": "Private networking necessary for Mesos and Marathon?", "tags": ["mesos", "marathon", "mesosphere"], "last_activity_date": 1446507276, "accepted_answer_id": 25380384, "creation_date": 1408245708, "answers": [{"body": "<p>ZooKeeper is used for a few different things for both Marathon and Mesos:</p>\n\n<ol>\n<li>Leader election</li>\n<li>Storing state</li>\n<li>Resolving the Mesos masters</li>\n</ol>\n\n<p>At the moment, you can't skip ZooKeeper entirely because of 2 and 3 (although later versions of Mesos have their own registry which keeps track of state). AFAIK, Mesos doesn't rely on ZooKeeper for creation of private IPs - it'll bind to whatever is available (but you can force this via the <a href=\"http://mesosphere.io/docs/mesos/deep-dive/mesos-master/\" rel=\"nofollow\"><code>ip</code> parameter</a>). So, you won't be able to forgo ZooKeeper entirely with a private network.</p>\n\n<p>Private networking will provide some security for Mesos and Marathon - assuming you firewall off their access to the external world.  </p>\n\n<p>A good (although not necessarily the best) solution for keeping the instances on a private network is to set up an OpenVPN (or similar) network to one of the masters. Then, launch each instance on its private IP and make you also set the hostname parameter to that IP. Connect to the Mesos/Marathon web consoles via their private IP and the VPN and all should resolve correctly.</p>\n", "answer_id": 25380384, "last_activity_date": 1408441789, "creation_date": 1408441789, "score": 3, "owner": {"user_id": 948993, "profile_image": "https://www.gravatar.com/avatar/7ee6e3e1d1c7831d01acd349ff9ae9db?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 173, "link": "https://stackoverflow.com/users/948993/ssk2", "display_name": "ssk2"}, "is_accepted": true, "question_id": 25346050}, {"body": "<p>Mesos and marathon doesn't create private IPs between instance.\nFor that, I suggest you use <a href=\"https://github.com/gsliepen/tinc\" rel=\"nofollow\">tinc</a> or directly a docker image <a href=\"https://github.com/JensErat/docker-tinc\" rel=\"nofollow\">tinc</a></p>\n\n<p>Using this, I was able to do the config you want in 5 minutes, it's easier to configure than openvpn, and each host can connect to another, no need to use a vpn server to route all the traffic.</p>\n\n<p>Each node will store a private and public for connecting to each server of the private network.</p>\n\n<p>You <strong>should</strong> setup a private network for using mesos.</p>\n\n<p>After that, you can add in <code>/etc/hosts</code> all the hosts with the IP of the internal network.</p>\n\n<p>You will be able to bind zookeeper using the private network :</p>\n\n<pre><code>zk://master-1:2181,master-2:2181,master-3:2181\n</code></pre>\n\n<p>Then the proper way to start the master and slave processes is to bind to the secondary private IPs of each instance.</p>\n", "answer_id": 33488958, "last_activity_date": 1446507276, "creation_date": 1446507276, "score": 0, "owner": {"user_id": 2127277, "profile_image": "https://www.gravatar.com/avatar/e4222dda177339b2ade17d1a36cbac90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1232, "link": "https://stackoverflow.com/users/2127277/bigdong", "accept_rate": 59, "display_name": "BigDong"}, "is_accepted": false, "question_id": 25346050}], "score": 2, "link": "https://stackoverflow.com/questions/25346050/private-networking-necessary-for-mesos-and-marathon", "answer_count": 2, "owner": {"user_id": 1007926, "profile_image": "https://www.gravatar.com/avatar/dc0133e5980f0289b82d223562ec0a49?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 376, "link": "https://stackoverflow.com/users/1007926/peter-becich", "accept_rate": 83, "display_name": "Peter Becich"}, "view_count": 1763, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 25346050}{"body": "<p>So, we run Spark on DC/OS (Mesos) and have been running Java JARs for a while. Now, we are trying to run Python jobs and here's what we're trying to do:</p>\n\n<ol>\n<li>Download Python dependency (.egg file) using \"mesos.spark.uris\" from a http url. Mesos is supposed to download files to MESOS_SANDBOX directory which is \"/mnt/mesos/sandbox\".</li>\n<li>Use \"--py-files\" parameter to point to this file in \"/mnt/mesos/sandbox\" so Spark can set the necessary Python env vars and/or conf.</li>\n</ol>\n\n<p>However, this doesn't seem to work as intended. Here are some of the CLI commands I have tried:</p>\n\n<p><code>dcos spark run --submit-args='-Dspark.mesos.coarse=false --conf spark.mesos.uris=https://s3.amazonaws.com/bla/bla/some-egg-file.egg --py-files file:///mnt/mesos/sandbox/some-egg-file.egg https://s3.amazonaws.com/bla/bla/pi_requires_egg.py'</code></p>\n\n<p>which results in:</p>\n\n<pre><code>I1219 19:30:17.806810 15245 fetcher.cpp:547] Fetched 'https://s3.amazonaws.com/bla/bla/some-egg-file.egg' to '/var/lib/mesos/slave/slaves/40eb68aa-1595-46a1-9a87-52e18f1fa962-S3/frameworks/40eb68aa-1595-46a1-9a87-52e18f1fa962-0003/executors/driver-20161219193015-0019/runs/eae23c7c-274f-4a97-bf01-380c0f23a9b0/some-egg-file.egg'\n\nI1219 19:30:17.806816 15245 fetcher.cpp:409] Fetching URI 'file:///mnt/mesos/sandbox/some-egg-file.egg'\n\nI1219 19:30:17.806820 15245 fetcher.cpp:250] Fetching directly into the sandbox directory\n\nI1219 19:30:17.806835 15245 fetcher.cpp:187] Fetching URI 'file:///mnt/mesos/sandbox/some-egg-file.egg'\n\nI1219 19:30:17.806845 15245 fetcher.cpp:167] Copying resource with command:cp '/mnt/mesos/sandbox/some-egg-file.egg' '/var/lib/mesos/slave/slaves/40eb68aa-1595-46a1-9a87-52e18f1fa962-S3/frameworks/40eb68aa-1595-46a1-9a87-52e18f1fa962-0003/executors/driver-20161219193015-0019/runs/eae23c7c-274f-4a97-bf01-380c0f23a9b0/some-egg-file.egg'\n\ncp: cannot stat \u2018/mnt/mesos/sandbox/some-egg-file.egg\u2019: No such file or directory\n\nFailed to fetch 'file:///mnt/mesos/sandbox/some-egg-file.egg': Failed to copy with command 'cp '/mnt/mesos/sandbox/some-egg-file.egg' '/var/lib/mesos/slave/slaves/40eb68aa-1595-46a1-9a87-52e18f1fa962-S3/frameworks/40eb68aa-1595-46a1-9a87-52e18f1fa962-0003/executors/driver-20161219193015-0019/runs/eae23c7c-274f-4a97-bf01-380c0f23a9b0/some-egg-file.egg'', exit status: 256\n</code></pre>\n\n<p>and also tried this (notice no file:// prefix) :</p>\n\n<p><code>dcos spark run --submit-args='-Dspark.mesos.coarse=false --conf spark.mesos.uris=https://s3.amazonaws.com/bla/bla/some-egg-file.egg --py-files /mnt/mesos/sandbox/some-egg-file.egg https://s3.amazonaws.com/bla/bla/pi_requires_egg.py'</code></p>\n\n<p>which results in:</p>\n\n<pre><code>I1219 20:06:13.083654 15893 fetcher.cpp:409] Fetching URI 'file:/mnt/mesos/sandbox/some-egg-file.egg'\n\nI1219 20:06:13.083658 15893 fetcher.cpp:250] Fetching directly into the sandbox directory\n\nI1219 20:06:13.083678 15893 fetcher.cpp:187] Fetching URI 'file:/mnt/mesos/sandbox/some-egg-file.egg'\nFailed to fetch 'file:/mnt/mesos/sandbox/some-egg-file.egg': A relative path was passed for the resource but the Mesos framework home was not specified. Please either provide this config option or avoid using a relative path\n</code></pre>\n\n<p>So, my question is: How do I refer to/access this EGG file properly?</p>\n\n<p>Yes, I can pass the S3 URL directly to \"--py-files\" and that works, but we're trying to keep depedency operations consistent so whether that be a JAR file or an EGG file, we download it via spark.mesos.uris and let the files be accessed from \"/mnt/mesos/sandbox\", but this \"--py-files\" is our show stopper. We're having no issues with other dependencies (JAR files).</p>\n", "is_answered": false, "tags": ["python", "apache-spark", "mesos", "mesosphere", "dcos"], "last_edit_date": 1482179432, "title": "Mesos Spark Submit: \"--py-files\" with \"spark.mesos.uris\"", "last_activity_date": 1482179432, "answer_count": 0, "creation_date": 1482178663, "score": 0, "link": "https://stackoverflow.com/questions/41230339/mesos-spark-submit-py-files-with-spark-mesos-uris", "owner": {"user_id": 2669052, "profile_image": "https://www.gravatar.com/avatar/d01d2c722e975c27682f2da0c10ae6db?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 149, "link": "https://stackoverflow.com/users/2669052/urover", "accept_rate": 33, "display_name": "urover"}, "view_count": 168, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41230339}{"body": "<p>I am trying to destroy my sample apps that I deployed using marathon framework. Now I am trying to destroy that app but unfortunately, I can not destroy them for some reason.</p>\n\n<p>I have already tried:</p>\n\n<ol>\n<li>restarting marathon service on my slave.</li>\n<li>restarting mesos-manager.</li>\n<li>restarting mesos-master.</li>\n<li>checked if they are all connected to the each other properly.</li>\n</ol>\n\n<p>Why would an app go in the deployment mode when I destroy it?\nIs there any way to destroy this app now?\nErrors I am getting are as follows,</p>\n\n<ol>\n<li><p>While destroying app\nError Destroying Application\nError destroying null: App '/null' does not exist</p></li>\n<li><p>Spawning a new app\nApp is locked by one or more deployments. Override with the option '?force=true'. View details at '/v2/deployments/</p></li>\n</ol>\n", "is_answered": false, "tags": ["linux", "devops", "mesos", "marathon", "mesosphere"], "last_edit_date": 1499686489, "title": "Destroying app from Marathon puts it into the Deployments. How to destroy app in marathon?", "last_activity_date": 1499721479, "answer_count": 1, "creation_date": 1499454940, "score": 0, "link": "https://stackoverflow.com/questions/44978181/destroying-app-from-marathon-puts-it-into-the-deployments-how-to-destroy-app-in", "answers": [{"body": "<p>Just tried</p>\n\n<ol>\n<li>Restarting mesos-master</li>\n<li>Restarting mesos-slave</li>\n<li>Cleared cache for the mesos-zookeeper</li>\n<li>Went inside mesos-manager docker image and restarted all services.</li>\n</ol>\n\n<p>One of these is bound to work</p>\n", "answer_id": 44980352, "last_activity_date": 1499721479, "creation_date": 1499465452, "score": 0, "owner": {"user_id": 7188364, "profile_image": "https://www.gravatar.com/avatar/a3b288540196f7eb3d914a9e5f95fc06?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7188364/nachiket-joshi", "display_name": "Nachiket Joshi"}, "is_accepted": false, "last_edit_date": 1499721479, "question_id": 44978181}], "owner": {"user_id": 7188364, "profile_image": "https://www.gravatar.com/avatar/a3b288540196f7eb3d914a9e5f95fc06?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7188364/nachiket-joshi", "display_name": "Nachiket Joshi"}, "view_count": 25, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44978181}{"body": "<p>I created DC-OS cluster on azure, after creating with ssh public key I can access to master with the following commands,\nsudo ssh -v -A -p 2200 user@master-ip -i /root/.ssh/id_rsa</p>\n\n<p>After getting into Master I want to access agents so I copied id_rsa and id_rsa.pub key from host to master node.\nand run the following command.</p>\n\n<p>ssh -p 22 10.32.0.4\ndebug1: No more authentication methods to try.\nPermission denied (public key)</p>\n\n<p>but unfortunately it will give following error, I have tried so many ways but didn't ssh into the salve.</p>\n", "is_answered": true, "title": "How to login into DC-OS slave through Master", "last_edit_date": 1493262098, "tags": ["azure", "azure-virtual-machine", "master-slave", "dcos", "azure-container-service"], "view_count": 149, "accepted_answer_id": 43647929, "last_activity_date": 1493262098, "answers": [{"body": "<p>We can follow those steps to SSH agent:<br>\n1.<strong>Upload</strong> private key to master, I upload private key(222222) to this directory:</p>\n\n<pre><code>root@dcos-master-B9E522B-0:/home/jason/.ssh# pwd\n/home/jason/.ssh\nroot@dcos-master-B9E522B-0:/home/jason/.ssh# ls\n222222  authorized_keys  known_hosts\nroot@dcos-master-B9E522B-0:/home/jason/.ssh# \n</code></pre>\n\n<p>2.<strong>change</strong> permission for this private key, change to <strong>600</strong>:</p>\n\n<pre><code>jason@dcos-master-B9E522B-0:~/.ssh$ ll -a\ntotal 20\ndrwx------ 2 jason jason 4096 Apr 27 02:39 ./\ndrwxr-xr-x 4 jason jason 4096 Apr 27 02:39 ../\n-rw-rw-r-- 1 jason jason 1675 Apr 27 02:38 222222\n-rw------- 1 jason jason  381 Apr 27 02:17 authorized_keys\n-rw-r--r-- 1 jason jason  222 Apr 27 02:35 known_hosts\njason@dcos-master-B9E522B-0:~/.ssh$ chmod 600 222222 \n</code></pre>\n\n<p>3.Use this key to SSH agent:</p>\n\n<pre><code>jason@dcos-master-B9E522B-0:~/.ssh$ ssh jason@10.32.0.4 -i /home/jason/.ssh/222222 \nssh: /opt/mesosphere/lib/libcrypto.so.1.0.0: no version information available (required by ssh)\nssh: /opt/mesosphere/lib/libcrypto.so.1.0.0: no version information available (required by ssh)\nWelcome to Ubuntu 16.04 LTS (GNU/Linux 4.4.0-28-generic x86_64)\n\n * Documentation:  https://help.ubuntu.com/\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n0 packages can be updated.\n0 updates are security updates.\n\n\n\nThe programs included with the Ubuntu system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\n\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\njason@dcos-agent-private-B9E522B000000:~$ \n</code></pre>\n\n<p><strong>Note</strong>:<br>\n1.We can use CLI 2.0 to find the VMSS' instance admin user name, <strong>the name same as your master admin user</strong>:</p>\n\n<pre><code>C:\\Users&gt;az vmss list-instances -n \"dcos-agent-private-B9E522B-vmss0\" -g dcos\n\"osProfile\": {\n      \"adminPassword\": null,\n      \"adminUsername\": \"jason\",\n      \"computerName\": \"dcos-agent-private-B9E522B000000\",\n</code></pre>\n\n<p>2.Also we should check the private key permission, we should set it to <strong>600</strong>.<br>\n3.Make sure <code>.ssh</code> directory permission is <strong>700</strong> or <strong>755</strong>.</p>\n\n<pre><code>drwx------ 2 jason jason 4096 Apr 27 02:39 .ssh/\n</code></pre>\n", "answer_id": 43647929, "last_activity_date": 1493262016, "creation_date": 1493262016, "score": 2, "owner": {"user_id": 6851908, "profile_image": "https://www.gravatar.com/avatar/96ae2cbc5ed313e05565f7f869b5d3b2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 4831, "link": "https://stackoverflow.com/users/6851908/jason-ye-msft", "display_name": "Jason Ye - MSFT"}, "is_accepted": true, "question_id": 43638792}], "score": 1, "link": "https://stackoverflow.com/questions/43638792/how-to-login-into-dc-os-slave-through-master", "answer_count": 1, "owner": {"user_id": 7213333, "profile_image": "https://lh5.googleusercontent.com/-mygCiIKPP0A/AAAAAAAAAAI/AAAAAAAAAcg/sQKi9AryV1Q/photo.jpg?sz=128", "user_type": "registered", "reputation": 8, "link": "https://stackoverflow.com/users/7213333/parag-bharne", "display_name": "Parag Bharne"}, "creation_date": 1493221234, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43638792}{"body": "<p>Can DC/OS run on in an offline environment? <br><br>\nAfter a successfull installation in my offline environemnt the login web screen would not open with the following message:<br><br> \n<code>The server refused the connection</code>.</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "dcos"], "title": "Can DC/OS run in Offline Mode", "last_activity_date": 1463923026, "answer_count": 1, "creation_date": 1463580921, "score": 0, "link": "https://stackoverflow.com/questions/37302282/can-dc-os-run-in-offline-mode", "answers": [{"body": "<p>I had to disable authentication in my cluster because Im running it in a private offline network. \n<br>Just add the following line  in <code>genconf/config.yaml</code> before custom installation: <br>\n<br>\n<code>oatuh_enabled: 'false'</code><br></p>\n\n<p><br>this way authentication needed.<br></p>\n\n<p><a href=\"https://dcos.io/docs/1.7/administration/opt-out/\" rel=\"nofollow\">https://dcos.io/docs/1.7/administration/opt-out/</a></p>\n", "answer_id": 37374876, "last_activity_date": 1463923026, "creation_date": 1463923026, "score": 1, "owner": {"user_id": 6351473, "profile_image": "https://www.gravatar.com/avatar/8291716211337931a8b695e27c874681?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6351473/ofir-ben-shahar", "display_name": "ofir ben shahar"}, "is_accepted": false, "question_id": 37302282}], "owner": {"user_id": 6351473, "profile_image": "https://www.gravatar.com/avatar/8291716211337931a8b695e27c874681?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6351473/ofir-ben-shahar", "display_name": "ofir ben shahar"}, "view_count": 170, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37302282}{"body": "<p>I can use e.g. Marathon + Docker to easily run my long running applications, and applications are packaged as Docker images and retrieved from public/private registry.</p>\n\n<p>However, if I were to create my own framework (such as has been done for Cassandra and Spark) how would I go about to \"packaging\" my application?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Packaging applicaitons for Mesos", "last_activity_date": 1432328827, "answer_count": 2, "creation_date": 1432278040, "score": 1, "link": "https://stackoverflow.com/questions/30390284/packaging-applicaitons-for-mesos", "answers": [{"body": "<p>You can still use Docker containers, since Docker is supported directly in Mesos. That's actually how Marathon does it.</p>\n\n<p>As an alternative, you can have multiple files and/or archives that have to be fetched prior to task start.</p>\n", "answer_id": 30393945, "last_activity_date": 1432289370, "creation_date": 1432289370, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 30390284}, {"body": "<p>If you want to develop your own framework you can start from here: <a href=\"http://codefutures.com/mesos-docker-tutorial-how-to-build-your-own-framework/\" rel=\"nofollow\">Framework Tutorial</a> and <a href=\"http://mesos.apache.org/documentation/latest/app-framework-development-guide/\" rel=\"nofollow\">Mesos Framework Development Guide</a>.</p>\n\n<p>Usually you use a containerizer to run your application/code inside: The two standard containerizer are <a href=\"http://mesos.apache.org/documentation/latest/mesos-containerizer/\" rel=\"nofollow\">Mesos Containerizer</a> and <a href=\"http://mesos.apache.org/documentation/latest/docker-containerizer/\" rel=\"nofollow\">Docker Containerizer</a> (this means you can still use Docker for your own frameworks as alex mentioned). </p>\n", "answer_id": 30405875, "last_activity_date": 1432328827, "creation_date": 1432328827, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 30390284}], "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 60, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30390284}{"body": "<p>I'm using mesosphere on 3 host over Ubuntu 14.04 as follow:</p>\n\n<ul>\n<li>one with mesos master</li>\n<li>two with mesos slave</li>\n</ul>\n\n<p>All work fine, but after restart all physical hosts all scheduled job was lost. <strong>It's normal?</strong> I'm expected that zookeeper will store the current jobs, then when the system will need restart it, all jobs will be rescheduled after the master boot.</p>\n\n<p><strong>Update:</strong>\nI'm using marathon and mesos on a same node, and I'm run marathon with flag <strong>--zk</strong> </p>\n", "is_answered": true, "title": "Mesos cluster does not recover when physical host restart", "last_edit_date": 1423085544, "tags": ["apache-zookeeper", "mesos", "mesosphere"], "view_count": 1043, "accepted_answer_id": 33038784, "last_activity_date": 1463130852, "answers": [{"body": "<p>With marathon's <code>--zk</code> and <code>--ha</code> enabled, Marathon should be storing its state in ZK and recovering it on restart, as long as Mesos allows it to reregister with the same framework ID.</p>\n\n<p>However, you'll also need to enable the Mesos registry (even for a single master), to ensure that Mesos persists information about what frameworkIds are registered in the event of master failover. This can be accomplished by setting the <code>--registry=replicated_log</code> (default), <code>--quorum=1</code> (since you only have 1 master), and <code>--work_dir=/path/to/registry</code> (where to store the state).</p>\n", "answer_id": 28420346, "last_activity_date": 1423519602, "creation_date": 1423519602, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 28330001}, {"body": "<p>I solved the problem following this installation instructions: <a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04\" rel=\"nofollow\">How To Configure a Production-Ready Mesosphere Cluster on Ubuntu 14.04</a></p>\n", "answer_id": 33038784, "last_activity_date": 1444395085, "creation_date": 1444395085, "score": 0, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "is_accepted": true, "question_id": 28330001}, {"body": "<p>Although you found a solution, I'd like to explain more to this issue:)</p>\n\n<p>In official doc\uff1a<a href=\"http://mesos.apache.org/documentation/latest/slave-recovery/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/slave-recovery/</a></p>\n\n<blockquote>\n  <p>Note that if the operating system on the slave is rebooted, all\n  executors and tasks running on the host are killed and are not\n  automatically restarted when the host comes back up.</p>\n</blockquote>\n\n<p>So all frameworks on Mesos will be killed after reboot. One way to restart the frameworks is to run all frameworks on Marathon, which will manage other frameworks and restart them in need.</p>\n\n<p>However, then you need to auto-restart Marathon when it's killed. In the digitialocean link you mentioned, the Marathon is installed with script in init.d, so it can be restarted after rebooted. Otherwise, if you installed the Marathon via source code, you can use tools like supervisord to monitor Marathon.</p>\n", "answer_id": 37205950, "last_activity_date": 1463130852, "creation_date": 1463130852, "score": 0, "owner": {"user_id": 1799224, "profile_image": "https://www.gravatar.com/avatar/d357fe7f9ac30e77f82a6b6eead54539?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 430, "link": "https://stackoverflow.com/users/1799224/dark-passenger", "display_name": "Dark.Passenger"}, "is_accepted": false, "question_id": 28330001}], "score": 0, "link": "https://stackoverflow.com/questions/28330001/mesos-cluster-does-not-recover-when-physical-host-restart", "answer_count": 3, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "creation_date": 1423078906, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 28330001}{"body": "<p>I am a newbie to Mesos. I have installed a DCOS cluster locally in one system (Centos 7).</p>\n\n<p>Everything went up properly and I am able to access the GUI of DCOS  but when I am trying to connect through CLI, it is asking me for password.</p>\n\n<p>I have not been prompted for any kind of password during local installation through vagrant.</p>\n\n<p>But when I issue the following command:</p>\n\n<pre><code>[root@blade7 dcos-vagrant]# dcos node ssh --master-proxy --leader\n\nRunning `ssh -A -t core@192.168.65.90 ssh -A -t core@192.168.65.90 `\ncore@192.168.65.90's password:\nPermission denied, please try again.\ncore@192.168.65.90's password:\n</code></pre>\n\n<p>I don\u2019t know the password to be given. \nKindly help me in resolving this issue</p>\n", "is_answered": true, "title": "Unable to ssh to master node in mesos local cluster installed system", "last_edit_date": 1497043319, "tags": ["docker", "mesos", "mesosphere", "dcos"], "view_count": 89, "accepted_answer_id": 44427053, "last_activity_date": 1497043319, "answers": [{"body": "<p>The command shows that you are trying to login to the server using the userid \"core\". If you do not know the password of user \"core\", I suggest reset \"core\" user password and try it again.</p>\n", "answer_id": 44427053, "last_activity_date": 1496898454, "creation_date": 1496898454, "score": -1, "owner": {"user_id": 5168007, "profile_image": "https://www.gravatar.com/avatar/27bdecacf38aba3f18a066bf056dc871?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 89, "link": "https://stackoverflow.com/users/5168007/asatsi", "display_name": "asatsi"}, "is_accepted": true, "question_id": 44425235}], "score": 1, "link": "https://stackoverflow.com/questions/44425235/unable-to-ssh-to-master-node-in-mesos-local-cluster-installed-system", "answer_count": 1, "owner": {"user_id": 8128606, "profile_image": "https://www.gravatar.com/avatar/f273b5be12e4f5ad2a4beb5f63489d6f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 10, "link": "https://stackoverflow.com/users/8128606/pravin-k", "display_name": "Pravin K"}, "creation_date": 1496885214, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44425235}{"body": "<p>I'm trying to set some env vars on our DCOS/Mesos cluster - what's the simplest way to do that?</p>\n", "is_answered": false, "tags": ["mesos", "dcos"], "title": "How to set env vars on all nodes in a Mesos cluster?", "last_activity_date": 1490688758, "answer_count": 1, "creation_date": 1468282436, "score": 1, "link": "https://stackoverflow.com/questions/38318100/how-to-set-env-vars-on-all-nodes-in-a-mesos-cluster", "answers": [{"body": "<p>I would suggest you taking a look at <code>Consul</code> and <code>envconsul</code> combo.\nUse Consul as K/V for storing and managing the variables across the cluster and envconsul to feed them to the apps inside the container. For secrets - add <code>Vault</code>.\nYou have mentioned you were looking for simple solution. I would say it's relatively simple and elegant way to achieve that. </p>\n", "answer_id": 43064076, "last_activity_date": 1490688758, "creation_date": 1490688758, "score": 0, "owner": {"user_id": 1661204, "profile_image": "https://www.gravatar.com/avatar/b6d8debae0c2654a22d93ac1df3a7609?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/1661204/pawe%c5%82-rein", "display_name": "Pawe\u0142 Rein"}, "is_accepted": false, "question_id": 38318100}], "owner": {"user_id": 969982, "profile_image": "https://i.stack.imgur.com/yj48k.jpg?s=128&g=1", "user_type": "registered", "reputation": 1080, "link": "https://stackoverflow.com/users/969982/eugenemi", "accept_rate": 22, "display_name": "EugeneMi"}, "view_count": 46, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 38318100}{"body": "<p>Can't seem to install the Cassandra package, marathon get's stuck in deployment in phase 1/2 and dcos cassandra subcommand issues the following stacktrace, any help appreciated.</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/azureuser/.dcos/subcommands/cassandra/env/bin/dcos-cassandra\", line 5, in &lt;module&gt;\n    from pkg_resources import load_entry_point\n  File \"/opt/mesosphere/lib/python3.4/site-packages/pkg_resources.py\", line 2701, in &lt;module&gt;\n    parse_requirements(__requires__), Environment()\n  File \"/opt/mesosphere/lib/python3.4/site-packages/pkg_resources.py\", line 572, in resolve\n    raise DistributionNotFound(req)\npkg_resources.DistributionNotFound: requests\n\n\nPython version: Python 3.4.2\nrequests version : 1.8.1\n</code></pre>\n", "is_answered": true, "tags": ["python", "cassandra", "mesosphere", "dcos"], "last_edit_date": 1461524297, "title": "dcos cassandra subcommand error", "last_activity_date": 1461696967, "answer_count": 2, "creation_date": 1461522316, "score": 1, "link": "https://stackoverflow.com/questions/36827158/dcos-cassandra-subcommand-error", "answers": [{"body": "<p>I'm on the team that's building the Cassandra service. Thanks for trying it out!</p>\n\n<p>We've just updated the Cassandra CLI package to better define its pip dependencies. In your case it looks like it was trying to reuse an old version of the <code>requests</code> library? To kick your CLI's Cassandra module to the latest version, try running <code>dcos package uninstall --cli cassandra; dcos package install --cli cassandra</code>. Note that the <code>--cli</code> is important; omitting it can result in uninstalling the Cassandra service itself, while all we want is to reinstall the local CLI module.</p>\n\n<p>Keep in mind that you should also be able to access the Cassandra service directly over HTTP. The CLI module is effectively a thin interface around the service's HTTP API. For example, <code>curl -H \"Authorization:token=$(dcos config show core.dcos_acs_token)\" http://&lt;your-dcos-host&gt;/service/cassandra/v1/plan | jq '.'</code>. See the <code>curl</code> examples in the <a href=\"https://docs.mesosphere.com/cassandra-1-7/\" rel=\"nofollow\">Cassandra 1.7 docs</a> for other endpoints.</p>\n\n<p>Once you've gotten the CLI up and running, that should give more insight into the state of the service, but logs may give more thorough information, particularly if the service is failing to start. You can access the service logs directly by visiting the dashboard at <code>http://&lt;your-dcos-host&gt;/</code>:</p>\n\n<ol>\n<li>Click <code>Services</code> on the left, then select <code>marathon</code> from the list. The Cassandra service manager is run as a Marathon task.</li>\n<li>A panel will come up showing a list of all tasks being managed by Marathon. Click <code>cassandra</code> on this list to show its working directory, including the available log files.</li>\n<li>When hovering over files, a magnifying glass will appear. Click a magnifying glass to display the corresponding file in-line.</li>\n</ol>\n", "answer_id": 36847569, "last_activity_date": 1461606429, "creation_date": 1461606429, "score": 1, "owner": {"user_id": 6252585, "profile_image": "https://www.gravatar.com/avatar/7d417ac7bcd1caca822d4704f4e6b380?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/6252585/nickbp", "display_name": "nickbp"}, "is_accepted": false, "question_id": 36827158}, {"body": "<p>Unfortunately we're still having the same problem, though we've managed to get a workaround.  It seems there are more than one distinct issues with DC/OS on Azure, anyway I'll provide further feedback. If using the Marketplace version of DC/OS 1.7.0, Cassandra doesn't deploy, it get's stuck in Marathon on phase 1/2, upon inspection of the logs it seems to have a problem with accessing the default ports. </p>\n\n<p><a href=\"http://pastebin.com/1eaJ6TRp\" rel=\"nofollow\">Pastebin to log file</a></p>\n\n<p>On the other hand that problem doesn't appear on ACS DC/OS, Cassandra deploys correctly appearing in the DC/OS Service tab as well as on Marathon. The DCOS Cassandra CLI doesn't work on any. Upon a not very thorough inspection, it seems that when we installed DCOS CLI using the method above there are some issues with the dependencies specially taking into account the $PYTHONPATH variable</p>\n\n<pre><code>/opt/mesosphere/lib/python3.4/site-packages\n</code></pre>\n\n<p>We were able to solve the dependencies issue by taking two actions:  </p>\n\n<ul>\n<li><p>First Dependency issue was with requests module, which was solved with the following actions after installing cli for the Cassandra subcommand.</p>\n\n<pre><code>cd ~/.dcos/subcommands/cassandra\nsource env/bin/activate\npip install -Iv requests\n</code></pre></li>\n</ul>\n\n<p>We used -Iv since the usual update procedure fails with external dependency in $PYTHONPATH path, so requests dependency solved.</p>\n\n<ul>\n<li><p>Second dependency which the cassandra subcommand was requiring was docopt, again by using the same method we were able to solve the issue and now the subcommand works as per the documentation</p>\n\n<pre><code>pip install -Iv docopt\n</code></pre></li>\n</ul>\n\n<p>This does seem a bit hackish, wondering if there's anything more appropriate to be done.</p>\n\n<p>output of dcos cassandra connection after taking above steps</p>\n\n<pre><code>{\n\"address\": [\n    \"10.32.0.9:9042\",\n    \"10.32.0.6:9042\",\n    \"10.32.0.8:9042\"\n],\n\"dns\": [\n    \"node-0.cassandra.mesos:9042\",\n    \"node-1.cassandra.mesos:9042\",\n    \"node-2.cassandra.mesos:9042\"\n]\n}\n</code></pre>\n\n<p>The same happens for other DC/OS subcommands like for example the Kafka one.</p>\n", "answer_id": 36865904, "last_activity_date": 1461696967, "creation_date": 1461676099, "score": 1, "owner": {"user_id": 6207834, "profile_image": "https://www.gravatar.com/avatar/29bdef804d5ff111b04eff5b335452e8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6207834/hugo-matinho", "display_name": "Hugo Matinho"}, "is_accepted": false, "last_edit_date": 1461696967, "question_id": 36827158}], "owner": {"user_id": 6207834, "profile_image": "https://www.gravatar.com/avatar/29bdef804d5ff111b04eff5b335452e8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6207834/hugo-matinho", "display_name": "Hugo Matinho"}, "view_count": 355, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36827158}{"body": "<p>I'm running mesos 0.20 master node under Ubuntu 14.04. All configuration options I keep in <code>/etc/default/mesos-master</code>. I have a problem with <code>MESOS_CREDENTIALS</code> variable. It points to an existing and accessible file with a whitespace separated list of login/password pairs.</p>\n\n<p>File <code>/etc/default/mesos-master</code></p>\n\n<pre><code>MESOS_AUTHENTICATE=TRUE\nMESOS_AUTHENTICATE_SLAVES=TRUE \nMESOS_CREDENTIALS=/etc/mesos-master/credentials.txt\n</code></pre>\n\n<p>File <code>/etc/mesos-master/credentials.txt</code></p>\n\n<pre><code>login1 password1\nlogin2 password2\n</code></pre>\n\n<p>I'm receiving an error on <code>mesos-master</code> start:</p>\n\n<pre><code>Failed to load unknown flag 'credentials.txt'\n</code></pre>\n\n<p>What am I doing wrong?</p>\n", "is_answered": true, "title": "Mesos master configuration error: Failed to load unknown flag", "tags": ["ubuntu", "ubuntu-14.04", "mesos", "mesosphere"], "last_activity_date": 1431525671, "accepted_answer_id": 30217180, "creation_date": 1422014516, "answers": [{"body": "<p>That error occurs when Mesos is parsing the flags, so it has nothing to do with the contents of the file, and more to do with the syntax of expressing the flag. I can't see anything obviously wrong with what you're doing. You could try wrapping the value in \"quotes\", or test it out by running <code>mesos-master</code> directly on the command-line with the environment variable set manually.</p>\n", "answer_id": 28134213, "last_activity_date": 1422170658, "creation_date": 1422170658, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 28109487}, {"body": "<p>Mesos does not uses a consolidated configuration file. All configuration options you want to set you can set either through environment variables or by creating \"option\" files in Mesos config directory (<code>/etc/mesos-master/</code> in my case). </p>\n\n<p>For example if you want to change <code>--work_dir</code> option you can do one of the below:\n  * create a file <code>/etc/mesos-master/work_dir</code> containing some value\n  * set environment variable <code>MESOS_WORK_DIR</code>.</p>\n\n<p>Any files in <code>/etc/mesos-master/</code> named other than known Mesos options lead to the \"unknown flag\" error.</p>\n\n<p>See <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/configuration/</a></p>\n", "answer_id": 30217180, "last_activity_date": 1431525671, "creation_date": 1431525671, "score": 0, "owner": {"user_id": 1308194, "profile_image": "https://www.gravatar.com/avatar/727e63bbcfdd604ac8feeb5ae2121958?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 10276, "link": "https://stackoverflow.com/users/1308194/maksym-polshcha", "accept_rate": 86, "display_name": "Maksym Polshcha"}, "is_accepted": true, "question_id": 28109487}], "score": 1, "link": "https://stackoverflow.com/questions/28109487/mesos-master-configuration-error-failed-to-load-unknown-flag", "answer_count": 2, "owner": {"user_id": 1308194, "profile_image": "https://www.gravatar.com/avatar/727e63bbcfdd604ac8feeb5ae2121958?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 10276, "link": "https://stackoverflow.com/users/1308194/maksym-polshcha", "accept_rate": 86, "display_name": "Maksym Polshcha"}, "view_count": 643, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28109487}{"body": "<p>I'm working with mesos + marathon + docker quite a while but I got stuck at some point. At the moment I try to deal with persistent container and I tried to play around with the \"volumes-from\" parameter but I can't make it work because I have no clue how I can figure out the name of the data box to put it as a key in the json. I tried it with the example from <a href=\"https://github.com/mesosphere/marathon/blob/5f9ed0248805f231cd2900b429b0cb85217f92fe/docs/docs/native-docker.md\">here</a></p>\n\n<pre><code>    {\n    \"id\": \"privileged-job\",\n    \"container\": {\n        \"docker\": {\n            \"image\": \"mesosphere/inky\"\n            \"privileged\": true,\n            \"parameters\": [\n                { \"key\": \"hostname\", \"value\": \"a.corp.org\" },\n                { \"key\": \"volumes-from\", \"value\": \"another-container\" },\n                { \"key\": \"lxc-conf\", \"value\": \"...\" }\n            ]\n        },\n        \"type\": \"DOCKER\",\n        \"volumes\": []\n    },\n    \"args\": [\"hello\"],\n    \"cpus\": 0.2,\n    \"mem\": 32.0,\n    \"instances\": 1\n}\n</code></pre>\n\n<p>I would really appreciate any kind of help :-)</p>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "How to use volumes-from in marathon", "last_activity_date": 1492803759, "answer_count": 4, "creation_date": 1426448067, "score": 10, "link": "https://stackoverflow.com/questions/29065246/how-to-use-volumes-from-in-marathon", "answers": [{"body": "<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>{\r\n    \"id\": \"data-container\",\r\n    \"container\": {\r\n        \"docker\": {\r\n            \"image\": \"mesosphere/inky\"\r\n        },\r\n        \"type\": \"DOCKER\",\r\n        \"volumes\": [\r\n      {\r\n        \"containerPath\": \"/data\",\r\n        \"hostPath\": \"/var/data/a\",\r\n        \"mode\": \"RW\"\r\n      }\r\n    ]\r\n    },\r\n    \"args\": [\"data-only\"],\r\n    \"cpus\": 0.2,\r\n    \"mem\": 32.0,\r\n    \"instances\": 1\r\n}\r\n{\r\n    \"id\": \"privileged-job\",\r\n    \"container\": {\r\n        \"docker\": {\r\n            \"image\": \"mesosphere/inky\"\r\n            \"privileged\": true,\r\n            \"parameters\": [\r\n                { \"key\": \"hostname\", \"value\": \"a.corp.org\" },\r\n                { \"key\": \"volumes-from\", \"value\": \"data-container\" },\r\n                { \"key\": \"lxc-conf\", \"value\": \"...\" }\r\n            ]\r\n        },\r\n        \"type\": \"DOCKER\",\r\n        \"volumes\": []\r\n    },\r\n    \"args\": [\"hello\"],\r\n    \"cpus\": 0.2,\r\n    \"mem\": 32.0,\r\n    \"instances\": 1\r\n}</code></pre>\r\n</div>\r\n</div>\r\n</p>\n\n<p>Something like that maybe?</p>\n", "answer_id": 29081930, "last_activity_date": 1426523067, "creation_date": 1426523067, "score": 0, "owner": {"user_id": 4611801, "profile_image": "https://lh6.googleusercontent.com/-dJcaH_BvDDI/AAAAAAAAAAI/AAAAAAAAAAw/j-m82OEAceA/photo.jpg?sz=128", "user_type": "registered", "reputation": 1635, "link": "https://stackoverflow.com/users/4611801/aholt", "display_name": "aholt"}, "is_accepted": false, "question_id": 29065246}, {"body": "<p>From what I know : \ndocker <code>--volume-from</code> take the ID or the name of a container. </p>\n\n<p>Since your datacontainer is launch with Marathon too, it get an ID (not sur how to get this ID from marathon) and a name of that form : <code>mesos-0fb2e432-7330-4bfe-bbce-4f77cf382bb4</code> which is not related to task ID in Mesos nor docker ID.</p>\n\n<p>The solution would be to write something like this for your web-ubuntu application : </p>\n\n<pre><code>\"parameters\": [\n    { \"key\": \"volumes-from\", \"value\": \"mesos-0fb2e432-7330-4bfe-bbce-4f77cf382bb4\" }\n]\n</code></pre>\n\n<p>Since this docker-ID is unknown from Marathon it is not practical to use datacontainer that are started with Marathon.</p>\n\n<p>You can try to start a datacontainer directly with Docker (without using Marathon) and use it as you do before but since you don't know in advance where <code>web-ubuntu</code> will be scheduled (unless you add a constraint to force it) it is not practical.</p>\n", "answer_id": 31982574, "last_activity_date": 1439452571, "creation_date": 1439452571, "score": 1, "owner": {"user_id": 5222462, "profile_image": "https://www.gravatar.com/avatar/16a6fc8ecc95ec098395cae479b84bd5?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/5222462/tgermain", "display_name": "tgermain"}, "is_accepted": false, "question_id": 29065246}, {"body": "<p>Mesos support passing the parameter of volume plugin using \"key\" &amp; \"value\". But the issue is how to pass the volume name which Mesos expects to be either an absolute path or if absolute path is not passed then it will merge the name provided with the slave container sandbox folder. They do that primarily to support checkpointing, in case slave goes down accidentally.</p>\n\n<p>The only option, till the above get enhanced, is to use another key value pair parameter. For e.g. in above case </p>\n\n<p>{ \"key\": \"volumes-from\", \"value\": \"databox\" },\n { \"key\": \"volume\", \"value\": \"datebox_volume\" }</p>\n\n<p>I have tested above with a plugin and it works.</p>\n", "answer_id": 32464493, "last_activity_date": 1441735788, "creation_date": 1441735788, "score": 0, "owner": {"user_id": 5054802, "profile_image": "https://graph.facebook.com/851031298321131/picture?type=large", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/5054802/vaibhav-khanduja", "accept_rate": 11, "display_name": "Vaibhav Khanduja"}, "is_accepted": false, "question_id": 29065246}, {"body": "<p>Another approach is to write a custom mesos framework capable of running the docker command you want. In order to know what offers to accept and where to place each task you can use marathon information from: /apps/v2/ (under tasks key).</p>\n\n<p>A good starting point for writing a new mesos framework is: <a href=\"https://github.com/mesosphere/RENDLER\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/RENDLER</a></p>\n", "answer_id": 43550801, "last_activity_date": 1492803759, "creation_date": 1492803759, "score": -1, "owner": {"user_id": 2162582, "profile_image": "https://www.gravatar.com/avatar/db1df9ccce3e34b6b0ec23e56f43e8af?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 10, "link": "https://stackoverflow.com/users/2162582/radu-cosnita", "display_name": "Radu Cosnita"}, "is_accepted": false, "question_id": 29065246}], "owner": {"user_id": 4673181, "profile_image": "https://graph.facebook.com/10203776894680057/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/4673181/hammi", "display_name": "hammi"}, "view_count": 3539, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 29065246}{"is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "Docker mesosphere/chronos container fails immediately after launch", "last_activity_date": 1432801369, "answer_count": 1, "creation_date": 1432694270, "score": 1, "link": "https://stackoverflow.com/questions/30472224/docker-mesosphere-chronos-container-fails-immediately-after-launch", "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 605, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 30472224}{"body": "<p>Scheduler launches a task, Mesos Master (apache mesos 1.0.0) accepts and gives this task to a mesos agent. After that mesos agent keeps on running that task infinitely on failure. Is there a parameter to control retry for failed task.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "mesos agent keeps relaunching failed task infinitely", "last_activity_date": 1472812499, "answer_count": 1, "creation_date": 1472776531, "score": 0, "link": "https://stackoverflow.com/questions/39282721/mesos-agent-keeps-relaunching-failed-task-infinitely", "answers": [{"body": "<p>Which scheduler are you using (Restarting tasks is a schedulers responsibility)? \nCould it be you are using marathon? Marathon is designed for long-running tasks, i.e., it will restart (failed) tasks.</p>\n", "answer_id": 39290308, "last_activity_date": 1472812499, "creation_date": 1472812499, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 39282721}], "owner": {"user_id": 1726183, "profile_image": "https://www.gravatar.com/avatar/e052c9c68ad2978015d389b4c00513f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 674, "link": "https://stackoverflow.com/users/1726183/varun-gupta", "accept_rate": 55, "display_name": "Varun Gupta"}, "view_count": 70, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39282721}{"body": "<p>I am running Apache Spark on cluster mode using Apache Mesos. But, when I start Spark-Shell to run a simple test command (sc.parallelize(0 to 10, 8).count) I receive the following warning message:</p>\n\n<p>16/03/10 11:50:55 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources</p>\n\n<p>If I check on Mesos WebUI I can see that Spark-Shell is listed as a framework and I have listed one slave (my own machine). Any help how to troubleshoot it?</p>\n", "is_answered": false, "tags": ["apache-spark", "apache-spark-sql", "mesos", "mesosphere"], "last_edit_date": 1457629370, "title": "Apache Spark on Mesos: Initial job has not accepted any resources", "last_activity_date": 1457629370, "answer_count": 0, "creation_date": 1457621715, "score": 0, "link": "https://stackoverflow.com/questions/35919906/apache-spark-on-mesos-initial-job-has-not-accepted-any-resources", "owner": {"user_id": 6039705, "profile_image": "https://www.gravatar.com/avatar/4a7c4adda1e0b71cdd679cf9c9ccf29c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/6039705/juniorstack2", "display_name": "JuniorStack2"}, "view_count": 419, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35919906}{"body": "<p>I think I am missing something really fundamental here but I can't seem to it figure out.</p>\n\n<p>I am deploying a mesosphere environment using Salt, and what I want to do is run state files depending on the minion's role.</p>\n\n<p>I have seen an example <a href=\"https://github.com/Marmelatze/saltstack-mesos-test\" rel=\"nofollow noreferrer\">here</a> where they're targeting using the top.sls file, but there are very few examples I can find doing the same thing.</p>\n\n<p>So if my file-structure is thus:</p>\n\n<pre><code>  mesos\n      |_ init.sls\n      |_ mesos-master.sls\n      |_ mesos-slave\n</code></pre>\n\n<p>and I only want to run the <code>mesos-slave.sls</code> on a minion with the slave role, what is the best way to do this.</p>\n\n<p>In my infinite wisdom I thought doing the following would work (see fundamental misunderstanding opening paragraph)</p>\n\n<p>init.sls</p>\n\n<pre><code>add_mesosphere_apt_repo:\n  pkgrepo.managed:\n    - name: deb http://repos.mesosphere.io/ubuntu {{ UBUNTU_VER }} main\n    - dist: {{ UBUNTU_VER }}\n    - file: /etc/apt/sources.list.d/mesosphere.list\n    - keyid: E56151BF\n    - keyserver: keyserver.ubuntu.com\n\n{% if salt[grains.get]('role') == 'master' %}\n  include:\n    - .mesos-master\n{% endif %}\n</code></pre>\n\n<p>but all I get here are errors of duplicate IDs.</p>\n\n<p>I'm sure the answer is very simple, I just can't seem to find anything conclusive using Google.</p>\n", "is_answered": false, "tags": ["salt-stack", "mesosphere"], "title": "Invoke a salt state depending on minion role", "last_activity_date": 1487881736, "answer_count": 2, "creation_date": 1487848315, "score": 0, "link": "https://stackoverflow.com/questions/42414115/invoke-a-salt-state-depending-on-minion-role", "answers": [{"body": "<p>I have decided to go down the targeting via <code>top.sls</code> like so:</p>\n\n<pre><code>'roles:ms':\n  - match:grain\n  - mesos.mesos-slave\n</code></pre>\n", "answer_id": 42415899, "last_activity_date": 1487859012, "creation_date": 1487853235, "score": 0, "owner": {"user_id": 6921637, "profile_image": "https://www.gravatar.com/avatar/0b85c612fab1c0be106f3a0399ff54ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 92, "link": "https://stackoverflow.com/users/6921637/max-weaver", "accept_rate": 55, "display_name": "Max Weaver"}, "is_accepted": false, "last_edit_date": 1487859012, "question_id": 42414115}, {"body": "<h1>Matching using grains</h1>\n\n<p>You can use grain data when targeting minions:</p>\n\n<pre><code>salt -G 'role:mesos-slave' test.ping\n</code></pre>\n\n<h1>Matching using grains in the topfile</h1>\n\n<p>Matching using grains in the <code>top.sls</code> can be very efficient:</p>\n\n<pre><code>'role:mesos-slave':\n  - match: grain\n  - mesos.mesos-slave\n</code></pre>\n\n<h1>Manually syncing grains</h1>\n\n<p>Grains are automatically synced when <code>state.highstate</code> is called. It's however possible to sync and reload them manually:</p>\n\n<pre><code>salt '*' saltutil.sync_grains\nsalt '*' saltutil.sync_all \n</code></pre>\n\n<h1>Is targeting using grains secure?</h1>\n\n<p>Grains can be set by users that have access to the minion configuration files on the local system, therefore grains are considers less secure than other identifiers in Salt! </p>\n\n<p><strong>Note:</strong> it's best practice to not use grains for matching in your pillar top file for any sensitive pillars!</p>\n\n<h1>Duplicate ID's</h1>\n\n<blockquote>\n  <p>... but all I get here are errors of duplicate IDs.</p>\n</blockquote>\n\n<p>Salt currently checks for duplicate IDs before execution. The ID must be unique across the entire state tree. All subsequent ID declarations with the same name will be ignored. </p>\n\n<p>A simple solution for this problem might to ensure each ID is unique. You could for example include the SLS file name in the ID declaration: </p>\n\n<p>For the <code>mesos.mesos_master</code> you could use:</p>\n\n<pre><code>mesos_master:\n  file.managed:\n    - name: ...\n    - ...\n</code></pre>\n\n<p>For the <code>mesos.mesos_slave</code> you could use:</p>\n\n<pre><code>mesos_slave:\n  file.managed:\n    - name: ...\n    - ...\n</code></pre>\n\n<p>This ways you won't receive the '<em>duplicate ID</em>' errors when including and excluding other SLS files.</p>\n", "answer_id": 42425579, "last_activity_date": 1487881736, "creation_date": 1487881736, "score": 0, "owner": {"user_id": 4779556, "profile_image": "https://www.gravatar.com/avatar/06acde1d128b9fadc43f9a486318c13e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 648, "link": "https://stackoverflow.com/users/4779556/roald-nefs", "display_name": "Roald Nefs"}, "is_accepted": false, "question_id": 42414115}], "owner": {"user_id": 6921637, "profile_image": "https://www.gravatar.com/avatar/0b85c612fab1c0be106f3a0399ff54ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 92, "link": "https://stackoverflow.com/users/6921637/max-weaver", "accept_rate": 55, "display_name": "Max Weaver"}, "view_count": 40, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42414115}{"body": "<p>I have a vagrant environment setup, with one mesos master and two mesos agents. After, registering the cassandra framework once, if I tear it down and try to re-register it. It is unable to start cassandra tasks on mesos agent.</p>\n\n<p>What is the reason behind it, who is maintaining the state of previous cassandra framework, such as mesos-master, or zookeeper or mesos-agents?</p>\n\n<p>EDIT:\nWhat I discovered is that, mesos-agent is not offering the resources which were used by previous cassandra framework registration. From my understanding, once the framework is teared down, it should free up resources from mesos-agents also.</p>\n\n<p>EDIT:\nWhen I restart the mesos-master process on vagrant environment, I see all the completed frameworks go away from the mesos UI, so I believe it is clearing up its state but mesos agent's even after re-starting still holds the previous completed frameworks list, so where can I clear up mesos-slave state?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1473187216, "title": "unable to re-register cassandra framework on vagrant environment after tearing it down", "last_activity_date": 1473198731, "answer_count": 1, "creation_date": 1473181685, "score": 0, "link": "https://stackoverflow.com/questions/39354405/unable-to-re-register-cassandra-framework-on-vagrant-environment-after-tearing-i", "answers": [{"body": "<p>After uninstalling Cassandra framework/service, if you would like to re-install it fresh you need to cleanup it's Zookeeper state, please refer to this documentation for more details: <a href=\"https://docs.mesosphere.com/1.8/usage/managing-services/uninstall/\" rel=\"nofollow\">https://docs.mesosphere.com/1.8/usage/managing-services/uninstall/</a></p>\n\n<p>tl;dr</p>\n\n<p>Run this command from any host within the DC/OS cluster to clear up Zookeeper state w.r.t. Cassandra service:</p>\n\n<pre><code>docker run mesosphere/janitor /janitor.py -r cassandra-role -p cassandra-principal -z dcos-service-cassandra\n</code></pre>\n\n<p>Installation uses following defaults:</p>\n\n<ul>\n<li>Role: cassandra-role</li>\n<li>Principal: cassandra-principal</li>\n<li>ZNode: dcos-service-cassandra</li>\n</ul>\n\n<p>If you changed any of above, please update the command accordingly.</p>\n", "answer_id": 39358393, "last_activity_date": 1473198731, "creation_date": 1473198731, "score": 1, "owner": {"user_id": 154917, "profile_image": "https://www.gravatar.com/avatar/4f9ddde97e53bca54270fdbd3ec02d83?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2020, "link": "https://stackoverflow.com/users/154917/mohitsoni", "display_name": "mohitsoni"}, "is_accepted": false, "question_id": 39354405}], "owner": {"user_id": 1726183, "profile_image": "https://www.gravatar.com/avatar/e052c9c68ad2978015d389b4c00513f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 674, "link": "https://stackoverflow.com/users/1726183/varun-gupta", "accept_rate": 55, "display_name": "Varun Gupta"}, "view_count": 35, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39354405}{"is_answered": false, "tags": ["mesos", "mesosphere"], "title": "Set up mesosphere chronos cluster", "last_activity_date": 1446113599, "answer_count": 1, "creation_date": 1446085909, "score": 1, "link": "https://stackoverflow.com/questions/33404968/set-up-mesosphere-chronos-cluster", "owner": {"user_id": 1137191, "profile_image": "https://i.stack.imgur.com/bUz08.jpg?s=128&g=1", "user_type": "registered", "reputation": 334, "link": "https://stackoverflow.com/users/1137191/ucdream", "accept_rate": 30, "display_name": "ucdream"}, "view_count": 207, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 33404968}{"body": "<p>I'd like to change set various configuration options for Marathon, and I'm unsure how to do this. For example, I'd like to add <code>--event_subscriber http_callback</code> to the launch command.</p>\n", "is_answered": true, "title": "Changing configuration options for Marathon", "tags": ["mesos", "mesosphere"], "last_activity_date": 1447692533, "accepted_answer_id": 30870484, "creation_date": 1433917908, "answers": [{"body": "<p>For each configuration you can create a file in the directory /etc/default/marathon where the filename is the name of the option and a single line in the file containing the value for that option.</p>\n\n<p>Eg. Make a file /etc/default/marathon/event_subscriber that contains the line \"http_callback\"</p>\n\n<p>This also works for mesos.</p>\n", "answer_id": 30870484, "last_activity_date": 1434464770, "creation_date": 1434464770, "score": 0, "owner": {"user_id": 4751598, "profile_image": "https://lh4.googleusercontent.com/-K50s84aoK9g/AAAAAAAAAAI/AAAAAAAAADY/FxWBVy8tJy4/photo.jpg?sz=128", "user_type": "registered", "reputation": 556, "link": "https://stackoverflow.com/users/4751598/matthew-jones", "accept_rate": 62, "display_name": "Matthew Jones"}, "is_accepted": true, "question_id": 30748716}, {"body": "<p>Actually the directory has to be <code>/etc/marathon/conf</code>. This is valid for <strong>0.11.1</strong>.</p>\n", "answer_id": 33740473, "last_activity_date": 1447692533, "creation_date": 1447692533, "score": 0, "owner": {"user_id": 5509784, "profile_image": "https://www.gravatar.com/avatar/212308daef15abc91ec012383a7e1fe8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5509784/alex-bordei", "display_name": "Alex Bordei"}, "is_accepted": false, "question_id": 30748716}], "score": 0, "link": "https://stackoverflow.com/questions/30748716/changing-configuration-options-for-marathon", "answer_count": 2, "owner": {"user_id": 88770, "profile_image": "https://www.gravatar.com/avatar/cce6dedd189d53eea48e6121bb9a0383?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1058, "link": "https://stackoverflow.com/users/88770/wedtm", "accept_rate": 96, "display_name": "WedTM"}, "view_count": 304, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 30748716}{"body": "<p>Is there any way of running a service (single instance) on each deployed agent node? I need that because each agent needs to mount a storage from S3 using <code>s3fs</code></p>\n", "is_answered": true, "title": "DC/OS running a service on each agent", "last_edit_date": 1482170239, "tags": ["dcos"], "view_count": 37, "accepted_answer_id": 41231958, "last_activity_date": 1482186145, "answers": [{"body": "<p>The name of the feature you're looking for is \"daemon tasks\", but unfortunately, it's still in the planning phase for Mesos itself. \nDue to the fact that schedulers don't know the entire state of the cluster, Mesos needs to add a feature to enable this functionality. Once in Mesos it can be integrated with DC/OS.</p>\n\n<p>The primary workaround is to use Marathon to deploy an app with the UNIQUE constraint (<code>\"constraints\": [[\"hostname\", \"UNIQUE\"]]</code>) and set the app <code>instances</code> to the number of agent nodes. Unfortunately this means you have to adjust the instances number when you add new nodes.</p>\n", "answer_id": 41231958, "last_activity_date": 1482186145, "creation_date": 1482186145, "score": 1, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "question_id": 41228341}], "score": 1, "link": "https://stackoverflow.com/questions/41228341/dc-os-running-a-service-on-each-agent", "answer_count": 1, "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "creation_date": 1482170032, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41228341}{"body": "<p>After upgrading apache Mesos to 0.27 on Ubuntu 14.04 (3 master - 3 slave setup) I get the following error while trying to connect to the cluster with Spark 1.6 (client mode without using docker images):</p>\n\n<pre><code> I0219 12:40:47.684662 11484 fetcher.cpp:379] Fetching URI   \n 'hdfs://auto-ha/spark/spark.tgz'\n I0219 12:40:47.684691 11484 fetcher.cpp:250] Fetching directly into the sandbox directory\n I0219 12:40:47.684720 11484 fetcher.cpp:187] Fetching URI     \n 'hdfs://auto-ha/spark/spark.tgz'\n I0219 12:40:48.139446 11484 fetcher.cpp:109] Downloading resource     \n with Hadoop client from 'hdfs://auto-ha/spark/spark.tgz' to     '/tmp/mesos/slaves/a7907b94-6dc9-437c-b027-b71379a9e0e1-  S3/frameworks/a7907b94-6dc9-437c-b027-b71379a9e0e1- 0006/executors/5/runs/48753051-450a-4043-908d-58f277633cf4/spark.tgz'\n F0219 12:40:48.140929 11484 process.cpp:892] Failed to initialize: Failed   to bind on 172.16.8.166:5051: Address already in use: Address already in   use [98]\n*** Check failure stack trace: ***\n    @     0x7ff38fe76a3d  google::LogMessage::Fail()\n@     0x7ff38fe7887d  google::LogMessage::SendToLog()\n@     0x7ff38fe7662c  google::LogMessage::Flush()\n@     0x7ff38fe76839  google::LogMessage::~LogMessage()\n@     0x7ff38fe777a2  google::ErrnoLogMessage::~ErrnoLogMessage()\n@     0x7ff38fe1d149  process::initialize()\n@     0x7ff38fe1e7d2  process::ProcessBase::ProcessBase()\n@     0x7ff38fe4d631  process::reap()\n@     0x7ff38fe56235  process::subprocess()\n@     0x7ff38f603059  HDFS::copyToLocal()\n@           0x40eecd  download()\n@           0x40b8ea  main\n@     0x7ff38de81ec5  (unknown)\n@           0x40d2c3  (unknown)\nAborted (core dumped)\n\nEnd fetcher log for container 48753051-450a-4043-908d-58f277633cf4\n</code></pre>\n\n<p>Seems to be a port conflict on the mesos-fetcher, however using:</p>\n\n<pre><code>sudo lsof -i | grep 5051\n</code></pre>\n\n<p>nothing appears to be listenning on that port. </p>\n\n<p><strong>Mesos 0.26 worked well</strong> on the same setup. </p>\n\n<p>The hdfs filesystem is working and the docker containerizer is working well.\nI have also checked for fetcher port config but nothing.</p>\n\n<p>Any hints?</p>\n\n<p>Thanks! </p>\n", "is_answered": true, "title": "Apache Mesos 0.27 fetcher Error: Address already in use:", "tags": ["apache-spark", "mesos", "mesosphere"], "last_activity_date": 1456473074, "accepted_answer_id": 35646281, "creation_date": 1455796885, "answers": [{"body": "<p>Port <code>5051</code> is used by <code>mesos-slave</code> for communication with <code>mesos-master</code>. For checking port usage, use rather:</p>\n\n<pre><code>netstat -tulpn | grep 5051\n</code></pre>\n\n<p>or (without port names translation - port <code>5051</code> is called <code>enbd-cstatd</code>)</p>\n\n<pre><code>lsof -i -P | grep 5051\n</code></pre>\n\n<p>Mesos slave typically uses higher range of ports <code>31000-32000</code>, with Mesosphere release you can easily control range of ports allocated for Mesos tasks:</p>\n\n<pre><code>echo \"[20000-32000]\" &gt; /etc/mesos-slave/resources/ports\n</code></pre>\n", "answer_id": 35523912, "last_activity_date": 1455974854, "creation_date": 1455974854, "score": 0, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": false, "question_id": 35480929}, {"body": "<p>After doing a cold reboot with and upgrade of all the nodes of the cluster(the mesos package was upgraded too) everything is running fine.</p>\n\n<p>Sems to be a bug of mesos after the upgrade to 0.27. </p>\n\n<p>Thanks anyway!</p>\n", "answer_id": 35646281, "last_activity_date": 1456473074, "creation_date": 1456473074, "score": 0, "owner": {"user_id": 4195070, "profile_image": "https://lh4.googleusercontent.com/-bd_bfuB2yFI/AAAAAAAAAAI/AAAAAAAATwc/Gf2sFz9YoDM/photo.jpg?sz=128", "user_type": "registered", "reputation": 48, "link": "https://stackoverflow.com/users/4195070/eingel", "display_name": "Eingel"}, "is_accepted": true, "question_id": 35480929}], "score": 1, "link": "https://stackoverflow.com/questions/35480929/apache-mesos-0-27-fetcher-error-address-already-in-use", "answer_count": 2, "owner": {"user_id": 4195070, "profile_image": "https://lh4.googleusercontent.com/-bd_bfuB2yFI/AAAAAAAAAAI/AAAAAAAATwc/Gf2sFz9YoDM/photo.jpg?sz=128", "user_type": "registered", "reputation": 48, "link": "https://stackoverflow.com/users/4195070/eingel", "display_name": "Eingel"}, "view_count": 385, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35480929}{"body": "<p>I have installed HDFS from universe on my DCOS cluster of 10 Core OS machines (3 master nodes, 7 agent nodes). My HA HDFS config has 2 name nodes, 3 journal nodes and 5 data nodes. Now, my question is. Shouldn\u2019t the HDFS be resilient to machine restarts? If I restart a machine where a data node is installed the data node gets rebuilt as a mirror of the others (only after restarting the HDFS service from the DC/OS UI). In the case of a restart where a journal node or a name node is, the nodes will be just marked as lost and never rebuilt.</p>\n", "is_answered": true, "title": "HDFS resiliency to machine restarts in DC/OS", "last_edit_date": 1487150627, "tags": ["hadoop", "hdfs", "mesos", "marathon", "dcos"], "view_count": 61, "accepted_answer_id": 42245252, "last_activity_date": 1487150627, "answers": [{"body": "<p>A quick summary of the HDFS resiliency model for an HA deployment like yours:</p>\n\n<ul>\n<li>The two NameNodes form an active/standby pair.  In the event of a machine restart of the active, then the system detects failure of the active and the standby takes over as the new active.  Once the machine completes its restart, the NameNode process runs again, and it becomes the new standby.  There is no downtime unless both NameNodes are down simultaneously.  The data on the host (e.g. the fsimage metadata file) is typically maintained between restarts.  If this is not the case in your environment, then you'll need additional recovery steps to re-establish the standby, such as by running the <code>hdfs namenode -bootstrapStandby</code> command.</li>\n<li>The 3 JournalNodes form a quorum.  In the event of a machine restart, the NameNode can continue writing its edit log transactions to the remaining 2 JournalNodes.  Once the machine completes its restart, the JournalNode process runs again, catches up with transactions it may have missed, and then the NameNode writes to all 3 again.  There is no downtime unless 2 or more JournalNodes are down simultaneously.  If data (e.g. the edits files) are not maintained across restarts, then the restarted JournalNode will catch up by copying from a running JournalNode.</li>\n<li>DataNodes are mostly disposable.  In the event of a machine restart, clients will be rerouted to other running DataNodes for their reads and writes (assuming the typical replication factor of 3).  Once the machine completes its restart, the DataNode process runs again, and it can start serving read/write traffic from clients again.  There is no downtime unless a mass simultaneous failure event (extremely unlikely and probably correlated with bigger data center problems) causes all the DataNodes hosting replicas of a particular block are down simultaneously.  If data (the block file directory) is not maintained across restarts, then after a restart, it will look like a whole new DataNode coming online.  If this causes cluster imbalance, then that can be remedied by running the HDFS Balancer.</li>\n</ul>\n", "answer_id": 41964148, "last_activity_date": 1485884794, "creation_date": 1485884794, "score": 0, "owner": {"user_id": 786223, "profile_image": "https://i.stack.imgur.com/Fi4pw.jpg?s=128&g=1", "user_type": "registered", "reputation": 5833, "link": "https://stackoverflow.com/users/786223/chris-nauroth", "display_name": "Chris Nauroth"}, "is_accepted": false, "question_id": 41943112}, {"body": "<p>Eventually the problem was found in a buggy version of the universe HDFS package for DC/OS. However, a completely new HDFS package for DC/OS will be released on Universe in the next few weeks.</p>\n\n<p><a href=\"https://dcos-community.slack.com/archives/data-services/p1485717889001709\" rel=\"nofollow noreferrer\">https://dcos-community.slack.com/archives/data-services/p1485717889001709</a></p>\n\n<p><a href=\"https://dcos-community.slack.com/archives/data-services/p1485801481001734\" rel=\"nofollow noreferrer\">https://dcos-community.slack.com/archives/data-services/p1485801481001734</a></p>\n", "answer_id": 42245252, "last_activity_date": 1487150581, "creation_date": 1487150581, "score": 1, "owner": {"user_id": 7019448, "profile_image": "https://i.stack.imgur.com/zLZj2.png?s=128&g=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/7019448/andrea-t-bonanno", "accept_rate": 67, "display_name": "Andrea T. Bonanno"}, "is_accepted": true, "question_id": 41943112}], "score": 2, "link": "https://stackoverflow.com/questions/41943112/hdfs-resiliency-to-machine-restarts-in-dc-os", "answer_count": 2, "owner": {"user_id": 7019448, "profile_image": "https://i.stack.imgur.com/zLZj2.png?s=128&g=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/7019448/andrea-t-bonanno", "accept_rate": 67, "display_name": "Andrea T. Bonanno"}, "creation_date": 1485801471, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41943112}{"body": "<p>I have installed Mesos on Centos 6.8. Now when I start mesos-master using following command:</p>\n\n<pre><code>mesos-master --ip=10.150.240.10 --work_dir=/tmp/mesos/\n</code></pre>\n\n<p>I'm getting the below error:</p>\n\n<blockquote>\n  <p>mesos-master: error while loading shared libraries: libdb-5.3.so: cannot open shared object file: No such file or directory.</p>\n</blockquote>\n\n<p>How can I solve this?</p>\n", "is_answered": true, "title": "Not able to start mesos-master", "last_edit_date": 1478887985, "tags": ["apache", "mesos", "mesosphere"], "view_count": 162, "accepted_answer_id": 40731250, "last_activity_date": 1479770482, "answers": [{"body": "<p>This looks like version for 7.1 try with version for 6.5 available <a href=\"http://repos.mesosphere.com/el-testing/6/x86_64/RPMS/mesos-1.1.0-1.0.98.rc1.centos65.x86_64.rpm\" rel=\"nofollow\">here</a> </p>\n", "answer_id": 40731250, "last_activity_date": 1479770482, "creation_date": 1479770482, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 40552523}], "score": 1, "link": "https://stackoverflow.com/questions/40552523/not-able-to-start-mesos-master", "answer_count": 1, "owner": {"user_id": 5003970, "profile_image": "https://www.gravatar.com/avatar/f644389a1ef05582c6b26343c2aa48f8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/5003970/midhun-mathew-sunny", "accept_rate": 65, "display_name": "Midhun Mathew Sunny"}, "creation_date": 1478882716, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 40552523}{"body": "<p>I have created a Haproxy setting in Marathon-lb like :</p>\n\n<pre><code>\"HAPROXY_0_FRONTEND_HEAD\":\"\\nfrontend central-rmq\\n  bind *:8081\\n  mode tcp\\n\"\n</code></pre>\n\n<p>For this, i want to create a acl rule like :</p>\n\n<pre><code>acl host_{cleanedUpHostname} path_beg /centralrmq\\n use_backend {backend} if host_{cleanedUpHostname}\\n\"\n</code></pre>\n\n<p>But i am not able to find any parameter for this. Only available option is <strong>HAPROXY_HTTP_FRONTEND_ACL</strong>, which will not work in my case.</p>\n\n<p>Is there any way to attach this acl (without using <strong>HAPROXY_HTTP_FRONTEND_HEAD</strong>) ?</p>\n", "is_answered": false, "tags": ["haproxy", "marathon", "dcos"], "title": "ACL rule for Haproxy frontend in Marathon-LB", "last_activity_date": 1501778900, "answer_count": 0, "creation_date": 1501778900, "score": 0, "link": "https://stackoverflow.com/questions/45490262/acl-rule-for-haproxy-frontend-in-marathon-lb", "owner": {"user_id": 2342287, "profile_image": "https://www.gravatar.com/avatar/d27331309193685631c8eafe2348d961?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3, "link": "https://stackoverflow.com/users/2342287/vivek-kumar", "display_name": "Vivek Kumar"}, "view_count": 19, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45490262}{"body": "<p>I am wondering if Mesos or K8s can offer resources from multiple network interfaces?\nI would like to attach multiple Network Interfaces (public eth0, private eth1) on mesos (or K8s) slave nodes and would like to bind specific applications that I run on Mesos's slave nodes on specific interfaces?\ndoes not mesos Or K8s need distinct physical networks like OpenStack has four distinct physical networks??\nis there any reference guide or doc?</p>\n", "is_answered": true, "tags": ["kubernetes", "mesos", "mesosphere"], "last_edit_date": 1467920035, "title": "Support public and private networks on Mesos or Kubernetes?", "last_activity_date": 1467920035, "answer_count": 1, "creation_date": 1467605562, "score": 1, "link": "https://stackoverflow.com/questions/38176856/support-public-and-private-networks-on-mesos-or-kubernetes", "answers": [{"body": "<p>On Kubernetes, there is not a fully supported way to do this.   I think this is not supported by docker either (<a href=\"https://github.com/docker/docker/issues/1824\" rel=\"nofollow\">https://github.com/docker/docker/issues/1824</a>)  </p>\n\n<p>As a work around, you could sort of do it this way:</p>\n\n<ul>\n<li><p>have one interface be the \"default network interface\" for pods.  It is the one you configure Kubelet and docker to use.  Most of your pods use this one. They get a PodIP.</p></li>\n<li><p>For \"special\" pods that need access to the other interface, or to both, use the \"hostNet: true\" parameter on those pods, and Kubernetes will not put the pod in a network container.  These pods</p>\n\n<ul>\n<li>can bind to either interface. </li>\n<li>will not get a \"podIP\", but use the IPs of whichever interface they use.</li>\n<li>you will have to manage port conflicts yourself.  You may want to use DaemonSet for these pods.</li>\n<li>you won't get any NetworkPolicy protection between pods with <code>hostNet</code>.</li>\n<li>all the pods on the same node with <code>hostNet</code> will be able to talk to each other on localhost, so you get less isolation.</li>\n</ul></li>\n</ul>\n\n<p>This workaround is good if only one or a few applications need \"non-default\" networking, and those apps are \"system applications\", managed by the same team that manages the cluster, rather than by a \"less trusted\" application team.  Or if you have a small organization with only a few people running the Kubernetes cluster.</p>\n", "answer_id": 38250377, "last_activity_date": 1467907763, "creation_date": 1467907763, "score": 1, "owner": {"user_id": 4215254, "profile_image": "https://lh3.googleusercontent.com/-qImNt9WhVK4/AAAAAAAAAAI/AAAAAAAAAHs/gQPWlTrkinQ/photo.jpg?sz=128", "user_type": "registered", "reputation": 1222, "link": "https://stackoverflow.com/users/4215254/eric-tune", "display_name": "Eric Tune"}, "is_accepted": false, "question_id": 38176856}], "owner": {"user_id": 6545636, "profile_image": "https://www.gravatar.com/avatar/712dd4f0adfd2e7401bcfe3fc023f0ab?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6545636/angrytony", "display_name": "AngryTony"}, "view_count": 71, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38176856}{"is_answered": true, "tags": ["mesosphere"], "title": "Mesosphere installation PermissionError:/genconf/config.yaml", "last_activity_date": 1479107381, "answer_count": 3, "creation_date": 1460711401, "score": 4, "link": "https://stackoverflow.com/questions/36642909/mesosphere-installation-permissionerror-genconf-config-yaml", "owner": {"user_id": 6208258, "profile_image": "https://www.gravatar.com/avatar/032a28a7609b67a637c17f2e591b6235?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/6208258/sun-zhe", "display_name": "Sun.zhe"}, "view_count": 1092, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 36642909}{"body": "<p>I have create a cluster on Azure container service with the DC/OS orchestrator and the following characteristics.</p>\n\n<pre><code>   {\n    \"agentPoolProfiles\": [\n      {\n        \"count\": 2,\n        \"dnsPrefix\": \"XXXagents\",\n        \"fqdn\": \"XXXagents.westeurope.cloudapp.azure.com\",\n        \"name\": \"agentpools\",\n        \"vmSize\": \"Standard_D2_v2\"\n      }\n    ],\n    \"customProfile\": null,\n    \"diagnosticsProfile\": {\n      \"vmDiagnostics\": {\n        \"enabled\": true,\n        \"storageUri\": \"https://5ygr5x3zcagpkdiag0.blob.core.windows.net/\"\n      }\n    },\n    \"id\": \"/subscriptions/092d03c2-6d61-451b-9970-9edaaec1e45c/resourceGroups/XXX/providers/Microsoft.ContainerService/containerServices/findmecontainer\",\n    \"linuxProfile\": {\n      \"adminUsername\": \"stijn\",\n      \"ssh\": {\n        \"publicKeys\": [\n          {\n            \"keyData\": \"XXX\"\n          }\n        ]\n      }\n    },\n    \"location\": \"westeurope\",\n    \"masterProfile\": {\n      \"count\": 1,\n      \"dnsPrefix\": \"XXXmgmt\",\n      \"fqdn\": \"XXXmgmt.westeurope.cloudapp.azure.com\"\n    },\n    \"name\": \"XXX\",\n    \"orchestratorProfile\": {\n      \"orchestratorType\": \"DCOS\"\n    },\n    \"provisioningState\": \"Succeeded\",\n    \"resourceGroup\": \"XXX\",\n    \"servicePrincipalProfile\": null,\n    \"tags\": null,\n    \"type\": \"Microsoft.ContainerService/ContainerServices\",\n    \"windowsProfile\": null\n  }\n</code></pre>\n\n<p>I have installed zeppelin 0.7.O with Spark 2.1.0  in line with <a href=\"https://github.com/jshenguru/dcos-zeppelin\" rel=\"nofollow noreferrer\">https://github.com/jshenguru/dcos-zeppelin</a>. Where I set the following values options file (zeppelin-0.7.0.json):</p>\n\n<pre><code>    {\n  \"volumes\": null,\n  \"id\": \"/zeppelin\",\n  \"cmd\": \"sed \\\"s#&lt;value&gt;8080&lt;/value&gt;#&lt;value&gt;$PORT0&lt;/value&gt;#\\\" &lt; conf/zeppelin-site.xml.template &gt; conf/zeppelin-site.xml &amp;&amp; sed -i \\\"s#&lt;value&gt;-1&lt;/value&gt;#&lt;value&gt;$PORT1&lt;/value&gt;#\\\" conf/zeppelin-site.xml &amp;&amp; SPARK_HOME_TGZ=$(ls ${MESOS_SANDBOX}/spark-*.tgz) SPARK_HOME=${SPARK_HOME_TGZ%.tgz} bin/zeppelin.sh start\",\n  \"args\": null,\n  \"user\": null,\n  \"env\": {\n    \"SPARK_MESOS_EXECUTOR_DOCKER_IMAGE\": \"mesosphere/spark:1.0.7-2.1.0-hadoop-2.7\",\n    \"SPARK_CORES_MAX\": \"16\",\n    \"SPARK_EXECUTOR_MEMORY\": \"20g\",\n    \"ZEPPELIN_JAVA_OPTS\": \"-Dspark.mesos.coarse=true -Dspark.mesos.executor.home=/opt/spark/dist\",\n    \"ZEPPELIN_INTP_JAVA_OPTS\": \"-Dspark.mesos.coarse=true -Dspark.mesos.executor.home=/opt/spark/dist\"\n  },\n  \"instances\": 2,\n  \"cpus\": 2,\n  \"mem\": 4000,\n  \"disk\": 30000,\n  \"gpus\": 0,\n  \"executor\": null,\n  \"constraints\": null,\n  \"fetch\": [\n    {\n      \"uri\": \"https://downloads.mesosphere.io/spark/assets/spark-2.1.0-bin-2.7.tgz\"\n    }\n  ],\n  \"storeUrls\": null,\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"jshenguru/dcos-zeppelin:0.7.0\",\n      \"forcePullImage\": false,\n      \"privileged\": false,\n      \"network\": \"HOST\"\n    }\n  },\n...\n}\n</code></pre>\n\n<p>When I run a notebook in zeppelin, there is hardly any CPU used to execute the Py(Spark) job (see image in appendix)</p>\n\n<p><a href=\"https://i.stack.imgur.com/DaxSK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DaxSK.png\" alt=\"enter image description here\"></a>. </p>\n\n<p>Could anybody explain whqg the problem could be? </p>\n", "is_answered": false, "tags": ["azure", "apache-zeppelin", "pyspark-sql", "dcos", "azure-container-service"], "title": "No CPU allocated to a PySpark Job in Zeppelin on Azure Container Service with DC/OS orchestrator", "last_activity_date": 1496085348, "answer_count": 0, "creation_date": 1496085348, "score": 1, "link": "https://stackoverflow.com/questions/44249182/no-cpu-allocated-to-a-pyspark-job-in-zeppelin-on-azure-container-service-with-dc", "owner": {"user_id": 6583277, "profile_image": "https://graph.facebook.com/10207983117909571/picture?type=large", "user_type": "registered", "reputation": 96, "link": "https://stackoverflow.com/users/6583277/stijn", "accept_rate": 45, "display_name": "Stijn"}, "view_count": 21, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44249182}{"is_answered": false, "tags": ["github", "mesos", "http-error", "dcos"], "title": "Http error 406 after adding my own universe repo in DCOS", "last_activity_date": 1485483412, "answer_count": 0, "creation_date": 1485192213, "score": 0, "link": "https://stackoverflow.com/questions/41812065/http-error-406-after-adding-my-own-universe-repo-in-dcos", "owner": {"user_id": 3358927, "profile_image": "https://www.gravatar.com/avatar/1d55888f9dce36510f6f0e8e2a9a0a5e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 427, "link": "https://stackoverflow.com/users/3358927/ddd", "accept_rate": 90, "display_name": "ddd"}, "view_count": 41, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41812065}{"body": "<p>I have a 200 node mesos cluster that can run around 2700 executors concurrently. Around 10-20% of my executors are LOST at the very beginning. They go only until extracting the executor tar file. </p>\n\n<pre><code>    WARNING: Logging before InitGoogleLogging() is written to STDERR\n    I0617 21:35:09.947180 45885 fetcher.cpp:76] Fetching URI 'http://download_url/remote_executor.tgz'\n    I0617 21:35:09.947273 45885 fetcher.cpp:126] Downloading 'http://download_url/remote_executor.tgz' to '/mesos_dir/remote_executor.tgz' \n    I0617 21:35:57.551722 45885 fetcher.cpp:64] Extracted resource '/mesos_dir/remote_executor.tgz' into '/extracting_mesos_dir/'\n</code></pre>\n\n<p>My executor tar ball is pretty large (around 40 MB or so) and most of the executors that take 30+ secs to download get LOST. Does mesos master wait for all executors until a certain time period to register and marks them LOST if the executors fail to do that?</p>\n\n<p>Executor details:</p>\n\n<p>I am using python to implement both the scheduler and executor. The executor code is a python file that extends base class 'Executor'. I have implemented the launchTasks method of Executor class that simply does what the executor is supposed to do.</p>\n\n<p>The executor info is: </p>\n\n<pre><code>    executor = mesos_pb2.ExecutorInfo()\n    executor.executor_id.value = \"executor-%s\" % (str(task_id),)\n    executor.command.value = 'python -m myexecutor'\n\n    # where to download executor from\n    tar_uri = '%s/remote_executor.tgz' % (\n        self.conf.remote_executor_cache_url)\n    executor.command.uris.add().value = tar_uri\n    executor.name = 'some_executor_name'\n    executor.source = \"executor_test\"\n</code></pre>\n", "is_answered": true, "title": "Is there a timeout for an executor to register with Mesos master?", "tags": ["distributed-computing", "distributed-system", "mesos", "mesosphere"], "last_activity_date": 1435644571, "accepted_answer_id": 31130815, "creation_date": 1435597501, "answers": [{"body": "<p>The default timeout for an executor with an slave is 1 minute and can be changed with the <code>--executor_registration_timeout</code> slave flag.</p>\n\n<p>From <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow\">Mesos Configuration</a></p>\n\n<blockquote>\n  <p>--executor_registration_timeout=VALUE Amount of time to wait for an executor to register with the slave before considering it hung and shutting it down (e.g., 60secs, 3mins, etc) (default: 1mins)</p>\n</blockquote>\n", "answer_id": 31130815, "last_activity_date": 1435644571, "creation_date": 1435644571, "score": 2, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "question_id": 31121506}], "score": 1, "link": "https://stackoverflow.com/questions/31121506/is-there-a-timeout-for-an-executor-to-register-with-mesos-master", "answer_count": 1, "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 674, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31121506}{"body": "<p>I want to configure mesos agent with connection pool as custom resource with 10 connections.\nAfter this, I assume connection will be a part of Mesos Offer. I also understand that Mesos does not take care of isolation of custom resources.</p>\n\n<p>My questions are</p>\n\n<ol>\n<li><p>I am offered 1 connection along with other resources. If I accept the offer, will that reduce connection count to 9 for that slave. \n   Will number of connections will be 10 again only after running task is finished/killed ? </p></li>\n<li><p>I am offered 1 connection along with other resources. I accepted the offer and in TaskInfo I did not add connection as resource. \n   Will that still make my connections reduce by 1 or number of connections will be same ?</p></li>\n</ol>\n", "is_answered": true, "title": "How custom resources are handled by Apache Mesos?", "tags": ["mesos", "mesosphere"], "last_activity_date": 1489875165, "accepted_answer_id": 42880505, "creation_date": 1489746570, "answers": [{"body": "<ol>\n<li>Yes it will be reduced but only if you specify connections as a scalar. </li>\n<li>If you don't explicitly declare resources nothing will be subtracted. </li>\n</ol>\n\n<p>Take a look at <a href=\"http://mesos.apache.org/documentation/latest/attributes-resources/\" rel=\"nofollow noreferrer\">attributes-resources docs</a></p>\n", "answer_id": 42880505, "last_activity_date": 1489875165, "creation_date": 1489875165, "score": 0, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 42855099}], "score": 0, "link": "https://stackoverflow.com/questions/42855099/how-custom-resources-are-handled-by-apache-mesos", "answer_count": 1, "owner": {"user_id": 1266150, "profile_image": "https://www.gravatar.com/avatar/7732616c0735b113af792c141346dafc?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 63, "link": "https://stackoverflow.com/users/1266150/amar-gajbhiye", "accept_rate": 75, "display_name": "Amar Gajbhiye"}, "view_count": 52, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42855099}{"body": "<p>When I install a docker tomcat container using docker I can see it is assigned an ip etc. However when I use  marathon/mesos to deploy and run a docker container I see is is not assigned an ip. I ran the docker inspect in both the cases and found this difference. Can someone comment why is this difference?</p>\n", "is_answered": true, "title": "Difference b/w installing docker container using docker vs using marathon mesos", "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_activity_date": 1423565720, "accepted_answer_id": 28429885, "creation_date": 1423543444, "answers": [{"body": "<p>By default Mesos/Marathon use docker's Host networking mode, so that all container ports are directly exposed on the host's ports on the host IP. You can use Bridge networking mode so that the container has its own IP and you have to manually specify which container ports to forward to which host ports. See the \"Bridged Networking Mode\" section in <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/native-docker.html</a></p>\n", "answer_id": 28429885, "last_activity_date": 1423565720, "creation_date": 1423565720, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 28424292}], "score": 1, "link": "https://stackoverflow.com/questions/28424292/difference-b-w-installing-docker-container-using-docker-vs-using-marathon-mesos", "answer_count": 1, "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 650, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28424292}{"body": "<p>I have been prototyping Spark Streaming <code>1.6.1</code> using kafka receiver on a Mesos <code>0.28</code> cluster running with Coarse grained mode.</p>\n\n<p>I have 6 mesos slaves each with <code>64GB RAM and 16 Cores</code>.<br>\nMy kafka topic has 3 partitions.<br>\nMy goal is to launch 3 executors in all (each on a different mesos slave) with each executor having one kafka receiver reading from one kafka partition. </p>\n\n<p>When I launch my spark application with <code>spark.cores.max</code> set to 24 and <code>spark.executor.memory</code> set to 8GB, I get two executors - with 16 cores on one slave and with 8 cores on another slave.  </p>\n\n<p>I am looking to get 3 executors with 8 cores each on three different slaves. Is that possible with mesos through resource reservation / isolation, constraints etc. ? </p>\n\n<p>Only workaround that works for me now is to scale down each mesos slave node to only have 8 cores max. I don't want to use mesos in fine-grained mode for performance reasons and plus its support is going away soon.</p>\n", "is_answered": true, "title": "Spark Streaming through Kafka receiver on Coarse Grain Mesos cluster", "tags": ["apache-spark", "spark-streaming", "mesos", "mesosphere"], "last_activity_date": 1461480979, "accepted_answer_id": 36820208, "creation_date": 1461448542, "answers": [{"body": "<p>Mesosphere has contributed the following patch to Spark: <a href=\"https://github.com/apache/spark/commit/80cb963ad963e26c3a7f8388bdd4ffd5e99aad1a\" rel=\"nofollow\">https://github.com/apache/spark/commit/80cb963ad963e26c3a7f8388bdd4ffd5e99aad1a</a>. This improvement will land in Spark 2.0. Mesosphere has backported this and other improvements to Spark 1.6.1 and made it available in DC/OS (<a href=\"http://dcos.io\" rel=\"nofollow\">http://dcos.io</a>).</p>\n\n<p>This patch introduces a new \"spark.executor.cores\" config variable in course gain mode. When the \"spark.executor.cores\" config variable is set, executors will be sized with the specified number of cores.</p>\n\n<p>If an offer arrives with a multiple of (spark.executor.memory, spark.executor.cores), multiple executors will be launched on that offer. This means there could be multiple, but seperate, Spark executors running on the same Mesos agent node.</p>\n\n<p>There is no way (currently) to spread the executors across N Mesos agents. We briefly discussed adding the ability to spread Spark executors across N Mesos agents but concluded it doesn't buy much in terms of improved availability.</p>\n\n<p>Can you help us understand your motivations for spreading Spark executors across 3 Mesos agents? It's likely we haven't considered all possibly use cases and advantages.</p>\n\n<p>Keith</p>\n", "answer_id": 36820208, "last_activity_date": 1461480979, "creation_date": 1461480979, "score": 4, "owner": {"user_id": 6246622, "profile_image": "https://www.gravatar.com/avatar/7e4d8347cba31effd96865efb2cd4f59?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/6246622/keith-chambers", "display_name": "Keith Chambers"}, "is_accepted": true, "question_id": 36816913}], "score": 4, "link": "https://stackoverflow.com/questions/36816913/spark-streaming-through-kafka-receiver-on-coarse-grain-mesos-cluster", "answer_count": 1, "owner": {"user_id": 288621, "profile_image": "https://www.gravatar.com/avatar/51a8f83aa9c6ccd33efbf2948f2c83e6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/288621/rohit", "display_name": "rohit"}, "view_count": 172, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36816913}{"body": "<p>I am trying to run a service using DC/OS and Docker. I created my Stack using the template for my region from <a href=\"https://downloads.dcos.io/dcos/stable/aws.html?_ga=2.172601514.849625456.1502340930-419559210.1502340930\" rel=\"noreferrer\">here</a>. I also created the following Dockerfile:</p>\n\n<pre><code>FROM ubuntu:16.04\nRUN apt-get update &amp;&amp; apt-get install -y expect openssh-client\n\nWORKDIR \"/root\"\nENTRYPOINT eval \"$(ssh-agent -s)\" &amp;&amp; \\\n           mkdir -p .ssh &amp;&amp; \\\n           echo $PRIVATE_KEY &gt; .ssh/id_rsa &amp;&amp; \\\n           chmod 600 /root/.ssh/id_rsa &amp;&amp; \\\n           expect -c \"spawn ssh-add /root/.ssh/id_rsa; expect \\\"Enter passphrase for /root/.ssh/id_rsa:\\\" send \\\"\\\"; interact \" &amp;&amp; \\\n           while true; do ssh-add -l; sleep 2; done\n</code></pre>\n\n<p>I have a private repository that I would like to clone/pull from when the docker container starts. This is why I am trying to add the private key to the <code>ssh-agent</code>.</p>\n\n<p>If I run this image as a docker container locally and supply the private key using the <code>PRIVATE_KEY</code> environment variable, everything works fine. I see that the identity is added.</p>\n\n<p>The problem that I have is that when I try to run a service on DC/OS using the docker image, the <code>ssh-agent</code> does not seem to remember the identity that was added using the private key.</p>\n\n<p>I have checked the error log from DC/OS. There are no errors.</p>\n\n<p>Does anyone know why running the docker container on DC/OS is any different compared to running it locally?</p>\n\n<p><strong>EDIT:</strong> I have added details of the description of the DC/OS service in case it helps:</p>\n\n<pre><code>{\n \"id\": \"/SOME-ID\",\n \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 0,\n  \"gpus\": 0,\n  \"constraints\": [],\n  \"fetch\": [],\n  \"storeUrls\": [],\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": {\n                \"type\": \"DOCKER\",\n                \"volumes\": [],\n                \"docker\": {\n                \"image\": \"IMAGE NAME FROM DOCKERHUB\",\n                \"network\": \"BRIDGE\",\n                \"portMappings\": [{\n                                  \"containerPort\": SOME PORT NUMBER,\n                                  \"hostPort\": SOME PORT NUMBER,\n                                  \"servicePort\": SERVICE PORT NUMBER,\n                                  \"protocol\": \"tcp\",\n                                  \"name\": \u201cdefault\u201d\n                                 }],\n                \"privileged\": false,\n                \"parameters\": [],\n                \"forcePullImage\": true\n               }\n  },\n  \"healthChecks\": [],\n  \"readinessChecks\": [],\n  \"dependencies\": [],\n  \"upgradeStrategy\": {\n                      \"minimumHealthCapacity\": 1,\n                      \"maximumOverCapacity\": 1\n                     },\n  \"unreachableStrategy\": {\n                          \"inactiveAfterSeconds\": 300,\n                          \"expungeAfterSeconds\": 600\n                         },\n  \"killSelection\": \"YOUNGEST_FIRST\",\n  \"requirePorts\": true,\n  \"env\": {\n          \"PRIVATE_KEY\": \"ID_RSA PRIVATE_KEY WITH \\n LINE BREAKS\",\n         }\n  }\n</code></pre>\n", "is_answered": true, "title": "ssh-agent does not remember identities when running inside a docker container in DC/OS", "last_edit_date": 1503086597, "tags": ["docker", "ssh-keys", "dcos"], "view_count": 196, "accepted_answer_id": 46065384, "last_activity_date": 1504664520, "answers": [{"body": "<p>The key file contents being passed via <code>PRIVATE_KEY</code> originally contain line breaks. After echoing the <code>PRIVATE_KEY</code> variable content to <code>~/.ssh/id_rsa</code> the line breaks will be gone. You can fix that issue by wrapping the <code>$PRIVATE_KEY</code> variable with double quotes.</p>\n\n<p>Another issue arises when the container is started without attached TTY, typically via <code>-i -t</code> command line parameters to <code>docker run</code>. The password request will fail and won't add the ssh key to the ssh-agent. For the container being run in DC/OS, the interaction probably won't make sense, so you should change your entrypoint script accordingly. That will require your ssh key to be passwordless.</p>\n\n<p>This changed Dockerfile should work:</p>\n\n<pre><code>ENTRYPOINT eval \"$(ssh-agent -s)\" &amp;&amp; \\\n           mkdir -p .ssh &amp;&amp; \\\n           echo \"$PRIVATE_KEY\" &gt; .ssh/id_rsa &amp;&amp; \\\n           chmod 600 /root/.ssh/id_rsa &amp;&amp; \\\n           ssh-add /root/.ssh/id_rsa &amp;&amp; \\\n           while true; do ssh-add -l; sleep 2; done\n</code></pre>\n", "answer_id": 45745680, "last_activity_date": 1503181600, "creation_date": 1503007863, "score": 0, "owner": {"user_id": 372019, "profile_image": "https://www.gravatar.com/avatar/c48b19be51d176cb054dde6e64cfc561?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1061, "link": "https://stackoverflow.com/users/372019/gesellix", "display_name": "gesellix"}, "is_accepted": false, "last_edit_date": 1503181600, "question_id": 45604968}, {"body": "<h2>Docker Version</h2>\n\n<p>Check that your local version of Docker matches the version installed on the DC/OS agents. By default, the DC/OS 1.9.3 AWS CloudFormation templates uses <a href=\"https://coreos.com/releases/#1235.12.0\" rel=\"nofollow noreferrer\">CoreOS 1235.12.0</a>, which comes with <a href=\"https://github.com/moby/moby/releases/tag/v1.12.6\" rel=\"nofollow noreferrer\">Docker 1.12.6</a>. It's possible that the entrypoint behavior has changed since then.</p>\n\n<h2>Docker Command</h2>\n\n<p>Check the Mesos task logs for the Marathon app in question and see what docker run command was executed. You might be passing it slightly different arguments when testing locally.</p>\n\n<h2>Script Errors</h2>\n\n<p>As mentioned in another answer, the script you provided has several errors that may or may not be related to the failure.</p>\n\n<ol>\n<li><code>echo $PRIVATE_KEY</code> should be <code>echo \"$PRIVATE_KEY\"</code> to preserve line breaks. Otherwise key decryption will fail with <code>Bad passphrase, try again for /root/.ssh/id_rsa:</code>.</li>\n<li><code>expect -c \"spawn ssh-add /root/.ssh/id_rsa; expect \\\"Enter passphrase for /root/.ssh/id_rsa:\\\" send \\\"\\\"; interact \"</code> should be <code>expect -c \"spawn ssh-add /root/.ssh/id_rsa; expect \\\"Enter passphrase for /root/.ssh/id_rsa:\\\"; send \\\"\\n\\\"; interact \"</code>. It's missing a semi-colon and a line break. Otherwise the expect command fails without executing. </li>\n</ol>\n\n<h2>File Based Secrets</h2>\n\n<p>Enterprise DC/OS 1.10 (1.10.0-rc1 out now) has a new feature named File Based Secrets which allows for injecting files (like id_rsa files) without including their contents in the Marathon app definition, storing them securely in <a href=\"https://www.vaultproject.io/\" rel=\"nofollow noreferrer\">Vault</a> using <a href=\"https://docs.mesosphere.com/1.10/security/secrets/\" rel=\"nofollow noreferrer\">DC/OS Secrets</a>.</p>\n\n<ul>\n<li>Creation: <a href=\"https://docs.mesosphere.com/1.10/security/secrets/create-secrets/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.10/security/secrets/create-secrets/</a></li>\n<li>Usage: <a href=\"https://docs.mesosphere.com/1.10/security/secrets/use-secrets/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.10/security/secrets/use-secrets/</a></li>\n</ul>\n\n<p>File based secrets wont do the ssh-add for you, but it should make it easier and more secure to get the file into the container.</p>\n\n<h2>Mesos Bug</h2>\n\n<p>Mesos 1.2.0 switched to using Docker --env_file instead of -e to pass in environment variables. This triggers a <a href=\"https://github.com/moby/moby/issues/12997\" rel=\"nofollow noreferrer\">Docker env_file bug</a> that it doesn't support line breaks. A <a href=\"https://jira.mesosphere.com/browse/DCOS_OSS-793\" rel=\"nofollow noreferrer\">workaround was put into Mesos and DC/OS</a>, but the fix may not be in the minor version you are using.</p>\n\n<p>A manual workaround is to convert the rsa_id to base64 for the Marathon definition and back in your entrypoint script. </p>\n", "answer_id": 46065384, "last_activity_date": 1504664520, "creation_date": 1504660714, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "last_edit_date": 1504664520, "question_id": 45604968}], "score": 9, "link": "https://stackoverflow.com/questions/45604968/ssh-agent-does-not-remember-identities-when-running-inside-a-docker-container-in", "answer_count": 2, "owner": {"user_id": 4917583, "profile_image": "https://i.stack.imgur.com/83lch.jpg?s=128&g=1", "user_type": "registered", "reputation": 360, "link": "https://stackoverflow.com/users/4917583/siavashk", "accept_rate": 100, "display_name": "siavashk"}, "creation_date": 1502342004, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45604968}{"is_answered": true, "tags": ["digital-ocean", "apache-flink", "dcos"], "title": "Error installing Flink in DCOS", "last_activity_date": 1501437125, "answer_count": 1, "creation_date": 1501348645, "score": 3, "link": "https://stackoverflow.com/questions/45391980/error-installing-flink-in-dcos", "owner": {"user_id": 5314214, "profile_image": "https://lh4.googleusercontent.com/-6GDfPZnUjLg/AAAAAAAAAAI/AAAAAAAAAEE/7shbkutOcvM/photo.jpg?sz=128", "user_type": "registered", "reputation": 169, "link": "https://stackoverflow.com/users/5314214/beckham", "accept_rate": 89, "display_name": "Beckham"}, "view_count": 65, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45391980}{"body": "<p>We have a spring boot application deployed in a docker container and managed using mesosphere (marathon + mesos). The spring boot app is intended to be deployed via marathon, and once complete, it will exit with code = 0.</p>\n\n<p>Currently, every time the boot application terminates, marathon redeploys the app again, which I wish to disable. Is there a setting that I can set in the application's marathon json config file that will prevent marathon from redeploying an app if it does not exit with a non-zero code?</p>\n", "is_answered": true, "title": "Marathon - do not redeploy app when return code = 0?", "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_activity_date": 1455649239, "accepted_answer_id": 35440876, "creation_date": 1455567225, "answers": [{"body": "<p>I think there's a principled problem in the understanding of what Marathon does: it is meant for long-running tasks (or put in other words: there's a <code>while</code> loop somewhere in there, maybe an implicit one). If your app exists, Marathon sees this and assumes it has failed and re-starts it again.</p>\n", "answer_id": 35427517, "last_activity_date": 1455611778, "creation_date": 1455611778, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 35418221}, {"body": "<p>If you just want to run one-time jobs, I think <a href=\"https://github.com/mesos/chronos\" rel=\"nofollow\">Chronos</a> would be the right tool. Marathon is, as Michael wrote, for long-running tasks.</p>\n", "answer_id": 35440876, "last_activity_date": 1455649239, "creation_date": 1455649239, "score": 2, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 35418221}], "score": 2, "link": "https://stackoverflow.com/questions/35418221/marathon-do-not-redeploy-app-when-return-code-0", "answer_count": 2, "owner": {"user_id": 582411, "profile_image": "https://www.gravatar.com/avatar/167b165d27b6ddf06944a81e55c392a2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1064, "link": "https://stackoverflow.com/users/582411/sayak-banerjee", "accept_rate": 73, "display_name": "Sayak Banerjee"}, "view_count": 154, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35418221}{"body": "<p>I'm working with some servers that have 32 cores in them (That's including hyperthreading).  However, when I look at the details for the framework for the node, I've seen several that report more than 32 allocated CPUs.  Why is that?</p>\n\n<p>Edit 1:</p>\n\n<p>Looking at one of the nodes, /proc/cpuinfo lists the correct number of CPUs.  The only framework registered with this node is Marathon and that's where I see the overallocation of CPUs (via the Mesos UI).  Mesos does report I have 32 CPUs.</p>\n", "is_answered": true, "title": "Why does mesos report more allocated CPUs than actual cores?", "last_edit_date": 1466772939, "tags": ["mesos", "mesosphere"], "view_count": 80, "accepted_answer_id": 38058632, "last_activity_date": 1467043815, "answers": [{"body": "<p>As <a href=\"https://github.com/apache/mesos/blob/d1b681f140fbae58001f96b4b4b8a4a0cadb6a6b/src/slave/slave.cpp#L3993-L4003\" rel=\"nofollow\">code comment says</a> it's possible to have more allocated CPUs then actually system has. Framework is accepting offer that need to fit into resources constraints but then slave add some non zero resources for executor. So same could happen with MEM.</p>\n\n<pre><code>// Default cpu resource given to a command executor.\nconstexpr double DEFAULT_EXECUTOR_CPUS = 0.1;\n// Default memory resource given to a command executor.\nconstexpr Bytes DEFAULT_EXECUTOR_MEM = Megabytes(32);\n...\n// Add an allowance for the command executor. This does lead to a\n// small overcommit of resources.\n// TODO(vinod): If a task is using revocable resources, mark the\n// corresponding executor resource (e.g., cpus) to be also\n// revocable. Currently, it is OK because the containerizer is\n// given task + executor resources on task launch resulting in\n// the container being correctly marked as revocable.\nexecutor.mutable_resources()-&gt;MergeFrom(\n    Resources::parse(\n      \"cpus:\" + stringify(DEFAULT_EXECUTOR_CPUS) + \";\" +\n      \"mem:\" + stringify(DEFAULT_EXECUTOR_MEM.megabytes())).get());\n</code></pre>\n\n<p>WebUI shows values taken from <code>master/metrics</code> endpoint and values there are calculated form Executor not just tasks.</p>\n", "answer_id": 38058632, "last_activity_date": 1467043815, "creation_date": 1467043815, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 38000750}], "score": 0, "link": "https://stackoverflow.com/questions/38000750/why-does-mesos-report-more-allocated-cpus-than-actual-cores", "answer_count": 1, "owner": {"user_id": 290541, "profile_image": "https://i.stack.imgur.com/92EyJ.jpg?s=128&g=1", "user_type": "registered", "reputation": 934, "link": "https://stackoverflow.com/users/290541/blockcipher", "accept_rate": 61, "display_name": "blockcipher"}, "creation_date": 1466711966, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38000750}{"body": "<p>There are a lot of examples of the <a href=\"http://bigdata-madesimple.com/smackspark-mesos-akka-kafka/\" rel=\"nofollow noreferrer\">SMACK stack</a>, but in my infrastructure I would like to use ElasticSearch and Confluent Kafka Connect and Kafka Streams.</p>\n\n<p>There is a <a href=\"https://blog.codecentric.de/en/2016/04/smack-stack-hands/\" rel=\"nofollow noreferrer\">great tutorial on deploying a CloudFormation-based SMACK stack environment</a> and another in <a href=\"https://dcos.io/docs/1.8/usage/tutorials/iot_pipeline/\" rel=\"nofollow noreferrer\">creating an IoT pipeline with SMACK</a> as well.</p>\n\n<p>Since I am working on a <a href=\"http://lambda-architecture.net/\" rel=\"nofollow noreferrer\">Lambda architecture</a>, I am first starting with my batch data using ElasticSearch (not Cassandra) and would like to know if there are CloudFormation templates that use Kafka Connect, ElasticSearch.  Eventually we want to use Kafka Streams with InfluxDB?</p>\n", "is_answered": false, "tags": ["elasticsearch", "amazon-cloudformation", "dcos", "apache-kafka-streams", "apache-kafka-connect"], "last_edit_date": 1485281656, "title": "Is there a CloudFormation template for DC/OS, ElasticSearch, Kafka Connect and Kafka Streams?", "last_activity_date": 1485482329, "answer_count": 1, "creation_date": 1485273287, "score": -3, "link": "https://stackoverflow.com/questions/41832562/is-there-a-cloudformation-template-for-dc-os-elasticsearch-kafka-connect-and-k", "answers": [{"body": "<p>DC/OS has AWS <a href=\"https://downloads.dcos.io/dcos/stable/aws.html\" rel=\"nofollow noreferrer\">CloudFormation templates</a> and <a href=\"https://dcos.io/docs/1.8/administration/installing/cloud/aws/\" rel=\"nofollow noreferrer\">install instructions</a>. Once you have DC/OS installed you can install ElasticSearch and Kafka from the Mesosphere Universe as DC/OS packages.</p>\n", "answer_id": 41886030, "last_activity_date": 1485482329, "creation_date": 1485482329, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 41832562}], "owner": {"user_id": 172359, "profile_image": "https://www.gravatar.com/avatar/5e175feb0a9092abd02950f4973d376a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6610, "link": "https://stackoverflow.com/users/172359/elhaix", "accept_rate": 93, "display_name": "ElHaix"}, "view_count": 146, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41832562}{"body": "<p>Given that I have only one machine(high configuration laptop), can I run the entire DCOS on my laptop (for purely simulation/learning purpose). The way I was thinking to set this up was using some N number of docker containers (with networking enabled between them), where some of those from N would be masters, some slaves, one zookeeper maybe, and 1 container to run the scheduler/application. So basically the 1 docker container would be synonymous to a machine instance in this case. (since I don't have multiple machines and using multiple VMs on one machine would be an overkill) </p>\n\n<p>Has this been already done, so that I can straight try it out or am I completely missing something here with regards to understanding?</p>\n", "is_answered": true, "title": "DC/OS on top of a docker container cluster", "last_edit_date": 1461825730, "tags": ["docker", "cluster-computing", "mesos", "mesosphere", "dcos"], "view_count": 230, "accepted_answer_id": 36907393, "last_activity_date": 1461858130, "answers": [{"body": "<p>We're running such a development configuration where ZooKeeper, Mesos Masters and Slaves as well as Marathon runs fully dockerized (but on 3 bare metal machine cluster) on CoreOS latest stable. It has some known downsides, like when a slave dies the running tasks cannot be recovered AFAIK by the restarted slave.</p>\n\n<p>I think it also depends on the OS what you're running on your laptop. If it's non-Windows, you should normally be fine. If your system supports <code>systemd</code>, then you can have a look at <a href=\"https://github.com/tobilg/coreos-setup\" rel=\"nofollow\">tobilg/coreos-setup</a> to see how I start the Mesos services via Docker.</p>\n\n<p>Still, I would recommend to use a Vagrant/VirtualBox solution if you just want to test how Mesos works/\"feels\"... Those will probably save you some headaches compared to a \"from scratch\" solution. The <a href=\"https://github.com/tobilg/coreos-mesos-cluster\" rel=\"nofollow\">tobilg/coreos-mesos-cluster</a> project runs the services via Docker on CoreOS within Vagrant.</p>\n\n<p>Also, you can have a look at <a href=\"https://github.com/dharmeshkakadia/awesome-mesos\" rel=\"nofollow\">dharmeshkakadia/awesome-mesos</a> and especially the <a href=\"https://github.com/dharmeshkakadia/awesome-mesos#vagrant-based-setups\" rel=\"nofollow\">Vagrant based setup section</a> to get some references.</p>\n", "answer_id": 36907393, "last_activity_date": 1461828323, "creation_date": 1461826586, "score": 2, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "last_edit_date": 1461828323, "question_id": 36907027}, {"body": "<p>Have a look at <a href=\"https://github.com/dcos/dcos-docker\" rel=\"nofollow\">https://github.com/dcos/dcos-docker</a> it is quite young but enables you to do exactly what you want.</p>\n\n<p>It starts a DC/OS cluster with masters and agents on a single node in docker containers.</p>\n", "answer_id": 36919434, "last_activity_date": 1461858130, "creation_date": 1461858130, "score": 2, "owner": {"user_id": 401357, "profile_image": "https://www.gravatar.com/avatar/7f9a4c3ea6976d40c06a522151a6377b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 299, "link": "https://stackoverflow.com/users/401357/seb", "display_name": "Seb"}, "is_accepted": false, "question_id": 36907027}], "score": 2, "link": "https://stackoverflow.com/questions/36907027/dc-os-on-top-of-a-docker-container-cluster", "answer_count": 2, "owner": {"user_id": 2686821, "profile_image": "https://www.gravatar.com/avatar/5dd46afe4f5a75f2667569582b20ac9b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 457, "link": "https://stackoverflow.com/users/2686821/soupybionics", "accept_rate": 54, "display_name": "soupybionics"}, "creation_date": 1461825351, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36907027}{"body": "<p>Before hand let me say that I'm new to Mesosphere stack. I am trying to migrate an existing Rails application deployment to Mesos and I'm successful so far, but currently I'm on the middle of running migrations and seeds (through Rake tasks) and I don't see a pretty way to get it done since those tasks are ephemeral and they don't match quite Marathon's idea. How should I proceed?</p>\n", "is_answered": true, "title": "Ephemeral tasks on Marathon", "last_edit_date": 1412904200, "tags": ["ruby-on-rails", "deployment", "mesosphere", "marathon"], "view_count": 545, "accepted_answer_id": 26647789, "last_activity_date": 1496087175, "answers": [{"body": "<p>You could also use <a href=\"https://github.com/mesosphere/chronos\" rel=\"nofollow\">Chronos</a> to run a task \"Now\" that is expected to complete at some point.</p>\n\n<p>Marathon is targeted at long-running services that should always keep running.</p>\n", "answer_id": 26647789, "last_activity_date": 1414656170, "creation_date": 1414656170, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 26237045}, {"body": "<p>Recent development has included the \"Job\" capability via Metronome (Chronos replacement) or you can also use <a href=\"https://github.com/klarna/eremetic\" rel=\"nofollow noreferrer\">Eremetic</a> framework for one-off tasks. </p>\n", "answer_id": 44249508, "last_activity_date": 1496087175, "creation_date": 1496087175, "score": 0, "owner": {"user_id": 2555634, "profile_image": "https://i.stack.imgur.com/i5eug.jpg?s=128&g=1", "user_type": "registered", "reputation": 89, "link": "https://stackoverflow.com/users/2555634/subodh-pachghare", "display_name": "Subodh Pachghare"}, "is_accepted": false, "question_id": 26237045}], "score": 1, "link": "https://stackoverflow.com/questions/26237045/ephemeral-tasks-on-marathon", "answer_count": 2, "owner": {"user_id": 829928, "profile_image": "https://www.gravatar.com/avatar/8f2a2dbbd68def108e07d81b32f1df53?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1334, "link": "https://stackoverflow.com/users/829928/carlos-castellanos", "accept_rate": 83, "display_name": "Carlos Castellanos"}, "creation_date": 1412688042, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 26237045}{"body": "<p>Is it possible to use DC/OS or Marathon to repeatedly check when a new container image update is available and update the live containers in the cluster? I'd like to avoid having Docker Hub be aware of the cluster and implementing web hooks... versus the cluster just check for image updates via a job.</p>\n", "is_answered": true, "tags": ["docker", "containers", "mesos", "marathon", "dcos"], "last_edit_date": 1475320532, "title": "DC/OS schedule container updates", "last_activity_date": 1475320532, "answer_count": 1, "creation_date": 1475264137, "score": 2, "link": "https://stackoverflow.com/questions/39798904/dc-os-schedule-container-updates", "answers": [{"body": "<p>Marathon doesn't do this. </p>\n\n<p>If you want polling, however, you could try using custom scheduled jobs with Metronome (built into DC/OS 1.8) or Chronos. Poll for dockerhub image updates and use the Marathon API to trigger app updates.</p>\n", "answer_id": 39799700, "last_activity_date": 1475267723, "creation_date": 1475267723, "score": 2, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 39798904}], "owner": {"user_id": 796219, "profile_image": "https://www.gravatar.com/avatar/dd2f4b41ea239513651096e8fb43ec1f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1705, "link": "https://stackoverflow.com/users/796219/jonathan-dunlap", "accept_rate": 67, "display_name": "Jonathan Dunlap"}, "view_count": 90, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39798904}{"body": "<p>I have installed HDFS from universe on my dcos cluster of 10 Core OS machines (3 master nodes, 7 agent nodes). My HA HDFS config has 2 name nodes, 3 journal nodes and 5 data nodes. In the long run, the agent nodes where HDFS is running - all of them, no matter if they are name nodes, journal nodes or data nodes - close their port 22, so I cannot ssh into them, whereas the nodes where  HDFS is not running keep their port 22 open. Any idea about why it happens or what I should look for to understand why it happens?</p>\n\n<p>Here are the logs after running nmap on the cluster agent nodes. Nodes 13 and 16 have no HDFS role and keep their 22 port open. All the other nodes having HDFS installed have port 22 closed.</p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>root@svr-17:/home/andreab# nmap svc-10.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:37 GMT\r\nNmap scan report for svc-10.dc01 (192.168.111.70)\r\nHost is up (0.00061s latency).\r\nNot shown: 997 closed ports\r\nPORT     STATE SERVICE\r\n5051/tcp open  ida-agent\r\n9000/tcp open  cslistener\r\n9003/tcp open  unknown\r\nMAC Address: 52:54:00:DE:8E:96 (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.72 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-11.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:38 GMT\r\nNmap scan report for svc-11.dc01 (192.168.111.71)\r\nHost is up (0.00084s latency).\r\nNot shown: 996 closed ports\r\nPORT     STATE SERVICE\r\n5051/tcp open  ida-agent\r\n9001/tcp open  tor-orport\r\n9002/tcp open  dynamid\r\n9003/tcp open  unknown\r\nMAC Address: 52:54:00:31:1A:E9 (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.70 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-12.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:38 GMT\r\nNmap scan report for svc-12.dc01 (192.168.111.72)\r\nHost is up (0.00082s latency).\r\nNot shown: 996 closed ports\r\nPORT     STATE SERVICE\r\n5051/tcp open  ida-agent\r\n9001/tcp open  tor-orport\r\n9002/tcp open  dynamid\r\n9003/tcp open  unknown\r\nMAC Address: 52:54:00:D9:B4:F7 (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.69 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-13.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:38 GMT\r\nNmap scan report for svc-13.dc01 (192.168.111.73)\r\nHost is up (0.00025s latency).\r\nNot shown: 998 closed ports\r\nPORT     STATE SERVICE\r\n22/tcp   open  ssh\r\n5051/tcp open  ida-agent\r\nMAC Address: 52:54:00:43:96:45 (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.69 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-14.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:38 GMT\r\nNmap scan report for svc-14.dc01 (192.168.111.74)\r\nHost is up (0.00029s latency).\r\nNot shown: 998 closed ports\r\nPORT     STATE SERVICE\r\n5051/tcp open  ida-agent\r\n9003/tcp open  unknown\r\nMAC Address: 52:54:00:77:9D:2E (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.70 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-15.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:39 GMT\r\nNmap scan report for svc-15.dc01 (192.168.111.75)\r\nHost is up (0.00020s latency).\r\nNot shown: 998 closed ports\r\nPORT     STATE SERVICE\r\n5051/tcp open  ida-agent\r\n9003/tcp open  unknown\r\nMAC Address: 52:54:00:B9:03:FA (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 23.51 seconds\r\n\r\n\r\n\r\nroot@svr-17:/home/andreab# nmap svc-16.dc01\r\n\r\nStarting Nmap 6.47 ( http://nmap.org ) at 2017-01-29 11:39 GMT\r\nNmap scan report for svc-16.dc01 (192.168.111.76)\r\nHost is up (0.00065s latency).\r\nNot shown: 998 closed ports\r\nPORT     STATE SERVICE\r\n22/tcp   open  ssh\r\n5051/tcp open  ida-agent\r\nMAC Address: 52:54:00:E8:D6:07 (QEMU Virtual NIC)\r\n\r\nNmap done: 1 IP address (1 host up) scanned in 1.72 seconds</code></pre>\r\n</div>\r\n</div>\r\n</p>\n", "is_answered": true, "title": "HDFS on DC/OS closes port 22. Cannot SSH on any of the HDFS nodes", "tags": ["hadoop", "ssh", "hdfs", "coreos", "dcos"], "last_activity_date": 1487150783, "accepted_answer_id": 42245334, "creation_date": 1485691163, "answers": [{"body": "<p>As mentioned in my answer to <a href=\"https://stackoverflow.com/questions/41943112/hdfs-resiliency-to-machine-restarts-in-dc-os/42245252#42245252\">HDFS resiliency to machine restarts in DC/OS</a>:</p>\n\n<p>problems were found in a buggy version of the universe HDFS package for DC/OS. A completely new HDFS package for DC/OS will be released on Universe in the next few weeks.</p>\n\n<p><a href=\"https://dcos-community.slack.com/archives/data-services/p1485717889001709\" rel=\"nofollow noreferrer\">https://dcos-community.slack.com/archives/data-services/p1485717889001709</a></p>\n\n<p><a href=\"https://dcos-community.slack.com/archives/data-services/p1485801481001734\" rel=\"nofollow noreferrer\">https://dcos-community.slack.com/archives/data-services/p1485801481001734</a></p>\n", "answer_id": 42245334, "last_activity_date": 1487150783, "creation_date": 1487150783, "score": 0, "owner": {"user_id": 7019448, "profile_image": "https://i.stack.imgur.com/zLZj2.png?s=128&g=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/7019448/andrea-t-bonanno", "accept_rate": 67, "display_name": "Andrea T. Bonanno"}, "is_accepted": true, "last_edit_date": 1495535378, "question_id": 41920641}], "score": 0, "link": "https://stackoverflow.com/questions/41920641/hdfs-on-dc-os-closes-port-22-cannot-ssh-on-any-of-the-hdfs-nodes", "answer_count": 1, "owner": {"user_id": 7019448, "profile_image": "https://i.stack.imgur.com/zLZj2.png?s=128&g=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/7019448/andrea-t-bonanno", "accept_rate": 67, "display_name": "Andrea T. Bonanno"}, "view_count": 45, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41920641}{"body": "<p>We need to capture Marathon Application events at various places in our application architecture (Nginx for generating conf files, UI updates in frontend  when a marathon app is restarting etc.) Presently, we are polling /v2/apps/{appID} endpoint to be aware of things. But I don't think that is the best approach to go.</p>\n\n<p>So far, I am planning to replace that with /v2/events stream or /v2/eventSubscriptions callback functionalities but I was kind of more inclined to fetch these updates from Zookeeper instead, to have a consistent and common source of such information in future. As of now, I am not really sure if Zookeeper has such event updates etc pushed into it by Marathon that could be subscribed. If yes, could you please direct me to appropriate documentation ? </p>\n", "is_answered": true, "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon"], "title": "Capture Marathon event notifications from Zookeeper", "last_activity_date": 1440681920, "answer_count": 1, "creation_date": 1440588550, "score": 1, "link": "https://stackoverflow.com/questions/32225424/capture-marathon-event-notifications-from-zookeeper", "answers": [{"body": "<p>The events are not stored in the persistent store (zookeeper). You can query the current state of all applications via the <code>/v2/apps</code> endpoint and then attach to the <code>/v2/events</code> stream endpoint to get notified about all changes to that state. See the <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html\" rel=\"nofollow\">REST API</a> Documentation.</p>\n", "answer_id": 32250649, "last_activity_date": 1440681920, "creation_date": 1440681920, "score": 1, "owner": {"user_id": 1171399, "profile_image": "https://www.gravatar.com/avatar/ec612689fde31f40f65b775a65c85867?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/1171399/m-v", "display_name": "m v"}, "is_accepted": false, "question_id": 32225424}], "owner": {"user_id": 2657830, "profile_image": "https://www.gravatar.com/avatar/d509ab1246e8e6fa5f39b03d1ebe0706?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 318, "link": "https://stackoverflow.com/users/2657830/akskap", "accept_rate": 0, "display_name": "akskap"}, "view_count": 206, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32225424}{"body": "<p>I'm using DCOS-kafka on Mesos and I cannot figure out how to update the number of partitions for a topic.  It seems that you can update the topic using</p>\n\n<pre><code>dcos kafka update [topic-name] [parameter]=[value]\n</code></pre>\n\n<p>Unfortunately, I can't figure out what the parameter for updating the number of partitions would be.  Is it even possible?</p>\n", "is_answered": false, "tags": ["apache-kafka", "mesos", "mesosphere", "marathon"], "title": "How to update the number of topic partitions on dcos-kafka?", "last_activity_date": 1452893726, "answer_count": 0, "creation_date": 1452893726, "score": 1, "link": "https://stackoverflow.com/questions/34820241/how-to-update-the-number-of-topic-partitions-on-dcos-kafka", "owner": {"user_id": 2651381, "profile_image": "https://graph.facebook.com/1551160354/picture?type=large", "user_type": "registered", "reputation": 570, "link": "https://stackoverflow.com/users/2651381/tim-martin", "accept_rate": 40, "display_name": "Tim Martin"}, "view_count": 56, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34820241}{"is_answered": true, "tags": ["meteor", "meteorite"], "last_edit_date": 1380050740, "title": "Mesosphere success/failure callback errors", "last_activity_date": 1390854576, "answer_count": 1, "creation_date": 1377403067, "score": 0, "link": "https://stackoverflow.com/questions/18425539/mesosphere-success-failure-callback-errors", "accepted_answer_id": 21391026, "owner": {"user_id": 1191551, "profile_image": "https://www.gravatar.com/avatar/97ced8a229689b73b098a542636052e8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4303, "link": "https://stackoverflow.com/users/1191551/chet", "accept_rate": 46, "display_name": "Chet"}, "view_count": 165, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 18425539}{"body": "<p>Is it possible to see all the mesos resources as a giant Linux box without custom code for the framework?</p>\n\n<p>I am wondering, if I want to run a program using 2500tb of ram, can mesos abstract the master slave architecture away? Do I have to use custom code?</p>\n", "is_answered": false, "tags": ["distributed", "distributed-computing", "mesos", "mesosphere"], "title": "Mesos as a giant Linux box", "last_activity_date": 1454626420, "answer_count": 2, "creation_date": 1446050890, "score": 0, "link": "https://stackoverflow.com/questions/33396884/mesos-as-a-giant-linux-box", "answers": [{"body": "<p>You have to write custom code. Mesos offers resources per agent (slave) basis and it is up to you how to coordinate binaries of your app running on different machines.</p>\n", "answer_id": 33403722, "last_activity_date": 1446076970, "creation_date": 1446076970, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 33396884}, {"body": "<p><strong>Q1</strong>: Mesos is a resource manager. Yes, it's a giant pool of resources. Although at a given time it will offer you only a subspace of all resources. Assuming that there are other users that might need some resources (don't worry there's a way how to utilize almost whole cluster).</p>\n\n<p><a href=\"https://i.stack.imgur.com/0j2Cz.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0j2Cz.png\" alt=\"mesos scheduler\"></a></p>\n\n<p><strong>Q2</strong>: Mesos is designed for a commodity hardware (many nodes, not a single giant HPC computer). A framework running on Mesos will be given a list resources (and slaves - worker nodes) and Mesos will execute a task within bound of given resources. This way you can start an MPI job or run a task on top of <a href=\"http://spark.apache.org/\" rel=\"nofollow noreferrer\">Apache Spark</a> which will handle the communication between nodes for you (but not Mesos itself).</p>\n\n<p><strong>Q3</strong>: You haven't specified what kind of task you'd like to compute. Spark comes with quite <a href=\"https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples\" rel=\"nofollow noreferrer\">a few examples</a>. You can run any of those without writing own code.</p>\n\n<p>(Image credits: Malte Schwarzkopf, Google talk EuroSys 2013 in Prague)</p>\n", "answer_id": 35213248, "last_activity_date": 1454626420, "creation_date": 1454626420, "score": 0, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": false, "question_id": 33396884}], "owner": {"user_id": 5499350, "profile_image": "https://www.gravatar.com/avatar/de953bfe48958078621541fb20332b70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/5499350/jxieeducation", "display_name": "jxieeducation"}, "view_count": 41, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 33396884}{"body": "<p>I am running dcos spark-submit and it keeps on downloading docker image everytime saying it looks like you are running for 1st time. Dint find any hit on this on google.</p>\n\n<pre><code> spark_submit_jobs$ dcos spark run --submit-args='-Dspark.mesos.coarse=true --driver-cores 1 --driver-memory 1024M --class org.apache.spark.examples.SparkPi https://downloads.mesosphere.com/spark/assets/spark-examples_2.10-1.4.0-SNAPSHOT.jar 30'\n</code></pre>\n\n<p>Spark distribution spark-1.6.2 not found locally.\nIt looks like this is your first time running Spark!\nDownloading <a href=\"https://downloads.mesosphere.com/spark/assets/spark-1.6.2.tgz\" rel=\"nofollow noreferrer\">https://downloads.mesosphere.com/spark/assets/spark-1.6.2.tgz</a>...</p>\n\n<p>Tried removing and installing spark.</p>\n\n<p>I am running:  1.0.1-1.6.2 and 1.0.6-2.0.2-hadoop-2.6</p>\n\n<p>I have two clusters running two different versions of spark on one everything is ok but on other its causing an issues with the older version.</p>\n", "is_answered": false, "tags": ["apache-spark", "docker", "mesos", "mesosphere", "dcos"], "last_edit_date": 1483604726, "title": "mesos dcos: spark keeps on downloading the docker image", "last_activity_date": 1483638380, "answer_count": 1, "creation_date": 1483568485, "score": -1, "link": "https://stackoverflow.com/questions/41474197/mesos-dcos-spark-keeps-on-downloading-the-docker-image", "answers": [{"body": "<p>Two possible reasons:</p>\n\n<p>1.6.2 keeps file in tmp dir which gets over written every time try with 1.6.3</p>\n\n<p>Use root account to run dcos command.</p>\n", "answer_id": 41491481, "last_activity_date": 1483638380, "creation_date": 1483638380, "score": 0, "owner": {"user_id": 6679867, "profile_image": "https://www.gravatar.com/avatar/5927b9523649911cd6afc0665d0aef87?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/6679867/cloudvar", "accept_rate": 25, "display_name": "cloudvar"}, "is_accepted": false, "question_id": 41474197}], "owner": {"user_id": 6679867, "profile_image": "https://www.gravatar.com/avatar/5927b9523649911cd6afc0665d0aef87?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/6679867/cloudvar", "accept_rate": 25, "display_name": "cloudvar"}, "view_count": 46, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41474197}{"body": "<p>I installed DC/OS 1.9 on my own three VM, all node have no GPU resources, and the slave/slave-public node started up successfully. In one slave log it shows below:</p>\n\n<pre><code>Jun 15 04:43:28 localhost.localdomain mesos-agent[31752]: E0615 04:43:28.488627 31752 containerizer.cpp:335] Cannot create the Nvidia GPU isolator: NVML is not available\nJun 15 04:43:28 localhost.localdomain mesos-agent[31752]: 2017-06-15 04:43:28,494:31752(0x7f9291dd8700):ZOO_INFO@log_env@726: Client environment:zookeeper.version=zookeeper C client 3.4.8\n.....\nJun 15 04:43:28 localhost.localdomain mesos-agent[31752]: I0615 04:43:28.495215 31752 slave.cpp:211] Mesos agent started on (1)@192.168.3.72:5051\n</code></pre>\n\n<p>In my another test environment whose mesos version is 1.0.1, I start a mesos slave (the node also have no GPU resources) with \"cgroups/devices,gpu/nvidia\" isolation, but it failed to start. The logs show:</p>\n\n<pre><code>Jun 15 09:29:39 w-388965952-ClusterTest-sysadmin linker-start-agent.sh[25300]: Failed to create a containerizer: Could not create MesosContainerizer: Failed to create isolator 'gpu/nvidia': Cannot create the Nvidia GPU isolator: NVML is not available\nJun 15 09:29:39 w-388965952-ClusterTest-sysadmin systemd[1]: dcos-mesos-slave.service: main process exited, code=exited, status=1/FAILURE\nJun 15 09:29:39 w-388965952-ClusterTest-sysadmin systemd[1]: Unit dcos-mesos-slave.service entered failed state.\nJun 15 09:29:39 w-388965952-ClusterTest-sysadmin systemd[1]: dcos-mesos-slave.service failed.\n</code></pre>\n\n<p>I want to know: Does a node with no GPU resources can start mesos-salve with gpu/nvidia isolation? If yes, how?</p>\n", "is_answered": true, "tags": ["gpu", "mesos", "dcos"], "last_edit_date": 1497632712, "title": "gpu/nvidia isolation in dc/os", "last_activity_date": 1497814933, "answer_count": 1, "creation_date": 1497603748, "score": 1, "link": "https://stackoverflow.com/questions/44585116/gpu-nvidia-isolation-in-dc-os", "answers": [{"body": "<p>The behavior here for DC/OS is slightly different than in vanilla Mesos.</p>\n\n<ul>\n<li><p>With vanilla Mesos, the agent will refuse to start if you enable the <code>gpu/nvidia</code> isolator but NVML is not installed.</p></li>\n<li><p>With DC/OS, the agent will emit a warning message if NVML is not installed (the <code>gpu/nvidia</code> isolator is always enabled).</p></li>\n</ul>\n\n<p><em>Note:</em> the dependency is on the NVML libraries, not actual GPU resources. If NVML is installed but no GPUs are found on the box, then the agent won't fail to start with the <code>gpu/nvidia</code> isolator enabled.</p>\n", "answer_id": 44599457, "last_activity_date": 1497814933, "creation_date": 1497657671, "score": 2, "owner": {"user_id": 5327044, "profile_image": "https://www.gravatar.com/avatar/ab97f776b0390a6b6bc72290ea3d9ff0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 281, "link": "https://stackoverflow.com/users/5327044/neil-conway", "display_name": "Neil Conway"}, "is_accepted": false, "last_edit_date": 1497814933, "question_id": 44585116}], "owner": {"user_id": 8170671, "profile_image": "https://www.gravatar.com/avatar/a587027b0f0fa5800625da27fdb52963?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/8170671/%e5%88%98%e5%b7%8d%e9%94%8b", "accept_rate": 0, "display_name": "\u5218\u5dcd\u950b"}, "view_count": 61, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44585116}{"body": "<p>I'm having issues pulling from a private docker repo when I add a marathon application. I've tarred my ~/.docker folder (including the docker.config file which contains my login information) and distributed that along to my mesos slaves as /etc/docker.tar.gz (I'm using docker 1.6.2).</p>\n\n<p>I've then added a new marathon app with:</p>\n\n<pre><code>dcos marathon add app marathon.json\n</code></pre>\n\n<p>My marathon.json is as follows:</p>\n\n<pre><code>{\n  \"id\": \"api\",\n  \"cpus\": 1,\n  \"mem\": 1024,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"company/api\",\n    }\n  },\n  \"args\": [\"java\", \"-jar\", \"api.jar\"],\n  \"uris\": [\n    \"file:///etc/docker.tar.gz\"\n  ]\n}\n</code></pre>\n\n<p>The marathon app never starts, however. In my slave logs I've found the following line: </p>\n\n<p>Container x for executor y of framework z failed to start: Failed to 'docker pull company/api': exit status = exited with status 1 stderr = time=\"2015-11-12T00:03:57Z\" level=fatal msg=\"Error: image company/api:latest not found\"</p>\n\n<p>How can I get this to pull correctly?</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1447343372, "title": "Marathon With Private Docker Repo", "last_activity_date": 1447343372, "answer_count": 0, "creation_date": 1447293053, "score": 1, "link": "https://stackoverflow.com/questions/33663134/marathon-with-private-docker-repo", "owner": {"user_id": 2542922, "profile_image": "https://i.stack.imgur.com/tYjvN.png?s=128&g=1", "user_type": "registered", "reputation": 891, "link": "https://stackoverflow.com/users/2542922/cscan", "accept_rate": 73, "display_name": "cscan"}, "view_count": 299, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33663134}{"body": "<p>I have Spark installed, but when I launch, there is always only one executor allocated to the application (and that is the driver one). I\u2019ve tried everything, but haven\u2019t been able to find out why this is happening.</p>\n\n<p>Here\u2019s the command I used to launch, to give you an idea of all the parameters:</p>\n\n<pre><code>dcos spark run --submit-args='--class &lt;class-name&gt; --executor-memory 6g --total-executor-cores 32 --driver-memory 6g &lt;jar-file-source&gt; &lt;application-command-line-params&gt;\n</code></pre>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "dcos"], "last_edit_date": 1478018903, "title": "Why does a Spark Application launch with only a single executor on DC/OS?", "last_activity_date": 1478018903, "answer_count": 0, "creation_date": 1478017341, "score": 3, "link": "https://stackoverflow.com/questions/40364205/why-does-a-spark-application-launch-with-only-a-single-executor-on-dc-os", "owner": {"user_id": 5292454, "profile_image": "https://www.gravatar.com/avatar/2b0e16734f44d112cc29a978bf9d0c10?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 136, "link": "https://stackoverflow.com/users/5292454/chbh", "accept_rate": 38, "display_name": "chbh"}, "view_count": 60, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40364205}{"body": "<p>I am currently working with a pre-built Mesos Marathon Heat template, trying to stop specific apps/containers getting deployed based on a custom node attribute, but that's where my problems begin</p>\n\n<p>I'm using </p>\n\n<pre><code>resources:\n  specific_label:\n    type: text\n    value: defining_label\n</code></pre>\n\n<p>as part of my Heat Template, but the deployment to Mesos is failing out there. </p>\n\n<p>As the beginning part of my question, I'm assuming I don't have a good grasp on the concept of Attributes yet? Can someone enlighten how I'm doing it wrong?</p>\n\n<p>I was under the impression the attributes are part of the deployment of the node, so when the nested Heat Templates are being deployed, it would see the specific attribute in a conditional, and then using the Marathon scheduling constraints, just stop the deployment all together if it matched the corresponding conditional?</p>\n", "is_answered": false, "tags": ["mesos", "marathon", "mesosphere", "heat", "openstack-heat"], "title": "Trying to stop the deployment of specific apps to mesos marathon cluster based on custom attribute", "last_activity_date": 1496778979, "answer_count": 0, "creation_date": 1496778979, "score": 0, "link": "https://stackoverflow.com/questions/44398766/trying-to-stop-the-deployment-of-specific-apps-to-mesos-marathon-cluster-based-o", "owner": {"user_id": 4660085, "profile_image": "https://lh6.googleusercontent.com/-ow1h4mC7gb4/AAAAAAAAAAI/AAAAAAAAB4s/pVxhd8v3YrA/photo.jpg?sz=128", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/4660085/conedmiro", "accept_rate": 73, "display_name": "conedmiro"}, "view_count": 18, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44398766}{"body": "<p>I have just set up a DC/OS cluster via Microsoft Azure, and installed Arango 3.0 on the cluster using the DC/OS dashboard (via the ssh tunnel). I am able to SSH into the cluster and communicate with the Arango cluster:</p>\n\n<pre><code>$ curl --dump - http://localhost:8529/_api/gharial\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nServer: ArangoDB\nConnection: Keep-Alive\nContent-Length: 38\n\n{\"error\":false,\"graphs\":[],\"code\":200}\n</code></pre>\n\n<p><strong>Question #1</strong>: Even after I insert a graph using the POST requested described <a href=\"https://docs.arangodb.com/3.0/HTTP/Gharial/Management.html#create-a-graph\" rel=\"nofollow\">here in the docs</a>, the Arango Dashboard (accessed through the DC/OS Dashboard via the ssh tunnel) doesn't show the graph. Why is that? Here is \"evidence\" that the graph <code>social</code> was created:</p>\n\n<pre><code>$ curl -X POST --data-binary @- --dump - http://localhost:8529/_api/gharial/social/vertex/male &lt;&lt;EOF\n&gt; {\n&gt;     \"name\" : \"social\",\n&gt;     \"edgeDefinitions\" : [\n&gt;       {\n&gt;         \"collection\" : \"relation\",\n&gt;         \"from\" : [\n&gt;           \"female\",\n&gt;           \"male\"\n&gt;         ],\n&gt;         \"to\" : [\n&gt;           \"female\",\n&gt;           \"male\"\n&gt;         ]\n&gt;       }\n&gt;     ]\n&gt; }\n&gt; EOF\nHTTP/1.1 202 Accepted\nEtag: 129726\nContent-Type: application/json; charset=utf-8\nServer: ArangoDB\nConnection: Keep-Alive\nContent-Length: 89\n\n$ curl --dump - http://localhost:8529/_api/gharial\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nServer: ArangoDB\nConnection: Keep-Alive\nContent-Length: 226\n\n{\"error\":false,\"graphs\":[{\"_key\":\"social\",\"_id\":\"_graphs/social\",\"_rev\":\"125906\",\"edgeDefinitions\":[{\"collection\":\"relation\",\"from\":[\"female\",\"male\"],\"to\":[\"female\",\"male\"]}],\"orphanCollections\":[\"otherVertices\"]}],\"code\":200}\n</code></pre>\n\n<hr>\n\n<p>I'm also having trouble using the Arango shell. Even though Arango is clearly installed on he server (as shown by the above curl), the Arango shell still isn't recognized:</p>\n\n<pre><code>$ arangosh\narangosh: command not found\n</code></pre>\n\n<p><strong>Question #2</strong>: Do I have to manually install Arango onto this machine even though I already installed Arango it through the DC/OS dashboard? If so, how should I get Arango? (I tried using <code>apt-get</code> but there were differing-version issue). Or is there another way of communicated with this cluster that I'm missing?</p>\n\n<p>(Basically, I'm trying to bulk-import a large graph into Arango. I feel like there should be a way of importing directly from a file -- i.e. not over HTTP -- since that is probably faster / more efficient).</p>\n", "is_answered": true, "title": "Running Arango Shell on DC/OS cluster", "last_edit_date": 1468452776, "tags": ["arangodb", "dcos"], "view_count": 148, "accepted_answer_id": 38370229, "last_activity_date": 1468487795, "answers": [{"body": "<h1>#1 Graph</h1>\n\n<p>If I get that correctly, you only created the graph definition; there is no data inside your graph yet. So it will show up in the list of graphs, but the screen will be blank. </p>\n\n<p>If you want to create a graph with content, you may <a href=\"https://docs.arangodb.com/3.0/Manual/Graphs/index.html#example-graphs\" rel=\"nofollow\">either do this using arangosh</a> once you've got it running, or click on '+ Add Graph', Choose the 'Example Graphs' tab, Choose one, press 'Create'. Please note that some of these graphs may collide with the empty graph you've already created, so you may want to drop it first.</p>\n\n<h1>#2 - Arangosh</h1>\n\n<p>The DC/OS Agent deploys ArangoDB inside of docker containers. These docker containers will also contain arangosh (and <a href=\"https://docs.arangodb.com/3.0/Manual/Administration/Arangoimp.html\" rel=\"nofollow\">arangoimp</a>).\nIf I get that correctly, you're ssh-ing into the agent host? \nAs you tried, you <a href=\"https://www.arangodb.com/download/debian/\" rel=\"nofollow\">could install the arangodb3-client package</a> in the host - you need to add the repository URL first.</p>\n\n<p>This is probably the most convenient way to get arangosh; Another possibility may be to attach the arango docker container and run it in there. You need to make shure you correctly connect the coordinator host; which is why installing arangosh in the agent host is more compfortable.</p>\n", "answer_id": 38370229, "last_activity_date": 1468487795, "creation_date": 1468487795, "score": 1, "owner": {"user_id": 3237176, "profile_image": "https://i.stack.imgur.com/2zu7q.png?s=128&g=1", "user_type": "registered", "reputation": 4374, "link": "https://stackoverflow.com/users/3237176/dothebart", "accept_rate": 75, "display_name": "dothebart"}, "is_accepted": true, "question_id": 38363315}], "score": 0, "link": "https://stackoverflow.com/questions/38363315/running-arango-shell-on-dc-os-cluster", "answer_count": 1, "owner": {"user_id": 4238485, "profile_image": "https://www.gravatar.com/avatar/eb8fc278a3bae395ba64c0923434bfe7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 14, "link": "https://stackoverflow.com/users/4238485/zach-kirsch", "accept_rate": 80, "display_name": "Zach Kirsch"}, "creation_date": 1468452435, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 38363315}{"body": "<p>I've already setup a single-master single-slave DC/OS 1.9 for test purpose. I did reboot master node and it failed to restart itself (Server is up, but none of dcos-* services are running). Is there any procedure to recover my master? I did find slave recovery in the docs, but there was nothing about master.</p>\n\n<p>Please tell me how should i recover my master.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1501482000, "title": "DC/OS single-node master does not recover manual reboot", "last_activity_date": 1501482000, "answer_count": 0, "creation_date": 1501480836, "score": 0, "link": "https://stackoverflow.com/questions/45408436/dc-os-single-node-master-does-not-recover-manual-reboot", "owner": {"user_id": 1202498, "profile_image": "https://www.gravatar.com/avatar/b3893f5b38832d3decd07b1538baf9f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/1202498/uchiha-sasuke", "accept_rate": 50, "display_name": "Uchiha_Sasuke"}, "view_count": 28, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45408436}{"body": "<p>Mesosphere did a great job on simplifying the process of running Spark on Mesos.  I am using this guide to setup a development Mesos cluster on Google Cloud Compute.</p>\n\n<p><a href=\"https://mesosphere.com/docs/tutorials/run-spark-on-mesos/\" rel=\"nofollow noreferrer\">https://mesosphere.com/docs/tutorials/run-spark-on-mesos/</a></p>\n\n<p>I can run the example that's in the guide by using <code>spark-shell</code> (finding numbers less than 10).  However, when I attempt to submit an application that otherwise works fine with Spark locally it blows up with TASK_FAILED messages (i.e. <code>CoarseMesosSchedulerBackend: Mesos task 4 is now TASK_FAILED</code>).</p>\n\n<p>Here's the command I'm using with the provided Spark Pi example.</p>\n\n<p><code>./spark-submit --class org.apache.spark.examples.SparkPi --master mesos://10.173.40.36:5050 ~/spark-1.3.0-bin-hadoop2.4/lib/spark-examples-1.3.0-hadoop2.4.0.jar 100</code></p>\n\n<p>And the output:</p>\n\n<pre><code>jclouds@development-5159-d9:~/learning-spark$ ~/spark-1.3.0-bin-hadoop2.4/bin/spark-submit --class org.apache.spark.examples.SparkPi --master mesos://10.173.40.36:5050 ~/spark-1.3.0-bin-hadoop2.4/lib/spark-examples-1.3.0-hadoop2.4.0.jar 100\nSpark assembly has been built with Hive, including Datanucleus jars on classpath\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n15/03/22 16:44:02 INFO SparkContext: Running Spark version 1.3.0\n15/03/22 16:44:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n15/03/22 16:44:03 INFO SecurityManager: Changing view acls to: jclouds\n15/03/22 16:44:03 INFO SecurityManager: Changing modify acls to: jclouds\n15/03/22 16:44:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jclouds); users with modify permissions: Set(jclouds)\n15/03/22 16:44:03 INFO Slf4jLogger: Slf4jLogger started\n15/03/22 16:44:03 INFO Remoting: Starting remoting\n15/03/22 16:44:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@development-5159-d9.c.learning-spark.internal:60301]\n15/03/22 16:44:03 INFO Utils: Successfully started service 'sparkDriver' on port 60301.\n15/03/22 16:44:03 INFO SparkEnv: Registering MapOutputTracker\n15/03/22 16:44:03 INFO SparkEnv: Registering BlockManagerMaster\n15/03/22 16:44:03 INFO DiskBlockManager: Created local directory at /tmp/spark-27fad7e3-4ad7-44d6-845f-4a09ac9cce90/blockmgr-a558b7be-0d72-49b9-93fd-5ef8731b314b\n15/03/22 16:44:03 INFO MemoryStore: MemoryStore started with capacity 265.0 MB\n15/03/22 16:44:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-de9ac795-381b-4acd-a723-a9a6778773c9/httpd-7115216c-0223-492b-ae6f-4134ba7228ba\n15/03/22 16:44:04 INFO HttpServer: Starting HTTP Server\n15/03/22 16:44:04 INFO Server: jetty-8.y.z-SNAPSHOT\n15/03/22 16:44:04 INFO AbstractConnector: Started SocketConnector@0.0.0.0:36663\n15/03/22 16:44:04 INFO Utils: Successfully started service 'HTTP file server' on port 36663.\n15/03/22 16:44:04 INFO SparkEnv: Registering OutputCommitCoordinator\n15/03/22 16:44:04 INFO Server: jetty-8.y.z-SNAPSHOT\n15/03/22 16:44:04 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040\n15/03/22 16:44:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n15/03/22 16:44:04 INFO SparkUI: Started SparkUI at http://development-5159-d9.c.learning-spark.internal:4040\n15/03/22 16:44:04 INFO SparkContext: Added JAR file:/home/jclouds/spark-1.3.0-bin-hadoop2.4/lib/spark-examples-1.3.0-hadoop2.4.0.jar at http://10.173.40.36:36663/jars/spark-examples-1.3.0-hadoop2.4.0.jar with timestamp 1427042644934\nWarning: MESOS_NATIVE_LIBRARY is deprecated, use MESOS_NATIVE_JAVA_LIBRARY instead. Future releases will not support JNI bindings via MESOS_NATIVE_LIBRARY.\nWarning: MESOS_NATIVE_LIBRARY is deprecated, use MESOS_NATIVE_JAVA_LIBRARY instead. Future releases will not support JNI bindings via MESOS_NATIVE_LIBRARY.\nI0322 16:44:05.035423   308 sched.cpp:137] Version: 0.21.1\nI0322 16:44:05.038136   309 sched.cpp:234] New master detected at master@10.173.40.36:5050\nI0322 16:44:05.039261   309 sched.cpp:242] No credentials provided. Attempting to register without authentication\nI0322 16:44:05.040351   310 sched.cpp:408] Framework registered with 20150322-040336-606645514-5050-2744-0019\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Registered as framework ID 20150322-040336-606645514-5050-2744-0019\n15/03/22 16:44:05 INFO NettyBlockTransferService: Server created on 44177\n15/03/22 16:44:05 INFO BlockManagerMaster: Trying to register BlockManager\n15/03/22 16:44:05 INFO BlockManagerMasterActor: Registering block manager development-5159-d9.c.learning-spark.internal:44177 with 265.0 MB RAM, BlockManagerId(&lt;driver&gt;, development-5159-d9.c.learning-spark.internal, 44177)\n15/03/22 16:44:05 INFO BlockManagerMaster: Registered BlockManager\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 2 is now TASK_RUNNING\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 1 is now TASK_RUNNING\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 0 is now TASK_RUNNING\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 2 is now TASK_FAILED\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 1 is now TASK_FAILED\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 0 is now TASK_FAILED\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n15/03/22 16:44:05 INFO SparkContext: Starting job: reduce at SparkPi.scala:35\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 3 is now TASK_RUNNING\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 4 is now TASK_RUNNING\n15/03/22 16:44:05 INFO DAGScheduler: Got job 0 (reduce at SparkPi.scala:35) with 100 output partitions (allowLocal=false)\n15/03/22 16:44:05 INFO DAGScheduler: Final stage: Stage 0(reduce at SparkPi.scala:35)\n15/03/22 16:44:05 INFO DAGScheduler: Parents of final stage: List()\n15/03/22 16:44:05 INFO DAGScheduler: Missing parents: List()\n15/03/22 16:44:05 INFO DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:31), which has no missing parents\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 3 is now TASK_FAILED\n15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Blacklisting Mesos slave value: \"20150322-040336-606645514-5050-2744-S1\"\n due to too many failures; is Spark installed on it?\n 15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 4 is now TASK_FAILED\n 15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Blacklisting Mesos slave value: \"20150322-040336-606645514-5050-2744-S0\"\n  due to too many failures; is Spark installed on it?\n  15/03/22 16:44:05 INFO MemoryStore: ensureFreeSpace(1848) called with curMem=0, maxMem=277842493\n  15/03/22 16:44:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1848.0 B, free 265.0 MB)\n  15/03/22 16:44:05 INFO MemoryStore: ensureFreeSpace(1296) called with curMem=1848, maxMem=277842493\n  15/03/22 16:44:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1296.0 B, free 265.0 MB)\n  15/03/22 16:44:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on development-5159-d9.c.learning-spark.internal:44177 (size: 1296.0 B, free: 265.0 MB)\n  15/03/22 16:44:05 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0\n  15/03/22 16:44:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:839\n  15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 5 is now TASK_RUNNING\n  15/03/22 16:44:05 INFO DAGScheduler: Submitting 100 missing tasks from Stage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:31)\n  15/03/22 16:44:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 100 tasks\n  15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Mesos task 5 is now TASK_FAILED\n  15/03/22 16:44:05 INFO CoarseMesosSchedulerBackend: Blacklisting Mesos slave value: \"20150322-040336-606645514-5050-2744-S2\"\n   due to too many failures; is Spark installed on it?\n   15/03/22 16:44:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n</code></pre>\n\n<p>I suspect it may have something to do with the <strong>mesos slave nodes not finding the application jar</strong>, but when I put it in HDFS and provide the URL to it, <code>spark-submit</code> tells me it will <code>Skip remote jar</code>.</p>\n\n<pre><code>jclouds@development-5159-d9:~/learning-spark$ ~/spark-1.3.0-bin-hadoop2.4/bin/spark-submit --class org.apache.spark.examples.SparkPi --master mesos://10.173.40.36:5050 hdfs://10.173.40.36/tmp/spark-examples-1.3.0-hadoop2.4.0.jar 100Spark assembly has been built with Hive, including Datanucleus jars on classpath\nWarning: Skip remote jar hdfs://10.173.40.36/tmp/spark-examples-1.3.0-hadoop2.4.0.jar.\njava.lang.ClassNotFoundException: org.apache.spark.examples.SparkPi\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:423)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:356)\n        at java.lang.Class.forName0(Native Method)\n        at java.lang.Class.forName(Class.java:266)\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:538)\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n</code></pre>\n\n<p>--</p>\n\n<p>EDIT: Just to bring this to conclusion, <code>hbogert</code> on the spark user list pointed me in the direction of debugging the <code>spark</code> logs on one of my slave nodes and the problem was as clear as day.</p>\n\n<p><code>\njclouds@development-5159-d3d:/tmp/mesos/slaves/20150322-040336-606645514-5050-2744-S1/frameworks/20150322-040336-606645514-5050-2744-0037/executors/1/runs/latest$ cat stderr\nI0329 20:34:26.107267 10026 exec.cpp:132] Version: 0.21.1\nI0329 20:34:26.109591 10031 exec.cpp:206] Executor registered on slave 20150322-040336-606645514-5050-2744-S1\nsh: 1: /home/jclouds/spark-1.3.0-bin-hadoop2.4/bin/spark-class: not found\njclouds@development-5159-d3d:/tmp/mesos/slaves/20150322-040336-606645514-5050-2744-S1/frameworks/20150322-040336-606645514-5050-2744-0037/executors/1/runs/latest$ cat stdout\nRegistered executor on 10.217.7.180\nStarting task 1\nForked command at 10036\nsh -c ' \"/home/jclouds/spark-1.3.0-bin-hadoop2.4/bin/spark-class\" org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url akka.tcp://sparkDriver@development-5159-d9.c.learning-spark.internal:54746/user/CoarseGrainedScheduler --executor-id 20150322-040336-606645514-5050-2744-S1 --hostname 10.217.7.180 --cores 10 --app-id 20150322-040336-606645514-5050-2744-0037'\nCommand exited with status 127 (pid: 10036)\n</code></p>\n\n<p>Related: </p>\n\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/19939853/how-to-run-hadoop-on-a-mesos-cluster\">How to run Hadoop on a Mesos cluster?</a></li>\n<li><a href=\"http://apache-spark-user-list.1001560.n3.nabble.com/Spark-submit-failing-on-cluster-td8369.html\" rel=\"nofollow noreferrer\">http://apache-spark-user-list.1001560.n3.nabble.com/Spark-submit-failing-on-cluster-td8369.html</a></li>\n</ul>\n", "is_answered": true, "title": "Can't run spark-submit with an application jar on a Mesos cluster", "last_edit_date": 1495540745, "tags": ["apache-spark", "mesos", "mesosphere"], "view_count": 3312, "accepted_answer_id": 29240825, "last_activity_date": 1427978496, "answers": [{"body": "<p>It's hard to tell without knowing what's the stderr output in the Mesos sandbox logs, but usually you need to make sure you set the <code>MESOS_NATIVE_LIBRARY</code> (in <code>spark-env.sh</code>) and also the <code>spark.executor.uri</code> (in <code>spark-defaults.conf</code>) URL pointing to a Spark tar correctly.  If not you need to have spark installed at the same location in each slave.</p>\n", "answer_id": 29240825, "last_activity_date": 1427978496, "creation_date": 1427223862, "score": 4, "owner": {"user_id": 4072708, "profile_image": "https://www.gravatar.com/avatar/7011b2b24cb4c7c5844c0e7d2658d1c8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/4072708/tim-chen", "display_name": "Tim Chen"}, "is_accepted": true, "last_edit_date": 1427978496, "question_id": 29198522}], "score": 1, "link": "https://stackoverflow.com/questions/29198522/cant-run-spark-submit-with-an-application-jar-on-a-mesos-cluster", "answer_count": 1, "owner": {"user_id": 895309, "profile_image": "https://www.gravatar.com/avatar/1de0fa835b38ce73fc9eccff47d1aa6b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1145, "link": "https://stackoverflow.com/users/895309/sean-glover", "accept_rate": 85, "display_name": "Sean Glover"}, "creation_date": 1427050772, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29198522}{"body": "<p>First of all, I'm new to DC/OS ...</p>\n\n<p>I installed DC/OS locally with Vagrant, everything worked fine. Then I installed Cassandra, Spark and I think to understand the container concept with Docker, so far so good.</p>\n\n<p>Now it's time to develop an Akka service and I'm a little bit confused how I should start. The Akka service should simply offer a HTTP REST endpoint and store some data to Cassandra.</p>\n\n<p>So I have my DC/OS ready, and Eclipse in front of me. Now I would like to develop the Akka service and connect to Cassandra from outside DC/OS, how can I do that? Is this the wrong approach? Should I install Cassandra separately and only if I\u2019m ready I would deploy to DC/OS?</p>\n\n<p>Because it was so simple to install Cassandra, Spark and all the rest I would like to use it for development as well.</p>\n", "is_answered": true, "title": "DC/OS service development with Akka", "last_edit_date": 1476188227, "tags": ["akka", "mesos", "mesosphere", "dcos"], "view_count": 508, "accepted_answer_id": 39977151, "last_activity_date": 1476263047, "answers": [{"body": "<p>While slightly outdated (since it's using DC/OS 1.7 and you should be really using 1.8 these days) there's a very nice tutorial from <a href=\"https://blog.codecentric.de/en/2016/04/smack-stack-hands/\" rel=\"nofollow\">codecentric</a> that should contain everything you need to get started:</p>\n\n<ol>\n<li>It walks you through setting up DC/OS, Cassandra, Kafka, and Spark</li>\n<li>It shows how to use Akka reactive streams and the <a href=\"https://github.com/akka/reactive-kafka\" rel=\"nofollow\">reactive kafka extension</a> to ingest data from Twitter into Kafka</li>\n<li>It shows how to use Spark to ingest data Cassandra</li>\n</ol>\n\n<p>Another great walkthrough resource is available via <a href=\"http://www.cakesolutions.net/teamblogs/smack-stack-on-dcos\" rel=\"nofollow\">Cake Solutions</a>:</p>\n\n<ol>\n<li>It walks you through setting up DC/OS, Cassandra, Kafka, and Marathon-LB (a load balancer)</li>\n<li>It explains service discovery for Akka</li>\n<li>It shows how to expose a service via Marathon-LB</li>\n</ol>\n", "answer_id": 39977151, "last_activity_date": 1476263047, "creation_date": 1476188554, "score": 3, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "last_edit_date": 1476263047, "question_id": 39966907}], "score": 3, "link": "https://stackoverflow.com/questions/39966907/dc-os-service-development-with-akka", "answer_count": 1, "owner": {"user_id": 2143867, "profile_image": "https://www.gravatar.com/avatar/192f49218ea4ae96741562c3cd156d10?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 172, "link": "https://stackoverflow.com/users/2143867/nextremos", "accept_rate": 100, "display_name": "Nextremos"}, "creation_date": 1476134399, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39966907}{"body": "<p>After install Marathon by <code>apt-get install marathon</code>, I failed to start Marathon by <code>service marathon start</code>; the command return process id but can not retrieve it by <code>ps</code>. And I can not get log of it.</p>\n\n<p>If I run <code>/usr/bin/marathon</code>, I got following message <code>run_jar --zk zk://mesosStagingCompute9:2181/marathon --master zk://mesosStagingCompute9:2181/mesos</code>.</p>\n\n<p>Any suggestion?</p>\n", "is_answered": true, "title": "Failed to start Marathon in ubuntu", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1445128889, "accepted_answer_id": 33193147, "creation_date": 1444743139, "answers": [{"body": "<p>This's because the default JRE is openjdk-7; need change the default JRE to openjdk-8.</p>\n", "answer_id": 33193147, "last_activity_date": 1445128889, "creation_date": 1445128889, "score": 0, "owner": {"user_id": 5433459, "profile_image": "https://lh4.googleusercontent.com/-uCULoDnIw00/AAAAAAAAAAI/AAAAAAAAAB0/9evjVtAPn6A/photo.jpg?sz=128", "user_type": "registered", "reputation": 30, "link": "https://stackoverflow.com/users/5433459/klaus-ma", "display_name": "Klaus Ma"}, "is_accepted": true, "question_id": 33104061}], "score": 0, "link": "https://stackoverflow.com/questions/33104061/failed-to-start-marathon-in-ubuntu", "answer_count": 1, "owner": {"user_id": 5433459, "profile_image": "https://lh4.googleusercontent.com/-uCULoDnIw00/AAAAAAAAAAI/AAAAAAAAAB0/9evjVtAPn6A/photo.jpg?sz=128", "user_type": "registered", "reputation": 30, "link": "https://stackoverflow.com/users/5433459/klaus-ma", "display_name": "Klaus Ma"}, "view_count": 207, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 33104061}{"is_answered": false, "tags": ["event-bus", "dcos", "event-stream"], "title": "dcos event-bus : do not receive any data on the event-stream", "last_activity_date": 1491494004, "answer_count": 0, "creation_date": 1491494004, "score": 0, "link": "https://stackoverflow.com/questions/43260096/dcos-event-bus-do-not-receive-any-data-on-the-event-stream", "owner": {"user_id": 296923, "profile_image": "https://www.gravatar.com/avatar/cb7b3af2d2d967711454dc8d9c21798f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6136, "link": "https://stackoverflow.com/users/296923/ziffusion", "accept_rate": 84, "display_name": "Ziffusion"}, "view_count": 26, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 43260096}{"body": "<p>I use Spark 1.6.1, Hadoop 2.6.4 and Mesos 0.28 on Debian 8.</p>\n\n<p>While trying to submit a job via <code>spark-submit</code> to a Mesos cluster a slave fails with the following in stderr log:</p>\n\n<pre><code>I0427 22:35:39.626055 48258 fetcher.cpp:424] Fetcher Info: {\"cache_directory\":\"\\/tmp\\/mesos\\/fetch\\/slaves\\/ad642fcf-9951-42ad-8f86-cc4f5a5cb408-S0\\/hduser\",\"items\":[{\"action\":\"BYP$\nI0427 22:35:39.628031 48258 fetcher.cpp:379] Fetching URI 'hdfs://xxxxxxxxx:54310/sources/spark/SimpleEventCounter.jar'\nI0427 22:35:39.628057 48258 fetcher.cpp:250] Fetching directly into the sandbox directory\nI0427 22:35:39.628078 48258 fetcher.cpp:187] Fetching URI 'hdfs://xxxxxxx:54310/sources/spark/SimpleEventCounter.jar'\nE0427 22:35:39.629243 48258 shell.hpp:93] Command 'hadoop version 2&gt;&amp;1' failed; this is the output:\nsh: 1: hadoop: not found\nFailed to fetch 'hdfs://xxxxxxx:54310/sources/spark/SimpleEventCounter.jar': Failed to create HDFS client: Failed to execute 'hadoop version 2&gt;&amp;1'; the command was e$\nFailed to synchronize with slave (it's probably exited)\n</code></pre>\n\n<ol>\n<li>My Jar file contains hadoop 2.6 binaries</li>\n<li>The path to spark executor/binary is via an <code>hdfs://</code> link </li>\n</ol>\n\n<p>My jobs don't appear in the framework tab, but they do appear in the driver with the status 'queued' and they just sit there till I shut down the <code>spark-mesos-dispatcher.sh</code> service.</p>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere"], "last_edit_date": 1462041011, "title": "Why does Spark job fail on Mesos with \"hadoop: not found\"?", "last_activity_date": 1463524248, "answer_count": 1, "creation_date": 1461878354, "score": 0, "link": "https://stackoverflow.com/questions/36925634/why-does-spark-job-fail-on-mesos-with-hadoop-not-found", "answers": [{"body": "<p>I was seeing a very similar error and I figured out my problem was that hadoop_home wasn't set in the mesos agent. \nI added to /etc/default/mesos-slave (path may be different on your install) on each mesos-slave the following line: <code>MESOS_hadoop_home=\"/path/to/my/hadoop/install/folder/\"</code></p>\n\n<p>EDIT: Hadoop has to be installed on each slave, the path/to/my/haoop/install/folder is a local path</p>\n", "answer_id": 37287175, "last_activity_date": 1463524248, "creation_date": 1463523754, "score": 0, "owner": {"user_id": 1274764, "profile_image": "https://i.stack.imgur.com/ch7dR.jpg?s=128&g=1", "user_type": "registered", "reputation": 303, "link": "https://stackoverflow.com/users/1274764/hardy", "accept_rate": 82, "display_name": "Hardy"}, "is_accepted": false, "last_edit_date": 1463524248, "question_id": 36925634}], "owner": {"user_id": 4493251, "profile_image": "https://www.gravatar.com/avatar/ae5b9542e3afec3255b47cf5be31fd04?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/4493251/yasir-k", "display_name": "Yasir K"}, "view_count": 643, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36925634}{"body": "<p>I have been looking into Docker containerization for a while now but few things are still confusing to me. I understand that all the containers are grouped into a cluster and cluster management tools like Docker Swarm, DC/OS, Kubernetes or Rancher can be used to manage docker containers. I have been testing out Container cluster management with DC/OS and Kubernetes, but still a few questions remain unanswered to me.</p>\n\n<p><strong>How does auto scaling in container level help us in production servers?</strong> How does the application serve traffic from multiple containers? </p>\n\n<p>Suppose we have deployed a web application using containers and they have auto scaled. How does the traffic flow to the containers? How are the sessions managed?</p>\n\n<p>What metrics are calculated for autoscaling containers?</p>\n", "is_answered": true, "title": "AutoScaling in Docker Containers", "last_edit_date": 1477681245, "tags": ["docker", "kubernetes", "dcos"], "view_count": 139, "accepted_answer_id": 40311725, "last_activity_date": 1477681630, "answers": [{"body": "<p>Kubernetes has concept called <code>service</code>. A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. Kubernetes uses services to serve traffic from multiple containers. You can read more about services <a href=\"http://kubernetes.io/docs/user-guide/services/#virtual-ips-and-service-proxies\" rel=\"nofollow\">here</a>.</p>\n\n<p>AFAIK, Sessions are managed outside kubernetes, but Client-IP based session affinity can be selected by setting service.spec.sessionAffinity to \"ClientIP\". You can read more about Service and session affinity <a href=\"http://nishadikirielle.blogspot.in/2016/03/load-balancing-kubernetes-services-and.html\" rel=\"nofollow\">here</a></p>\n\n<p>Multiple metrics like cpu and memory can be used for autoscaling containers. There is a good <a href=\"http://blog.kubernetes.io/2016/07/autoscaling-in-kubernetes.html\" rel=\"nofollow\">blog</a> you can read about autoscaling, when and how.</p>\n", "answer_id": 40301127, "last_activity_date": 1477643726, "creation_date": 1477643726, "score": 1, "owner": {"user_id": 512126, "profile_image": "https://www.gravatar.com/avatar/4f231a026687d47a1aee39fc6ef60787?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/512126/hrishikesh-kumar", "display_name": "Hrishikesh Kumar"}, "is_accepted": false, "question_id": 40298694}, {"body": "<p>The autoscaling in DC/OS (note: Mesosphere is the company, DC/OS the open source project) the autoscaling is described in detail in the <a href=\"https://dcos.io/docs/1.8/usage/tutorials/autoscaling/\" rel=\"nofollow\">docs</a>. Essentially the same as with Kubernetes, you can use either low-level metrics such as CPU utilization to decide when to increase the number of instances of an app or higher-level stuff like app throughput, for example using the <a href=\"https://dcos.io/docs/1.8/usage/tutorials/autoscaling/microscaling-queue/\" rel=\"nofollow\">Microscaling</a> approach.</p>\n\n<p>Regarding your question how the routing works (how are requests forwarded to an instance, that is a single container running): you need a load balancer and again, DC/OS provides you with this out of the box. And again, the options are detailed out in the <a href=\"https://dcos.io/docs/1.8/usage/service-discovery/load-balancing-vips/\" rel=\"nofollow\">docs</a>, essentially: HAProxy-based North-South or IPtables-based, East-West (cluster internal) load balancers.</p>\n", "answer_id": 40311725, "last_activity_date": 1477681630, "creation_date": 1477681630, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 40298694}], "score": 1, "link": "https://stackoverflow.com/questions/40298694/autoscaling-in-docker-containers", "answer_count": 2, "owner": {"user_id": 6265955, "profile_image": "https://lh5.googleusercontent.com/-Hic2s2PvyRc/AAAAAAAAAAI/AAAAAAAAABQ/ykizuGdHKzk/photo.jpg?sz=128", "user_type": "registered", "reputation": 354, "link": "https://stackoverflow.com/users/6265955/ali", "display_name": "Ali"}, "creation_date": 1477633053, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40298694}{"body": "<p>Let's say I have a single domain <code>fooapi.com</code> and two versions of the API: v1 and v2. How do I configure HAProxy in the <code>marathon.json</code> file so that both API versions can live behind the same domain but with a different path? Eg. <code>fooapi.com/v1/</code> and <code>fooapi.com/v2/</code>.</p>\n\n<p>The following configuration doesn't work (latest DCOS):</p>\n\n<pre><code>\"labels\": {\n\"HAPROXY_0_VHOST\": \"fooapi.com\",\n\"HAPROXY_DEPLOYMENT_GROUP\": \"api-grp\",\n\"HAPROXY_GROUP\": \"external\",\n\"HAPROXY_0_PATH\": \"/v1\"\n}\n</code></pre>\n", "is_answered": true, "title": "How do I route by path in DC/OS?", "tags": ["haproxy", "marathon", "dcos"], "last_activity_date": 1501663180, "accepted_answer_id": 45306788, "creation_date": 1500982179, "answers": [{"body": "<p>After reading through the Marathon-lb docs, I've solved it by adding the <code>HAPROXY_0_HTTP_BACKEND_PROXYPASS_PATH</code> config parameter:</p>\n\n<pre><code>\"labels\": {\n\"HAPROXY_0_VHOST\": \"fooapi.com\",\n\"HAPROXY_DEPLOYMENT_GROUP\": \"api-grp\",\n\"HAPROXY_GROUP\": \"external\",\n\"HAPROXY_0_HTTP_BACKEND_PROXYPASS_PATH\": \"/v1\",\n\"HAPROXY_0_PATH\": \"/v1\"\n}\n</code></pre>\n", "answer_id": 45306788, "last_activity_date": 1501663180, "creation_date": 1500994265, "score": 1, "owner": {"user_id": 1759948, "profile_image": "https://i.stack.imgur.com/po0MK.jpg?s=128&g=1", "user_type": "registered", "reputation": 668, "link": "https://stackoverflow.com/users/1759948/r%c4%83zvan", "accept_rate": 85, "display_name": "R\u0103zvan"}, "is_accepted": true, "last_edit_date": 1501663180, "question_id": 45301960}], "score": 0, "link": "https://stackoverflow.com/questions/45301960/how-do-i-route-by-path-in-dc-os", "answer_count": 1, "owner": {"user_id": 1759948, "profile_image": "https://i.stack.imgur.com/po0MK.jpg?s=128&g=1", "user_type": "registered", "reputation": 668, "link": "https://stackoverflow.com/users/1759948/r%c4%83zvan", "accept_rate": 85, "display_name": "R\u0103zvan"}, "view_count": 35, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45301960}{"body": "<p>Hi have launched my own elastic search docker from Marathon UI. I can see docker from \"docker ps\". Now I scaled instances to 2. I can see two dockers from Marathon, Mesos UI and on host also.</p>\n\n<p>Now I scaled down to 1 instance. I can see only one running docker from Marathon and Mesos UI. But two dockers running on host. It means it's killed from host.\nWhile I used other dockers like \"wildfly\"(example), it's removing properly.</p>\n\n<p>I'm not getting it's issue from my docker or Marathon ? Am I missing anything while building docker ?</p>\n\n<p><strong>App definition:</strong></p>\n\n<pre><code>{\n  \"id\":\"elasticsearch\",\n  \"cmd\":\"docker run -t \\\\\\n--net host \\\\\\n-e CLUSTER_NAME=cluster \\\\\\n-v /data/docker/elasticsearch/data/:/var/lib/elasticsearch \\\\\\n-v /data/docker/elasticsearch/log/:/var/log/elasticsearch \\\\\\n-p 9200 -p 9300 \\\\\\nuser/elasticsearch:2.3.0\",\n  \"cpus\":0.5,\n  \"mem\":128,\n  \"disk\":0,\n  \"instances\":1\n}\n</code></pre>\n", "is_answered": false, "tags": ["docker", "docker-compose", "mesos", "marathon", "mesosphere"], "last_edit_date": 1481013577, "title": "Why Marathon not deleting container from host after destroying UI?", "last_activity_date": 1481013577, "answer_count": 0, "creation_date": 1480941689, "score": 0, "link": "https://stackoverflow.com/questions/40974538/why-marathon-not-deleting-container-from-host-after-destroying-ui", "owner": {"user_id": 4932458, "profile_image": "https://lh4.googleusercontent.com/-jbf1x3YtcL8/AAAAAAAAAAI/AAAAAAAAADA/GmEutmV70q0/photo.jpg?sz=128", "user_type": "registered", "reputation": 7, "link": "https://stackoverflow.com/users/4932458/soma-sekhar-kuruva", "accept_rate": 100, "display_name": "Soma Sekhar Kuruva"}, "view_count": 44, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 40974538}{"body": "<p>I\u2019m doing a POC to deploy Kafka as an application on Mesos Cluster. I came across these 2 codebases on github. One developed by apache-mesos (<a href=\"https://github.com/mesos/kafka\" rel=\"nofollow noreferrer\">github page</a>) &amp; other developed by mesosphere and can run only on DCOS (<a href=\"https://github.com/mesosphere/dcos-kafka-service/\" rel=\"nofollow noreferrer\">github page</a>).</p>\n\n<p>Question: Would like to know if there are any differences between DCOS-Kafka &amp; mesos-Kafka in terms of features and extended functionality.</p>\n\n<p>Regarding Mesos-Kafka:\nI don\u2019t see active participation on github (and some open issues) for mesos-kafka in the past months. Can I assume that the service is robust enough that I can use in production environment? Any Inputs on this would be helpful.</p>\n", "is_answered": true, "title": "difference between dcos-kafka-service and mesos-kafka", "tags": ["apache-kafka", "mesos", "mesosphere", "dcos"], "last_activity_date": 1499196511, "accepted_answer_id": 44912988, "creation_date": 1496856836, "answers": [{"body": "<p>kakfa-mesos is a package that includes a release of Kafka and a custom mesos scheduler that was meant to work around issues with running Kafka as a stateful service on Marathon. I think <a href=\"https://www.confluent.io/blog/making-apache-kafka-elastic-with-apache-mesos/\" rel=\"nofollow noreferrer\">post</a> but confluent is useful. It also includes a RESTful api for doing ops tasks and aims to include these features in the future (this is pulled from the article I linked) </p>\n\n<ul>\n<li>Integrating Kafka commands (e.g. kafka-topics, etc) into the Scheduler so it can be used through the CLI and REST API.</li>\n<li>Auto-scaling clusters (including auto reassignment of partitions) so that the resources (CPU, RAM, etc.) that brokers are using can be used elsewhere in known valleys of traffic.</li>\n<li>Rack-aware partition assignment for fault tolerance.</li>\n<li>Hooks so that producers and consumers can also be launched from the Scheduler and managed with the cluster.</li>\n<li>Automated partition reassignment based on load and traffic</li>\n</ul>\n\n<p>I haven't used it in a production environment myself but it has the support of Confluent which is a good sign. </p>\n\n<p>DC/OS Kafka on the other hand is a DC/OS service which will probably only be useful if you are already running or plan on running services through Mesosphere's DC/OS. It also includes an API and a CLI management tool but is less ambitious with additional features. It's current feature set includes</p>\n\n<ul>\n<li>Single-command installation for rapid provisioning</li>\n<li>Multiple clusters for multiple tenancy with DC/OS</li>\n<li>High availability runtime configuration and software updates</li>\n<li>Storage volumes for enhanced data durability, known as Mesos Dynamic * * Reservations and Persistent Volumes</li>\n<li>Integration with syslog-compatible logging services for diagnostics and troubleshooting</li>\n<li>Integration with statsd-compatible metrics services for capacity and performance monitoring</li>\n</ul>\n", "answer_id": 44912988, "last_activity_date": 1499196511, "creation_date": 1499196511, "score": 0, "owner": {"user_id": 4175046, "profile_image": "https://www.gravatar.com/avatar/aab1e032261adbd0503af525909be1a4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 74, "link": "https://stackoverflow.com/users/4175046/william-hammond", "display_name": "William Hammond"}, "is_accepted": true, "question_id": 44419288}], "score": 3, "link": "https://stackoverflow.com/questions/44419288/difference-between-dcos-kafka-service-and-mesos-kafka", "answer_count": 1, "owner": {"user_id": 1579792, "profile_image": "https://www.gravatar.com/avatar/e8090139f031a5feb694e4fba55fdcd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 18, "link": "https://stackoverflow.com/users/1579792/satya-karthik", "display_name": "satya karthik"}, "view_count": 83, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44419288}{"is_answered": true, "tags": ["command-line-interface", "apache-kafka", "apache-zookeeper", "mesosphere", "dcos"], "title": "Kafka CLI in DC/OS Mesosphere", "last_activity_date": 1478934116, "answer_count": 1, "creation_date": 1478817912, "score": 0, "link": "https://stackoverflow.com/questions/40538332/kafka-cli-in-dc-os-mesosphere", "accepted_answer_id": 40539150, "owner": {"user_id": 5776153, "profile_image": "https://lh6.googleusercontent.com/-AyKgvKwjOoI/AAAAAAAAAAI/AAAAAAAAlgc/5kakE8XljaA/photo.jpg?sz=128", "user_type": "registered", "reputation": 35, "link": "https://stackoverflow.com/users/5776153/barsha-shrestha", "display_name": "barsha shrestha"}, "view_count": 172, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 40538332}{"body": "<p>I am just starting to try out Mesos.  I followed the instructions to get the master installed.  For now, I am using a single master (with 3 slaves).  I am installing on CentOS 6.5 - which is a Virtual Machine, terminal only.</p>\n\n<p>The problem I am having is that if I navigate to port 5050 on that virtual machine from my desktop browser, I get no response.</p>\n\n<p>However, from a terminal window if I do:</p>\n\n<pre><code>curl http://localhost:5050/\n</code></pre>\n\n<p>I get back an AngularJS page.  Which looks in part like:</p>\n\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\" ng-app=\"mesos\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;title&gt;Mesos&lt;/title&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;meta name=\"description\" content=\"\"&gt;\n    &lt;meta name=\"author\" content=\"\"&gt;\n\n    &lt;link href=\"/static/css/bootstrap-3.0.3.min.css\" rel=\"stylesheet\"&gt;\n    &lt;link href=\"/static/css/mesos.css\" rel=\"stylesheet\"&gt;\n\n    &lt;link rel=\"shortcut icon\" href=\"/static/ico/favicon.ico\"&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;div data-ng-show=\"doneLoading\" style=\"width: 75px; margin: 0 auto; text-align: center;\"&gt; \n</code></pre>\n\n<p>If I ping the VM from my desktop, that works fine too.  However, if I use the curl command from my desktop (using the 'IP ADDRESS':5050), I get \"couldn't connect to host\"</p>\n\n<p>Anyone with suggestions on what I might try to get this to work properly?</p>\n\n<p><strong>New Information</strong></p>\n\n<p>I ran netstat on the VM.  It gives me:</p>\n\n<pre><code>netstat -tapen | grep 5050\ntcp        0      0 0.0.0.0:5050                0.0.0.0:*          LISTEN      0        21589      2852/mesos-master   \n</code></pre>\n\n<p>I suspect that is telling me what is wrong, but not sure how to fix it!  Also, running nmap from my desktop machine and scanning ports 5000-5100 on the VM shows all 101 ports closed.</p>\n", "is_answered": true, "title": "Mesos master setup, but home page does not return", "last_edit_date": 1420045639, "tags": ["mesos", "mesosphere"], "view_count": 193, "accepted_answer_id": 27733724, "last_activity_date": 1420139096, "answers": [{"body": "<p>Depends on what VM networking mode you're using. If the VM has an external IP (like 10.0.2.15), then you may be able to reach Mesos on <code>http://10.0.2.15:5050</code>, otherwise you may need to set up port forwarding or bridged/host-only networking modes. Check out this article on VM (virtualbox) networking for more info: <a href=\"https://blogs.oracle.com/fatbloke/entry/networking_in_virtualbox1\" rel=\"nofollow\">https://blogs.oracle.com/fatbloke/entry/networking_in_virtualbox1</a></p>\n", "answer_id": 27733724, "last_activity_date": 1420139096, "creation_date": 1420139096, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 27723997}], "score": 0, "link": "https://stackoverflow.com/questions/27723997/mesos-master-setup-but-home-page-does-not-return", "answer_count": 1, "owner": {"user_id": 1538856, "profile_image": "https://www.gravatar.com/avatar/88c3d6e99e36ef817078d4c168c9f8e5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2552, "link": "https://stackoverflow.com/users/1538856/joeg", "accept_rate": 81, "display_name": "JoeG"}, "creation_date": 1420044968, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 27723997}{"body": "<p>I have been successful till completely dockerizing my webserver application. Now I want to explore more by deploying them directly to a mesos slave through marathon framework.\nI can deploy a docker container in to a marathon in two different approaches , either command line or through marathon web UI.\nBoth worked for me but challenge is when I am trying to deploy my docker image, marathon frequently restarting a job and in mesos UI page I can see many finished job for the same container. Close to 10 tasks per minute. Which is not expected I believe.</p>\n\n<p>My docker file looks like below:</p>\n\n<pre><code>FROM ubuntu:latest\n\n#---------- file Author / Maintainer\nMAINTAINER \"abc\"\n\n#---------- update the repository sources list\nRUN apt-get update &amp;&amp; apt-get install -y \\\napache2 \\\ncurl \\\nopenssl \\\nphp5 \\\nphp5-mcrypt \\\nunzip  \n\n#--------- installing  composer\nRUN curl -sS https://getcomposer.org/installer | php\nRUN mv composer.phar /usr/local/bin/composer\nRUN a2enmod rewrite\n\n#--------- modifying the 000default file\nCOPY ./ /var/www/airavata-php-gateway\nWORKDIR /etc/apache2/sites-available/ \nRUN sed -i 's/&lt;\\/VirtualHost&gt;/&lt;Directory \"\\/var\\/www\"&gt; \\n AllowOverride All \\n &lt;\\/Directory&gt; \\n &lt;\\/VirtualHost&gt;/g'  000-default.conf \nRUN sed -i 's/DocumentRoot \\/var\\/www\\/html/DocumentRoot \\/var\\/www/g'  000-default.conf\n\nWORKDIR /etc/php5/mods-available/ \nRUN sed -i 's/extension=mcrypt.so/extension=\\/usr\\/lib\\/php5\\/20121212\\/mcrypt.so/g' mcrypt.ini \nWORKDIR /var/www/airavata-php-gateway/\nRUN php5enmod mcrypt\n\n#--------- making storage folder writable\nRUN chmod -R 777 /var/www/airavata-php-gateway/app/storage\n\n#-------- starting command\nCMD [\"sh\", \"-c\", \"sh pga-setup.sh ; service apache2 restart ; /bin/bash\"]\n\n#--------- exposing apache to default port\nEXPOSE 80\n</code></pre>\n\n<p>Now I am clueless how to resolve this issue,any guidance will be highly appreciated.\nThanks</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "frequent restart - docker containers in marathon/mesos", "last_activity_date": 1438154320, "answer_count": 1, "creation_date": 1438102413, "score": 1, "link": "https://stackoverflow.com/questions/31682597/frequent-restart-docker-containers-in-marathon-mesos", "answers": [{"body": "<p>Marathon is meant to run long-running tasks. So in your case, if you start a Docker container that does not keep listening on a specific port, meaning it exits successfully or unsuccessfully, Marathon will start it again.</p>\n\n<p>For example, I started a Docker container using the simplest image <code>hello-world</code>. That generated more than 10 processes in Mesos UI in a matter of seconds! This was expected. Code inside Docker container was executing successfully and exiting normally. And since it exited, Marathon made sure that another instance of the app was started immediately.</p>\n\n<p>On the other hand, when I start an nginx container which keeps listening on port 80, it becomes a long running task and a new task (Docker container) is spun up only when the existing container exits (successfully or unsuccessfully).</p>\n\n<p>You probably need to work on the <code>CMD</code> section of your Dockerfile. Does the container in question keep running when started normally? That is, without Marathon - just using plain <code>docker run</code>? If yes, check if it keeps running in detached mode - <code>docker run -d</code>. If it exits, then <code>CMD</code> is the part you need to work on.</p>\n", "answer_id": 31693724, "last_activity_date": 1438154320, "creation_date": 1438154320, "score": 0, "owner": {"user_id": 395670, "profile_image": "https://i.stack.imgur.com/ANDAD.jpg?s=128&g=1", "user_type": "registered", "reputation": 1336, "link": "https://stackoverflow.com/users/395670/dharmit", "accept_rate": 77, "display_name": "Dharmit"}, "is_accepted": false, "question_id": 31682597}], "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 1025, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31682597}{"is_answered": false, "tags": ["apache-zookeeper", "mesosphere"], "title": "Chronos + Mesosphere. How to execute tasks in parallel?", "last_activity_date": 1414656838, "answer_count": 2, "creation_date": 1412177543, "score": 0, "link": "https://stackoverflow.com/questions/26144992/chronos-mesosphere-how-to-execute-tasks-in-parallel", "owner": {"user_id": 1395576, "profile_image": "https://www.gravatar.com/avatar/82d67cc7623b35d4392a87babfe6226d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 86, "link": "https://stackoverflow.com/users/1395576/parttimeninja", "accept_rate": 43, "display_name": "partTimeNinja"}, "view_count": 557, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 26144992}{"is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "title": "Fig / Docker-Compose-like JSON to feed into Mesosphere/Marathon to setup Multi-Tier Application", "last_activity_date": 1430565898, "answer_count": 1, "creation_date": 1430506348, "score": 6, "link": "https://stackoverflow.com/questions/29993194/fig-docker-compose-like-json-to-feed-into-mesosphere-marathon-to-setup-multi-t", "accepted_answer_id": 30001700, "owner": {"user_id": 2362699, "profile_image": "https://www.gravatar.com/avatar/72ff3403c968926e53a05eb04f35a357?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/2362699/user2362699", "accept_rate": 43, "display_name": "user2362699"}, "view_count": 1316, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 29993194}{"is_answered": true, "tags": ["docker", "vagrant", "dcos"], "last_edit_date": 1462629290, "title": "zsh: command not found: dcos", "last_activity_date": 1462815707, "answer_count": 2, "creation_date": 1462603578, "score": 1, "link": "https://stackoverflow.com/questions/37085420/zsh-command-not-found-dcos", "accepted_answer_id": 37089485, "owner": {"user_id": 1805902, "profile_image": "https://i.stack.imgur.com/0W7rW.png?s=128&g=1", "user_type": "registered", "reputation": 4708, "link": "https://stackoverflow.com/users/1805902/pangpang", "accept_rate": 93, "display_name": "pangpang"}, "view_count": 755, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 37085420}{"body": "<p>I deployed a service on DC/OS with the following config</p>\n\n<p><a href=\"https://i.stack.imgur.com/di0Ls.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/di0Ls.png\" alt=\"enter image description here\"></a></p>\n\n<p>when I access this address (<a href=\"http://eureka.marathon.l4lb.thisdcos.directory:8761/\" rel=\"nofollow noreferrer\">http://eureka.marathon.l4lb.thisdcos.directory:8761/</a>) it says the site can't be reached, although all services are healthy on my dashboard.<br>\nHow can I access the public IP of the service?</p>\n\n<p>I don't know if it is related or not but when I look into the load balancing config of my public slaves, I get <code>0 of 2 instances in service</code></p>\n", "is_answered": true, "title": "Access public address of a DC/OS service", "last_edit_date": 1478549647, "tags": ["marathon", "dcos"], "view_count": 234, "accepted_answer_id": 40473617, "last_activity_date": 1493426594, "answers": [{"body": "<p>in windows command prompt(administrator mode) type \"nslookup domain of service\".\nIn your case \"nslookup eureka.marathon.l4lb.thisdcos.directory\". In your case it will provide all instance ip address.</p>\n\n<p>if your service deployed properly it will give you all instance ip address.</p>\n", "answer_id": 40466787, "last_activity_date": 1478526442, "creation_date": 1478526442, "score": 0, "owner": {"user_id": 6304363, "profile_image": "https://www.gravatar.com/avatar/02e59cf2f213be9d00d99f8a8f58afa7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 19, "link": "https://stackoverflow.com/users/6304363/tango", "display_name": "tango"}, "is_accepted": false, "question_id": 40466674}, {"body": "<p><code>&lt;vip-name&gt;.marathon.l4lb.thisdcos.directory:&lt;vip-port&gt;</code> is the internal named virtual IP, configured with the <code>VIP_0</code> env var in your example.</p>\n\n<p>VIPs are not externally exposed. They are made possible via layer 4 name and IP mapping performed by DC/OS components on each node.</p>\n\n<p>In order to expose a public address you have a few options:</p>\n\n<ol>\n<li><a href=\"https://dcos.io/docs/1.8/usage/tutorials/public-app/\" rel=\"nofollow noreferrer\">Deploy your app on a public node</a></li>\n<li><a href=\"https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/marathon-lb-basic-tutorial/\" rel=\"nofollow noreferrer\">Deploy Marathon_LB on a public node and configure your app to be exposed via a virtual host</a></li>\n<li>Set up your own reverse proxy on a public node</li>\n<li>Make all your private nodes publicly accessible and then use the host agent node IP and host port</li>\n<li>If your app is a Mesos framework, it can register a <code>webui_url</code> for <a href=\"https://dcos.io/docs/1.8/development/dcos-integration/#framework-web-ui-url\" rel=\"nofollow noreferrer\">administrative access via the admin router</a>.</li>\n</ol>\n", "answer_id": 40473617, "last_activity_date": 1493426594, "creation_date": 1478548909, "score": 5, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "last_edit_date": 1493426594, "question_id": 40466674}], "score": 4, "link": "https://stackoverflow.com/questions/40466674/access-public-address-of-a-dc-os-service", "answer_count": 2, "owner": {"user_id": 587406, "profile_image": "https://www.gravatar.com/avatar/02a20fe4dfe590751c91892f76acc960?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2609, "link": "https://stackoverflow.com/users/587406/luiz-e", "accept_rate": 89, "display_name": "Luiz E."}, "creation_date": 1478526131, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 40466674}{"body": "<p>I was following this <a href=\"https://docs.mesosphere.com/1.8/usage/service-guides/spark/spark-shell/\" rel=\"nofollow noreferrer\">interactive Spark Shell tutorial</a> but I was getting this error. could you help pls.</p>\n\n<pre><code>root@ip-10-0-1-240:/opt/spark/dist# ./bin/spark-shell --master mesos://10.0.1.240:5050 --conf spark.mesos.executor.docker.image=mesosphere/spark:1.0.4-2.0.1 --conf spark.mesos.executor.home=/opt/spark/dist\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel).\n17/03/11 19:51:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nI0311 19:51:54.263944   110 sched.cpp:226] Version: 1.0.1\nI0311 19:51:54.266858   106 sched.cpp:330] New master detected at master@10.0.1.240:5050\nI0311 19:51:54.267210   106 sched.cpp:341] No credentials provided. Attempting to register without authentication\nE0311 19:51:54.267364   109 process.cpp:2145] Failed to shutdown socket with fd 229: Transport endpoint is not connected\n</code></pre>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "spark mesos Transport endpoint is not connected", "last_activity_date": 1489262385, "answer_count": 0, "creation_date": 1489262385, "score": 0, "link": "https://stackoverflow.com/questions/42739956/spark-mesos-transport-endpoint-is-not-connected", "owner": {"user_id": 455806, "profile_image": "https://www.gravatar.com/avatar/34943eaf195270666803a4b4ef973067?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 274, "link": "https://stackoverflow.com/users/455806/hamed", "accept_rate": 0, "display_name": "hamed"}, "view_count": 101, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42739956}{"body": "<p>Anyone knows how to install the package cli command, e.g. \"dcos spark\", after the package itself was installed via the DCOS web interface?  Thx.</p>\n", "is_answered": true, "title": "DC/OS package install Web UI & CLI subcommand", "last_edit_date": 1463663040, "tags": ["mesosphere", "dcos"], "view_count": 155, "accepted_answer_id": 37324094, "last_activity_date": 1463663113, "answers": [{"body": "<p>By using the <code>--cli</code> option with <code>dcos package install</code> as per the <a href=\"https://dcos.io/docs/1.7/usage/cli/command-reference/\" rel=\"nofollow\">CLI Reference</a>.</p>\n", "answer_id": 37324094, "last_activity_date": 1463663113, "creation_date": 1463663113, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 37318904}], "score": 1, "link": "https://stackoverflow.com/questions/37318904/dc-os-package-install-web-ui-cli-subcommand", "answer_count": 1, "owner": {"user_id": 1059610, "profile_image": "https://www.gravatar.com/avatar/6a04ed8e4d6e027f3f6ae67c8e470275?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 167, "link": "https://stackoverflow.com/users/1059610/1001b", "accept_rate": 83, "display_name": "1001b"}, "creation_date": 1463649486, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37318904}{"body": "<p>I have a Spark application that uses Cassandra. I want to setup a co-located deployment so that the Spark nodes will have local access to C* to improve performance. In a traditional setup, I would've installed C* manually on my servers and then install Spark standalone on those same nodes.</p>\n\n<p>But I would like to make use of Apache Mesos to manage my cluster. Is there anyway in Mesos to get this done, so that Mesos will run both C* and Spark on the same nodes?  </p>\n", "is_answered": true, "title": "Co-Locating Spark & Cassandra with Mesos", "tags": ["cassandra", "apache-spark", "mesos", "mesosphere"], "last_activity_date": 1441032089, "accepted_answer_id": 32313899, "creation_date": 1440908463, "answers": [{"body": "<p>I looked up a bit more and it seems to me now that the constraints in Marathon is the way to do this. In case anyone else is looking for the same, Marathon constraints documentation explains this well.</p>\n\n<p><a href=\"https://github.com/mesosphere/marathon/blob/master/docs/docs/constraints.md\" rel=\"nofollow\">https://github.com/mesosphere/marathon/blob/master/docs/docs/constraints.md</a></p>\n", "answer_id": 32293816, "last_activity_date": 1440915564, "creation_date": 1440915564, "score": 0, "owner": {"user_id": 279320, "profile_image": "https://www.gravatar.com/avatar/8d29260ebfd4460f660d512f020d6a5e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4013, "link": "https://stackoverflow.com/users/279320/yohan-liyanage", "accept_rate": 76, "display_name": "Yohan Liyanage"}, "is_accepted": false, "question_id": 32293117}, {"body": "<p>I'm not sure Marathon constraints do the job if you use Spark framework for Mesos, because it's always a framework's scheduler which decides where to launch tasks. You may try to launch C* and Spark jobs on same nodes via Marathon only, but it may not be as flexible as using dedicated frameworks. We have ideas to address locality in so-called \"Infrastructure frameworks\", but this is WIP.</p>\n", "answer_id": 32313899, "last_activity_date": 1441032089, "creation_date": 1441032089, "score": 2, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": true, "question_id": 32293117}], "score": 2, "link": "https://stackoverflow.com/questions/32293117/co-locating-spark-cassandra-with-mesos", "answer_count": 2, "owner": {"user_id": 279320, "profile_image": "https://www.gravatar.com/avatar/8d29260ebfd4460f660d512f020d6a5e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4013, "link": "https://stackoverflow.com/users/279320/yohan-liyanage", "accept_rate": 76, "display_name": "Yohan Liyanage"}, "view_count": 338, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32293117}{"body": "<p>I'm running DC/OS 1.7 with marathon-lb.</p>\n\n<p>spray.io 1.3.3 is returning 400 to all marathon-lb/HAProxy heath check calls: <code>request has a relative URI and is missing a Host header</code> so marathon-lb never routes any requests to the service.</p>\n\n<p>The health check in the marathon json is:</p>\n\n<pre><code>   \"healthChecks\": [\n     {\n       \"path\": \"/health\",\n       \"protocol\": \"HTTP\",\n       \"portIndex\": 0,\n       \"gracePeriodSeconds\": 10,\n       \"intervalSeconds\": 2,\n       \"timeoutSeconds\": 10,\n       \"maxConsecutiveFailures\": 10,\n       \"ignoreHttp1xx\": false\n     }   ],\n</code></pre>\n\n<p>and the logging by spray.io in the docker container is:</p>\n\n<blockquote>\n  <p>[WARN] [08/19/2016 23:53:42.534]\n  [asp-service-akka.actor.default-dispatcher-5]\n  [akka://asp-service/user/IO-HTTP/listener-0/4] Illegal request,\n  responding with status '400 Bad Request': Illegal request: Cannot\n  establish effective request URI of\n  HttpRequest(GET,/health,List(),Empty,HTTP/1.0), request has a relative\n  URI and is missing a <code>Host</code> header</p>\n</blockquote>\n\n<p>The <code>/health</code> endpoint works fine from curl against the mesos managed ip:port.</p>\n\n<p>I can't find any docs on making HAProxy via marathon-lb more forgiving or suppressing spray.io's 400.</p>\n\n<p><a href=\"https://i.stack.imgur.com/sOCBR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/sOCBR.png\" alt=\"enter image description here\"></a></p>\n", "is_answered": true, "title": "marathon-lb health check failing on all spray.io containers", "last_edit_date": 1471653347, "tags": ["spray", "mesosphere", "marathon", "dcos"], "view_count": 251, "accepted_answer_id": 39090339, "last_activity_date": 1471909723, "answers": [{"body": "<p>Please try to add the <code>HAPROXY_BACKEND_HTTP_HEALTHCHECK_OPTIONS</code> label, you can try to replace <code>www</code> with <code>{hostname}</code> in this example:\n<a href=\"https://github.com/mesosphere/marathon-lb/wiki#custom-http-headers-in-health-check\" rel=\"nofollow\">https://github.com/mesosphere/marathon-lb/wiki#custom-http-headers-in-health-check</a></p>\n\n<p>Additional links:</p>\n\n<ol>\n<li><a href=\"https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#haproxy_backend_http_healthcheck_options\" rel=\"nofollow\">https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#haproxy_backend_http_healthcheck_options</a></li>\n<li><a href=\"https://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4.2-option%20httpchk\" rel=\"nofollow\">https://cbonte.github.io/haproxy-dconv/1.6/configuration.html#4.2-option%20httpchk</a></li>\n</ol>\n", "answer_id": 39059636, "last_activity_date": 1471737976, "creation_date": 1471736468, "score": 1, "owner": {"user_id": 3052074, "profile_image": "https://www.gravatar.com/avatar/619c2a3b094423dd741dc8eb161836f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 330, "link": "https://stackoverflow.com/users/3052074/andrey-dyatlov", "display_name": "Andrey Dyatlov"}, "is_accepted": false, "last_edit_date": 1471737976, "question_id": 39049235}, {"body": "<p>from the mesosphere team, sends the hostname in header via the <code>\"labels\": {</code> section in the marathon json:</p>\n\n<pre><code>    \"HAPROXY_0_BACKEND_HTTP_HEALTHCHECK_OPTIONS\": \"  http-send-name-header Host\\n  timeout check {healthCheckTimeoutSeconds}s\\n\"\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/mAPLS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/mAPLS.png\" alt=\"enter image description here\"></a></p>\n", "answer_id": 39090339, "last_activity_date": 1471909723, "creation_date": 1471909723, "score": 3, "owner": {"user_id": 7223, "profile_image": "https://www.gravatar.com/avatar/3ba7e831b71e59f6904d09a47f1973b6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 663, "link": "https://stackoverflow.com/users/7223/navicore", "accept_rate": 87, "display_name": "navicore"}, "is_accepted": true, "question_id": 39049235}], "score": 1, "link": "https://stackoverflow.com/questions/39049235/marathon-lb-health-check-failing-on-all-spray-io-containers", "answer_count": 2, "owner": {"user_id": 7223, "profile_image": "https://www.gravatar.com/avatar/3ba7e831b71e59f6904d09a47f1973b6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 663, "link": "https://stackoverflow.com/users/7223/navicore", "accept_rate": 87, "display_name": "navicore"}, "creation_date": 1471651773, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39049235}{"body": "<p>In Dcos on premises , How outside world reach to docker container if we are using <strong>mesos-dns for service discovery</strong> ?</p>\n\n<p>Lets say my mesos domain  is marathon.mesos\nI have deployed Nginx container using Marathon framework and mesos-dns discover as \"nginx.marathon.mesos\" . Within the cluster i can access <a href=\"http://nginx.marathon.mesos\" rel=\"nofollow\">http://nginx.marathon.mesos</a> via web brower , thats no issue. </p>\n\n<p>But in outside the cluster( in public world) that nginx container server need to present as \"abc.xyz.com\" \nwhen someone type abc.xyz.com , <strong>traffic should route to nginx container</strong>, If i use mesos-dns for service discovery how can we deal with this scenario ?</p>\n", "is_answered": false, "tags": ["docker", "haproxy", "mesos", "mesosphere"], "title": "Dcos on premises , How out side world reach to docker container if we are using mesos-dns?", "last_activity_date": 1448163880, "answer_count": 2, "creation_date": 1436685410, "score": 0, "link": "https://stackoverflow.com/questions/31365377/dcos-on-premises-how-out-side-world-reach-to-docker-container-if-we-are-using", "answers": [{"body": "<p>In order to achieve that you would need to setup a node with a public IP and run a task with a reverse proxy on there (like in the tutorials) that forwards to the internal mesos dns backed service.</p>\n\n<p>If you have more questions or need follow up on this one, please contact mesosphere support.</p>\n", "answer_id": 31379153, "last_activity_date": 1436777808, "creation_date": 1436777808, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 31365377}, {"body": "<p>I have resoved this problem. you can refer the document,<a href=\"https://docs.mesosphere.com/tutorials/publicapp/\" rel=\"nofollow\">https://docs.mesosphere.com/tutorials/publicapp/</a> \nIf your app running on port:80, you can access from the public slave node's domain.</p>\n\n<p>If you have any question , you can reply to me.</p>\n", "answer_id": 33851369, "last_activity_date": 1448163880, "creation_date": 1448163880, "score": 0, "owner": {"user_id": 4336108, "profile_image": "https://i.stack.imgur.com/YbIA0.png?s=128&g=1", "user_type": "registered", "reputation": 184, "link": "https://stackoverflow.com/users/4336108/hao-kang", "display_name": "Hao Kang"}, "is_accepted": false, "question_id": 31365377}], "owner": {"user_id": 5107411, "profile_image": "https://www.gravatar.com/avatar/1487b6ebdcb60777c963ec8d295396c8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/5107411/dumiya", "display_name": "Dumiya"}, "view_count": 422, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 31365377}{"body": "<p>I am trying to set up Apache Spark to run on Mesos, but I get the following message on terminal:</p>\n\n<blockquote>\n  <p>W0309 10:37:10.570291  4017 sched.cpp:700] Ignoring framework registered message because it was sent from 'master@127.0.1.1:5050' instead of the leading master 'master@127.0.0.1:5050'</p>\n</blockquote>\n\n<p>This message keeps appearing on the spark-shell and I am not able to run any command. I started spark-shell using the command:</p>\n\n<pre><code>./bin/spark-shell --master mesos://127.0.0.1:5050 --conf spark.executor.uri=/home/user/spark/spark-1.6.0-bin-hadoop2.6.tgz\n</code></pre>\n\n<p>When I check the Framework tab on Mesos WebUI, Spark Shell is listed as a framework.</p>\n\n<p>Any idea on why I faced the above message and cannot run commands from spark-shell? Or, any good reference to run Spark on Mesos?</p>\n", "is_answered": true, "title": "How to connect spark-shell to Mesos?", "last_edit_date": 1459484642, "tags": ["apache-spark", "apache-spark-sql", "mesos", "mesosphere"], "view_count": 637, "accepted_answer_id": 35894398, "last_activity_date": 1459484642, "answers": [{"body": "<p>I'll be doing a bit of quess work here but I'm assuming you did not specify an <code>--ip</code> parameter when starting <code>mesos-master.sh</code>. In such case you should change your startup script to:</p>\n\n<p><code>./bin/spark-shell --master mesos://127.0.1.1:5050 --conf spark.executor.uri=/home/user/spark/spark-1.6.0-bin-hadoop2.6.tgz</code></p>\n\n<p>I'm guessing you have a <code>127.0.1.1</code> entry in your <code>/etc/hosts</code> (or whichever file is used for that resolution on your system) and Mesos is resolving to <code>127.0.1.1</code> by default. You can use the <code>ip</code> parameter to change it to <code>127.0.0.1</code> if you prefer for some reason.</p>\n", "answer_id": 35894398, "last_activity_date": 1457534919, "creation_date": 1457533838, "score": 2, "owner": {"user_id": 217019, "profile_image": "https://www.gravatar.com/avatar/ede807eedb7fe77242664741f91627f7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9983, "link": "https://stackoverflow.com/users/217019/mateusz-dymczyk", "accept_rate": 90, "display_name": "Mateusz Dymczyk"}, "is_accepted": true, "last_edit_date": 1457534919, "question_id": 35893506}], "score": 4, "link": "https://stackoverflow.com/questions/35893506/how-to-connect-spark-shell-to-mesos", "answer_count": 1, "owner": {"user_id": 6039705, "profile_image": "https://www.gravatar.com/avatar/4a7c4adda1e0b71cdd679cf9c9ccf29c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/6039705/juniorstack2", "display_name": "JuniorStack2"}, "creation_date": 1457531515, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 35893506}{"is_answered": true, "tags": ["dcos"], "title": "How to utilize disk space of Amazon EBS attached to a DCOS Agent machine", "last_activity_date": 1483735366, "answer_count": 1, "creation_date": 1483611819, "score": 0, "link": "https://stackoverflow.com/questions/41482499/how-to-utilize-disk-space-of-amazon-ebs-attached-to-a-dcos-agent-machine", "accepted_answer_id": 41514030, "owner": {"user_id": 1642790, "profile_image": "https://i.stack.imgur.com/OvpjC.jpg?s=128&g=1", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/1642790/pjesudhas", "accept_rate": 71, "display_name": "pjesudhas"}, "view_count": 97, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41482499}{"body": "<p>Is it possible to run Impala on Mesos? </p>\n\n<p>Has anyone tried this before? </p>\n\n<p>I know there is <a href=\"http://cloudera.github.io/llama/\" rel=\"nofollow\">Llama</a> for running Impala on YARN. Is there something similar with Mesos? </p>\n", "is_answered": true, "title": "Running Impala on Mesos", "tags": ["hadoop", "impala", "mesos", "mesosphere"], "last_activity_date": 1414657113, "accepted_answer_id": 26648019, "creation_date": 1411449178, "answers": [{"body": "<p>Haven't heard of anybody running Impala on Mesos, although it shouldn't be too hard to run it on Marathon or build a custom framework for it.</p>\n\n<p>You could also run Impala on Llama on YARN on <a href=\"https://github.com/mesos/myriad\" rel=\"nofollow\">Myriad</a> on Mesos, but that might be too many layers for you.</p>\n", "answer_id": 26648019, "last_activity_date": 1414657113, "creation_date": 1414657113, "score": 4, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 25987334}], "score": 1, "link": "https://stackoverflow.com/questions/25987334/running-impala-on-mesos", "answer_count": 1, "owner": {"user_id": 744415, "profile_image": "https://www.gravatar.com/avatar/5f269f615988885697a78ac4faef307d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 3805, "link": "https://stackoverflow.com/users/744415/nightwolf", "accept_rate": 86, "display_name": "NightWolf"}, "view_count": 478, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 25987334}{"is_answered": true, "tags": ["apache-spark", "spark-streaming", "mesos", "dcos"], "title": "Spark web ui on mesos/dcos", "last_activity_date": 1468419991, "answer_count": 1, "creation_date": 1468394127, "score": 1, "link": "https://stackoverflow.com/questions/38344969/spark-web-ui-on-mesos-dcos", "accepted_answer_id": 38354460, "owner": {"user_id": 4605202, "profile_image": "https://i.stack.imgur.com/1v1HR.jpg?s=128&g=1", "user_type": "registered", "reputation": 67, "link": "https://stackoverflow.com/users/4605202/mananana", "accept_rate": 100, "display_name": "mananana"}, "view_count": 203, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 38344969}{"body": "<p>I have obtained <a href=\"https://s3-us-west-2.amazonaws.com/downloads.dcos.io/dcos/stable/commit/1b43ff7a0b9124db9439299b789f2e2dc3cc086c/cloudformation/multi-master.cloudformation.json\" rel=\"nofollow noreferrer\">the latest DC/OS 1.8.7 CloudFormation template</a> for 3 masters and 5 workers as <a href=\"https://downloads.dcos.io/dcos/stable/aws.html\" rel=\"nofollow noreferrer\">described on their AWS installation page</a>, and deployed it to my organization's AWS account.</p>\n\n<p>My actual implementation cloud-init files are found here:</p>\n\n<ul>\n<li><a href=\"https://gist.github.com/naftulikay/8a327d5205ed18f057e2b33840690698\" rel=\"nofollow noreferrer\">public workers</a></li>\n<li><a href=\"https://gist.github.com/naftulikay/8e3a82d10b2fc5962bde425518bb3af9\" rel=\"nofollow noreferrer\">private \"services\" workers</a></li>\n<li><a href=\"https://gist.github.com/naftulikay/f6a8032857ba3d64315472f670889d33\" rel=\"nofollow noreferrer\">masters</a></li>\n</ul>\n\n<p>This setup works just fine, the workers discover the master and add themselves, I can schedule tasks onto the workers and things seem to just work. ZooKeeper is clustered, etc. Everything looks healthy, everything works, etc.</p>\n\n<p>What is of note is that the only effective differences between the three types of instances are the roles at the bottom of the files:</p>\n\n<p><strong>masters</strong>:</p>\n\n<pre><code>  - path: /etc/mesosphere/roles/master\n    content: \"\"\n\n  - path: /etc/mesosphere/roles/aws_master\n    content: \"\"\n\n  - path: /etc/mesosphere/roles/aws\n    content: \"\"\n</code></pre>\n\n<p><strong>public workers</strong>:</p>\n\n<pre><code>  - path: /etc/mesosphere/roles/slave_public\n    content: \"\"\n\n  - path: /etc/mesosphere/roles/aws\n    content: \"\"\n</code></pre>\n\n<p><strong>services workers</strong>:</p>\n\n<pre><code>  - path: /etc/mesosphere/roles/slave\n    content: \"\"\n\n  - path: /etc/mesosphere/roles/aws\n    content: \"\"\n</code></pre>\n\n<p>If I change any of these roles to anything but <code>slave</code> or <code>slave_public</code>, these instances will never be able to join the DC/OS cluster. Since my requirements here dictate that I need at least four types of roles, this is somewhat of a roadblock.</p>\n\n<p>I need roles for the following:</p>\n\n<ul>\n<li>\u2611 master</li>\n<li>\u2611 public worker</li>\n<li>\u2610 services worker</li>\n<li>\u2610 data worker</li>\n</ul>\n\n<p>Due to my network layout and organizational needs, these extra types aren't negotiable.</p>\n\n<p>Are there some extra steps required to have DC/OS allow additional worker roles?</p>\n", "is_answered": true, "tags": ["amazon-web-services", "mesos", "dcos"], "title": "Workers Unable to Join Cluster, Allowed Role Set?", "last_activity_date": 1481240010, "answer_count": 1, "creation_date": 1481238286, "score": 2, "link": "https://stackoverflow.com/questions/41050379/workers-unable-to-join-cluster-allowed-role-set", "answers": [{"body": "<p>The <code>master</code>, <code>slave</code>, and <code>slave_public</code> arguments are the only ones known by the DC/OS installer. </p>\n\n<p>While <code>slave_public</code> argument does statically allocate all node resources to the <code>slave_public</code> role, the <code>slave</code> argument actually allocates all node resources to the <code>*</code> role, which is used for tasks with no role specified.</p>\n\n<p>In order to assign resources to other roles, there are two methods:</p>\n\n<ol>\n<li>Statically allocate the resources to custom roles by modifying the json content of <code>MESOS_RESOURCES</code> in the <code>/var/lib/dcos/mesos-resources</code> file on each agent node.</li>\n<li>Dynamically allocate the resources to custom roles using the Dynamic Reservation Mesos API: <a href=\"http://mesos.apache.org/documentation/latest/reservation/\" rel=\"nofollow noreferrer\">http://mesos.apache.org/documentation/latest/reservation/</a></li>\n</ol>\n", "answer_id": 41050714, "last_activity_date": 1481240010, "creation_date": 1481240010, "score": 3, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 41050379}], "owner": {"user_id": 128967, "profile_image": "https://www.gravatar.com/avatar/e6ce48656d5e39227a10b37a51754134?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 25871, "link": "https://stackoverflow.com/users/128967/naftuli-kay", "accept_rate": 86, "display_name": "Naftuli Kay"}, "view_count": 62, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 41050379}{"body": "<p>Is there any way to have a Docker-based service on Marathon restart itself at a given time everyday? What I'd like is a way to say something like \"scale to 0 at midnight and scale it to 1 at 6am\" or something like that.</p>\n\n<p>On <a href=\"https://dcos.io/docs/1.8/usage/jobs/\" rel=\"nofollow noreferrer\">DC/OS</a> there is the notion of <code>jobs</code> but it isn't clear to me whether a job can restart a running service.</p>\n", "is_answered": true, "tags": ["marathon", "dcos"], "last_edit_date": 1492244862, "title": "How to restart service at scheduled time in Marathon?", "last_activity_date": 1492353543, "answer_count": 2, "creation_date": 1492100939, "score": 0, "link": "https://stackoverflow.com/questions/43397388/how-to-restart-service-at-scheduled-time-in-marathon", "answers": [{"body": "<p>You can use mesos-chronos for scheduling job.Docker can be scheduled using it.More details at <a href=\"https://mesos.github.io/chronos/\" rel=\"nofollow noreferrer\">https://mesos.github.io/chronos/</a></p>\n", "answer_id": 43434378, "last_activity_date": 1492323811, "creation_date": 1492323811, "score": 0, "owner": {"user_id": 6838838, "profile_image": "https://www.gravatar.com/avatar/063168f6e5477ad7990330b95331d798?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 337, "link": "https://stackoverflow.com/users/6838838/girdhar-sojitra", "display_name": "Girdhar Sojitra"}, "is_accepted": false, "question_id": 43397388}, {"body": "<p>As far as I know Marathon has no such feature, Marathon is used to manage(create/delete/scale/health-check) apps on Mesos cluster as what <code>init</code> process(e.g. Systemd) do for Linux. Scheduled jobs is delegated to other frameworks, <a href=\"https://dcos.io/docs/1.8/usage/jobs/\" rel=\"nofollow noreferrer\">scheduled jobs functionality on CS/OS</a> mentioned in your question is provided by <a href=\"https://github.com/dcos/metronome\" rel=\"nofollow noreferrer\">metronome</a>, and there's also a sophisticated framework <a href=\"https://mesos.github.io/chronos/\" rel=\"nofollow noreferrer\">Chronos</a> to do the same thing, as what <code>crontab</code> job for Linux.</p>\n\n<p>Even Marathon has no built-in features like that, it provides rich <a href=\"https://mesosphere.github.io/marathon/api-console/index.html\" rel=\"nofollow noreferrer\">RESTful APIs</a>, you can easily resolve your problem by using Chronos and Marathon together:</p>\n\n<ol>\n<li>Create a script to stop/start your app through Marathon API</li>\n<li>Create Chronos job to run your script at midnight to stop your app</li>\n<li>Create Chronos job to run your script at 6AM to start app</li>\n</ol>\n", "answer_id": 43434679, "last_activity_date": 1492353543, "creation_date": 1492326319, "score": 1, "owner": {"user_id": 1000254, "profile_image": "https://www.gravatar.com/avatar/e1621f7d5eef73c430632061efdc97b0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3856, "link": "https://stackoverflow.com/users/1000254/shizhz", "accept_rate": 100, "display_name": "shizhz"}, "is_accepted": false, "last_edit_date": 1492353543, "question_id": 43397388}], "owner": {"user_id": 497398, "profile_image": "https://www.gravatar.com/avatar/1dac2c810e7a6d0787aadc020caa4d71?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2260, "link": "https://stackoverflow.com/users/497398/mfirry", "accept_rate": 41, "display_name": "mfirry"}, "view_count": 88, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43397388}{"body": "<p>I have a production DC/OS(v1.8.4) cluster and I am trying to setup a Cassandra cluster inside it. I use Marathon(v1.3.0) to deploy Cassandra nodes. I use the official Docker image of Cassandra and more specifically the 2.2.3 version.</p>\n\n<p><strong>First Case: Deploy Cassandra using HOST mode network - Everything OK</strong></p>\n\n<p>In this case, I first deploy a node that I call cassasndra-seed and it attaches to a physical host with IP 10.32.0.6. From the stdout log of Marathon for this service I can see that \"Node /10.32.0.6 state jump to normal\" and that listen_address and broadcast_address are set to 10.32.0.6. If I check the mesos-dns records using \"_cassandra-seed._tcp.marathon.mesos SRV\" in a master node I can see that the IP that resolves for this service is 10.32.0.6. The node is fully functional and I manage to create a test database. </p>\n\n<pre><code>{\n  \"id\": \"/cassandra-seed\",\n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"HOST\",\n      \"ports\": [7199,7000,7001,9160,9042],\n      \"requirePorts\": true,\n      \"privileged\": true\n    }\n  },\n  \"constraints\": [ [\"hostname\",\"UNIQUE\"] ],\n  \"env\": { \"CASSANDRA_CLUSTER_NAME\": \"democluster\" }\n}\n</code></pre>\n\n<p>Now I add one more node of cassandra using a separate deployment and providing 10.32.0.6 as seed (set \"CASSANDRA_SEEDS\": \"10.32.0.6\" in the env section of the deployment JSON). The new node gets the IP of another physical host (same pattern as before) and manages to gossip with the seed node. Thus, we have a functioning Cassandra cluster.</p>\n\n<pre><code>{\n  \"id\": \"/cassandra\",\n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"HOST\",\n      \"ports\": [7199,7000,7001,9160,9042],\n      \"requirePorts\": true,\n      \"privileged\": true\n    }\n  },\n  \"constraints\": [ [\"hostname\",\"UNIQUE\"] ],\n  \"env\": { \n    \"CASSANDRA_CLUSTER_NAME\": \"democluster\",\n    \"CASSANDRA_SEEDS\": \"10.32.0.6\" \n  }\n}\n</code></pre>\n\n<p><strong>Second Case: Deploy Cassandra using BRIDGE mode network - Houston we have a problem</strong></p>\n\n<p>In this case, I also deploy a first cassandra-seed node and it attaches to a physical host with IP 10.32.0.6. However, now at the stdout log of the service in Marathon I can see that \"Node /172.17.0.2 state jump to normal\" and that listen_address and broadcast_address are set to 172.17.0.2. 172.17.0.2 is the IP of the docker container (found using docker inspect). However, if I check the mesos-dns records using \"_cassandra-seed._tcp.marathon.mesos SRV\" in a master node I can see that the IP that resolves for this service is 10.32.0.6. The node is fully functional and I manage to create a test database. </p>\n\n<pre><code>{\n  \"id\": \"/cassandra-seed\",\n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n      \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\"containerPort\": 7000, \"hostPort\": 7000, \"servicePort\": 0 },\n        {\"containerPort\": 7001, \"hostPort\": 7001, \"servicePort\": 0 },\n        {\"containerPort\": 7199, \"hostPort\": 7199, \"servicePort\": 0 },\n        {\"containerPort\": 9042, \"hostPort\": 9042, \"servicePort\": 0 },\n        {\"containerPort\": 9160, \"hostPort\": 9160, \"servicePort\": 0 },\n      ],\n      \"privileged\": true,\n    }\n  },\n  \"constraints\": [ [ \"hostname\", \"UNIQUE\" ] ],\n  \"env\": {\"CASSANDRA_CLUSTER_NAME\": \"democluster\"}\n}\n</code></pre>\n\n<p>Now I add one more node of cassandra using a separate deployment and providing 10.32.0.6 as seed. The new node attaches to another host and gets the IP of his container (Node /172.17.0.2 state jump to normal). The result is that the new node cannot gossip with the seed.</p>\n\n<pre><code>{\n  \"id\": \"/cassandra\",\n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n      \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\"containerPort\": 7000, \"hostPort\": 7000, \"servicePort\": 0 },\n        {\"containerPort\": 7001, \"hostPort\": 7001, \"servicePort\": 0 },\n        {\"containerPort\": 7199, \"hostPort\": 7199, \"servicePort\": 0 },\n        {\"containerPort\": 9042, \"hostPort\": 9042, \"servicePort\": 0 },\n        {\"containerPort\": 9160, \"hostPort\": 9160, \"servicePort\": 0 },\n      ],\n      \"privileged\": true,\n    }\n  },\n  \"constraints\": [ [ \"hostname\", \"UNIQUE\" ] ],\n  \"env\": { \n    \"CASSANDRA_CLUSTER_NAME\": \"democluster\",\n    \"CASSANDRA_SEEDS\": \"10.32.0.6\" \n  }\n}\n</code></pre>\n\n<p>The question is how could I make the two nodes gossip in the second case? Which is the IP that I should provide as seed to the second node in order to find the first one? The 172.17.0.2 is the docker container IP and cannot be reached by the second node. For example, could cassandra instance in the seed node get the IP of the physical host just like in the host network mode?</p>\n\n<p>Thank you in advance!</p>\n", "is_answered": false, "tags": ["docker", "cassandra", "mesos", "marathon", "dcos"], "last_edit_date": 1484135198, "title": "How to set up Cassandra Docker cluster in Marathon with BRIDGE network?", "last_activity_date": 1497578502, "answer_count": 1, "creation_date": 1484126688, "score": 3, "link": "https://stackoverflow.com/questions/41586960/how-to-set-up-cassandra-docker-cluster-in-marathon-with-bridge-network", "answers": [{"body": "<p>When forming a cassandra cluster in bridge network mode below settinhs should be taken care.\n1. Set below values to host Ip (not container ip)</p>\n\n<p>Seeds : public_ip\nBroadcast_address : public_ip\nBroadcast_rpc_address : public_ip</p>\n\n<ol start=\"2\">\n<li>Set listen_address to container Ip</li>\n</ol>\n\n<p>Listen_address : 172.17.x.x</p>\n\n<p>3 . Set rpc_address to 0.0.0.0 (don't use localhost)</p>\n\n<p>This way we can actually form a Cassandra cluster using bridge network.</p>\n\n<p>Give it a try. Make sure required ports should be accessible from outside world.</p>\n", "answer_id": 44579664, "last_activity_date": 1497578502, "creation_date": 1497578502, "score": 0, "owner": {"user_id": 4711199, "profile_image": "https://www.gravatar.com/avatar/93d8f71e17f0b165aef28864af131ee6?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 43, "link": "https://stackoverflow.com/users/4711199/sandeep", "accept_rate": 25, "display_name": "sandeep"}, "is_accepted": false, "question_id": 41586960}], "owner": {"user_id": 1571583, "profile_image": "https://i.stack.imgur.com/eR0Ux.jpg?s=128&g=1", "user_type": "registered", "reputation": 541, "link": "https://stackoverflow.com/users/1571583/manolis", "accept_rate": 38, "display_name": "Manolis"}, "view_count": 297, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 41586960}{"body": "<p>Wanted to check if any of you uses Mesos API to start and stop the Slave nodes. </p>\n\n<p>I see Mesos API has some options to check the status of slaves, but not sure whether it will allow shutdown from an API. </p>\n\n<p><a href=\"http://mesos.apache.org/documentation/latest/endpoints/master/machine/down/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/endpoints/master/machine/down/</a></p>\n", "is_answered": false, "tags": ["apache", "docker", "mesos", "mesosphere", "dcos"], "title": "Mesos API for starting and stopping Slave nodes", "last_activity_date": 1475511025, "answer_count": 0, "creation_date": 1475511025, "score": 0, "link": "https://stackoverflow.com/questions/39835922/mesos-api-for-starting-and-stopping-slave-nodes", "owner": {"user_id": 6007897, "profile_image": "https://www.gravatar.com/avatar/c28cef0e80457a591b4cde76e7173e58?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 38, "link": "https://stackoverflow.com/users/6007897/cloudninja", "display_name": "cloudninja"}, "view_count": 77, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39835922}{"body": "<p>How can stateful containers be run inside Mesos?</p>\n\n<p>According to the Mesos documentation sandbox can be used to store state:</p>\n\n<blockquote>\n  <p>With the introduction of persistent volumes, executors and tasks\n  should never create files outside of the sandbox.</p>\n</blockquote>\n\n<p>At the same time Sandbox files are scheduled for garbage collection when:</p>\n\n<ul>\n<li>An executor is removed or terminated. </li>\n<li>A framework is removed. </li>\n<li>An executor is recovered unsuccessfully during agent recovery.</li>\n</ul>\n\n<p>Is this the only way? Or can docker containers be used to maintain state (in a similar manner to a VM)?</p>\n\n<p>So for example, can a container be created and run across 2 nodes? Can such a container contain state and not be disposed of after the task is completed?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1473958660, "title": "How to run stateful applications in Apache Mesos?", "last_activity_date": 1481850295, "answer_count": 1, "creation_date": 1473958233, "score": 0, "link": "https://stackoverflow.com/questions/39516435/how-to-run-stateful-applications-in-apache-mesos", "answers": [{"body": "<p>The key statement in that quote from the Mesos documentation is</p>\n\n<blockquote>\n  <p>With the introduction of persistent volumes...</p>\n</blockquote>\n\n<p>You're correct that sandboxes can be garbage collected. However, Mesos provides a primitive called <a href=\"http://mesos.apache.org/documentation/latest/persistent-volume/\" rel=\"nofollow\">persistent volumes</a> which allows you to create volumes that will persist across task failures and agent restarts and will not be garbage collected.</p>\n\n<p>Additionally, Mesos also now provides support for network storage via the <a href=\"http://mesos.apache.org/documentation/latest/docker-volume/\" rel=\"nofollow\">Docker volume isolator</a>. This allows you to mount network volumes using Docker volume drivers, which enables the use of a wide variety of storage back-ends.</p>\n\n<p>Docker containers can store persistent state, but they must do so in either a Mesos persistent volume or a network-attached volume via the Docker volume isolator. These volumes live outside the Docker container and are mounted into the container, so they persist after the container has died.</p>\n\n<p>Mesos tasks cannot be run across multiple nodes. Note that it would be possible for multiple tasks on different nodes to access the same network-attached volume via the Docker volume isolator, provided the back-end storage provider supports concurrent access.</p>\n", "answer_id": 39583326, "last_activity_date": 1474326076, "creation_date": 1474326076, "score": 1, "owner": {"user_id": 3461847, "profile_image": "https://www.gravatar.com/avatar/82b8cb6f44d1503bb2613525023ff73b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/3461847/greggomann", "display_name": "greggomann"}, "is_accepted": false, "question_id": 39516435}], "owner": {"display_name": "user1478046", "user_type": "does_not_exist"}, "view_count": 114, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39516435}{"body": "<p>From what I understand, Kubernetes/Mesosphere is  a cluster manager and Docker Swarm is an orchestration tool. I am trying to understand how they are different? Is Docker Swarm analogous to the POSIX API in the Docker world while Kubernetes/Mesosphere are different implementations? Or are they different layers?</p>\n", "is_answered": true, "title": "What is the difference between Docker Swarm and Kubernetes/Mesophere?", "tags": ["docker", "kubernetes", "mesosphere"], "last_activity_date": 1454073723, "accepted_answer_id": 27342089, "creation_date": 1417890359, "answers": [{"community_owned_date": 1417951144, "body": "<p>Swarm is a very simple add-on to Docker. It currently does not provide all the features of Kubernetes. It is currently hard to predict how the ecosystem of these tools will play out, it's possible that Kubernetes will make use of Swarm.</p>\n", "answer_id": 27342089, "last_activity_date": 1417951144, "creation_date": 1417951144, "score": 8, "owner": {"user_id": 717998, "profile_image": "https://www.gravatar.com/avatar/121dcfb4f05ed316247772545e2cd590?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3655, "link": "https://stackoverflow.com/users/717998/errordeveloper", "accept_rate": 80, "display_name": "errordeveloper"}, "is_accepted": true, "question_id": 27334934}, {"body": "<p><strong>Disclosure: I'm a lead engineer on Kubernetes</strong></p>\n\n<p>Kubernetes is a cluster orchestration system inspired by the container orchestration that runs at Google.  Built by many of the same engineers who built that system. It was designed from the ground up to be an environment for building distributed applications from containers. It includes primitives for replication and service discovery as core primitives, where-as such things are added via frameworks in Mesos. The primary goal of Kubernetes is a system for building, running and managing distributed systems.</p>\n\n<p>Swarm is an effort by Docker to extend the existing Docker API to make a cluster of machines look like a single Docker API. Fundamentally, our experience at Google and elsewhere indicates that the node API is insufficient for a cluster API. You can see a bunch of discussion on this here: <a href=\"https://github.com/docker/docker/pull/8859\" rel=\"noreferrer\">https://github.com/docker/docker/pull/8859</a> and here: <a href=\"https://github.com/docker/docker/issues/8781\" rel=\"noreferrer\">https://github.com/docker/docker/issues/8781</a></p>\n", "answer_id": 29020352, "last_activity_date": 1426195037, "creation_date": 1426195037, "score": 18, "owner": {"user_id": 4175029, "profile_image": "https://www.gravatar.com/avatar/c2ff012ca59db545fb777ea41917504c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2753, "link": "https://stackoverflow.com/users/4175029/brendan", "display_name": "brendan"}, "is_accepted": false, "question_id": 27334934}], "score": 8, "link": "https://stackoverflow.com/questions/27334934/what-is-the-difference-between-docker-swarm-and-kubernetes-mesophere", "answer_count": 2, "owner": {"user_id": 2448805, "profile_image": "https://www.gravatar.com/avatar/978b81ed7d3d71b7b0095447d9fdbdd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 392, "link": "https://stackoverflow.com/users/2448805/debnath-sinha", "accept_rate": 27, "display_name": "Debnath Sinha"}, "view_count": 5455, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 27334934}{"is_answered": false, "tags": ["digital-ocean", "terraform"], "last_edit_date": 1503217884, "title": "Terraform taking long to create DCOS master (digitalocean)", "last_activity_date": 1503217884, "answer_count": 0, "creation_date": 1503185581, "score": 0, "link": "https://stackoverflow.com/questions/45777178/terraform-taking-long-to-create-dcos-master-digitalocean", "owner": {"user_id": 4679199, "profile_image": "https://www.gravatar.com/avatar/024837a166e8fbe5bb734f5001cf57ec?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/4679199/evanilson-abril", "accept_rate": 0, "display_name": "Evanilson Abril"}, "view_count": 18, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45777178}{"is_answered": false, "tags": ["marathon", "dcos"], "last_edit_date": 1504685493, "title": "DCOS doesn&#39;t allocate resources", "last_activity_date": 1504685493, "answer_count": 0, "creation_date": 1504514046, "score": 0, "link": "https://stackoverflow.com/questions/46033184/dcos-doesnt-allocate-resources", "owner": {"user_id": 8483496, "profile_image": "https://www.gravatar.com/avatar/323c44279dbb732bcade69399df2c474?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 18, "link": "https://stackoverflow.com/users/8483496/tomasz", "display_name": "Tomasz"}, "view_count": 25, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 46033184}{"is_answered": true, "tags": ["mesosphere", "prometheus"], "title": "Configure Prometheus nginx exporter on mesosphere DCOS cluster using marathon", "last_activity_date": 1439401668, "answer_count": 1, "creation_date": 1439377635, "score": 0, "link": "https://stackoverflow.com/questions/31963430/configure-prometheus-nginx-exporter-on-mesosphere-dcos-cluster-using-marathon", "accepted_answer_id": 31972074, "owner": {"user_id": 5188802, "profile_image": "https://www.gravatar.com/avatar/96fdffb493ccaef2a9b3bb57a332ffe1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5188802/rajasi-kulkarni", "accept_rate": 100, "display_name": "Rajasi Kulkarni"}, "view_count": 504, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 31963430}{"body": "<p>I've setup a DCOS 1.8 cluster and am currently familiarizing. \nSo far I have marathon-lb working like a charm with Jenkins via Host networking. Now I am trying to set things up using Overlay.\nI have a couple of test containers, some in the dcos overlay network, some not. So far they can reach each other via IP, which is nice. However when I try to resolv containers on the overlay network using mesos-dns, all it resolves is the host address (not exactly what I am expecting). </p>\n\n<p>So I played around some with marathon to figure it out. What I did was add a discovery block to ipAddress:</p>\n\n<pre><code>{\n  \"volumes\": null,\n  \"id\": \"/mariadb10\",\n  \"cmd\": null,\n  \"args\": null,\n  \"user\": null,\n  \"env\": {\n    \"MYSQL_ROOT_PASSWORD\": \"foo\"\n  },\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 1024,\n  \"disk\": 0,\n  \"gpus\": 0,\n  \"executor\": null,\n  \"constraints\": null,\n  \"fetch\": null,\n  \"storeUrls\": null,\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"mariadb:10.0\",\n      \"forcePullImage\": false,\n      \"privileged\": false,\n      \"network\": \"USER\"\n    },\n    \"type\": \"DOCKER\",\n    \"volumes\": [\n      {\n        \"containerPath\": \"/var/lib/mysql\",\n        \"hostPath\": \"/mnt/foo\",\n        \"mode\": \"RW\"\n      }\n    ]\n  },\n  \"healthChecks\": [\n    {\n      \"protocol\": \"TCP\",\n      \"gracePeriodSeconds\": 30,\n      \"intervalSeconds\": 10,\n      \"timeoutSeconds\": 10,\n      \"maxConsecutiveFailures\": 3,\n      \"port\": 3306\n    }\n  ],\n  \"readinessChecks\": null,\n  \"dependencies\": null,\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 1,\n    \"maximumOverCapacity\": 1\n  },\n  \"labels\": null,\n  \"acceptedResourceRoles\": null,\n  \"ipAddress\": {\n    \"networkName\": \"dcos\",\n    \"discovery\": {\n        \"ports\": [\n            { \"number\": 3306, \"name\": \"mysql\", \"protocol\": \"tcp\" }\n            ]\n    }\n  },\n  \"residency\": null,\n  \"secrets\": null,\n  \"taskKillGracePeriodSeconds\": null\n}\n</code></pre>\n\n<p>Marathon tells me this is not allowed with \"Bridge\" or \"User\" networks. However it did not complain about the following and launched the container:</p>\n\n<pre><code>{\n\"volumes\": null,\n\"id\": \"/mariadb10\",\n\"cmd\": null,\n\"args\": null,\n\"user\": null,\n\"env\": {\n  \"MYSQL_ROOT_PASSWORD\": \"foo\"\n},\n\"instances\": 1,\n\"cpus\": 1,\n\"mem\": 1024,\n\"disk\": 0,\n\"gpus\": 0,\n\"executor\": null,\n\"constraints\": null,\n\"fetch\": null,\n\"storeUrls\": null,\n\"backoffSeconds\": 1,\n\"backoffFactor\": 1.15,\n\"maxLaunchDelaySeconds\": 3600,\n\"container\": {\n  \"docker\": {\n    \"image\": \"mariadb:10.0\",\n    \"forcePullImage\": false,\n    \"privileged\": false,\n    \"network\": \"USER\"\n  },\n  \"type\": \"DOCKER\",\n  \"volumes\": [\n    {\n      \"containerPath\": \"/var/lib/mysql\",\n      \"hostPath\": \"/mnt/foo\",\n      \"mode\": \"RW\"\n    }\n  ]\n},\n\"healthChecks\": [\n  {\n    \"protocol\": \"TCP\",\n    \"gracePeriodSeconds\": 30,\n    \"intervalSeconds\": 10,\n    \"timeoutSeconds\": 10,\n    \"maxConsecutiveFailures\": 3,\n    \"port\": 3306\n  }\n],\n\"readinessChecks\": null,\n\"dependencies\": null,\n\"upgradeStrategy\": {\n  \"minimumHealthCapacity\": 1,\n  \"maximumOverCapacity\": 1\n},\n\"labels\": null,\n\"acceptedResourceRoles\": null,\n\"ipAddress\": {\n  \"networkName\": \"dcos\"\n},\n\"residency\": null,\n\"secrets\": null,\n\"taskKillGracePeriodSeconds\": null\n}\n</code></pre>\n\n<p>Funny thing is, it does not use the overlay address anymore, but now listens to the hosts address and also announces the hosts address into the overlay network.</p>\n\n<p>Am I just doing it wrong or does that not work as expected, yet?</p>\n", "is_answered": true, "title": "Service Discovery versus DCOS Overlay Network", "tags": ["mesosphere", "service-discovery", "dcos"], "last_activity_date": 1475362388, "accepted_answer_id": 39720675, "creation_date": 1474466627, "answers": [{"body": "<p>So,</p>\n\n<p>I found the solution myself. The easy workaround is to edit <code>/opt/mesosphere/etc/mesos-dns.json</code>. Then change the order of IPSources to list netinfo first.</p>\n\n<p>For more information, you can also check <a href=\"https://github.com/mesosphere/mesos-dns/issues/474\" rel=\"nofollow\">here</a></p>\n", "answer_id": 39720675, "last_activity_date": 1474967567, "creation_date": 1474967567, "score": 1, "owner": {"user_id": 1649076, "profile_image": "https://www.gravatar.com/avatar/d06c06f469a6c2d73f8fdc1e9e04f452?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 304, "link": "https://stackoverflow.com/users/1649076/juwi", "accept_rate": 100, "display_name": "juwi"}, "is_accepted": true, "question_id": 39618856}, {"body": "<p>Alternatively, you can use <code>taskname.marathon.containerip.dcos.thisdcos.directory</code>. It is documented here: <a href=\"https://docs.mesosphere.com/1.8/administration/overlay-networks/\" rel=\"nofollow\">https://docs.mesosphere.com/1.8/administration/overlay-networks/</a>. </p>\n", "answer_id": 39812207, "last_activity_date": 1475362388, "creation_date": 1475362388, "score": 0, "owner": {"user_id": 10432, "profile_image": "https://www.gravatar.com/avatar/32a4d5002ac47f7b15c573c290912286?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1033, "link": "https://stackoverflow.com/users/10432/sargun-dhillon", "accept_rate": 71, "display_name": "Sargun Dhillon"}, "is_accepted": false, "question_id": 39618856}], "score": 1, "link": "https://stackoverflow.com/questions/39618856/service-discovery-versus-dcos-overlay-network", "answer_count": 2, "owner": {"user_id": 1649076, "profile_image": "https://www.gravatar.com/avatar/d06c06f469a6c2d73f8fdc1e9e04f452?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 304, "link": "https://stackoverflow.com/users/1649076/juwi", "accept_rate": 100, "display_name": "juwi"}, "view_count": 280, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39618856}{"body": "<p>I have a small cluster running DCOS. I'm able to successfully install kafka following <a href=\"https://docs.mesosphere.com/1.7/usage/service-guides/kafka/quick-start/\" rel=\"nofollow\">this</a> guide. running </p>\n\n<pre><code>$ dcos kafka connection\n</code></pre>\n\n<p>gives</p>\n\n<pre><code>{\n  \"address\": [\n    \"10.131.17.126:9475\",\n    \"10.131.24.6:9655\",\n    \"10.131.14.192:9181\"\n  ],\n  \"zookeeper\": \"master.mesos:2181/dcos-service-kafka\",\n  \"dns\": [\n    \"broker-0.kafka.mesos:9475\",\n    \"broker-1.kafka.mesos:9655\",\n    \"broker-2.kafka.mesos:9181\"\n  ]\n}\n</code></pre>\n\n<p>I can create topics and I've examined zookeeper with the cli tool and the state appears to be good</p>\n\n<pre><code>get /dcos-service-kafka/brokers/ids/0\n{\"jmx_port\":-1,\"timestamp\":\"1474206074029\",\"endpoints\":[\"PLAINTEXT://10.131.17.126:9475\"],\"host\":\"10.131.17.126\",\"version\":3,\"port\":9475}\nget /dcos-service-kafka/brokers/ids/1\n{\"jmx_port\":-1,\"timestamp\":\"1474206120002\",\"endpoints\":[\"PLAINTEXT://10.131.24.6:9655\"],\"host\":\"10.131.24.6\",\"version\":3,\"port\":9655}\nget /dcos-service-kafka/brokers/ids/2\n{\"jmx_port\":-1,\"timestamp\":\"1474206122985\",\"endpoints\":[\"PLAINTEXT://10.131.14.192:9181\"],\"host\":\"10.131.14.192\",\"version\":3,\"port\":9181}\n</code></pre>\n\n<p>However when I try publishing</p>\n\n<pre><code>echo \"Hello, World.\" | ./kafka-console-producer.sh --broker-list 10.131.17.126:9475, 10.131.24.6:9655, 10.131.14.192:9181 --topic topic1\n</code></pre>\n\n<p>I get </p>\n\n<pre><code>[2016-09-18 18:49:32,909] ERROR Error when sending message to topic topic1 with key: null, value: 13 bytes with error: Failed to update metadata after 60000 ms. (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)\n</code></pre>\n\n<p>I suspect it might be something to do with private vs. public ip addresses and perhaps host.name in server.properties.</p>\n\n<p>Can anyone give some suggestions as to how I might debug (and hopefully fix!) the problem so I can successfully publish messages?</p>\n\n<p>Thanks</p>\n\n<p>AJ</p>\n", "is_answered": true, "tags": ["apache-kafka", "mesos", "mesosphere", "apache-zookeeper", "dcos"], "last_edit_date": 1474229558, "title": "Problems publishing messages with kafka running on mesos DCOS", "last_activity_date": 1477674318, "answer_count": 2, "creation_date": 1474225387, "score": 0, "link": "https://stackoverflow.com/questions/39561514/problems-publishing-messages-with-kafka-running-on-mesos-dcos", "answers": [{"body": "<p>Edit: For anyone looking in the future.  <a href=\"https://github.com/mesosphere/dcos-kafka-service/issues/259#issuecomment-250155184\" rel=\"nofollow\">This was a problem in /etc/hosts caused by a terraform script</a>.</p>\n\n<p>Your suspicion is correct.  Those are private IP addresses which are not addressable from outside the cluster.  In order to communicate with Kafka you will either have to setup a VPN such that those IP addresses become reachable, or run your publishing command on a machine in the cluster.</p>\n\n<p>Also, it looks like you're running on a DC/OS version earlier than 1.8.  If you use 1.8, you'll get an easier broker endpoint to use, regardless of the dynamically assigned IP addresses.  You can used the named VIP <code>broker.kafka.l4lb.thisdcos.directory:9092</code> however this is only addressable from machines in the cluster.</p>\n\n<p>Setting up haproxy or nginx to point to the named VIP is also a way to get easy external access to a service (in this case Kafka) running on a DC/OS cluster.  You would want to ensure that these proxies run on a public Agent.  <a href=\"https://docs.mesosphere.com/1.8/usage/tutorials/public-app/\" rel=\"nofollow\">See here for more details</a>.</p>\n\n<p>Here is an example of installing, producing and consuming from the default Kafka installation:</p>\n\n<pre><code>~ $ dcos package install kafka\nInstalling Marathon app for package [kafka] version [1.1.11-0.10.0.0]\nInstalling CLI subcommand for package [kafka] version [1.1.11-0.10.0.0]\nNew command available: dcos kafka\nDC/OS Kafka Service is being installed.\n\n        Documentation: https://docs.mesosphere.com/usage/services/kafka/\n        Issues: https://docs.mesosphere.com/support/\n~ $ dcos kafka connection\n{\n  \"address\": [\n    \"10.0.3.64:9951\",\n    \"10.0.3.68:9795\",\n    \"10.0.3.66:9531\"\n  ],\n  \"zookeeper\": \"master.mesos:2181/dcos-service-kafka\",\n  \"dns\": [\n    \"broker-0.kafka.mesos:9951\",\n    \"broker-1.kafka.mesos:9795\",\n    \"broker-2.kafka.mesos:9531\"\n  ],\n  \"vip\": \"broker.kafka.l4lb.thisdcos.directory:9092\"\n}\n~ $ dcos kafka topic create topic0\n{\n  \"message\": \"Output: Created topic \\\"topic0\\\".\\n\"\n}\n~ $ dcos node ssh --master-proxy --leader\ncore@ip-10-0-7-56 ~ $ wget http://download.nextag.com/apache/kafka/0.10.0.1/kafka_2.11-0.10.0.1.tgz\ncore@ip-10-0-7-56 ~ $ tar xf kafka_2.11-0.10.0.1.tgz\ncore@ip-10-0-7-56 ~ $ cd kafka_2.11-0.10.0.1\ncore@ip-10-0-7-56 ~/kafka_2.11-0.10.0.1 $ bin/kafka-console-producer.sh --broker-list broker.kafka.l4lb.thisdcos.directory:9092 --topic topic0\nThis is a message\nThis is another message\n^Ccore@ip-10-0-7-56 ~/kafka_2.11-0.10.0.1 $ bin/kafka-console-consumer.sh --zookeeper master.mesos:2181/dcos-service-kafka --topic topic0 --from-beginning\nThis is a message\nThis is another message\n^CProcessed a total of 2 messages\n$ bin/kafka-console-producer.sh --broker-list 10.0.3.64:9951,10.0.3.68:9795,10.0.3.66:9531 --topic topic0\nfoo\nbar\nbaz\n^Ccore@ip-10-0-7-56 ~/kafka_2.11-0.10.0.1 $ bin/kafka-console-consumer.sh --zookeeper master.mesos:2181/dcos-service-kafka --topic topic0 --from-beginning\nThis is a message\nThis is another message\nfoo\nbar\nbaz\n^CProcessed a total of 5 messages\n</code></pre>\n", "answer_id": 39621923, "last_activity_date": 1477674318, "creation_date": 1474475386, "score": 1, "owner": {"user_id": 332990, "profile_image": "https://i.stack.imgur.com/D1r2v.jpg?s=128&g=1", "user_type": "registered", "reputation": 128, "link": "https://stackoverflow.com/users/332990/gabriel", "display_name": "Gabriel"}, "is_accepted": false, "last_edit_date": 1477674318, "question_id": 39561514}, {"body": "<p>Update - this does appear to have been caused by missing entries in /etc/hosts. I've updated my terraform script to write these during setup and your example above now works as expected.</p>\n\n<p>Thanks for your help</p>\n", "answer_id": 39749008, "last_activity_date": 1475069404, "creation_date": 1475069404, "score": 1, "owner": {"user_id": 2333690, "profile_image": "https://www.gravatar.com/avatar/aef36dc41b8589e06a6e27a59d42302d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 70, "link": "https://stackoverflow.com/users/2333690/andy-johnson", "accept_rate": 33, "display_name": "Andy Johnson"}, "is_accepted": false, "question_id": 39561514}], "owner": {"user_id": 2333690, "profile_image": "https://www.gravatar.com/avatar/aef36dc41b8589e06a6e27a59d42302d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 70, "link": "https://stackoverflow.com/users/2333690/andy-johnson", "accept_rate": 33, "display_name": "Andy Johnson"}, "view_count": 343, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39561514}{"body": "<p>I am trying to set DC/OS Spark-Kafka-Cassandra cluster using 1 master and 3 private AWS m3.xlarge instances (each having 4 processors, 15GB RAM).</p>\n\n<p>I have questions regarding some strange behaviour I have incurred in the spike I did several days ago. </p>\n\n<p>On each of the private nodes I have following <strong>fixed</strong> resources reserved (I speak about CPU usage, memory is not the issue)</p>\n\n<ul>\n<li>0.5 CPUs for Cassandra on <strong>each node</strong></li>\n<li>0.3 - 0.5 CPUs for Kafka one <strong>each node</strong></li>\n<li>0.5 CPUs is the Mesos overhead (I simply see in DC/OS UI that it is occupied 0.5CPUs more than the summation of all the services that are running on a node -> this probably belongs to some sort of Mesos overhead) </li>\n<li>rest of the resources I have available for running Spark jobs (around 2.5 CPUs)</li>\n</ul>\n\n<p>Now, I want to run 2 streaming jobs, so that they run on <strong>every node</strong> of the cluster. This requires me to set in <em>dcos spark run</em> command that number of executors is 3 (although I have 3 nodes in the cluster), as well as that number of CPU cores is 3 (it is impossible to set 1 or 2,because as far as I see minimum CPUs per executor is 1). Of course, for each of the streaming jobs, 1 CPU in the cluster is occupied by the driver program. </p>\n\n<blockquote>\n  <p>First strange situation that I see is that instead of running 3 executors with 1 core each, Mesos launches 2 executors on 2 nodes where one has 2 CPUs, while the other has 1 CPU. There is nothing launched on the 3rd node <strong>even though</strong> there were enough resources. How to force Mesos to run 3 executors on the cluster?</p>\n  \n  <p>Also, when I run 1 pipeline with 3 CPUs, I see that those CPUs are blocked, and cannot be reused by other streaming pipeline, even though they are not doing any workload. Why Mesos can not shift available resources between applications? Isn't that the main benefit of using Mesos? Or maybe simply there are not enough resources to be shifted?</p>\n</blockquote>\n\n<p><strong>EDITED</strong></p>\n\n<p>Also the question is can I assign less than one CPU per Executor?</p>\n\n<p>Kindest regards,</p>\n\n<p>Srdjan</p>\n", "is_answered": false, "tags": ["apache-spark", "spark-streaming", "mesos", "mesosphere", "dcos"], "last_edit_date": 1463585574, "title": "DC/OS SMACK cluster resource management", "last_activity_date": 1463585574, "answer_count": 0, "creation_date": 1463566040, "score": 0, "link": "https://stackoverflow.com/questions/37296431/dc-os-smack-cluster-resource-management", "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "view_count": 105, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37296431}{"body": "<p>I am trying to set up a <strong>mesos</strong> cluster on ubuntu. Not using <strong>zookeeper</strong> since i need only single master cluster. I started the master and then tried to start slave on another machine by running following command:</p>\n\n<pre><code>mesos-slave.sh --master=master-ip:5050\n</code></pre>\n\n<p>On the Mesos Web UI the slave is listed as <code>Deactivated</code>. if i try to start a slave on the same machine as master then the slave starts and is listed as <code>Activated</code>. </p>\n\n<p>Is there some configuration i am missing here to be able to start slaves?</p>\n", "is_answered": true, "tags": ["apache-spark", "mesos", "mesosphere"], "last_edit_date": 1456827216, "title": "Mesos setup slave deactivated", "last_activity_date": 1500552008, "answer_count": 2, "creation_date": 1456825574, "score": 1, "link": "https://stackoverflow.com/questions/35719474/mesos-setup-slave-deactivated", "answers": [{"body": "<p>Figured it out. We need to also specify the ip of the slave so that the master can communicate with it. </p>\n\n<pre><code>mesos-slave.sh --master=master-ip:5050 --ip=&lt;ip_of_slave_machine&gt;\n</code></pre>\n", "answer_id": 35723578, "last_activity_date": 1456837065, "creation_date": 1456837065, "score": 1, "owner": {"user_id": 1929867, "profile_image": "https://www.gravatar.com/avatar/21f2a3f41438d7efd4469d6d1755a67b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 106, "link": "https://stackoverflow.com/users/1929867/tweeper", "accept_rate": 46, "display_name": "tweeper"}, "is_accepted": false, "question_id": 35719474}, {"body": "<p>When you see the next lines on mesos-master logs it means you <strong>forget</strong> to mention mesos-agent \"--ip\" parameter when starting mesos-agent! </p>\n\n<pre><code>master.cpp:5639] Registered agent AGENT_ID... at slave(1)@127.0.1.1:5051 (AGENT-HOSTNAME) with ....\nmaster.cpp:1313] Agent AGENT_ID at slave(1)@127.0.1.1:5051 (AGENT-HOSTNAME) disconnected\nmaster.cpp:3197] Disconnecting agent AGENT_ID at slave(1)@127.0.1.1:5051 (AGENT-HOSTNAME)\nmaster.cpp:3216] Deactivating agent AGENT_ID at slave(1)@127.0.1.1:5051 (AGENT-HOSTNAME)\nprocess.cpp:2450] Failed to shutdown socket with fd 16, address 127.0.0.1:36622: Transport endpoint is not connected\n</code></pre>\n", "answer_id": 45214082, "last_activity_date": 1500552008, "creation_date": 1500552008, "score": 0, "owner": {"user_id": 4589040, "profile_image": "https://www.gravatar.com/avatar/6330850fb1a52e9a26de311828519801?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 39, "link": "https://stackoverflow.com/users/4589040/nix", "display_name": "nix"}, "is_accepted": false, "question_id": 35719474}], "owner": {"user_id": 1929867, "profile_image": "https://www.gravatar.com/avatar/21f2a3f41438d7efd4469d6d1755a67b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 106, "link": "https://stackoverflow.com/users/1929867/tweeper", "accept_rate": 46, "display_name": "tweeper"}, "view_count": 349, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 35719474}{"closed_date": 1462332471, "is_answered": true, "closed_reason": "off-topic", "tags": ["apache", "ubuntu", "mesos", "mesosphere"], "title": "Not able to install mesos on Ubuntu 16.04 Desktop", "body": "<p>Following the instructions at:</p>\n\n<p><a href=\"https://open.mesosphere.com/getting-started/install/\" rel=\"nofollow\">https://open.mesosphere.com/getting-started/install/</a></p>\n\n<p>Install mesos package gives the following error:</p>\n\n<pre><code>arun@arun-ubuntu:~$ sudo apt-get -y install mesos\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package mesos\n</code></pre>\n\n<p>Yes, the registry is configured:</p>\n\n<pre><code>arun@arun-ubuntu:~$ sudo apt-key adv --keyserver \n\nhkp://keyserver.ubuntu.com:80 --recv E56151BF\nExecuting: /tmp/tmp.EkBvspzAIM/gpg.1.sh --keyserver\nhkp://keyserver.ubuntu.com:80\n--recv\nE56151BF\ngpg: requesting key E56151BF from hkp server keyserver.ubuntu.com\ngpg: key E56151BF: \"Mesosphere Archive Automatic Signing Key &lt;support@mesosphere.io&gt;\" not changed\ngpg: Total number processed: 1\ngpg:              unchanged: 1\narun@arun-ubuntu:~$ DISTRO=$(lsb_release -is | tr '[:upper:]' '[:lower:]')\narun@arun-ubuntu:~$ CODENAME=$(lsb_release -cs)\narun@arun-ubuntu:~$ \narun@arun-ubuntu:~$ # Add the repository\narun@arun-ubuntu:~$ echo \"deb http://repos.mesosphere.com/${DISTRO} ${CODENAME} main\" | \\\n&gt;   sudo tee /etc/apt/sources.list.d/mesosphere.list\ndeb http://repos.mesosphere.com/ubuntu xenial main\narun@arun-ubuntu:~$ sudo apt-get -y update\nGet:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [92.2 kB]\nHit:2 http://us.archive.ubuntu.com/ubuntu xenial InRelease                     \nGet:3 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease [93.3 kB]   \nHit:4 http://repos.mesosphere.com/ubuntu xenial InRelease                      \nHit:5 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease           \nFetched 185 kB in 1s (117 kB/s)                   \nReading package lists... Done\nW: http://repos.mesosphere.com/ubuntu/dists/xenial/InRelease: Signature by key 81026D0004C44CF7EF55ADF8DF7D54CBE56151BF uses weak digest algorithm (SHA1)\n</code></pre>\n\n<p>What's missing?</p>\n", "view_count": 1087, "answers": [{"body": "<p>The mesos packages for Ubuntu 16.04 are not yet released. They should be available soon.</p>\n", "answer_id": 37016842, "last_activity_date": 1462324396, "creation_date": 1462324396, "score": 2, "owner": {"user_id": 5343540, "profile_image": "https://www.gravatar.com/avatar/68c554bc26aa5bcb590d40a3c40d3493?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/5343540/john", "display_name": "John"}, "is_accepted": false, "question_id": 37015871}], "last_activity_date": 1462324396, "score": 0, "link": "https://stackoverflow.com/questions/37015871/not-able-to-install-mesos-on-ubuntu-16-04-desktop", "answer_count": 1, "owner": {"user_id": 672246, "profile_image": "https://www.gravatar.com/avatar/268f57c236bb50c0f6e12ac38adc9d81?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2344, "link": "https://stackoverflow.com/users/672246/arun-gupta", "accept_rate": 32, "display_name": "Arun Gupta"}, "creation_date": 1462317026, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37015871}{"body": "<p>I am using 5 cloud-based VMs to install DC/OS\n1 mesos master\n3 mesos agent\n1 launching VM\nI have installed Docker on my launching VM and start installing DC/OS. It is running successfully during install_prereqs stage without any errors. But it's failing during preflight with below errors for each of my VM system.</p>\n\n<p>STDERR:\n          Connection to 129.114.18.235 closed.</p>\n\n<p>STDOUT:\n        Running preflight checks /opt/dcos_install_tmp/dcos_install.sh: line 225: getenforce: command not found</p>\n\n<pre><code>      Checking if docker is installed and in PATH: FAIL \n      Checking if unzip is installed and in PATH: FAIL \n      Checking if ipset is installed and in PATH: FAIL \n      Checking if systemd-notify is installed and in PATH: FAIL \n      /opt/dcos_install_tmp/dcos_install.sh: line 387: systemctl: command not found\n      Checking if systemctl is installed and in PATH: FAIL \n      Checking Docker is configured with a production storage driver: /opt/dcos_install_tmp/dcos_install.sh: line 285: docker: command not found\n</code></pre>\n\n<p>Do I need to install all  the required software into my master and agents VMS? Please guide.</p>\n", "is_answered": true, "tags": ["mesosphere", "dcos"], "title": "DC/OS installation failure during preflight", "last_activity_date": 1495944184, "answer_count": 2, "creation_date": 1468945253, "score": 1, "link": "https://stackoverflow.com/questions/38463811/dc-os-installation-failure-during-preflight", "answers": [{"body": "<p>We have a similar setup but using straight vm's.  We found docker needs to be running on all nodes, including masters, before running the install.  Also, make sure you look at: <code>/etc/sysconfig/docker-storage</code>and have:    <code>DOCKER_STORAGE_OPTIONS= -s overlay</code>set in the file on all nodes.\nI don't believe this is the production setup but should get you running. You also may want to check the privilege of the user executing the install on the remote nodes, does it have permission to see/run systemctl?</p>\n", "answer_id": 38529512, "last_activity_date": 1469199254, "creation_date": 1469199254, "score": 1, "owner": {"user_id": 6470473, "profile_image": "https://www.gravatar.com/avatar/0fbe0b19f229ab3c8fe37ff3cf7abc1f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 33, "link": "https://stackoverflow.com/users/6470473/grayzzz", "display_name": "grayzzz"}, "is_accepted": false, "question_id": 38463811}, {"body": "<p>I had the same error with the DC/OS web installer in version 1.9</p>\n\n<p>I solved the error after double-checking the bootstraps machines's private key in the web form. To create the key, log into the bootstrap machine and run:</p>\n\n<pre><code>$ ssh-keygen -t rsa\n$ for i in `cat dcos-ips.txt`; do ssh-copy-id root@$i; done\n$ cat ~/.ssh/id_rsa   \n</code></pre>\n", "answer_id": 44223705, "last_activity_date": 1495944184, "creation_date": 1495944184, "score": 0, "owner": {"user_id": 1183098, "profile_image": "https://www.gravatar.com/avatar/9fc092cc32b9e6f0bf5398547415af18?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1812, "link": "https://stackoverflow.com/users/1183098/r3x", "display_name": "r3x"}, "is_accepted": false, "question_id": 38463811}], "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 433, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 38463811}{"body": "<p>I've installed DC/OS via the Azure Container Service (ACS), but I can't find any information anywhere on how to either scale this manually (just increase the number of agents), or ideally automatically in response to load.</p>\n", "is_answered": true, "tags": ["azure", "dcos"], "title": "DC/OS scaling of clusters on Azure", "last_activity_date": 1474860202, "answer_count": 1, "creation_date": 1474582035, "score": 2, "link": "https://stackoverflow.com/questions/39649606/dc-os-scaling-of-clusters-on-azure", "answers": [{"body": "<p>There are a number of ways you can scale an ACS cluster:</p>\n\n<p>CLI: <a href=\"https://blogs.msdn.microsoft.com/azurelinux/2016/07/20/azure-cli-0-10-2-release-update-5th-july-2016/\" rel=\"nofollow\">https://blogs.msdn.microsoft.com/azurelinux/2016/07/20/azure-cli-0-10-2-release-update-5th-july-2016/</a></p>\n\n<p>ACS resource provider: simply resubmit your ARM template for ACS with a new number of agents.</p>\n\n<p>VMSS: use the portal to configure the scale set (including autoscale) <a href=\"https://azure.microsoft.com/en-us/documentation/articles/virtual-machine-scale-sets-autoscale-overview/\" rel=\"nofollow\">https://azure.microsoft.com/en-us/documentation/articles/virtual-machine-scale-sets-autoscale-overview/</a></p>\n", "answer_id": 39694256, "last_activity_date": 1474860202, "creation_date": 1474860202, "score": 3, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "question_id": 39649606}], "owner": {"user_id": 4801535, "profile_image": "https://www.gravatar.com/avatar/52bf046b6e3e41713318060cac3d2096?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/4801535/tom", "display_name": "Tom"}, "view_count": 263, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39649606}{"body": "<p>I setup both of my mesos-master and mesos-slave on a standalone server. E.g. To start my mesos-slave, I used this command:</p>\n\n<pre><code>sudo bin/mesos-slave.sh --master=zk://&lt;IP address of server&gt;:2181/mesos --log_dir=/var/log/mesos --containerizers=docker,mesos\n</code></pre>\n\n<p>What I am trying to figure out is how the containerizer on Mesos is implemented with just --containerizers=docker,mesos. </p>\n\n<p>Will it be able to automatically detect whether Docker is installed on the mesos-slave? If it is, which tcp port will it normally get? port 4243 or 2375?</p>\n", "is_answered": true, "title": "Apache Mesos's Docker Containerizer", "tags": ["docker", "mesos", "mesosphere"], "last_activity_date": 1423519210, "accepted_answer_id": 28420237, "creation_date": 1423042734, "answers": [{"body": "<p>Mesos will try to autodetect docker by running <code>docker version</code>. You can specific an absolute path for the docker executable by passing the <code>--docker=/path/to/docker</code> flag to the slave. There are other docker-specific flags for the slave, like <code>--docker_sandbox_directory</code>, <code>--docker_remove_delay</code>, and <code>--docker_stop_timeout</code>. For more details on those, see <a href=\"https://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow\">https://mesos.apache.org/documentation/latest/configuration/</a></p>\n\n<p>Mesos currently uses the docker command-line interface locally from the slave node, not via the remote API, so I don't think the docker port is relevant here.</p>\n", "answer_id": 28420237, "last_activity_date": 1423519210, "creation_date": 1423519210, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 28318029}], "score": 1, "link": "https://stackoverflow.com/questions/28318029/apache-mesoss-docker-containerizer", "answer_count": 1, "owner": {"user_id": 3888259, "profile_image": "https://www.gravatar.com/avatar/608d0729e98f93f696b3a7061d17c7ad?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 161, "link": "https://stackoverflow.com/users/3888259/han", "accept_rate": 73, "display_name": "Han"}, "view_count": 1217, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28318029}{"body": "<p>I am configuring a mesos-marathon cluster.\nI have the next role to install java and mesos. </p>\n\n<pre><code>---\n- name: importar key Mesosphere\n  shell: gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys E56151BF\n\n- name: ppa java8\n  apt_repository: repo='ppa:webupd8team/java' state=present\n\n- name: seleccionar licencia Oracle\n  shell: echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections\n\n- name: actualizar\n  apt: update_cache=yes\n\n- name: instalar java8\n  apt: name=oracle-java8-installer state=latest update-cache=yes force=yes\n\n- name: actualizar sources list\n  shell: DISTRO=$(lsb_release -is | tr '[:upper:]' '[:lower:]') &amp;&amp; CODENAME=$(lsb_release -cs) &amp;&amp; echo \"deb http://repos.mesosphere.io/${DISTRO} ${CODENAME} main\" | sudo tee /etc/apt/sources.list.d/mesosphere.list\n\n- name: actualizar paquetes\n  apt: update_cache=yes cache_valid_time=3600\n\n- name: instalar mesos\n  apt: name=mesos state=present install_recommends=yes force=yes\n\n- name: instalar mesosphere\n  apt: name=mesosphere state=present install_recommends=yes force=yes\n</code></pre>\n\n<p>My problem is that when I execute the playbook, it gives me the next error:</p>\n\n<pre><code>TASK [common : actualizar sources list] ****************************************\nchanged: [172.16.8.191]\n\nTASK [common : actualizar paquetes] ********************************************\nok: [172.16.8.191]\n\nTASK [common : instalar mesos] *************************************************\nfatal: [172.16.8.191]: FAILED! =&gt; {\"changed\": false, \"failed\": true, \"msg\": \"No package matching 'mesos' is available\"}\n\nPLAY RECAP *********************************************************************\n172.16.8.191               : ok=8    changed=5    unreachable=0    failed=1\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/cECDs.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cECDs.jpg\" alt=\"Ansible error\"></a></p>\n\n<p>But if I execute ansible for a second time it works perfectly you can see executing a second time:</p>\n\n<pre><code>TASK [common : actualizar paquetes] ********************************************\nok: [172.16.8.191]\n\nTASK [common : instalar mesos] *************************************************\nchanged: [172.16.8.191]\n\nTASK [common : instalar mesosphere] ********************************************\nchanged: [172.16.8.191]\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/QD1hg.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QD1hg.jpg\" alt=\"Ansible works\"></a></p>\n\n<p>What could be the problem?</p>\n\n<p>Thanks.</p>\n\n<p>SOLUTION BY @ydaetskcoR</p>\n\n<p>Change the task 'instalar mesos':</p>\n\n<pre><code>- name: instalar mesos\n  apt: name=mesos state=present install_recommends=yes update_cache=yes force=yes\n</code></pre>\n", "is_answered": true, "title": "No package matching 'mesos' is available on Ansible", "last_edit_date": 1454948033, "tags": ["ansible", "ansible-playbook", "mesos", "mesosphere", "ansible-2.x"], "view_count": 1282, "accepted_answer_id": 35273867, "last_activity_date": 1454953985, "answers": [{"body": "<p>The issue you have is that the <code>actualizar paquetes</code> task is only doing an <code>apt-get update</code> to refresh your repo lists if the last update was more than an hour ago.</p>\n\n<p>Considering you've only just added the Mesos repo in the previous task you won't then be able to find the package. Re-running the playbook triggers the <code>actualizar</code> task before that which doesn't have a <code>cache_valid_time</code> setting and so will force an <code>apt-get update</code> which will then allow you to use the Mesos repo that you added in the last playbook run.</p>\n\n<p>To fix it you could just remove the <code>cache_valid_time</code> from the <code>actualizar paquetes</code> task.</p>\n\n<p>As mentioned in the comments, you can also move the <code>update_cache</code> only <code>apt</code> tasks into the main <code>apt</code> task that actually installs packages and Ansible will run the <code>apt-get update</code> before the <code>apt-get install</code>.</p>\n", "answer_id": 35273867, "last_activity_date": 1454953985, "creation_date": 1454947114, "score": 3, "owner": {"user_id": 2291321, "profile_image": "https://www.gravatar.com/avatar/24a41cddd8faf69e3fbd0a778ba6fedf?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13573, "link": "https://stackoverflow.com/users/2291321/ydaetskcor", "accept_rate": 83, "display_name": "ydaetskcoR"}, "is_accepted": true, "last_edit_date": 1454953985, "question_id": 35227363}], "score": 1, "link": "https://stackoverflow.com/questions/35227363/no-package-matching-mesos-is-available-on-ansible", "answer_count": 1, "owner": {"user_id": 5621509, "profile_image": "https://www.gravatar.com/avatar/2ade806eb7a16154fb3d627a687383d4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 662, "link": "https://stackoverflow.com/users/5621509/asier-gomez", "accept_rate": 98, "display_name": "Asier Gomez"}, "creation_date": 1454684953, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35227363}{"body": "<p>I know apache mesos gives resource offers for based on cpu/mem.\nCan it also schedule volume space to different framework so each framework can use up to certain amount of space?</p>\n", "is_answered": true, "title": "Apache Mesos: sharing disk space?", "tags": ["apache", "mesos", "mesosphere"], "last_activity_date": 1470790774, "accepted_answer_id": 38862661, "creation_date": 1470771456, "answers": [{"body": "<p>Yes, Mesos can be used to allocate disk resources to frameworks. See the <code>disk</code> <a href=\"https://mesos.apache.org/documentation/latest/attributes-resources/\" rel=\"nofollow\">resource type</a>.</p>\n\n<p>By default, a task will be allowed to exceed its allocated disk space. Mesos supports different mechanisms for enforcing disk space allocation: see the \"POSIX Disk Isolator\" and \"XFS Disk Isolator\" sections in the <a href=\"https://mesos.apache.org/documentation/latest/mesos-containerizer/\" rel=\"nofollow\">containerizer docs</a>.</p>\n", "answer_id": 38862661, "last_activity_date": 1470790774, "creation_date": 1470790774, "score": 2, "owner": {"user_id": 5327044, "profile_image": "https://www.gravatar.com/avatar/ab97f776b0390a6b6bc72290ea3d9ff0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 281, "link": "https://stackoverflow.com/users/5327044/neil-conway", "display_name": "Neil Conway"}, "is_accepted": true, "question_id": 38859092}], "score": 1, "link": "https://stackoverflow.com/questions/38859092/apache-mesos-sharing-disk-space", "answer_count": 1, "owner": {"user_id": 1686628, "profile_image": "https://www.gravatar.com/avatar/a03a6bd4b5f83b04ff39aec4b44e17ed?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 3671, "link": "https://stackoverflow.com/users/1686628/ealeon", "accept_rate": 79, "display_name": "ealeon"}, "view_count": 102, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38859092}{"body": "<p>I'm running Mesos and Ceph clusters on CoreOS with a working <a href=\"https://github.com/tobilg/docker-volume-rbd\" rel=\"nofollow noreferrer\">Ceph RBD Docker volume plugin</a>, but it's very unclear to me how this can be used with Mesos/Marathon... Creating/using <code>rbd</code> volumes for single Docker containers is working flawlessly though.</p>\n\n<p>I can find no article/blog post/whatever that deals with the automated creation (and, in case of \"task migration\" between Mesos slaves, remapping) of these volumes via Marathon. Especially important to me is how to run multiple instances of a stateful service when each instance needs to have it's own volume (imagine a <a href=\"https://github.com/tobilg/docker-mongodb-marathon\" rel=\"nofollow noreferrer\">MongoDB ReplicaSet on Mesos/Marathon</a>).</p>\n\n<p>I know the <a href=\"http://mesos.apache.org/documentation/latest/persistent-volume/\" rel=\"nofollow noreferrer\">Mesos persistent volume docs</a>, and I also saw the <a href=\"https://github.com/mesosphere/marathon/issues/2493\" rel=\"nofollow noreferrer\">Marathon issue</a>, but still I'm very confused how or when this will be usable...</p>\n\n<p>There are also other questions here on SO:</p>\n\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/29065246/how-to-use-volumes-from-in-marathon\">How to use volumes-from in marathon</a></li>\n<li><a href=\"https://stackoverflow.com/questions/30155908/docker-on-mesos-volume-is-placed-on-which-node\">Docker on Mesos: Volume is placed on which node?</a></li>\n<li><a href=\"https://stackoverflow.com/questions/32189172/docker-volume-plugin-marathon\">Docker volume plugin marathon</a></li>\n</ul>\n\n<p>which unfortunately don't really have an answer to this specific problem.</p>\n\n<p>The <a href=\"http://blog.emccode.com/2015/08/28/run-your-stateful-apps-with-mesos-and-docker/\" rel=\"nofollow noreferrer\">EMC Code</a> example with RexRay also <strong>only</strong> covers a single instance example, which I could also handle with ease with the volume plugin mentioned above:</p>\n\n<pre><code>{\n    \"id\": \"nginx\",\n    \"container\": {\n        \"docker\": {\n            \"image\": \"million12/nginx\",\n            \"network\": \"BRIDGE\",\n            \"portMappings\": [{\n                \"containerPort\": 80,\n                \"hostPort\": 0,\n                \"protocol\": \"tcp\"\n            }],\n            \"parameters\": [{\n                \"key\": \"volume-driver\",\n                \"value\": \"rbd\"\n            }, {\n                \"key\": \"volume\",\n                \"value\": \"nginx-data:/data/www\"\n            }]\n        }\n    },\n    \"cpus\": 0.2,\n    \"mem\": 32.0,\n    \"instances\": 1\n}\n</code></pre>\n\n<p>The <code>nginx-data</code> volume would be created automatically in this case. But what if I want to use persistent volumes <strong>and</strong> multiple instances?</p>\n", "is_answered": true, "tags": ["docker", "cluster-computing", "mesos", "mesosphere", "docker-volume"], "last_edit_date": 1495539962, "title": "How to use Docker volumes as persistent volumes for Mesos/Marathon?", "last_activity_date": 1482523695, "answer_count": 1, "creation_date": 1453808232, "score": 3, "link": "https://stackoverflow.com/questions/35012960/how-to-use-docker-volumes-as-persistent-volumes-for-mesos-marathon", "answers": [{"body": "<p>This is a use case that Flocker is meant to solve. (Disclaimer: I'm the CTO at ClusterHQ). See <a href=\"https://clusterhq.com/2015/10/06/marathon-ha-demo/\" rel=\"nofollow\">this blog post</a> for a demo of the Flocker &lt;=> Mesos/Marathon interaction, which shows how the Flocker Control Service can act as the \"source of truth\" for which container volumes exist in a clustered setting. Flocker will then create on-demand, and then co-ordinate mapping and unmapping these volumes between hosts as the containers that reference these volumes move around in the cluster.</p>\n\n<p>Flocker does this by providing a cluster-wide namespace of volume names, these names can then be used via the Flocker plugin for Docker with Marathon to provide portability and high availability for stateful containers in a Mesos cluster.</p>\n\n<p>Flocker also has a Ceph driver:</p>\n\n<ul>\n<li>Google \"Flocker Ceph Driver\"</li>\n</ul>\n\n<p>And works on CoreOS:</p>\n\n<ul>\n<li>Google \"Flocker on CoreOS demo\"</li>\n</ul>\n\n<p>You can run multi-instance jobs (like MongoDB with replica sets) by giving each container its own volume name (like <code>mongo_1</code>, <code>mongo_2</code>, etc).</p>\n\n<p>Putting these pieces together would be non-trivial, but I'd be happy to help. I could write up a detailed guide specifically for your stack (Ceph + CoreOS + Docker + Mesos + Marathon) if you like.</p>\n", "answer_id": 35013603, "last_activity_date": 1453810360, "creation_date": 1453810360, "score": 3, "owner": {"user_id": 610131, "profile_image": "https://www.gravatar.com/avatar/736f63db11f36660370303e9b5c39da3?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 121, "link": "https://stackoverflow.com/users/610131/luke-marsden", "display_name": "Luke Marsden"}, "is_accepted": false, "question_id": 35012960}], "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "view_count": 1902, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 35012960}{"body": "<p>We are using Jenkins for CI.</p>\n\n<p>We used </p>\n\n<p><a href=\"https://github.com/rji/jenkins-standalone\" rel=\"nofollow\">https://github.com/rji/jenkins-standalone</a></p>\n\n<p>as per </p>\n\n<p><a href=\"https://github.com/jenkinsci/mesos-plugin\" rel=\"nofollow\">https://github.com/jenkinsci/mesos-plugin</a></p>\n\n<p>We tried to start jenkins with </p>\n\n<pre><code>\"-Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85\"\n</code></pre>\n\n<p>like </p>\n\n<pre><code># Start the master\nexport JENKINS_HOME=\"$(pwd)\"\n\njava -jar jenkins.war \\\n    -Djava.awt.headless=true \\\n\n    --webroot=war \\\n    --httpPort=${PORT} \\\n    --ajp13Port=-1 \\\n    --httpListenAddress=0.0.0.0 \\\n    --ajp13ListenAddress=127.0.0.1 \\\n    --preferredClassLoader=java.net.URLClassLoader \\\n    -Dhudson.slaves.NodeProvisioner.MARGIN=30 \\\n    -Dhudson.slaves.NodeProvisioner.MARGIN0=0.6 \\\n    --logfile=../jenkins.log\n</code></pre>\n\n<p>But we are not able to start the jenkins, jenkin logs showing </p>\n\n<pre><code>Running from: /var/jenkins/jenkins-standalone/jenkins.war\nException in thread \"main\" java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at Main._main(Main.java:293)\n        at Main.main(Main.java:98)\nCaused by: java.lang.IllegalArgumentException: Multiple command line argument specified: -Djava.hudson.slaves.NodeProvisioner.MARGIN=30\n        at winstone.cmdline.CmdLineParser.parse(CmdLineParser.java:68)\n        at winstone.Launcher.getArgsFromCommandLine(Launcher.java:361)\n        at winstone.Launcher.main(Launcher.java:334)\n        ... 6 more\n</code></pre>\n\n<p>Any suggestions</p>\n\n<p>Thank you.</p>\n", "is_answered": true, "tags": ["jenkins", "continuous-integration", "jenkins-plugins", "mesos", "mesosphere"], "title": "NodeProvisioner for Jenkins in mesos cluster", "last_activity_date": 1441169711, "answer_count": 1, "creation_date": 1441123512, "score": 0, "link": "https://stackoverflow.com/questions/32336228/nodeprovisioner-for-jenkins-in-mesos-cluster", "answers": [{"body": "<p>Got the solution.</p>\n\n<p>Need to pass</p>\n\n<pre><code>\"-Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85\"\n</code></pre>\n\n<p>these variables before </p>\n\n<pre><code>-jar jenkins.war \\\n</code></pre>\n\n<p>Thank you.</p>\n", "answer_id": 32344877, "last_activity_date": 1441169711, "creation_date": 1441169711, "score": 2, "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "is_accepted": false, "question_id": 32336228}], "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "view_count": 272, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32336228}{"body": "<p>When I publish a service with a VIP, the advertised address does not route properly to the advertised port. For example, for a MariaDB Galera 3-node cluster service with a VIP specified as:</p>\n\n<pre><code>      \"labels\": {\n        \"VIP_0\": \"/mariadb-galera:3306\"\n      }\n</code></pre>\n\n<p>On the configuration tab of the service page (and according to the docs), the load balanced address is:</p>\n\n<p>mariadb-galera.marathon.l4lb.thisdcos.directory:3306</p>\n\n<p>I can ping the DNS name just fine, but...</p>\n\n<p>When I try to connect a front-end service (Drupal7, wordpress) to consume this load balanced address:port combination, there will be numerous connection failures and timeouts.  It isn't that it never works but that it works quite sporadically, if at all.  Drupal7 dies almost immediately and starts kicking up Bad Gateway errors.</p>\n\n<p>What I have found through experimentation is that if I specify a <strong>hostPort</strong> for the service in question, the load balanced address will work as long as I use the hostPort value, and not the advertised load balanced service port as above.  In this specific case I specified a hostPort of 3310.</p>\n\n<pre><code>  \"network\":\"USER\",\n  \"portMappings\": [\n    {\n      \"containerPort\": 3306,\n      \"hostPort\": 3310,\n      \"servicePort\": 10000,\n      \"name\": \"mariadb-galera\",\n      \"labels\": {\n        \"VIP_0\": \"/mariadb-galera:3306\"\n      }\n    }\n</code></pre>\n\n<p>Then if I use the load balanced address (mariadb-galera.marathon.l4lb.thisdcos.directory) with the host port value (3310) in my Drupal7 settings.php, the front end connects and works fine.</p>\n\n<p>I've noticed similar behaviour with custom applications connecting to mongodb backends also in a DC/OS environment... it seems the load balanced address/port combination specified never works reliably... but if you substitute the hostPort value, it does.</p>\n\n<p>The docs clearly state that:</p>\n\n<p><strong>address and port is load balanced as a pair rather than individually.</strong></p>\n\n<p>(from <a href=\"https://docs.mesosphere.com/1.9/networking/dns-overview/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.9/networking/dns-overview/</a>)</p>\n\n<p>Yet I am unable to effectively connect when I specify the VIP designated port.  Yet IT DOES WORK when I use the hostPort (and will not work at all unless I designate a specific hostPort in the service definition json).  Wether or not this approach is actually load balanced remains a question to me based on the wording in the documentation.</p>\n\n<p>I must be doing something wrong, but I am at a loss... any help is appreciated.</p>\n\n<p>My cluster nodes are VMWare virtual machines.</p>\n", "is_answered": false, "tags": ["dns", "dcos"], "title": "DC/OS 1.9 VIP load balancing not working for advertised ports", "last_activity_date": 1497466334, "answer_count": 0, "creation_date": 1497466334, "score": 0, "link": "https://stackoverflow.com/questions/44552549/dc-os-1-9-vip-load-balancing-not-working-for-advertised-ports", "owner": {"user_id": 7829379, "profile_image": "https://lh4.googleusercontent.com/-1irM_ZDL3mE/AAAAAAAAAAI/AAAAAAAABW0/NRsNFdVT7Ns/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7829379/sean-hignett", "display_name": "Sean Hignett"}, "view_count": 26, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44552549}{"is_answered": false, "tags": ["cluster-computing", "mesos", "arangodb", "dcos"], "last_edit_date": 1484038522, "title": "ArangoDB DCOS: Coordinator dies when writing data", "last_activity_date": 1484038522, "answer_count": 0, "creation_date": 1483978504, "score": 0, "link": "https://stackoverflow.com/questions/41552232/arangodb-dcos-coordinator-dies-when-writing-data", "owner": {"user_id": 7395244, "profile_image": "https://www.gravatar.com/avatar/42491a19032006426689af7d516638e7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7395244/kenw", "display_name": "kenw"}, "view_count": 89, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41552232}{"body": "<p>I created a mesos slave docker image with Oracle Linux 7.2 as the base image. The dockerfile builds correctly but when I try to run the image, it gives the following error:</p>\n\n<pre><code>I0414 17:57:30.659329     1 logging.cpp:188] INFO level logging started!\nI0414 17:57:30.666347     1 main.cpp:223] Build: 2016-03-17 17:47:25 by root\nI0414 17:57:30.666445     1 main.cpp:225] Version: 0.28.0\nI0414 17:57:30.666483     1 main.cpp:228] Git tag: 0.28.0\nI0414 17:57:30.666543     1 main.cpp:232] Git SHA: 961edbd82e691a619a4c171a7aadc9c32957fa73\nI0414 17:57:30.726467     1 systemd.cpp:236] systemd version `219` detected\nI0414 17:57:30.726622     1 main.cpp:240] Inializing systemd state\nFailed to initialize systemd: Failed to locate systemd runtime directory: /run/systemd/system\n</code></pre>\n\n<p>Here is the dockerfile:</p>\n\n<pre><code>FROM oraclelinux:7.2\n\nRUN rpm -Uvh http://repos.mesosphere.io/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm\nRUN yum -y update\nRUN yum -y install mesos\n\nENTRYPOINT [\"mesos-slave\"]\n</code></pre>\n\n<p>The OS of the host machine is Oracle Linux 7.2 as well. I was able to run an image build with Ubuntu 14.04 as well as the existing image created by Mesosphere (<a href=\"https://hub.docker.com/r/mesosphere/mesos-slave/\" rel=\"nofollow\">https://hub.docker.com/r/mesosphere/mesos-slave/</a>) successfully.</p>\n\n<p>Any idea why this is happening? Thanks in advance.</p>\n", "is_answered": false, "tags": ["linux", "docker", "mesos", "mesosphere"], "last_edit_date": 1460668039, "title": "Mesos slave container with Oracle Linux 7 base image fails to start", "last_activity_date": 1474475821, "answer_count": 2, "creation_date": 1460657721, "score": 0, "link": "https://stackoverflow.com/questions/36630889/mesos-slave-container-with-oracle-linux-7-base-image-fails-to-start", "answers": [{"body": "<p>docker can't start systemd in runtime. this is core reason.</p>\n", "answer_id": 37037004, "last_activity_date": 1462392154, "creation_date": 1462392154, "score": -1, "owner": {"user_id": 193584, "profile_image": "https://www.gravatar.com/avatar/58bf89ba2dfa037971b05d1afb0480a3?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 857, "link": "https://stackoverflow.com/users/193584/xds2000", "display_name": "xds2000"}, "is_accepted": false, "question_id": 36630889}, {"body": "<p>Try this in your Dockerfile:</p>\n\n<pre><code>ENV MESOS_SYSTEMD_ENABLE_SUPPORT false\n</code></pre>\n", "answer_id": 39622050, "last_activity_date": 1474475821, "creation_date": 1474475821, "score": 0, "owner": {"user_id": 457292, "profile_image": "https://www.gravatar.com/avatar/b5380bafe3b95c1e1c79db55e50925a7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 114, "link": "https://stackoverflow.com/users/457292/andrey-kozyrev", "accept_rate": 100, "display_name": "Andrey.Kozyrev"}, "is_accepted": false, "question_id": 36630889}], "owner": {"user_id": 1341823, "profile_image": "https://www.gravatar.com/avatar/27e5dc68b333fdc1f3a9c5de012a188d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 81, "link": "https://stackoverflow.com/users/1341823/sanjay", "accept_rate": 20, "display_name": "Sanjay"}, "view_count": 359, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 36630889}{"body": "<p>I have created a Mesosphere DCOS cluster on AWS using the DCOS template. I want to stop the instances after the day end. But after stopping the instances they are terminated and replaced by new instances. Please suggest how to stop the instances.</p>\n\n<p>If the EC2 instances are detached from the auto scaling groups, is the functioning of the DCOS cluster hampered?</p>\n", "is_answered": true, "title": "Mesososphere DCOS cluster on AWS. EC2 instances are terminated and again restarted after they are stopped", "last_edit_date": 1438850929, "tags": ["amazon-web-services", "mesos", "mesosphere"], "view_count": 694, "accepted_answer_id": 31849590, "last_activity_date": 1443602786, "answers": [{"body": "<p>To fully shut down the cluster, follow the steps in the <a href=\"https://docs.mesosphere.com/install/removeaws/\" rel=\"nofollow\">docs</a>, which means deleting the CloudFormation stack as well as removing the S3 bucket that contains config data.</p>\n\n<p>UPDATE: since the OP made it clear that the underlying motivation is to 'pause' the cluster over night in order to cut down on costs, I'm clarifying hereby that this is not possible, currently. In order to keep the configuration data around while minimizing the costs you can <a href=\"https://support.mesosphere.com/hc/en-us/articles/204622489-How-can-I-scale-my-DCOS-cluster-in-AWS-\" rel=\"nofollow\">scale the DCOS cluster down</a>, for a certain period of time.</p>\n", "answer_id": 31849590, "last_activity_date": 1438851624, "creation_date": 1438846647, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "last_edit_date": 1438851624, "question_id": 31848810}, {"body": "<p>I found this is the instance behaviour when a server is part of an autoscaling group. Remove the servers from the autoscaling groups then you can stop them. You can add them back later.</p>\n\n<p><a href=\"https://stackoverflow.com/questions/19194893/why-does-my-aws-ec2-instance-terminates-when-stopped\">Why does my AWS EC2 Instance terminates when stopped?</a></p>\n\n<p><a href=\"http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/detach-instance-asg.html\" rel=\"nofollow noreferrer\">http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/detach-instance-asg.html</a></p>\n\n<p>Luck!</p>\n", "answer_id": 32861721, "last_activity_date": 1443602786, "creation_date": 1443602786, "score": 0, "owner": {"user_id": 2621528, "profile_image": "https://www.gravatar.com/avatar/1d80900651d0fe9d18bf336508732487?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 48, "link": "https://stackoverflow.com/users/2621528/g-rodriguez", "display_name": "G Rodriguez"}, "is_accepted": false, "last_edit_date": 1495540730, "question_id": 31848810}], "score": 3, "link": "https://stackoverflow.com/questions/31848810/mesososphere-dcos-cluster-on-aws-ec2-instances-are-terminated-and-again-restart", "answer_count": 2, "owner": {"user_id": 5188802, "profile_image": "https://www.gravatar.com/avatar/96fdffb493ccaef2a9b3bb57a332ffe1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5188802/rajasi-kulkarni", "accept_rate": 100, "display_name": "Rajasi Kulkarni"}, "creation_date": 1438844284, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 31848810}{"body": "<p>I have a DC/OS cluster running a local instance of 'universe'.   What is the specific procedure for adding custom packages to a local 'universe'?  The only documentation I have found so far (which is very limited), is related to adding packages to the global universe repo.   While this is great for the DC/OS community, it does not help in regards to maintaining private universes and repos.</p>\n\n<p>The only procedures I found say:</p>\n\n<p>1-Create a fork of the public universe repo: <a href=\"https://github.com/mesosphere/universe\" rel=\"nofollow\">https://github.com/mesosphere/universe</a></p>\n\n<p>2-Creating a custom package and then resubmitting it back to the community.</p>\n\n<p>This is not exactly what I was expecting to see.   I was hoping for a simple local package creation process.   Is there such a thing?</p>\n\n<p>Thanks,</p>\n\n<p>GAOTU</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "dcos"], "title": "dcos install package to local universe", "last_activity_date": 1499882993, "answer_count": 2, "creation_date": 1472656705, "score": 2, "link": "https://stackoverflow.com/questions/39253394/dcos-install-package-to-local-universe", "answers": [{"body": "<p>Do you want to add the package to your local universe, correct (i.e., not the mesosphere universe)?</p>\n\n<p>In this case, after creating your custom package (and yes, there should be better documentation...) you can add this local/custom universe to a DC/OS cluster: <a href=\"https://dcos.io/docs/1.7/usage/repo/#adding\" rel=\"nofollow\">https://dcos.io/docs/1.7/usage/repo/#adding</a></p>\n\n<p>In general, you don't even have to fork the universe: a package repo is basically a simple folder structure. Check out the universe_builder.py <a href=\"https://github.com/mesosphere/dcos-commons/tree/master/tools\" rel=\"nofollow\">here</a> : It build a zip file, uploads it to S3, which you can then add as a new package repository as described above (and as output by the script).</p>\n\n<p>In general feel to contribute and help to help improve the documentation!</p>\n", "answer_id": 39290571, "last_activity_date": 1472813666, "creation_date": 1472813343, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "last_edit_date": 1472813666, "question_id": 39253394}, {"body": "<ol>\n<li><p>Fork this universe repo and clone the fork:</p>\n\n<p>git clone <a href=\"https://github.com/\" rel=\"nofollow noreferrer\">https://github.com/</a>/universe.git /path/to/universe</p></li>\n<li><p>Add your package to the repo in right folder. Write the necessary markup files\n(config.json, marathon.json.mustache, resource.json, package.json etc.)</p></li>\n<li><p>Run the verification and build script to validate and build the Universe artifacts:</p>\n\n<p>scripts/build.sh</p>\n\n<p>This verifies the syntax of the files you added.</p></li>\n<li><p>Build the Universe Server Docker image: </p>\n\n<p>DOCKER_TAG=\"my-package\" docker/server/build.bash</p>\n\n<p>This will create your docker image of local universe(ngnix server) and marathon.json to start the universe server.</p></li>\n<li><p>Run Universe Server</p>\n\n<p>dcos marathon app add marathon.json</p></li>\n<li><p>Point DC/OS to local universe server</p>\n\n<p>dcos package repo add --index=0 dev-universe <a href=\"http://universe.marathon.mesos:8085/repo\" rel=\"nofollow noreferrer\">http://universe.marathon.mesos:8085/repo</a></p></li>\n<li><p>Install your newly added package in DC/OS cluster</p>\n\n<p>dcos package install new_package</p></li>\n</ol>\n", "answer_id": 40566071, "last_activity_date": 1478974211, "creation_date": 1478974211, "score": 2, "owner": {"user_id": 3670965, "profile_image": "https://www.gravatar.com/avatar/ff213d2e4e9dbcd790807bc5bde9700f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 33, "link": "https://stackoverflow.com/users/3670965/abhijeet-jadhav", "display_name": "Abhijeet Jadhav"}, "is_accepted": false, "question_id": 39253394}], "owner": {"user_id": 6779413, "profile_image": "https://www.gravatar.com/avatar/6b4ef72ded0732c4658b25f449e92f4e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6779413/gaotu", "display_name": "gaotu"}, "view_count": 711, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 39253394}{"body": "<p>I have a DCOS cluster with 3 agent nodes; I have few services like spark running on DCOS. </p>\n\n<blockquote>\n  <ol>\n  <li>If i scale my DCOS cluster, do i need to scale my spark as well\n  (because if i add a 4th node to DCOS cluster and when i run a spark\n  job, master may allocate resources for the spark job to be run on the\n  4th node where spark is not installed and hence it will fail)?</li>\n  </ol>\n</blockquote>\n\n<p>In my observation, i found that the jobs are being submitted to any node that Mesos master sees.</p>\n\n<blockquote>\n  <ol start=\"2\">\n  <li>Is there a way where i can specify Spark job not run on certain nodes?</li>\n  </ol>\n</blockquote>\n", "is_answered": true, "title": "DCOS cluster scaling", "tags": ["apache-spark", "scaling", "mesosphere", "dcos"], "last_activity_date": 1487092974, "accepted_answer_id": 42200558, "creation_date": 1486973661, "answers": [{"body": "<ol>\n<li>Not by default, so you will have to scale Spark. In this context by scale I refer to adding more executors. There is no need to perform any additional package installs to support this.</li>\n</ol>\n\n<p>Dynamic allocation may help, but I've not used it:</p>\n\n<p><a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html#dynamic-resource-allocation-with-mesos\" rel=\"nofollow noreferrer\">http://spark.apache.org/docs/latest/running-on-mesos.html#dynamic-resource-allocation-with-mesos</a></p>\n\n<p><a href=\"http://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation\" rel=\"nofollow noreferrer\">http://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation</a></p>\n\n<ol start=\"2\">\n<li>You can control where jobs run in Marathon, but to my knowledge not Spark, via DCOS. I think you will be able to achieve it in the underlying Mesos configuration, but it's not recommended.  You can create multiple Spark 'clusters' within one DCOS cluster and choose which spark instance to submit to:</li>\n</ol>\n\n<blockquote>\n  <p>To install mutiple instances of the DC/OS Spark package, set each\n  service.name to a unique name (e.g.: \u201cspark-dev\u201d) in your JSON\n  configuration file during installation:</p>\n</blockquote>\n\n<pre><code>{\n  \"service\": {\n    \"name\": \"spark-dev\"\n  }\n}\n</code></pre>\n\n<blockquote>\n  <p>To use a specific Spark instance from the DC/OS Spark CLI:</p>\n</blockquote>\n\n<p><code>$ dcos config set spark.app_id &lt;service.name&gt;</code></p>\n\n<p><a href=\"https://docs.mesosphere.com/1.8/usage/service-guides/spark/install/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.8/usage/service-guides/spark/install/</a></p>\n", "answer_id": 42200558, "last_activity_date": 1487092974, "creation_date": 1486977791, "score": 1, "owner": {"user_id": 4697497, "profile_image": "https://i.stack.imgur.com/DOI0i.jpg?s=128&g=1", "user_type": "registered", "reputation": 1425, "link": "https://stackoverflow.com/users/4697497/imdarreng", "display_name": "ImDarrenG"}, "is_accepted": true, "last_edit_date": 1487092974, "question_id": 42199408}], "score": 0, "link": "https://stackoverflow.com/questions/42199408/dcos-cluster-scaling", "answer_count": 1, "owner": {"user_id": 1605937, "profile_image": "https://www.gravatar.com/avatar/fa3c33ab2b22f2d68ca3a9063a0952ce?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1754, "link": "https://stackoverflow.com/users/1605937/learninghuman", "accept_rate": 46, "display_name": "learninghuman"}, "view_count": 172, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42199408}{"is_answered": true, "tags": ["volume", "persistent", "dcos"], "last_edit_date": 1462764677, "title": "how to create persistence volume using mesos DCOS and marathon", "last_activity_date": 1462783213, "answer_count": 1, "creation_date": 1462723781, "score": 1, "link": "https://stackoverflow.com/questions/37101941/how-to-create-persistence-volume-using-mesos-dcos-and-marathon", "owner": {"user_id": 6307069, "profile_image": "https://www.gravatar.com/avatar/b6498aaa9c53492ca1ff7034b19bd460?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6307069/barznik", "display_name": "barznik"}, "view_count": 722, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 37101941}{"body": "<p>With Spark-18232 allowing for CNI network names to be supplied for the executor, I am having issues getting the executor to work either with or without dynamic allocation of executors.  I keep getting the following stack trace below.  I am using Calico (CNI) with Mesos.</p>\n\n<pre><code>org.apache.spark.shuffle.FetchFailedException: Failed to connect to /0.0.0.0:36120\n    at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:361)\n    at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:336)\n    at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:54)\n    at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n    at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n    at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n    at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)\n    at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n    at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)\n    at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n    at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n    at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)\n    at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n    at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n    at org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n    at org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n    at org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1423)\n    at org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1420)\n    at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n    at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n    at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n    at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n    at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n    at org.apache.spark.scheduler.Task.run(Task.scala:99)\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: Failed to connect to /0.0.0.0:36120\n    at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:232)\n    at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:182)\n    at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:97)\n    at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)\n    at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)\n    at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:171)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)\n    ... 1 more\nCaused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /0.0.0.0:36120\n    at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n    at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n    at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)\n    at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)\n    at io.netty.channel.nio.NioEvent\n</code></pre>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere", "project-calico"], "last_edit_date": 1494519990, "title": "Spark's Ability to co-exist with CNI on mesos", "last_activity_date": 1494519990, "answer_count": 0, "creation_date": 1494283016, "score": 1, "link": "https://stackoverflow.com/questions/43858294/sparks-ability-to-co-exist-with-cni-on-mesos", "owner": {"user_id": 6481439, "profile_image": "https://lh5.googleusercontent.com/-F8oyVFhmPA0/AAAAAAAAAAI/AAAAAAAAAC8/PUYZzYjjy0w/photo.jpg?sz=128", "user_type": "registered", "reputation": 228, "link": "https://stackoverflow.com/users/6481439/john-leach", "display_name": "John Leach"}, "view_count": 27, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43858294}{"body": "<p>We are working on setting up an ArangoDB cluster in DC/OS. For the data storage we've mounted 100 GB of\nEBS to <code>/dcos/volume1</code> as mentioned and the disk space is getting reflected in the DC/OS dashboard.</p>\n\n<p>However the ArangoDB Db server process gets launched with the below docker command :</p>\n\n<blockquote>\n  <p>I0110 13:04:25.273998 21115 docker.cpp:815] Running docker -H unix:///var/run/docker.sock run --cpu-shares 1024 --memory 16106127360 -e CLUSTER_ROLE=primary -e CLUSTER_ID=DBServer005 -e ADDITIONAL_ARGS= -e AGENCY_ENDPOINTS=tcp://172.22.0.75:1025 tcp://172.22.0.198:1025 tcp://172.22.0.171:1025 -e HOST=172.22.0.128 -e PORT0=1025 -e LIBPROCESS_IP=172.22.0.128 -e MESOS_SANDBOX=/mnt/mesos/sandbox -e MESOS_CONTAINER_NAME=mesos-085398be-0bc9-4b23-9a13-4a7379530ea9-S3.1db76e46-20c1-48ba-ad2f-978874118930 -v /var/lib/mesos/slave/slaves/085398be-0bc9-4b23-9a13-4a7379530ea9-S3/frameworks/085398be-0bc9-4b23-9a13-4a7379530ea9-0045/executors/6f9b1b94-5dee-4454-bbe8-48f82e65d4d3/runs/1db76e46-20c1-48ba-ad2f-978874118930/myPersistentVolume:/var/lib/arangodb3:rw -v /var/lib/mesos/slave/slaves/085398be-0bc9-4b23-9a13-4a7379530ea9-S3/frameworks/085398be-0bc9-4b23-9a13-4a7379530ea9-0045/executors/6f9b1b94-5dee-4454-bbe8-48f82e65d4d3/runs/1db76e46-20c1-48ba-ad2f-978874118930:/mnt/mesos/sandbox --net bridge -p 1025:8529/tcp --name mesos-085398be-0bc9-4b23-9a13-4a7379530ea9-S3.1db76e46-20c1-48ba-ad2f-978874118930 arangodb/arangodb-mesos:3.1</p>\n</blockquote>\n\n<p>Does this mean that the persistent data is stored within this location: <code>/var/lib/</code>? If so, is there any option to make the data get stored in different volume such as <code>/dcos/volume1</code>?</p>\n\n<p>In the ArangoDB DCOS install config, I couldn't find any options to attach persistent volumes.</p>\n", "is_answered": false, "tags": ["arangodb", "dcos"], "last_edit_date": 1484135080, "title": "How to use Amazon EBS for persistent storage in ArangoDB?", "last_activity_date": 1484135080, "answer_count": 0, "creation_date": 1484132503, "score": 1, "link": "https://stackoverflow.com/questions/41589115/how-to-use-amazon-ebs-for-persistent-storage-in-arangodb", "owner": {"user_id": 1642790, "profile_image": "https://i.stack.imgur.com/OvpjC.jpg?s=128&g=1", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/1642790/pjesudhas", "accept_rate": 71, "display_name": "pjesudhas"}, "view_count": 62, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41589115}{"body": "<p>Is there any link/documentation available around installing DC/OS on Google Compute Engine where instances are ubuntu 16.04 instances including the bootstrap node instead of CentOS 7?</p>\n\n<p>Currently , the documents I find use Ansible and CentOS 7 on GCE as below.\n<a href=\"https://dcos.io/docs/1.7/administration/installing/cloud/gce/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.7/administration/installing/cloud/gce/</a></p>\n", "is_answered": true, "title": "DC/OS on GCE Ubuntu", "last_edit_date": 1503334630, "tags": ["google-compute-engine", "dcos"], "view_count": 33, "accepted_answer_id": 45879097, "last_activity_date": 1504166024, "answers": [{"body": "<p><strong>Short answer</strong>: Debian based distributions are currently (at least up to DC/OS 1.10) not supported.</p>\n\n<p><strong>Long answer</strong>:</p>\n\n<p>DC/OS doesn't use any RedHat specific features. Most important differences could be solved by symlinks for few system binaries, as RedHat systems have different paths and systemd doesn't support <code>$PATH</code> variable in service definition. Basically all you need is following:</p>\n\n<pre><code>sudo apt-get install libcurl3-nss ipset selinux-utils curl unzip bc\nsudo ln -s /bin/mkdir /usr/bin/mkdir\nsudo ln -s /bin/ln /usr/bin/ln\nsudo ln -s /bin/tar /usr/bin/tar\nsudo ln -s /bin/rm /usr/bin/rm\nsudo ln -s /usr/sbin/useradd /usr/bin/useradd\nsudo ln -s /bin/bash /usr/bin/bash\n</code></pre>\n\n<p>Another requirements are:</p>\n\n<ul>\n<li><code>systemd</code> with version <code>&gt;=200</code></li>\n<li>Docker <code>&gt;=1.6</code></li>\n</ul>\n\n<p>Slightly outdated <a href=\"https://github.com/JohnOmernik/dcosprep\" rel=\"nofollow noreferrer\">scripts from John Omernik</a>, there's also <a href=\"https://github.com/deric/puppet-dcos\" rel=\"nofollow noreferrer\">puppet module</a> (I'm the author). For further details see discussion on <a href=\"https://dcosjira.atlassian.net/browse/DCOS-25\" rel=\"nofollow noreferrer\">DC/OS Jira</a>.</p>\n\n<p>Unless you don't want to run packages from DC/OS Universe (like Elastic, Kafka, etc.) that depends on <code>libmesos-bundle</code>, you might be just fine (without agent based health checks). The bundle is fetched into each executor's directory, it includes numerous libraries, such as <code>libmesos.so</code></p>\n\n<pre><code>... \n-rwxr-xr-x 1 nobody nogroup 55077256 Jun 28 19:50 libmesos-1.4.0.so\n-rwxr-xr-x 1 nobody nogroup     1487 Jun 28 19:50 libmesos.la\nlrwxrwxrwx 1 nobody nogroup       17 Jun 28 19:50 libmesos.so -&gt; libmesos-1.4.0.so\n-rwxr-xr-x 1 nobody nogroup   398264 Jun 28 19:53 libpcre.so.1\n-rwxr-xr-x 1 nobody nogroup   121296 Jun 28 19:53 libsasl2.so.3\n-rwxr-xr-x 1 nobody nogroup   155744 Jun 28 19:53 libselinux.so.1\n-rwxr-xr-x 1 nobody nogroup   454008 Jun 28 19:53 libssl.so.10\n-rwxr-xr-x 1 nobody nogroup   999944 Jun 28 19:53 libstdc++.so.6\n-rwxr-xr-x 1 nobody nogroup    79000 Jun 28 19:53 libsvn_delta-1.so.0\n-rwxr-xr-x 1 nobody nogroup  1820208 Jun 28 19:53 libsvn_subr-1.so.0\n-rwxr-xr-x 1 nobody nogroup    20040 Jun 28 19:53 libuuid.so.1\n-rwxr-xr-x 1 nobody nogroup    90664 Jun 28 19:53 libz.so.1\ndrwxr-xr-x 3 nobody nogroup     4096 Jun 28 19:53 mesos\ndrwxr-xr-x 2 nobody nogroup     4096 Jun 28 19:37 pkgconfig\n</code></pre>\n\n<p>Some libraries might be compatible with your system, but the versions between CentOS and Debian might (and will) differ. You might encounter errors like:</p>\n\n<pre><code>libmesos-bundle/lib/libcurl.so.4: version `CURL_OPENSSL_3' not found (required by curl)\n</code></pre>\n\n<p>which will cause that all agent based health checks that use <code>curl</code> won't work, therefore most instances will refuse to start. As Debian based systems aren't between supported systems you can't expect that such issue will be fixed.</p>\n\n<p>A workaround is to provide your own bundle compiled for your system or update <code>LD_LIBRARY_PATH</code> for the app with proper libraries:</p>\n\n<pre><code>export LD_LIBRARY_PATH=$MESOS_SANDBOX/libmesos-bundle/lib:$LD_LIBRARY_PATH;\n</code></pre>\n\n<p>In the end most problematic dependencies are SSL and curl libraries. Agent based checks requires modification of <code>LD_LIBRARY_PATH</code> for <code>mesos-slave</code> e.g. in <code>/opt/mesosphere/etc/mesos-slave-common</code>. However this will break <code>mesos-fetcher</code>, so you'll end up with recompiling all Mesos (C++) components with dependencies compatible with your distribution.</p>\n\n<p>To sum it up, it requires a lot of modifications that might not be worth the effort. Proper solution would be to distribute binary components (<code>mesos-master</code>, <code>mesos-slave</code>, <code>libmesos</code>) as OS dependent binary packages (<code>*.deb</code>,<code>*.rpm</code>). Python, Erlang based components should not be dependent on distribution.</p>\n", "answer_id": 45879097, "last_activity_date": 1504166024, "creation_date": 1503655684, "score": 1, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": true, "last_edit_date": 1504166024, "question_id": 45789566}], "score": 1, "link": "https://stackoverflow.com/questions/45789566/dc-os-on-gce-ubuntu", "answer_count": 1, "owner": {"user_id": 1742932, "profile_image": "https://www.gravatar.com/avatar/edac1e57616cb46109fa7df68ab11a6d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1366, "link": "https://stackoverflow.com/users/1742932/fortm", "accept_rate": 87, "display_name": "fortm"}, "creation_date": 1503291647, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45789566}{"is_answered": true, "tags": ["docker", "hazelcast", "mesos"], "last_edit_date": 1458198610, "title": "Hazelcast TCP/IP discovery on DCOS/ Marathon and docker", "last_activity_date": 1458198610, "answer_count": 2, "creation_date": 1448122549, "score": 1, "link": "https://stackoverflow.com/questions/33845653/hazelcast-tcp-ip-discovery-on-dcos-marathon-and-docker", "accepted_answer_id": 35151583, "owner": {"user_id": 1570935, "profile_image": "https://www.gravatar.com/avatar/2e4358916745de3e3f777120ac53e14c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 168, "link": "https://stackoverflow.com/users/1570935/vivek-kothari", "accept_rate": 88, "display_name": "Vivek Kothari"}, "view_count": 499, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 33845653}{"body": "<p>I'm using flocker to persist and migrate docker containers data through ZfS Dataset backend.</p>\n\n<pre><code>docker run -v test:/data --volume-driver flocker busybox \n sh -c \"echo hello world &gt; /data/file.txt\"\n</code></pre>\n\n<p>I had this error for a week:</p>\n\n<blockquote>\n  <p>Unable to find image 'busybox:latest' locally latest: Pulling from\n  library/busybox 583635769552: Pull complete  b175bcb79023: Pull\n  complete  Digest:\n  sha256:c1bc9b4bffe665bf014a305cc6cf3bca0e6effeb69d681d7a208ce741dad58e0\n  Status: Downloaded newer image for busybox:latest Error response from\n  daemon: Cannot start container\n  128ddff1c0e9d6740c23b2f475b14206775a131878b4ed725a3280e22de79666:\n  Timed out waiting for dataset to mount...</p>\n</blockquote>\n\n<p>Any help would be appreciated.</p>\n\n<p>flocker-docker-plugin.log</p>\n\n<pre><code>{\n  \"task_uuid\": \"4001196a-902c-4139-8b4f-e217490242ab\",\n  \"error\": true,\n  \"timestamp\": 1459172727.570846,\n  \"message\": \"Unhandled Error\\nTraceback (most recent call last):\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/dockerplugin/_script.py\\\", line 93, in docker_plugin_main\\n    options=DockerPluginOptions()).main()\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/common/script.py\\\", line 294, in main\\n    self._react(run_and_log, [], _reactor=self._reactor)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/twisted/internet/task.py\\\", line 882, in react\\n    finished = main(_reactor, *argv)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/common/script.py\\\", line 282, in run_and_log\\n    d = maybeDeferred(self.script.main, reactor, options)\\n--- &lt;exception caught here&gt; ---\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/twisted/internet/defer.py\\\", line 150, in maybeDeferred\\n    result = f(*args, **kw)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/dockerplugin/_script.py\\\", line 71, in main\\n    certificates_path.child(b\\\"plugin.key\\\"))\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/apiclient/_client.py\\\", line 592, in __init__\\n    cert_path, key_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_validation.py\\\", line 137, in treq_with_authentication\\n    user_credential = UserCredential.from_files(user_cert_path, user_key_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_ca.py\\\", line 371, in from_files\\n    certificate = load_certificate_file(certificate_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_ca.py\\\", line 232, in load_certificate_file\\n    e.filename, code, failure\\nflocker.ca._ca.PathError: Certificate file could not be opened. No such file or directory /etc/flocker/plugin.crt\\n\",\n  \"message_type\": \"twisted:log\",\n  \"task_level\": [\n    1\n  ]\n}\n{\n  \"task_uuid\": \"846b9f01-f618-4723-bf9e-2ce7ac6b79c9\",\n  \"error\": true,\n  \"timestamp\": 1459172727.57451,\n  \"message\": \"main function encountered error\\nTraceback (most recent call last):\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/dockerplugin/_script.py\\\", line 93, in docker_plugin_main\\n    options=DockerPluginOptions()).main()\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/common/script.py\\\", line 294, in main\\n    self._react(run_and_log, [], _reactor=self._reactor)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/twisted/internet/task.py\\\", line 882, in react\\n    finished = main(_reactor, *argv)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/common/script.py\\\", line 282, in run_and_log\\n    d = maybeDeferred(self.script.main, reactor, options)\\n--- &lt;exception caught here&gt; ---\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/twisted/internet/defer.py\\\", line 150, in maybeDeferred\\n    result = f(*args, **kw)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/dockerplugin/_script.py\\\", line 71, in main\\n    certificates_path.child(b\\\"plugin.key\\\"))\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/apiclient/_client.py\\\", line 592, in __init__\\n    cert_path, key_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_validation.py\\\", line 137, in treq_with_authentication\\n    user_credential = UserCredential.from_files(user_cert_path, user_key_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_ca.py\\\", line 371, in from_files\\n    certificate = load_certificate_file(certificate_path)\\n  File \\\"/opt/flocker/local/lib/python2.7/site-packages/flocker/ca/_ca.py\\\", line 232, in load_certificate_file\\n    e.filename, code, e file could nfailure\\nflocker.ca._ca.PathError: Certificatot be opened. No such file or directory /etc/flocker/plugin.crt\\n\",\n  \"message_type\": \"twisted:log\",\n  \"task_level\": [\n    1\n  ]\n}{\n  \"task_uuid\": \"7aab456b-a754-4160-8bcb-0b618a63ecda\",\n  \"error\": false,\n  \"timestamp\": 1459172727.575473,\n  \"message\": \"Main loop terminated.\",\n  \"message_type\": \"twisted:log\",\n  \"task_level\": [\n    1\n  ]\n}{\n  \"task_uuid\": \"5b490165-8eb1-4755-9c87-1b49f00bc700\",\n  \"error\": false,\n  \"timestamp\": 1459172728.921761,\n  \"message\": \"Log opened.\",\n  \"message_type\": \"twisted:log\",\n  \"task_level\": [\n    1\n  ]\n}\n</code></pre>\n\n<p>flocker-dataset-agent.log</p>\n\n<pre><code>{\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"cluster_state\": {\n    \"node_uuid_to_era\": {\n      \"values\": [\n        [\n          {\n            \"hex\": \"e4b23086-3d3e-44c4-acc4-8b5d31c8fc9b\",\n            \"$__class__$\": \"UUID\"\n          },\n          {\n            \"hex\": \"c1ccd75f-14c4-4e33-a9a9-b6ea876c5a05\",\n            \"$__class__$\": \"UUID\"\n          }\n        ],\n        [\n          {\n            \"hex\": \"70f6f5dd-378c-4913-8b2f-0b0f1f55f0a8\",\n            \"$__class__$\": \"UUID\"\n          },\n          {\n            \"hex\": \"f824f593-8723-47f3-8605-a45b2262b268\",\n            \"$__class__$\": \"UUID\"\n          }\n        ]\n      ],\n      \"$__class__$\": \"PMap\"\n    },\n    \"nodes\": [\n      {\n        \"paths\": {\n          \"values\": [\n            [\n              \"7645c292-5329-4aa3-b606-981c2f4e4892\",\n              {\n                \"path\": \"/flocker/55ab515f-43eb-488b-b3a3-e65fa5c62249.default.7645c292-5329-4aa3-b606-981c2f4e4892\",\n                \"$__class__$\": \"FilePath\"\n              }\n            ]\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"uuid\": {\n          \"hex\": \"e4b23086-3d3e-44c4-acc4-8b5d31c8fc9b\",\n          \"$__class__$\": \"UUID\"\n        },\n        \"$__class__$\": \"NodeState\",\n        \"hostname\": \"192.168.224.7\",\n        \"devices\": {\n          \"values\": [\n\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"applications\": [\n\n        ],\n        \"manifestations\": {\n          \"values\": [\n            [\n              \"7645c292-5329-4aa3-b606-981c2f4e4892\",\n              {\n                \"dataset\": {\n                  \"deleted\": false,\n                  \"dataset_id\": \"7645c292-5329-4aa3-b606-981c2f4e4892\",\n                  \"metadata\": {\n                    \"values\": [\n\n                    ],\n                    \"$__class__$\": \"PMap\"\n                  },\n                  \"maximum_size\": 80530636800,\n                  \"$__class__$\": \"Dataset\"\n                },\n                \"primary\": true,\n                \"$__class__$\": \"Manifestation\"\n              }\n            ]\n          ],\n          \"$__class__$\": \"PMap\"\n        }\n      },\n      {\n        \"paths\": {\n          \"values\": [\n\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"uuid\": {\n          \"hex\": \"70f6f5dd-378c-4913-8b2f-0b0f1f55f0a8\",\n          \"$__class__$\": \"UUID\"\n        },\n        \"$__class__$\": \"NodeState\",\n        \"hostname\": \"192.168.224.89\",\n        \"devices\": {\n          \"values\": [\n\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"applications\": [\n\n        ],\n        \"manifestations\": {\n          \"values\": [\n\n          ],\n          \"$__class__$\": \"PMap\"\n        }\n      }\n    ],\n    \"nonmanifest_datasets\": {\n      \"values\": [\n\n      ],\n      \"$__class__$\": \"PMap\"\n    },\n    \"$__class__$\": \"DeploymentState\"\n  },\n  \"action_type\": \"flocker:agent:converge\",\n  \"desired_configuration\": {\n    \"persistent_state\": {\n      \"blockdevice_ownership\": {\n        \"values\": [\n\n        ],\n        \"$__class__$\": \"PMap\"\n      },\n      \"$__class__$\": \"PersistentState\"\n    },\n    \"nodes\": [\n      {\n        \"applications\": [\n\n        ],\n        \"manifestations\": {\n          \"values\": [\n            [\n              \"7645c292-5329-4aa3-b606-981c2f4e4892\",\n              {\n                \"dataset\": {\n                  \"deleted\": false,\n                  \"dataset_id\": \"7645c292-5329-4aa3-b606-981c2f4e4892\",\n                  \"metadata\": {\n                    \"values\": [\n                      [\n                        \"name\",\n                        \"apples\"\n                      ]\n                    ],\n                    \"$__class__$\": \"PMap\"\n                  },\n                  \"maximum_size\": 80530636800,\n                  \"$__class__$\": \"Dataset\"\n                },\n                \"primary\": true,\n                \"$__class__$\": \"Manifestation\"\n              }\n            ]\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"uuid\": {\n          \"hex\": \"70f6f5dd-378c-4913-8b2f-0b0f1f55f0a8\",\n          \"$__class__$\": \"UUID\"\n        },\n        \"$__class__$\": \"Node\"\n      },\n      {\n        \"applications\": [\n\n        ],\n        \"manifestations\": {\n          \"values\": [\n\n          ],\n          \"$__class__$\": \"PMap\"\n        },\n        \"uuid\": {\n          \"hex\": \"e4b23086-3d3e-44c4-acc4-8b5d31c8fc9b\",\n          \"$__class__$\": \"UUID\"\n        },\n        \"$__class__$\": \"Node\"\n      }\n    ],\n    \"leases\": {\n      \"values\": [\n\n      ],\n      \"$__class__$\": \"PMap\"\n    },\n    \"$__class__$\": \"Deployment\"\n  },\n  \"timestamp\": 1459176487.344602,\n  \"action_status\": \"started\",\n  \"task_level\": [\n    2,\n    1\n  ]\n}{\n  \"timestamp\": 1459176487.345864,\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"action_type\": \"flocker:agent:discovery\",\n  \"action_status\": \"started\",\n  \"task_level\": [\n    2,\n    2,\n    1\n  ]\n}{\n  \"fsm_next_state\": \"&lt;ConvergenceLoopStates=CONVERGING&gt;\",\n  \"task_level\": [\n    3\n  ],\n  \"action_type\": \"fsm:transition\",\n  \"timestamp\": 1459176487.348982,\n  \"fsm_output\": [\n    \"&lt;ConvergenceLoopOutputs=CLEAR_WAKEUP&gt;\",\n    \"&lt;ConvergenceLoopOutputs=CONVERGE&gt;\"\n  ],\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"action_status\": \"succeeded\"\n}{\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"task_level\": [\n    2,\n    2,\n    2\n  ],\n  \"action_type\": \"flocker:agent:discovery\",\n  \"timestamp\": 1459176487.354977,\n  \"state\": \"NodeLocalState(node_state=NodeState(applications=None, paths=UnicodeFilepathPMap({}), manifestations=UnicodeManifestationPMap({}), hostname=u'192.168.224.89', uuid=UUID('70f6f5dd-378c-4913-8b2f-0b0f1f55f0a8'), devices=UuidFilepathPMap({})))\",\n  \"action_status\": \"succeeded\"\n}{\n  \"timestamp\": 1459176487.356563,\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"message_type\": \"flocker:agent:converge:actions\",\n  \"task_level\": [\n    2,\n    3\n  ],\n  \"calculated_actions\": \"NoOp(sleep=datetime.timedelta(0, 1))\"\n}{\n  \"timestamp\": 1459176487.356925,\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"action_type\": \"flocker:change:noop\",\n  \"action_status\": \"started\",\n  \"task_level\": [\n    2,\n    4,\n    1\n  ]\n}{\n  \"timestamp\": 1459176487.357233,\n  \"task_uuid\": \"e0a6549f-7515-427f-abb6-b31379895bde\",\n  \"action_type\": \"flocker:change:noop\",\n  \"action_status\": \"succeeded\",\n  \"task_level\": [\n    2,\n    4,\n    2\n  ]\n}\n</code></pre>\n", "is_answered": true, "tags": ["docker", "mesosphere"], "last_edit_date": 1459246724, "title": "Flocker data migration", "last_activity_date": 1459459031, "answer_count": 2, "creation_date": 1459205304, "score": 3, "link": "https://stackoverflow.com/questions/36272512/flocker-data-migration", "answers": [{"body": "<p>The logs contain the following error:</p>\n\n<p><code>_ca.PathError: Certificate file could not be opened. No such file or directory /etc/flocker/plugin.crt</code></p>\n\n<p>This means you are missing the necessary certificates in order for the docker plugin to communicate correctly.</p>\n\n<p>Please see the below link to create the necessary certificates.</p>\n\n<p><a href=\"https://docs.clusterhq.com/en/latest/docker-integration/generate-api-plugin.html\" rel=\"nofollow\">https://docs.clusterhq.com/en/latest/docker-integration/generate-api-plugin.html</a></p>\n", "answer_id": 36285512, "last_activity_date": 1459257549, "creation_date": 1459257549, "score": 2, "owner": {"user_id": 5595645, "profile_image": "https://lh6.googleusercontent.com/-FPQ1qhDFXvE/AAAAAAAAAAI/AAAAAAAAABM/TVz7pI50S2I/photo.jpg?sz=128", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/5595645/ryan-wallner", "display_name": "Ryan Wallner"}, "is_accepted": false, "question_id": 36272512}, {"body": "<p>The problem is still there. The full discussion with Ryan can be found in this link:\n<a href=\"https://groups.google.com/forum/#!topic/flocker-users/l5wCW-U1zKs\" rel=\"nofollow\">https://groups.google.com/forum/#!topic/flocker-users/l5wCW-U1zKs</a></p>\n", "answer_id": 36343970, "last_activity_date": 1459459031, "creation_date": 1459459031, "score": 1, "owner": {"user_id": 6044613, "profile_image": "https://www.gravatar.com/avatar/6b83db161a0a767785cd77120a4216f1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 50, "link": "https://stackoverflow.com/users/6044613/distephane", "display_name": "DiStephane"}, "is_accepted": false, "question_id": 36272512}], "owner": {"user_id": 6044613, "profile_image": "https://www.gravatar.com/avatar/6b83db161a0a767785cd77120a4216f1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 50, "link": "https://stackoverflow.com/users/6044613/distephane", "display_name": "DiStephane"}, "view_count": 358, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36272512}{"body": "<p>I have a situation where i need to create a mesos cluster considering KVM based agent nodes from different cloud platforms.</p>\n\n<p>I am trying to explain the situation here:</p>\n\n<p>I have access to project A and project B. For project A, I have 6 KVM based nodes and for project B, I have 3 KVM based nodes. Each of the KVM nodes has a public ip associated with it. Now I need to create a Mesos cluster of three masters from project A cloud, then need to associate 6 agents to the cluster, 3 from project A and 3 from project B. </p>\n\n<p>Problem That I have faced:</p>\n\n<p>I was able to setup the mesos master and agents in the same cloud platform (network) with their internal ip (like 10.0.0.50) but in the zookeeper if I mention floating ip the cluster does not start working.Now without public ips I can not add agents from the different cloud account.</p>\n\n<p>One straight question:\ncan we setup a Mesos master quorum of three nodes with their floating public ips instead of internal ip?</p>\n\n<p>Please suggest what could be the best way to incorporate multiple agent nodes from different networks. FYI, I am using mesosphere based packages to install messos/marathon and zookeeper.</p>\n", "is_answered": true, "tags": ["cloud", "mesos", "mesosphere"], "title": "creating a Mesos cluster considering nodes from different cloud platforms and network", "last_activity_date": 1468016834, "answer_count": 1, "creation_date": 1466092014, "score": 2, "link": "https://stackoverflow.com/questions/37863813/creating-a-mesos-cluster-considering-nodes-from-different-cloud-platforms-and-ne", "answers": [{"body": "<p>I have resolved the issue for single master and 3 agents resides in different networks.</p>\n\n<ul>\n<li>master public ip is: 129.11.22.33</li>\n<li>agent1 public ip is: 130.11.22.33</li>\n<li>agent1 public ip is: 135.11.22.33</li>\n<li>agent1 public ip is: 140.11.22.33</li>\n</ul>\n\n<p>to start mesos master :</p>\n\n<pre><code>sudo ./bin/mesos-master.sh --work_dir=/var/lib/mesos --advertise_ip=129.11.22.33 \n</code></pre>\n\n<p>to start mesos aglent:</p>\n\n<pre><code>sudo ./bin/mesos-slave.sh master=129.11.22.33 --advertise_ip=130.11.22.33\nsudo ./bin/mesos-slave.sh master=129.11.22.33 --advertise_ip=135.11.22.33\nsudo ./bin/mesos-slave.sh master=129.11.22.33 --advertise_ip=140.11.22.33\n</code></pre>\n\n<p>You can see all three mesos agents appearing in the mesos web UI at</p>\n\n<p>129.11.22.33:5050/slaves in the browser</p>\n", "answer_id": 38276218, "last_activity_date": 1468016834, "creation_date": 1468016834, "score": 1, "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "is_accepted": false, "question_id": 37863813}], "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 54, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37863813}{"is_answered": false, "tags": ["dcos"], "title": "Declaring service UI in DCOS results in broken links", "last_activity_date": 1488170551, "answer_count": 0, "creation_date": 1488170551, "score": 1, "link": "https://stackoverflow.com/questions/42477961/declaring-service-ui-in-dcos-results-in-broken-links", "owner": {"user_id": 1734628, "profile_image": "https://i.stack.imgur.com/xzu0z.jpg?s=128&g=1", "user_type": "registered", "reputation": 261, "link": "https://stackoverflow.com/users/1734628/steven-lowenthal", "accept_rate": 0, "display_name": "Steven Lowenthal"}, "view_count": 24, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42477961}{"is_answered": true, "tags": ["docker", "mesos", "mesosphere", "dcos", "kubernetes-mesos"], "last_edit_date": 1495013677, "title": "How to create pod in Mesosphere with container type as Docker?", "last_activity_date": 1495013677, "answer_count": 1, "creation_date": 1494958693, "score": 0, "link": "https://stackoverflow.com/questions/44008855/how-to-create-pod-in-mesosphere-with-container-type-as-docker", "owner": {"user_id": 2342287, "profile_image": "https://www.gravatar.com/avatar/d27331309193685631c8eafe2348d961?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3, "link": "https://stackoverflow.com/users/2342287/vivek-kumar", "display_name": "Vivek Kumar"}, "view_count": 59, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44008855}{"body": "<p>I have a cluster managed by DC/OS and a dockerized service that I want to deploy through Marathon. I already have a marathon-lb that is being used for service discovery and load balancing of other existing services. All these services are deployed using BRIDGE network.</p>\n\n<p>The new service exposes more than one ports. Port A is for communication between the instances of the service and port B is for accepting requests from the world. I want to use HOST (and not BRIGE) network for deploying the service. </p>\n\n<p>I would like to know how to configure the json of the service in order for marathon-lb to load-balance and expose externally port B.</p>\n\n<p>I have already tried various scenarios and configurations but none worked. The json that I have constructed is the below.</p>\n\n<pre><code>{\n  \"id\": \"/cassandra-seed\",   \n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"HOST\",\n      \"requirePorts\": true,\n      \"privileged\": true,\n      \"forcePullImage\": false     \n    }\n  },\n  \"constraints\": [[\"hostname\",\"UNIQUE\"]],\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"portDefinitions\": [\n    { \"port\": portA,\"protocol\": \"tcp\"},\n    { \"port\": portB,\"protocol\": \"tcp\"}\n  ]\n}\n</code></pre>\n\n<p>In <a href=\"https://mesosphere.github.io/marathon/docs/ports.html\" rel=\"nofollow noreferrer\">Marathon documentation</a> it is stated that by explicitly defining port B in portDefitions and setting requirePorts to true, service ports are equal to host port. Also, I deployed a new version of marathon-lb where port B is its portDefinitions section (violating the 10000-10100 default range).</p>\n\n<p>Thus, I assumed that by providing the HAPROXY_GROUP label in the service json, marathon-lb would expose port B as desired. However, this does not seem to be the case. If I deploy the service and <code>curl http://marathon-lb.marathon.mesos:portB</code> the response is \"Empty reply from server\". However, If I <code>curl http://physicalNodeIP:portB</code> I can connect to an instance of the service.</p>\n\n<p>Thank you in advance.</p>\n", "is_answered": true, "title": "How to config Marathon-lb to load balance a service launched in HOST network?", "tags": ["docker", "marathon", "dcos"], "last_activity_date": 1490700185, "accepted_answer_id": 41597504, "creation_date": 1484144205, "answers": [{"body": "<p>It looks like you have <code>requirePorts</code> in the wrong section of the app definition. It should be at the top level, like this:</p>\n\n<pre><code>{\n  \"id\": \"/cassandra-seed\",   \n  \"cpus\": 1.5,\n  \"mem\": 8192,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"cassandra:2.2.3\",\n      \"network\": \"HOST\",\n      \"privileged\": true,\n      \"forcePullImage\": false     \n    }\n  },\n  \"constraints\": [[\"hostname\",\"UNIQUE\"]],\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"requirePorts\": true,\n  \"portDefinitions\": [\n    { \"port\": portA,\"protocol\": \"tcp\"},\n    { \"port\": portB,\"protocol\": \"tcp\"}\n  ]\n}\n</code></pre>\n\n<p>As a sidenote, you should consider using the Cassandra framework, as opposed to running Cassandra on Marathon.</p>\n", "answer_id": 41597504, "last_activity_date": 1484157117, "creation_date": 1484157117, "score": 1, "owner": {"user_id": 4488486, "profile_image": "https://lh5.googleusercontent.com/-B_euLGuvgb4/AAAAAAAAAAI/AAAAAAAAUMI/XbYweAvxML0/photo.jpg?sz=128", "user_type": "registered", "reputation": 169, "link": "https://stackoverflow.com/users/4488486/brenden-matthews", "display_name": "Brenden Matthews"}, "is_accepted": true, "question_id": 41593231}], "score": 1, "link": "https://stackoverflow.com/questions/41593231/how-to-config-marathon-lb-to-load-balance-a-service-launched-in-host-network", "answer_count": 1, "owner": {"user_id": 1571583, "profile_image": "https://i.stack.imgur.com/eR0Ux.jpg?s=128&g=1", "user_type": "registered", "reputation": 541, "link": "https://stackoverflow.com/users/1571583/manolis", "accept_rate": 38, "display_name": "Manolis"}, "view_count": 313, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41593231}{"body": "<p>Both Marathon and Aurora are build on Mesos and supposedly are engineered for running long running services. My questions are:</p>\n\n<ol>\n<li>What are their differences? I have struggled in finding any good explanations regarding their key differences</li>\n<li>Do these frameworks run anything that runs on Linux? For Marathon they state that it can run anything that \"is executable in a shell\" but this is sort of vague :)</li>\n</ol>\n\n<p>Thanks!</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon", "aurora"], "last_edit_date": 1433810210, "title": "Marathon vs Aurora and their purposes", "last_activity_date": 1433810210, "answer_count": 4, "creation_date": 1424556455, "score": 41, "link": "https://stackoverflow.com/questions/28651922/marathon-vs-aurora-and-their-purposes", "answers": [{"body": "<p><em>Disclaimer: I don't have hands-on experience with Aurora, only with Marathon.</em></p>\n\n<p>ad Q1: In a nutshell Apache Aurora is capable of doing what Marathon + Chronos can provide, that is, schedule both long-running services and recurring (batch) jobs; see also <a href=\"http://aurora.incubator.apache.org/documentation/latest/user-guide/\" rel=\"nofollow\">Aurora user guide</a>. </p>\n\n<p>ad Q2: Yes, anything. Currently based on cgroups and Docker but hey, you can <a href=\"http://mesos.apache.org/documentation/latest/external-containerizer/\" rel=\"nofollow\">roll your own</a>.</p>\n", "answer_id": 29025817, "last_activity_date": 1426226529, "creation_date": 1426226529, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 28651922}, {"body": "<p>I have more experience with Marathon.</p>\n\n<p>Ideological:</p>\n\n<ul>\n<li>Marathon is a relatively tested product that is used in production at AirBnB. Aurora is an early Apache project (so YMMV).</li>\n<li>Both are open source and active. Feel free to contribute pull requests or file issues!</li>\n</ul>\n\n<p>Technical:</p>\n\n<ul>\n<li>Marathon doesn't schedule batch tasks or cron jobs</li>\n<li>Marathon has a friendly UI and better health indicators (in 0.8.x)</li>\n</ul>\n\n<p>In regards to your second question, you can run any command or docker container, and Mesos will do the resource isolation for you. If you have 50% CentOS nodes and 50% Ubuntu nodes and you run a task that executes <code>apt-get</code>, the task will have a 50% chance of failure. Mesos and Marathon have no awareness of the actual machines.</p>\n", "answer_id": 29041677, "last_activity_date": 1426279653, "creation_date": 1426279653, "score": 3, "owner": {"user_id": 4668914, "profile_image": "https://www.gravatar.com/avatar/552ba2bfb3055266f01460a2ef97f7f8?s=128&d=identicon&r=PG", "user_type": "unregistered", "reputation": 81, "link": "https://stackoverflow.com/users/4668914/abhay-agarwal", "display_name": "Abhay Agarwal"}, "is_accepted": false, "question_id": 28651922}, {"body": "<p>So I've been evaluating both and this is my summary.</p>\n\n<p>Aurora</p>\n\n<pre><code>[+] also handles recurring jobs\n[+] finer grained, extensive file-based configuration\n[+] has namespaces so multiple environments can co-exist\n[-] read-only UI, no official API\n[~] file based configuration and cli based execution brings overhead (which can be justified with more extensive feature set)\n</code></pre>\n\n<p>Marathon</p>\n\n<pre><code>[+] very easy to setup and use\n[+] UI that provides control and extensive API (even with features missing from UI at the moment)\n[+] event bus to listen in on api calls\n[-] handles only long-running jobs\n[-] does not have separate deployment-run-cleanup steps, these if necessary need to be combined in a script of one-liner\n</code></pre>\n\n<p>Even though Aurora has better capabilities, I prefer Marathon due to Auroras complexity/overhead and lack of UI (for control) &amp; API</p>\n", "answer_id": 29511619, "last_activity_date": 1428487429, "creation_date": 1428487429, "score": 20, "owner": {"user_id": 701260, "profile_image": "https://www.gravatar.com/avatar/660bb878ae25be5b78c87508f64e68f5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1419, "link": "https://stackoverflow.com/users/701260/eren-g%c3%bcven", "accept_rate": 80, "display_name": "Eren G\u00fcven"}, "is_accepted": false, "question_id": 28651922}, {"body": "<p><em>Disclaimer: I am the VP of Apache Aurora, and have been the tech lead of the Aurora team at Twitter for ~5 years.  My likely-biased opinions are my own and do not necessarily represent those of Twitter or the ASF.</em></p>\n\n<blockquote>\n  <p>Do these frameworks run anything that runs on Linux? For Marathon they\n  state that it can run anything that \"is executable in a shell\" but\n  this is sort of vague :)</p>\n</blockquote>\n\n<p>Essentially, yes.  Ultimately these systems are sophisticated machinery to execute shell code somewhere in a cluster :-)</p>\n\n<blockquote>\n  <p>What are their differences? I have struggled in finding any good\n  explanations regarding their key differences</p>\n</blockquote>\n\n<p>Aurora and Marathon do indeed offer similar feature sets, both being classified as \"service schedulers\".  In other words, you hand us instructions for how to run your application servers, and we do our best to keep them up.</p>\n\n<p>I'll offer some differences in broad strokes.  When it comes to shortcomings mentioned in each, I think it's safe to say that the  communities are aware and intend to fix them.</p>\n\n<p><strong>Ease of use</strong></p>\n\n<p>Aurora is not easy to install.  It will likely feel like you are trailblazing while setting it up.  It exposes a thrift API, which means you'll need a thrift client to interact with it programmatically (a REST-like API is coming, but is vaporware at the moment), or use our command line client.  Aurora has a DSL for <a href=\"https://github.com/apache/aurora/blob/master/docs/configuration-reference.md\" rel=\"noreferrer\" title=\"configuration\">configuration</a> which can be daunting, but allows you to easily share templates and common patterns as you use the system more.</p>\n\n<p>Marathon, on the other hand, helps you to run 'Hello World' as quickly as possible.  It has great <a href=\"https://docs.mesosphere.com/tutorials/\" rel=\"noreferrer\" title=\"docs\">docs</a> to do this in many environments and there's little overhead to get going.  It has a REST API, making it easier to adapt to custom tools.  It uses JSON for <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html#post-/v2/apps\" rel=\"noreferrer\" title=\"configuration\">configuration</a>, which is easy to start with but more prone to cargo culting.</p>\n\n<p><strong>Targeted use cases</strong></p>\n\n<p>Aurora has always been designed to handle a large engineering organization.  The clusters at Twitter have tens of thousands of machines and hundreds of engineers using them.  It is critical to Twitter's business.  As a result, we take our requirements of scale, stability, and security very seriously.  We make sure to only condone features that we believe are trustworthy at scale in production (for example, we have our Docker support labeled as beta because of known issues with Docker itself and the Mesos-Docker integration).  We also have features like preemption that make our clusters suitable for mixing business-critical services with prototypes and experiments.</p>\n\n<p>I can't make any claim for or against Marathon's scalability.  On the feature front, Marathon has build out features quickly, but this can feel bleeding edge in practice (Docker support is a good example).  This is not always due to Marathon itself, but also layers down the stack.  Marathon does not provide preemption.</p>\n\n<p><strong>Ownership</strong></p>\n\n<p>To some, ownership and governance of a project is important.  It feel that in practice it does not define the openness of a project, but for some people/companies the legal fine print can be a deal-breaker.</p>\n\n<ul>\n<li>Marathon is owned by a company (Mesosphere)</li>\n</ul>\n\n<p>To some, this is beneficial, to others is is not.  It means that you can pay for support and features.  It also means that there is something to be sold, and the project direction is ultimately decided by Mesosphere's interests.</p>\n\n<ul>\n<li>Aurora is owned by the Apache Software Foundation</li>\n</ul>\n\n<p>This means it is subject to the governance model of the ASF, driven by the community.  Aurora does not have paying customers, and there is not currently a software shop that you can pay for development.</p>\n\n<p><strong>tl;dr</strong> If you are just getting your feet wet with running services on Mesos, I would suggest Marathon as your first port of call.  It will be easier for you to get running and poke around the ecosystem.  If you are forming the 'private cloud strategy' for a company, I suggest seriously considering Aurora, as it is proven and specifically designed for that.</p>\n", "answer_id": 29858288, "last_activity_date": 1429913004, "creation_date": 1429913004, "score": 77, "owner": {"user_id": 34968, "profile_image": "https://www.gravatar.com/avatar/359afee74ee2d0e8d5f0f75029908184?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1139, "link": "https://stackoverflow.com/users/34968/bill", "display_name": "Bill"}, "is_accepted": false, "question_id": 28651922}], "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 15131, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 28651922}{"body": "<p>I'm currently trying to deploy <a href=\"https://www.github.com/eremetic-framework/eremetic\" rel=\"nofollow noreferrer\">Eremetic</a> (version 0.28.0) on top of Marathon using the <a href=\"https://github.com/eremetic-framework/eremetic/blob/v0.28.0/misc/eremetic.json\" rel=\"nofollow noreferrer\">configuration provided as an example</a>. I actually have been able to deploy it once, but suddenly, after trying to redeploy it, the framework stays inactive.</p>\n\n<p>By inspecting the logs I noticed a constant attempt to connect to some service that apparently never succeeds because of some authentication problem. </p>\n\n<pre><code>2017/08/14 12:30:45 Connected to [REDACTED_MESOS_MASTER_ADDRESS]\n2017/08/14 12:30:45 Authentication failed: EOF\n</code></pre>\n\n<p>It looks like the service returning an error is ZooKeeper and more precisely it looks like the error can be traced back to <a href=\"https://github.com/samuel/go-zookeeper/blob/master/zk/conn.go#L433\" rel=\"nofollow noreferrer\">this line</a> in the Go ZooKeeper library. ZooKeeper however seems to work: I've tried to query it directly with <code>zkCli</code> and to run a small Spark job (where the Mesos master is given with <code>zk://</code> URL) and everything seems to work.</p>\n\n<p>Unfortunately I'm not able to diagnose the problem further, what could it be?</p>\n", "is_answered": false, "tags": ["go", "apache-zookeeper", "mesos", "mesosphere", "eremetic"], "last_edit_date": 1502717277, "title": "Mesos framework stays inactive due to \"Authentication failed: EOF\"", "last_activity_date": 1502806307, "answer_count": 1, "creation_date": 1502714846, "score": 0, "link": "https://stackoverflow.com/questions/45674899/mesos-framework-stays-inactive-due-to-authentication-failed-eof", "answers": [{"body": "<p>It turned out to be a configuration problem. The master URL was simply wrong and this is how the error was reported.</p>\n", "answer_id": 45694652, "last_activity_date": 1502806307, "creation_date": 1502806307, "score": 0, "owner": {"user_id": 3314107, "profile_image": "https://www.gravatar.com/avatar/9bdb9cc374e313876de99a99d191ecd6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2045, "link": "https://stackoverflow.com/users/3314107/stefanobaghino", "accept_rate": 88, "display_name": "stefanobaghino"}, "is_accepted": false, "question_id": 45674899}], "owner": {"user_id": 3314107, "profile_image": "https://www.gravatar.com/avatar/9bdb9cc374e313876de99a99d191ecd6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2045, "link": "https://stackoverflow.com/users/3314107/stefanobaghino", "accept_rate": 88, "display_name": "stefanobaghino"}, "view_count": 52, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45674899}{"is_answered": true, "tags": ["python", "mesos", "mesosphere"], "title": "Installing Mesos from Mesosphere yum repository", "last_activity_date": 1492757327, "answer_count": 1, "creation_date": 1492725610, "score": 0, "link": "https://stackoverflow.com/questions/43530645/installing-mesos-from-mesosphere-yum-repository", "owner": {"user_id": 3602926, "profile_image": "https://www.gravatar.com/avatar/e8c4ff657f8b171eeb39a5a8c9bcd648?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/3602926/aj-jwair", "display_name": "AJ Jwair"}, "view_count": 180, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43530645}{"body": "<p>I have created a master on my machine with a credentials file that has a public IP on the network rather than localhost as follows:</p>\n\n<pre><code>./bin/mesos-master.sh --ip=192.168.0.3 --work_dir=/var/lib/mesos --credentials=file://master-cred.json\n</code></pre>\n\n<p>I then created a slave on another machine as follows: </p>\n\n<pre><code>./bin/mesos-slave.sh --ip=192.168.0.19 --master=&lt;master-ip&gt;:5050 --credential=file://slave-cred.json\n</code></pre>\n\n<p>Then the master outputs an incoming authentication request however each time it gets refused:</p>\n\n<pre><code>I0903 15:17:48.264104 165863424 master.cpp:4728] Authenticating slave(1)@192.168.0.19:5051\nI0903 15:17:48.264602 166936576 authenticator.cpp:92] Creating new server SASL connection\nI0903 15:17:48.269961 165326848 authenticator.cpp:197] Received SASL authentication start\nI0903 15:17:48.270058 165326848 authenticator.cpp:319] Authentication requires more steps\nI0903 15:17:48.272733 166400000 authenticator.cpp:225] Received SASL authentication step\nW0903 15:17:48.272817 166400000 authenticator.cpp:325] Authentication failure: authentication failure\nW0903 15:17:48.273136 166400000 master.cpp:4755] Failed to authenticate slave(1)@192.168.0.19:5051: Refused authentication\n</code></pre>\n\n<p>Both the credential files are correct.</p>\n\n<p>This is the output from the slave:</p>\n\n<pre><code>I0903 15:17:48.232733  2377 slave.cpp:747] Authenticating with master master@192.168.0.3:5050\nI0903 15:17:48.232951  2377 slave.cpp:752] Using default CRAM-MD5 authenticatee\nI0903 15:17:48.235091  2376 authenticatee.cpp:91] Initializing client SASL\nI0903 15:17:48.239701  2376 authenticatee.cpp:115] Creating new client SASL connection\nI0903 15:17:48.239914  2377 slave.cpp:720] Detecting new master\nI0903 15:17:48.241755  2377 slave.cpp:4193] Received oversubscribable resources  from the resource estimator\nI0903 15:17:48.287488  2378 authenticatee.cpp:206] Received SASL authentication mechanisms: CRAM-MD5\nI0903 15:17:48.287619  2378 authenticatee.cpp:232] Attempting to authenticate with mechanism 'CRAM-MD5'\nI0903 15:17:48.290863  2378 authenticatee.cpp:252] Received SASL authentication step\nMaster master@192.168.0.3:5050 refused authentication\n</code></pre>\n\n<p>However when I run the slave from the same machine as the master, it works fine. Any ideas?</p>\n", "is_answered": true, "title": "Why is my Mesos master failing authentication with slave?", "last_edit_date": 1441290286, "tags": ["authentication", "distributed-computing", "mesos", "mesosphere"], "view_count": 543, "accepted_answer_id": 32404550, "last_activity_date": 1462551183, "answers": [{"body": "<p>It was actually being caused by a problem with how I set up the networking on the virtual machine slave. </p>\n", "answer_id": 32404550, "last_activity_date": 1441391725, "creation_date": 1441391725, "score": 1, "owner": {"user_id": 3948757, "profile_image": "https://www.gravatar.com/avatar/cf5253308111eacc7dd05914daeb8a13?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 195, "link": "https://stackoverflow.com/users/3948757/tom", "accept_rate": 67, "display_name": "Tom"}, "is_accepted": true, "question_id": 32377243}], "score": 0, "link": "https://stackoverflow.com/questions/32377243/why-is-my-mesos-master-failing-authentication-with-slave", "answer_count": 1, "owner": {"user_id": 3948757, "profile_image": "https://www.gravatar.com/avatar/cf5253308111eacc7dd05914daeb8a13?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 195, "link": "https://stackoverflow.com/users/3948757/tom", "accept_rate": 67, "display_name": "Tom"}, "creation_date": 1441287491, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 32377243}{"body": "<p>I've created a one mesos master and three mesos slave environment. Now, marathon is running as a framework for mesos jobs. I am trying to deploy a simple job: </p>\n\n<pre><code>{\n    \"id\": \"basic-0\", \n    \"cmd\": \"while [ true ] ; do echo 'Hello Marathon' ; sleep 5 ; done\",\n    \"cpus\": 0.1,\n    \"mem\": 10.0,\n    \"instances\": 1\n}\n</code></pre>\n\n<p>But this is hanging into the marathon web ui for a long time. I have tried manually creating a marathon job, but that one also keeps itself in deployment state forever. I am clueless why its not running, any idea? </p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1439485675, "title": "Marathon jobs are hanging in the deployment stage", "last_activity_date": 1484445068, "answer_count": 1, "creation_date": 1439485048, "score": 1, "link": "https://stackoverflow.com/questions/31994268/marathon-jobs-are-hanging-in-the-deployment-stage", "answers": [{"body": "<p>Please check your marathon logs and it says reason why its still in waiting state. It can be due to multiple issues like slave deregistration frequently, insufficient resources, not meeting constraint requirement</p>\n", "answer_id": 41657016, "last_activity_date": 1484445068, "creation_date": 1484445068, "score": 0, "owner": {"user_id": 3413559, "profile_image": "https://www.gravatar.com/avatar/c1080c4ebb11405ced6a7f7dc16b4228?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/3413559/sathee005", "display_name": "sathee005"}, "is_accepted": false, "question_id": 31994268}], "owner": {"user_id": 5216670, "profile_image": "https://graph.facebook.com/1143994522296284/picture?type=large", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/5216670/pankaj-saha", "accept_rate": 0, "display_name": "Pankaj Saha"}, "view_count": 2001, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 31994268}{"is_answered": false, "tags": ["ubuntu-14.04", "apache-zookeeper", "mesos", "mesosphere"], "last_edit_date": 1463290423, "title": "Mesosphere: Webserver on port 5050 not responding / Failed to create Zookeeper, zookeeper_init: No such file or directory", "last_activity_date": 1471004228, "answer_count": 1, "creation_date": 1463217409, "score": 0, "link": "https://stackoverflow.com/questions/37224861/mesosphere-webserver-on-port-5050-not-responding-failed-to-create-zookeeper", "owner": {"user_id": 6333658, "profile_image": "https://www.gravatar.com/avatar/6e492657ac01d4004b0cd626e9413314?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/6333658/bobtheserverbuilder", "display_name": "BobTheServerBuilder"}, "view_count": 192, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37224861}{"body": "<p>I set up the master and slave with the method described at  <a href=\"https://open.mesosphere.com/getting-started/install/#master-setup\" rel=\"nofollow noreferrer\">https://open.mesosphere.com/getting-started/install/#master-setup</a>.</p>\n\n<p>After that I could run tasks on Mesos. When restarting the VM again, the IP/s have changed so the slave could not connect to the master anymore. </p>\n\n<p><a href=\"https://i.stack.imgur.com/Htt2k.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Htt2k.png\" alt=\"enter image description here\"></a></p>\n\n<p>I also tried to set the IP but failed.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1462306477, "title": "Slave could not register with the master", "last_activity_date": 1462306477, "answer_count": 1, "creation_date": 1460904570, "score": -1, "link": "https://stackoverflow.com/questions/36678048/slave-could-not-register-with-the-master", "answers": [{"body": "<p>If you are running the cluster in a High Availability mode, best way is to have zookeeper installed and let mesos-slaves use zookeeper to find out about the master.\nFor more details look up:\n<a href=\"http://mesos.apache.org/documentation/latest/high-availability/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/high-availability/</a></p>\n\n<p>For installing in HA mode:\n<a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04\" rel=\"nofollow\">https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04</a></p>\n\n<p>Now, it is very useful to have a static private IP for the masters. That way you're not changing the zk url after every reboot.</p>\n", "answer_id": 36685601, "last_activity_date": 1460954522, "creation_date": 1460954522, "score": 0, "owner": {"user_id": 4556415, "profile_image": "https://www.gravatar.com/avatar/56e1ff21595205fac1e665dfcc75efd2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/4556415/yogesh-nath", "display_name": "Yogesh Nath"}, "is_accepted": false, "question_id": 36678048}], "owner": {"user_id": 5330248, "profile_image": "https://www.gravatar.com/avatar/442c4d6415419c60e344534e7b150ac0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5330248/user5330248", "display_name": "user5330248"}, "view_count": 136, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36678048}{"body": "<p>I recently stumbled upon <a href=\"http://mantl.io/\" rel=\"nofollow\">http://mantl.io/</a> and <a href=\"https://mesosphere.com/infinity/\" rel=\"nofollow\">https://mesosphere.com/infinity/</a>. However, I am unsure about the advantages of each approach. </p>\n\n<p>So far I know <strong>mantl</strong> integrates some components like ELK, calico, vault, traefik which are nice to have out of the box for a common application. Whereas <strong>infinity</strong> seems to be well suited for IOT /big-data analytics applications.</p>\n\n<p>Can you help me to explain the difference / advantages of each approach.</p>\n", "is_answered": true, "title": "Infinity vs. mantl", "tags": ["cloud", "distributed-computing", "mesosphere"], "last_activity_date": 1450276703, "accepted_answer_id": 34314816, "creation_date": 1450000040, "answers": [{"body": "<p>A bit comparing apples and oranges. Infinity is what we call a DCOS stack, it's a combo of different services (in this case Kafka, Spark, C*, and Akka) for a specific domain, in this case IoT apps.</p>\n\n<p>I wouldn't say that ELK is a unique thing to mantl, since it's also <a href=\"https://github.com/mesosphere/multiverse/tree/version-1.x/repo/packages/E/elasticsearch/1\" rel=\"nofollow\">available on the DCOS</a> and in fact I did <a href=\"https://twitter.com/mhausenblas/status/651417553269575680\" rel=\"nofollow\">install ES</a> on DCOS myself a while ago, with little effort. The same is true for <a href=\"https://github.com/brndnmtthws/vault-dcos\" rel=\"nofollow\">Vault</a>, etc.</p>\n\n<p>DCOS comes with a <a href=\"https://docs.mesosphere.com/services/overview/\" rel=\"nofollow\">number of services</a>, growing every week, ready to be used in different application areas: from pure stateless deployments (for example a Web server farm) to CI/CD envs to analytics (and IoT).</p>\n", "answer_id": 34314816, "last_activity_date": 1450276703, "creation_date": 1450276703, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 34249798}], "score": 1, "link": "https://stackoverflow.com/questions/34249798/infinity-vs-mantl", "answer_count": 1, "owner": {"user_id": 2587904, "profile_image": "https://i.stack.imgur.com/31ZTY.jpg?s=128&g=1", "user_type": "registered", "reputation": 2400, "link": "https://stackoverflow.com/users/2587904/georg-heiler", "accept_rate": 95, "display_name": "Georg Heiler"}, "view_count": 358, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34249798}{"is_answered": true, "tags": ["cluster-computing", "coreos", "mesos", "mesosphere"], "last_edit_date": 1417633187, "title": "Main differences between mesosphere and coreos", "last_activity_date": 1417633187, "answer_count": 1, "creation_date": 1412403210, "score": 7, "link": "https://stackoverflow.com/questions/26190246/main-differences-between-mesosphere-and-coreos", "accepted_answer_id": 26190424, "owner": {"user_id": 3974509, "profile_image": "https://www.gravatar.com/avatar/ccf55715eef50a5302c972eeda323d06?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 69, "link": "https://stackoverflow.com/users/3974509/dante", "accept_rate": 100, "display_name": "Dante"}, "view_count": 3920, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 26190246}{"body": "<p>I am trying to link 2 docker containers using mesos/marathon framework. As I understand there is no way to use the docker link feature in mesos/martahon. So the way to go forward is to use service discovery. Since zookeeper is already used my question is how to use zookeeper for service discovery so that 1 container can talk to another one.</p>\n", "is_answered": true, "title": "Using zookeeper for service discovery of mesos slaves running docker", "tags": ["docker", "apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_activity_date": 1424537381, "accepted_answer_id": 28648334, "creation_date": 1424442983, "answers": [{"body": "<p>Although possible I would reconsider using Zookeeper as a centralized KV store for your configuration and services information. You could try to implement a daemon to ask and save data in zookeeper in order to configure your container's config files and live patching, but it's a complex solution (there are examples of this approach in <a href=\"http://engineering.pinterest.com/post/77933733851/zookeeper-resilience-at-pinterest\" rel=\"nofollow\">this post from Pinterest</a>, or in Hadoop's ZKFailoverController daemon). From my point of view there are more suited solutions as Consul or etcd, with implementations of the daemons as <a href=\"https://github.com/kelseyhightower/confd\" rel=\"nofollow\">kelseyhightower/confd</a> or <a href=\"https://github.com/hashicorp/consul-template\" rel=\"nofollow\">consul-template</a>.</p>\n", "answer_id": 28638612, "last_activity_date": 1424467997, "creation_date": 1424467997, "score": 0, "owner": {"user_id": 2862098, "profile_image": "https://www.gravatar.com/avatar/2489bd6fa9cdf4fee16418a572cc7f88?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 5693, "link": "https://stackoverflow.com/users/2862098/javier-cortejoso", "display_name": "Javier Cortejoso"}, "is_accepted": false, "question_id": 28631465}, {"body": "<p>For service discovery on Mesos/Marathon, you can use a proxy server (see <a href=\"https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html</a>) or a DNS server that derives settings from Mesos automatically (see <a href=\"https://github.com/mesosphere/mesos-dns\" rel=\"nofollow\">https://github.com/mesosphere/mesos-dns</a>). </p>\n", "answer_id": 28648334, "last_activity_date": 1424537381, "creation_date": 1424537381, "score": 1, "owner": {"user_id": 4591754, "profile_image": "https://www.gravatar.com/avatar/e32872da961a924555451e6d819079be?s=128&d=identicon&r=PG", "user_type": "unregistered", "reputation": 26, "link": "https://stackoverflow.com/users/4591754/chrisinba", "display_name": "Chrisinba"}, "is_accepted": true, "question_id": 28631465}], "score": 1, "link": "https://stackoverflow.com/questions/28631465/using-zookeeper-for-service-discovery-of-mesos-slaves-running-docker", "answer_count": 2, "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 642, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28631465}{"body": "<p>In lab got around 50 desktops with win 7 OS. They are unused during weekends. Looking for any feasibility to aggregate these hardware as single pool of compute, storage and network. Then virtualize them as as per the need, example put 10 core and 10 TB storage for an application. Note, the desktops need to function as individual machine during weekdays.</p>\n\n<pre><code> Thanking for the same, in advance!\n</code></pre>\n", "is_answered": false, "tags": ["aggregation", "mesos", "dcos"], "title": "Feasibility for Virtualization Aggregation with Desktops?", "last_activity_date": 1500375877, "answer_count": 0, "creation_date": 1500375877, "score": 0, "link": "https://stackoverflow.com/questions/45164973/feasibility-for-virtualization-aggregation-with-desktops", "owner": {"user_id": 983549, "profile_image": "https://www.gravatar.com/avatar/4dcdcfa2cb642e16c526b6cfe6ed86a0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3, "link": "https://stackoverflow.com/users/983549/user983549", "display_name": "user983549"}, "view_count": 9, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 45164973}{"body": "<p>I am using bosun+cadvisor to monitor docker containers across my mesos infrastructure.\nIs there any way to monitor specific docker container or containers and write an alert?</p>\n\n<p>Maybe using the label assigned to the containers? Because I cannot use the container name (mesos generates a custom name for the container).</p>\n\n<p>Thanks.</p>\n\n<p>EDIT:\nI found that cadvisor supports docker labels. Anyway to get the to scollector and to bosun to query using labels?</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "bosun", "cadvisor"], "last_edit_date": 1470129098, "title": "Monitor docker containers based on labels assigned", "last_activity_date": 1470159198, "answer_count": 1, "creation_date": 1470127784, "score": 1, "link": "https://stackoverflow.com/questions/38715827/monitor-docker-containers-based-on-labels-assigned", "answers": [{"body": "<p>You can use the <a class='doc-link' href=\"https://stackoverflow.com/documentation/bosun/721/scollector-process-and-service-monitoring/2660/monitoring-docker-containers#t=201608021731250466468\">TagOverride feature</a> in scollector to generate additional tags for the cadvisor metrics. I'm not sure what the docker_name format looks like for mesos, but for Kubernetes you would use:</p>\n\n<pre><code>[[Cadvisor]]\n  URL = \"http://mydockerhost01:8080\"\n\n#Override tags for Kubernetes containers\n[[TagOverride]]\n  CollectorExpr = \"cadvisor\"\n  [TagOverride.MatchedTags]\n    docker_name = 'k8s_(?P&lt;container_name&gt;[^\\.]+)\\.[0-9a-z]+_(?P&lt;pod_name&gt;[^-]+)'\n    docker_id = '^(?P&lt;docker_id&gt;.{12})'\n  [TagOverride.Tags]\n    docker_name = ''\n    name = ''\n</code></pre>\n\n<p>This would override the docker_id tags (shorten to 12 chars), add a container_name and pod_name tag, and remove the docker_name and name tag.</p>\n", "answer_id": 38727011, "last_activity_date": 1470159198, "creation_date": 1470159198, "score": 0, "owner": {"user_id": 17373, "profile_image": "https://www.gravatar.com/avatar/da1209aa320f9bbebbf128ac6a0751d3?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6776, "link": "https://stackoverflow.com/users/17373/greg-bray", "accept_rate": 88, "display_name": "Greg Bray"}, "is_accepted": false, "last_edit_date": 1495542259, "question_id": 38715827}], "owner": {"user_id": 880963, "profile_image": "https://www.gravatar.com/avatar/edacc2ea1717765faf2ab392116b7182?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 402, "link": "https://stackoverflow.com/users/880963/krish7919", "accept_rate": 43, "display_name": "krish7919"}, "view_count": 177, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38715827}{"body": "<p>I an using mesos-consul and deployed it via marathon. the json config for the job is </p>\n\n<pre><code>{\n  \"id\": \"/mesos-consul\",\n  \"cmd\": null,\n  \"cpus\": 0.1,\n  \"mem\": 256,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"constraints\": [\n    [\n      \"hostname\",\n      \"LIKE\",\n      \"fwvm.*\"\n    ]\n  ],\n  \"acceptedResourceRoles\": [],\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"ciscocloud/mesos-consul\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [],\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10000,\n      \"protocol\": \"tcp\",\n      \"name\": \"default\",\n      \"labels\": {}\n    }\n  ],\n  \"args\": [\n    \"--zk=zk://zookeeper.service.consul:2181/mesos\",\n    \"--log-level=debug\",\n    \"--consul\",\n    \"--refresh=5s\"\n  ]\n}\n</code></pre>\n\n<p>I am running consul with one server and one client. </p>\n\n<pre><code>consul members info\nNode  Address            Status  Type    Build  Protocol  DC\nvm1   10.21.10.22:8301  alive   server  0.7.5  2         devops\nvm2   10.21.10.25:8301  alive   client  0.7.5  2         devops\n</code></pre>\n\n<p>mesos and marathon also looks good. still its not working </p>\n\n<p>mesos-consul logs showing </p>\n\n<pre><code>I0410 14:45:17.917712 18194 exec.cpp:162] Version: 1.2.0\nI0410 14:45:17.929821 18200 exec.cpp:237] Executor registered on agent 92704ba7-7324-4e74-a7fd-7b7c642766b2-S0\nI0410 14:45:17.932121 18197 docker.cpp:850] Running docker -H unix:///var/run/docker.sock run --cpu-shares 102 --memory 268435456 --env-file /tmp/yDR5nL -v /var/lib/mesos/slaves/92704ba7-7324-4e74-a7fd-7b7c642766b2-S0/frameworks/2679cb7f-1fc2-4e8b-be3c-44f0fb54f618-0000/executors/mesos-consul.36b6d6d3-1dce-11e7-a717-0242b31c8310/runs/6a22da5d-4a33-4d1d-ada7-cd688474e4fc:/mnt/mesos/sandbox --net bridge --label=MESOS_TASK_ID=mesos-consul.36b6d6d3-1dce-11e7-a717-0242b31c8310 --name mesos-92704ba7-7324-4e74-a7fd-7b7c642766b2-S0.6a22da5d-4a33-4d1d-ada7-cd688474e4fc ciscocloud/mesos-consul --zk=zk://http://10.202.11.22:2181/mesos --log-level=debug --consul --refresh=5s\ntime=\"2017-04-10T09:15:22Z\" level=info msg=\"Using zookeeper: zk://http://10.202.11.22:2181/mesos\" \ntime=\"2017-04-10T09:15:22Z\" level=debug msg=\"Zookeeper address\" zk=\"zk://http://10.202.11.22:2181/mesos\" \n</code></pre>\n", "is_answered": false, "tags": ["mesos", "consul", "marathon", "mesosphere"], "last_edit_date": 1491827839, "title": "why applications running in mesos is not being registered in consul?", "last_activity_date": 1491905246, "answer_count": 1, "creation_date": 1491557716, "score": 0, "link": "https://stackoverflow.com/questions/43274677/why-applications-running-in-mesos-is-not-being-registered-in-consul", "answers": [{"body": "<p>got this issue fixed now. it was a network related issue. alpine linux was trying to query with </p>\n\n<p>nameserver 127.0.0.1</p>\n\n<p>replaced it with our dns server.</p>\n", "answer_id": 43342889, "last_activity_date": 1491905246, "creation_date": 1491905246, "score": 0, "owner": {"user_id": 3920996, "profile_image": "https://www.gravatar.com/avatar/5739558fcce2cb5096ffe82a2e5c3fd7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/3920996/amit", "accept_rate": 0, "display_name": "Amit"}, "is_accepted": false, "question_id": 43274677}], "owner": {"user_id": 3920996, "profile_image": "https://www.gravatar.com/avatar/5739558fcce2cb5096ffe82a2e5c3fd7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/3920996/amit", "accept_rate": 0, "display_name": "Amit"}, "view_count": 54, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43274677}{"is_answered": true, "tags": ["vagrant", "apache-kafka", "mesos", "dcos"], "title": "DCOS Kafka Deployment Stuck on Vagrant Cluster", "last_activity_date": 1470937423, "answer_count": 2, "creation_date": 1470155875, "score": 0, "link": "https://stackoverflow.com/questions/38726070/dcos-kafka-deployment-stuck-on-vagrant-cluster", "accepted_answer_id": 38902893, "owner": {"user_id": 1832287, "profile_image": "https://www.gravatar.com/avatar/ab02a6abea84aa5020773f755cab694e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 41, "link": "https://stackoverflow.com/users/1832287/user1832287", "accept_rate": 100, "display_name": "user1832287"}, "view_count": 359, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 38726070}{"body": "<p>Mesos slave is unable to add itself to the cluster. Right now i have 3 machine, with 3 slaves running and 1 master.</p>\n\n<p>But at the mesos page i can see just one master and one slave (same as the master's host present). I can see the marathon running, app etc.. \nBut just the other slaves are unable to connect to the master.</p>\n\n<p>slave logs :: </p>\n\n<pre><code>I0825 21:30:00.971642  4110 slave.cpp:4193] Received oversubscribable resources  from the resource estimator\nI0825 21:30:01.000732  4106 group.cpp:313] Group process (group(1)@127.0.1.1:5051) connected to ZooKeeper\nI0825 21:30:01.000821  4106 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0825 21:30:01.000874  4106 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0825 21:30:01.007753  4106 detector.cpp:138] Detected a new leader: (id='9')\nI0825 21:30:01.008038  4106 group.cpp:656] Trying to get '/mesos/info_0000000009' in ZooKeeper\nW0825 21:30:01.020577  4106 detector.cpp:444] Leading master master@127.0.1.1:5050 is using a Protobuf binary format when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0825 21:30:01.021152  4106 detector.cpp:481] A new leading master (UPID=master@127.0.1.1:5050) is detected\nI0825 21:30:01.021353  4106 status_update_manager.cpp:176] Pausing sending status updates\nI0825 21:30:01.021385  4105 slave.cpp:684] New master detected at master@127.0.1.1:5050\nI0825 21:30:01.022073  4105 slave.cpp:709] No credentials provided. Attempting to register without authentication\nE0825 21:30:01.022299  4113 socket.hpp:107] Shutdown failed on fd=11: Transport endpoint is not connected [107]\n</code></pre>\n\n<p>zookeeer on master :: </p>\n\n<pre><code> ls /mesos\n[info_0000000009, info_0000000010, log_replicas]\n ls /mesos/info_0000000009\n[]\n</code></pre>\n\n<p>Please note the lines in slave logs : </p>\n\n<pre><code>Trying to get '/mesos/info_0000000009' in ZooKeeper\n</code></pre>\n\n<p>and then why slave assumes the master as 127.0.1.1:5050 .. i never specified that</p>\n\n<pre><code>Leading master master@127.0.1.1:5050\n</code></pre>\n\n<p>but zookeeper returns \n      ls /mesos/info_0000000009\n        []</p>\n\n<p>looked into master's zookeeper and found that it was not set at all.. is t a bug in mesos or ki am missing some configuration.. </p>\n\n<p>also, the zookeeper logs on master closed the client connection(may now client started to connect to some other master)</p>\n\n<pre><code>2015-08-25 21:30:01,882 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxn@349] - caught \nend of stream exception\nEndOfStreamException: Unable to read additional data from client sessionid 0x14f657dafeb000d, likely cl\nient has closed socket\n        at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)\n        at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)\n        at java.lang.Thread.run(Thread.java:745)\n2015-08-25 21:30:01,884 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxn@1001] - Closed\n socket connection for client /192.168.0.3:53125 which had sessionid 0x14f657dafeb000d\n2015-08-25 21:30:01,952 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - \nAccepted socket connection from /192.168.0.3:53166\n</code></pre>\n\n<p>Note : slave on the same host as the master works perfectly fine. </p>\n\n<p>TRYING TO RESOLVE IT OVER MORE THAN 2 DAYS NOW .. PLEASEE HELP..</p>\n\n<p>Looks like a bug to me .. where can i see the current master in zookeeper .. is it something like  /mesos/info_0000000009  ? but  i was getting the in zookeeper</p>\n\n<p>ls /mesos/info_0000000009\n[]</p>\n\n<p>an empty array thr .. is this correct because from client logs were trying to look for this : ...</p>\n\n<pre><code>I0825 21:30:01.008038  4106 group.cpp:656] Trying to get '/mesos/info_0000000009' in ZooKeeper\nW0825 21:30:01.020577  4106 detector.cpp:444] Leading master master@127.0.1.1:5050 is using a Protobuf binary format when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0825 21:30:01.021152  4106 detector.cpp:481] A new leading master (UPID=master@127.0.1.1:5050) is detected\n</code></pre>\n\n<p>and then client tries for 127.0.1.1:5050</p>\n\n<h1>Here is the complete slave logs:</h1>\n\n<pre><code>Log file created at: 2015/08/27 07:12:56\nRunning on machine: vvwslave1\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nI0827 07:12:56.406455  1303 logging.cpp:172] INFO level logging started!\nI0827 07:12:56.438398  1303 main.cpp:162] Build: 2015-07-24 10:05:39 by root\nI0827 07:12:56.438534  1303 main.cpp:164] Version: 0.23.0\nI0827 07:12:56.438634  1303 main.cpp:167] Git tag: 0.23.0\nI0827 07:12:56.438733  1303 main.cpp:171] Git SHA: 4ce5475346a0abb7ef4b7ffc9836c5836d7c7a66\nI0827 07:12:56.510270  1303 containerizer.cpp:111] Using isolation: posix/cpu,posix/mem\nI0827 07:12:56.566021  1329 group.cpp:313] Group process (group(1)@127.0.1.1:5051) connected to ZooKeeper\nI0827 07:12:56.566082  1329 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0827 07:12:56.566108  1329 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0827 07:12:56.571959  1303 main.cpp:249] Starting Mesos slave\nI0827 07:12:56.587656  1303 slave.cpp:190] Slave started on 1)@127.0.1.1:5051\nI0827 07:12:56.587723  1303 slave.cpp:191] Flags at startup: --authenticatee=\"crammd5\" --cgroups_cpu_enable_pids_and\n_tids_count=\"false\" --cgroups_enable_cfs=\"false\" --cgroups_hierarchy=\"/sys/fs/cgroup\" --cgroups_limit_swap=\"false\" -\n-cgroups_root=\"mesos\" --container_disk_watch_interval=\"15secs\" --containerizers=\"mesos\" --default_role=\"*\" --disk_wa\ntch_interval=\"1mins\" --docker=\"docker\" --docker_kill_orphans=\"true\" --docker_remove_delay=\"6hrs\" --docker_sandbox_di\nrectory=\"/mnt/mesos/sandbox\" --docker_socket=\"/var/run/docker.sock\" --docker_stop_timeout=\"0ns\" --enforce_container_\ndisk_quota=\"false\" --executor_registration_timeout=\"1mins\" --executor_shutdown_grace_period=\"5secs\" --fetcher_cache_\ndir=\"/tmp/mesos/fetch\" --fetcher_cache_size=\"2GB\" --frameworks_home=\"\" --gc_delay=\"1weeks\" --gc_disk_headroom=\"0.1\" \n--hadoop_home=\"\" --help=\"false\" --initialize_driver_logging=\"true\" --isolation=\"posix/cpu,posix/mem\" --launcher_dir=\n\"/usr/libexec/mesos\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --master=\"zk://192.168.0.2:2\n281/mesos\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --port=\"505\n1\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registrat\nion_backoff_factor=\"1secs\" --resource_monitoring_interval=\"1secs\" --revocable_cpu_low_priority=\"true\" --strict=\"true\n\" --switch_user=\"true\" --version=\"false\" --work_dir=\"/tmp/mesos\"\nI0827 07:12:56.592327  1303 slave.cpp:354] Slave resources: cpus(*):2; mem(*):979; disk(*):67653; ports(*):[31000-32\n000]\nI0827 07:12:56.592576  1303 slave.cpp:384] Slave hostname: vvwslave1\nI0827 07:12:56.592608  1303 slave.cpp:389] Slave checkpoint: true\nI0827 07:12:56.633998  1330 state.cpp:36] Recovering state from '/tmp/mesos/meta'\nI0827 07:12:56.644068  1330 status_update_manager.cpp:202] Recovering status update manager\nI0827 07:12:56.644907  1330 containerizer.cpp:316] Recovering containerizer\nI0827 07:12:56.650073  1330 slave.cpp:4026] Finished recovery\nI0827 07:12:56.650527  1330 slave.cpp:4179] Querying resource estimator for oversubscribable resources\nI0827 07:12:56.650653  1330 slave.cpp:4193] Received oversubscribable resources  from the resource estimator\nI0827 07:12:56.657416  1329 detector.cpp:138] Detected a new leader: (id='14')\nI0827 07:12:56.657564  1329 group.cpp:656] Trying to get '/mesos/info_0000000014' in ZooKeeper\nW0827 07:12:56.659080  1329 detector.cpp:444] Leading master master@127.0.1.1:5050 is using a Protobuf binary format\n when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0827 07:12:56.677889  1329 detector.cpp:481] A new leading master (UPID=master@127.0.1.1:5050) is detected\nI0827 07:12:56.677989  1329 slave.cpp:684] New master detected at master@127.0.1.1:5050\nI0827 07:12:56.678146  1326 status_update_manager.cpp:176] Pausing sending status updates\nI0827 07:12:56.678195  1329 slave.cpp:709] No credentials provided. Attempting to register without authentication\nI0827 07:12:56.678239  1329 slave.cpp:720] Detecting new master\nI0827 07:12:56.678591  1329 slave.cpp:3087] master@127.0.1.1:5050 exited\nW0827 07:12:56.678702  1329 slave.cpp:3090] Master disconnected! Waiting for a new master to be elected\nE0827 07:12:56.678460  1332 socket.hpp:107] Shutdown failed on fd=11: Transport endpoint is not connected [107]\nE0827 07:12:57.068922  1332 socket.hpp:107] Shutdown failed on fd=11: Transport endpoint is not connected [107]\nE0827 07:12:58.829129  1332 socket.hpp:107] Shutdown failed on fd=11: Transport endpoint is not connected [107]\n</code></pre>\n\n<h1>And the complete zookeeper logs running on master on master</h1>\n\n<pre><code>2015-08-27 07:12:42,672 - INFO  [main:QuorumPeerConfig@101] - Reading configuration from: /etc/zookeeper/conf/zoo.cf\ng\n2015-08-27 07:12:42,718 - ERROR [main:QuorumPeerConfig@283] - Invalid configuration, only one server specified (igno\nring)\n2015-08-27 07:12:42,720 - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 10\n2015-08-27 07:12:42,720 - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0\n2015-08-27 07:12:42,721 - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.\n2015-08-27 07:12:42,721 - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running\n  in standalone mode\n2015-08-27 07:12:42,741 - INFO  [main:QuorumPeerConfig@101] - Reading configuration from: /etc/zookeeper/conf/zoo.cf\ng\n2015-08-27 07:12:42,765 - ERROR [main:QuorumPeerConfig@283] - Invalid configuration, only one server specified (igno\nring)\n2015-08-27 07:12:42,765 - INFO  [main:ZooKeeperServerMain@95] - Starting server\n2015-08-27 07:12:42,776 - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.5--1, built on 06/\n10/2013 17:26 GMT\n2015-08-27 07:12:42,776 - INFO  [main:Environment@100] - Server environment:host.name=vvw\n2015-08-27 07:12:42,776 - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_79\n2015-08-27 07:12:42,776 - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation\n2015-08-27 07:12:42,777 - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre\n2015-08-27 07:12:42,777 - INFO  [main:Environment@100] - Server environment:java.class.path=/etc/zookeeper/conf:/usr/share/java/jline.jar:/usr/share/java/log4j-1.2.jar:/usr/share/java/xercesImpl.jar:/usr/share/java/xmlParserAPIs.jar:/usr/share/java/netty.jar:/usr/share/java/slf4j-api.jar:/usr/share/java/slf4j-log4j12.jar:/usr/share/java/zookeeper.jar\n2015-08-27 07:12:42,777 - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib\n2015-08-27 07:12:42,779 - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp\n2015-08-27 07:12:42,779 - INFO  [main:Environment@100] - Server environment:java.compiler=&lt;NA&gt;\n2015-08-27 07:12:42,779 - INFO  [main:Environment@100] - Server environment:os.name=Linux\n2015-08-27 07:12:42,779 - INFO  [main:Environment@100] - Server environment:os.arch=amd64\n2015-08-27 07:12:42,780 - INFO  [main:Environment@100] - Server environment:os.version=3.19.0-25-generic\n2015-08-27 07:12:42,780 - INFO  [main:Environment@100] - Server environment:user.name=zookeeper\n2015-08-27 07:12:42,780 - INFO  [main:Environment@100] - Server environment:user.home=/var/lib/zookeeper\n2015-08-27 07:12:42,780 - INFO  [main:Environment@100] - Server environment:user.dir=/\n2015-08-27 07:12:42,789 - INFO  [main:ZooKeeperServer@726] - tickTime set to 2000\n2015-08-27 07:12:42,789 - INFO  [main:ZooKeeperServer@735] - minSessionTimeout set to -1\n2015-08-27 07:12:42,789 - INFO  [main:ZooKeeperServer@744] - maxSessionTimeout set to -1\n2015-08-27 07:12:42,806 - INFO  [main:NIOServerCnxnFactory@94] - binding to port 0.0.0.0/0.0.0.0:2281\n2015-08-27 07:12:42,826 - INFO  [main:FileSnap@83] - Reading snapshot /var/lib/zookeeper/version-2/snapshot.705\n2015-08-27 07:12:42,859 - INFO  [main:FileTxnSnapLog@240] - Snapshotting: 0x728 to /var/lib/zookeeper/version-2/snap\nshot.728\n2015-08-27 07:12:44,848 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted sock\net connection from /192.168.0.2:44500\n2015-08-27 07:12:44,857 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request\n from old client /192.168.0.2:44500; will be dropped if server is in r-o mode\n2015-08-27 07:12:44,859 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting \nto establish new session at /192.168.0.2:44500\n2015-08-27 07:12:44,862 - INFO  [SyncThread:0:FileTxnLog@199] - Creating new log file: log.729\n2015-08-27 07:12:45,299 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10000 with nego\ntiated timeout 10000 for client /192.168.0.2:44500\n2015-08-27 07:12:45,505 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted sock\net connection from /192.168.0.2:44501\n2015-08-27 07:12:45,506 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request\n from old client /192.168.0.2:44501; will be dropped if server is in r-o mode\n2015-08-27 07:12:45,506 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting \nto establish new session at /192.168.0.2:44501\n2015-08-27 07:12:45,509 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted sock\net connection from /192.168.0.2:44502\n2015-08-27 07:12:45,510 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request\n from old client /192.168.0.2:44502; will be dropped if server is in r-o mode\n2015-08-27 07:12:45,510 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44502\n2015-08-27 07:12:45,538 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.2:44503\n2015-08-27 07:12:45,538 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.2:44504\n2015-08-27 07:12:45,538 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request from old client /192.168.0.2:44503; will be dropped if server is in r-o mode\n2015-08-27 07:12:45,539 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44503\n2015-08-27 07:12:45,539 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request from old client /192.168.0.2:44504; will be dropped if server is in r-o mode\n2015-08-27 07:12:45,539 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44504\n2015-08-27 07:12:45,564 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10001 with negotiated timeout 10000 for client /192.168.0.2:44501\n2015-08-27 07:12:45,674 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10002 with negotiated timeout 10000 for client /192.168.0.2:44502\n2015-08-27 07:12:45,675 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10003 with negotiated timeout 10000 for client /192.168.0.2:44503\n2015-08-27 07:12:45,676 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10004 with negotiated timeout 10000 for client /192.168.0.2:44504\n2015-08-27 07:12:46,183 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.2:44506\n2015-08-27 07:12:46,189 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44506\n2015-08-27 07:12:46,232 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10005 with negotiated timeout 10000 for client /192.168.0.2:44506\n2015-08-27 07:12:48,195 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.2:44508\n2015-08-27 07:12:48,196 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44508\n2015-08-27 07:12:48,212 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10006 with negotiated timeout 40000 for client /192.168.0.2:44508\n2015-08-27 07:12:49,872 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.2:44509\n2015-08-27 07:12:49,873 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request from old client /192.168.0.2:44509; will be dropped if server is in r-o mode\n2015-08-27 07:12:49,873 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.2:44509\n2015-08-27 07:12:49,878 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10007 with negotiated timeout 10000 for client /192.168.0.2:44509\n2015-08-27 07:12:56,161 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.0.3:60436\n2015-08-27 07:12:56,161 - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@793] - Connection request from old client /192.168.0.3:60436; will be dropped if server is in r-o mode\n2015-08-27 07:12:56,161 - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2281:ZooKeeperServer@839] - Client attempting to establish new session at /192.168.0.3:60436\n2015-08-27 07:12:56,189 - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x14f6cd241e10008 with negotiated timeout 10000 for client /192.168.0.3:60436\n</code></pre>\n\n<h1>And the logs from master node</h1>\n\n<pre><code>I0827 07:12:45.412888  1604 leveldb.cpp:176] Opened db in 567.381081ms\nI0827 07:12:45.469497  1604 leveldb.cpp:183] Compacted db in 56.508537ms\nI0827 07:12:45.469674  1604 leveldb.cpp:198] Created db iterator in 21452ns\nI0827 07:12:45.502590  1604 leveldb.cpp:204] Seeked to beginning of db in 32.834339ms\nI0827 07:12:45.502900  1604 leveldb.cpp:273] Iterated through 3 keys in the db in 101809ns\nI0827 07:12:45.503026  1604 replica.cpp:744] Replica recovered with log positions 73 -&gt; 74 with 0 holes and 0 unlear\nned\nI0827 07:12:45.507745  1643 log.cpp:238] Attempting to join replica to ZooKeeper group\nI0827 07:12:45.507983  1643 recover.cpp:449] Starting replica recovery\nI0827 07:12:45.508095  1643 recover.cpp:475] Replica is in VOTING status\nI0827 07:12:45.508167  1643 recover.cpp:464] Recover process terminated\nI0827 07:12:45.536058  1604 main.cpp:383] Starting Mesos master\nI0827 07:12:45.559154  1604 master.cpp:368] Master 20150827-071245-16842879-5050-1604 (vvwmaster) started on 127.0.1\n.1:5050\nI0827 07:12:45.559239  1604 master.cpp:370] Flags at startup: --allocation_interval=\"1secs\" --allocator=\"Hierarchica\nlDRF\" --authenticate=\"false\" --authenticate_slaves=\"false\" --authenticators=\"crammd5\" --framework_sorter=\"drf\" --hel\np=\"false\" --hostname=\"vvwmaster\" --initialize_driver_logging=\"true\" --log_auto_initialize=\"true\" --log_dir=\"/var/log\n/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --max_slave_ping_timeouts=\"5\" --port=\"5050\" --quiet=\"false\" --quorum\n=\"1\" --recovery_slave_removal_limit=\"100%\" --registry=\"replicated_log\" --registry_fetch_timeout=\"1mins\" --registry_s\ntore_timeout=\"5secs\" --registry_strict=\"false\" --root_submissions=\"true\" --slave_ping_timeout=\"15secs\" --slave_rereg\nister_timeout=\"10mins\" --user_sorter=\"drf\" --version=\"false\" --webui_dir=\"/usr/share/mesos/webui\" --work_dir=\"/var/l\nib/mesos\" --zk=\"zk://192.168.0.2:2281/mesos\" --zk_session_timeout=\"10secs\"\nI0827 07:12:45.559460  1604 master.cpp:417] Master allowing unauthenticated frameworks to register\nI0827 07:12:45.559491  1604 master.cpp:422] Master allowing unauthenticated slaves to register\nI0827 07:12:45.559587  1604 master.cpp:459] Using default 'crammd5' authenticator\nW0827 07:12:45.559619  1604 authenticator.cpp:504] No credentials provided, authentication requests will be refused.\nI0827 07:12:45.559909  1604 authenticator.cpp:511] Initializing server SASL\nI0827 07:12:45.564357  1642 group.cpp:313] Group process (group(1)@127.0.1.1:5050) connected to ZooKeeper\nI0827 07:12:45.564539  1642 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0827 07:12:45.564590  1642 group.cpp:385] Trying to create path '/mesos/log_replicas' in ZooKeeper\nI0827 07:12:45.675650  1644 group.cpp:313] Group process (group(2)@127.0.1.1:5050) connected to ZooKeeper\nI0827 07:12:45.675717  1644 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (1, 0, 0)\nI0827 07:12:45.675750  1644 group.cpp:385] Trying to create path '/mesos/log_replicas' in ZooKeeper\nI0827 07:12:45.676774  1639 group.cpp:313] Group process (group(3)@127.0.1.1:5050) connected to ZooKeeper\nI0827 07:12:45.676828  1639 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0827 07:12:45.676857  1639 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0827 07:12:45.678182  1640 group.cpp:313] Group process (group(4)@127.0.1.1:5050) connected to ZooKeeper\nI0827 07:12:45.678235  1640 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0827 07:12:45.678380  1640 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0827 07:12:45.809567  1645 network.hpp:415] ZooKeeper group memberships changed\nI0827 07:12:45.816505  1644 group.cpp:656] Trying to get '/mesos/log_replicas/0000000013' in ZooKeeper\nI0827 07:12:45.820705  1645 network.hpp:463] ZooKeeper group PIDs: { log-replica(1)@127.0.1.1:5050 }\nI0827 07:12:46.020447  1644 contender.cpp:131] Joining the ZK group\nI0827 07:12:46.020498  1639 master.cpp:1420] Successfully attached file '/var/log/mesos/mesos-master.INFO'\nI0827 07:12:46.078451  1643 contender.cpp:247] New candidate (id='14') has entered the contest for leadership\nI0827 07:12:46.078984  1645 detector.cpp:138] Detected a new leader: (id='14')\nI0827 07:12:46.079110  1645 group.cpp:656] Trying to get '/mesos/info_0000000014' in ZooKeeper\nW0827 07:12:46.084359  1645 detector.cpp:444] Leading master master@127.0.1.1:5050 is using a Protobuf binary format when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0827 07:12:46.084485  1645 detector.cpp:481] A new leading master (UPID=master@127.0.1.1:5050) is detected\nI0827 07:12:46.084553  1645 master.cpp:1481] The newly elected leader is master@127.0.1.1:5050 with id 20150827-071245-16842879-5050-1604\nI0827 07:12:46.084653  1645 master.cpp:1494] Elected as the leading master!\nI0827 07:12:46.084682  1645 master.cpp:1264] Recovering from registrar\nI0827 07:12:46.084812  1645 registrar.cpp:313] Recovering registrar\nI0827 07:12:46.085160  1645 log.cpp:661] Attempting to start the writer\nI0827 07:12:46.085683  1639 replica.cpp:477] Replica received implicit promise request with proposal 18\nI0827 07:12:46.231271  1639 leveldb.cpp:306] Persisting metadata (8 bytes) to leveldb took 145.505945ms\nI0827 07:12:46.231402  1639 replica.cpp:345] Persisted promised to 18\nI0827 07:12:46.231667  1640 coordinator.cpp:230] Coordinator attemping to fill missing position\nI0827 07:12:46.231801  1640 log.cpp:677] Writer started with ending position 74\nI0827 07:12:46.232197  1646 leveldb.cpp:438] Reading position from leveldb took 60443ns\nI0827 07:12:46.232319  1646 leveldb.cpp:438] Reading position from leveldb took 21312ns\nI0827 07:12:46.232934  1646 registrar.cpp:346] Successfully fetched the registry (247B) in 148.019968ms\nI0827 07:12:46.233131  1646 registrar.cpp:445] Applied 1 operations in 17888ns; attempting to update the 'registry'\nI0827 07:12:46.234346  1640 log.cpp:685] Attempting to append 286 bytes to the log\nI0827 07:12:46.234463  1640 coordinator.cpp:340] Coordinator attempting to write APPEND action at position 75\nI0827 07:12:46.234748  1645 replica.cpp:511] Replica received write request for position 75\nI0827 07:12:46.274888  1645 leveldb.cpp:343] Persisting action (305 bytes) to leveldb took 40.044935ms\nI0827 07:12:46.275140  1645 replica.cpp:679] Persisted action at 75\nI0827 07:12:46.275503  1646 replica.cpp:658] Replica received learned notice for position 75\nI0827 07:12:46.307917  1646 leveldb.cpp:343] Persisting action (307 bytes) to leveldb took 32.320539ms\nI0827 07:12:46.308076  1646 replica.cpp:679] Persisted action at 75\nI0827 07:12:46.308112  1646 replica.cpp:664] Replica learned APPEND action at position 75\nI0827 07:12:46.308668  1646 registrar.cpp:490] Successfully updated the 'registry' in 75.472128ms\nI0827 07:12:46.308749  1646 registrar.cpp:376] Successfully recovered registrar\nI0827 07:12:46.308888  1646 log.cpp:704] Attempting to truncate the log to 75\nI0827 07:12:46.309002  1646 master.cpp:1291] Recovered 1 slaves from the Registry (247B) ; allowing 10mins for slaves to re-register\nI0827 07:12:46.309056  1646 coordinator.cpp:340] Coordinator attempting to write TRUNCATE action at position 76\nI0827 07:12:46.309252  1646 replica.cpp:511] Replica received write request for position 76\nI0827 07:12:46.352067  1646 leveldb.cpp:343] Persisting action (16 bytes) to leveldb took 42.749912ms\nI0827 07:12:46.352377  1646 replica.cpp:679] Persisted action at 76\nI0827 07:12:46.352900  1646 replica.cpp:658] Replica received learned notice for position 76\nI0827 07:12:46.407814  1646 leveldb.cpp:343] Persisting action (18 bytes) to leveldb took 54.686166ms\nI0827 07:12:46.408033  1646 leveldb.cpp:401] Deleting ~2 keys from leveldb took 50800ns\nI0827 07:12:46.408068  1646 replica.cpp:679] Persisted action at 76\nI0827 07:12:46.408102  1646 replica.cpp:664] Replica learned TRUNCATE action at position 76\nI0827 07:12:46.884490  1644 master.cpp:3332] Registering slave at slave(1)@127.0.1.1:5051 (vvw) with id 20150827-071245-16842879-5050-1604-S0\nI0827 07:12:46.900085  1644 registrar.cpp:445] Applied 1 operations in 43323ns; attempting to update the 'registry'\nI0827 07:12:46.901564  1639 log.cpp:685] Attempting to append 440 bytes to the log\nI0827 07:12:46.901736  1639 coordinator.cpp:340] Coordinator attempting to write APPEND action at position 77\nI0827 07:12:46.902035  1639 replica.cpp:511] Replica received write request for position 77\nI0827 07:12:46.947882  1639 leveldb.cpp:343] Persisting action (459 bytes) to leveldb took 45.777578ms\nI0827 07:12:46.948067  1639 replica.cpp:679] Persisted action at 77\nI0827 07:12:46.948422  1639 replica.cpp:658] Replica received learned notice for position 77\nI0827 07:12:46.992007  1639 leveldb.cpp:343] Persisting action (461 bytes) to leveldb took 43.518061ms\nI0827 07:12:46.992187  1639 replica.cpp:679] Persisted action at 77\nI0827 07:12:46.992249  1639 replica.cpp:664] Replica learned APPEND action at position 77\nI0827 07:12:46.992826  1640 registrar.cpp:490] Successfully updated the 'registry' in 92.466176ms\nI0827 07:12:46.992949  1639 log.cpp:704] Attempting to truncate the log to 77\nI0827 07:12:46.993027  1639 coordinator.cpp:340] Coordinator attempting to write TRUNCATE action at position 78\nI0827 07:12:46.993371  1639 replica.cpp:511] Replica received write request for position 78\nI0827 07:12:46.993588  1640 master.cpp:3395] Registered slave 20150827-071245-16842879-5050-1604-S0 at slave(1)@127.0.1.1:5051 (vvw) with cpus(*):4; mem(*):1846; disk(*):141854; ports(*):[31000-32000]\nI0827 07:12:46.993785  1644 hierarchical.hpp:528] Added slave 20150827-071245-16842879-5050-1604-S0 (vvw) with cpus(*):4; mem(*):1846; disk(*):141854; ports(*):[31000-32000] (allocated: )\nI0827 07:12:47.018685  1641 master.cpp:3687] Received update of slave 20150827-071245-16842879-5050-1604-S0 at slave(1)@127.0.1.1:5051 (vvw) with total oversubscribed resources \nI0827 07:12:47.018934  1641 hierarchical.hpp:588] Slave 20150827-071245-16842879-5050-1604-S0 (vvw) updated with oversubscribed resources  (total: cpus(*):4; mem(*):1846; disk(*):141854; ports(*):[31000-32000], allocated: )\nI0827 07:12:47.036170  1639 leveldb.cpp:343] Persisting action (16 bytes) to leveldb took 42.72315ms\nI0827 07:12:47.036388  1639 replica.cpp:679] Persisted action at 78\n</code></pre>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1485342129, "title": "mesos slave on different host unable to add itself", "last_activity_date": 1485342129, "answer_count": 2, "creation_date": 1440520251, "score": 4, "link": "https://stackoverflow.com/questions/32209335/mesos-slave-on-different-host-unable-to-add-itself", "answers": [{"body": "<blockquote>\n  <p>\"But at the mesos page i can see just one master and one slave (same as the master's host present).\"</p>\n</blockquote>\n\n<p>Most probably this happens because the master is not able to establish connection to agents (aka slaves) living on other machines. Right now (this may change with the new HTTP API), the master must be able to open a connection to an agent, which means an agent must report a non-local IP when to registers with the master. From your logs it looks like agents bind to local IPs (<code>127.0.1.1)</code>. You can change that via <code>--ip</code> flag.</p>\n", "answer_id": 32275220, "last_activity_date": 1440777659, "creation_date": 1440777659, "score": 6, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 32209335}, {"body": "<p>I have noticed that you are running mesos as a service, and I think there must be a configuration file where you should specify your master ip(or zookeeper ip) and the default value in the file is 127.0.1.1, so only your slave on the same machine with your master can connect to it. Because when running mesos-slave you must give it the master ip.</p>\n", "answer_id": 37427198, "last_activity_date": 1464146290, "creation_date": 1464146290, "score": 0, "owner": {"user_id": 6318890, "profile_image": "https://i.stack.imgur.com/PmQ25.jpg?s=128&g=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/6318890/night", "display_name": "Night"}, "is_accepted": false, "question_id": 32209335}], "owner": {"user_id": 1798482, "profile_image": "https://www.gravatar.com/avatar/26a42ad7c691cb79a45b21d27c470e2b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 549, "link": "https://stackoverflow.com/users/1798482/andnn", "accept_rate": 22, "display_name": "andNn"}, "view_count": 2777, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 32209335}{"body": "<p>I installed Kafka on DC/OS (Mesos) cluster on AWS. Enabled three brokers and created a topic called \"topic1\".</p>\n\n<pre><code>dcos kafka topic create topic1 --partitions 3 --replication 3\n</code></pre>\n\n<p>Then I wrote a Producer class to send messages and a Consumer class to receive them.</p>\n\n<pre><code>public class Producer {\n    public static void sendMessage(String msg) throws InterruptedException, ExecutionException {\n        Map&lt;String, Object&gt; producerConfig = new HashMap&lt;&gt;();\n        System.out.println(\"setting Producerconfig.\");\n        producerConfig.put(\"bootstrap.servers\", \n                \"172.16.20.207:9946,172.16.20.234:9125,172.16.20.36:9636\");\n\n        ByteArraySerializer serializer = new ByteArraySerializer();\n        System.out.println(\"Creating KafkaProcuder\");\n        KafkaProducer&lt;byte[], byte[]&gt; kafkaProducer = new KafkaProducer&lt;&gt;(producerConfig, serializer, serializer);\n        for (int i = 0; i &lt; 100; i++) {\n            String msgstr = msg + i;\n            byte[] message = msgstr.getBytes();\n            ProducerRecord&lt;byte[], byte[]&gt; record = new ProducerRecord&lt;&gt;(\"topic1\", message);\n            System.out.println(\"Sent:\" + msgstr);\n            kafkaProducer.send(record);\n        }\n        kafkaProducer.close();\n    }\n\n    public static void main(String[] args) throws InterruptedException, ExecutionException {\n        sendMessage(\"Kafka test message 2/27 3:32\");\n    }\n\n}\n\npublic class Consumer {\n    public static String getMessage() {\n        Map&lt;String, Object&gt; consumerConfig = new HashMap&lt;&gt;();\n        consumerConfig.put(\"bootstrap.servers\", \n                \"172.16.20.207:9946,172.16.20.234:9125,172.16.20.36:9636\");\n        consumerConfig.put(\"group.id\", \"dj-group\");\n        consumerConfig.put(\"enable.auto.commit\", \"true\");\n        consumerConfig.put(\"auto.offset.reset\", \"earliest\");\n        ByteArrayDeserializer deserializer = new ByteArrayDeserializer();\n        KafkaConsumer&lt;byte[], byte[]&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(consumerConfig, deserializer, deserializer);\n\n        kafkaConsumer.subscribe(Arrays.asList(\"topic1\"));\n        while (true) {\n            ConsumerRecords&lt;byte[], byte[]&gt; records = kafkaConsumer.poll(100);\n            System.out.println(records.count() + \" of records received.\");\n            for (ConsumerRecord&lt;byte[], byte[]&gt; record : records) {\n                System.out.println(Arrays.toString(record.value()));\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        getMessage();\n    }\n}\n</code></pre>\n\n<p>First I ran <code>Producer</code> on the cluster to send messages to <code>topic1</code>. However when I ran <code>Consumer</code>, it couldn't receive anything, just hang. </p>\n\n<p><code>Producer</code> is working since I was able to get all the messages by running the shell script that came with Kafka install </p>\n\n<pre><code>./bin/kafka-console-consumer.sh --zookeeper master.mesos:2181/dcos-service-kafka --topic topic1 --from-beginning\n</code></pre>\n\n<p>But why can't I receive with <code>Consumer</code>? This <a href=\"https://github.com/SOHU-Co/kafka-node/issues/11\" rel=\"nofollow noreferrer\">post</a> suggests group.id with old offset might be a possible cause. I only create group.id in the consumer not the producer. How do I config the offset for this group? </p>\n", "is_answered": true, "title": "Why consumer hangs while consuming messages from Kafka on DC/OS using Client API for Java?", "last_edit_date": 1488269204, "tags": ["java", "apache-kafka", "dcos"], "view_count": 254, "accepted_answer_id": 42500616, "last_activity_date": 1488269204, "answers": [{"body": "<p>As it turns out, <code>kafkaConsumer.subscribe(Arrays.asList(\"topic1\"));</code> is causing <code>poll()</code> to hang. According to <a href=\"https://stackoverflow.com/questions/34414308/kafka-consumer-does-not-receive-messages\">Kafka Consumer does not receive messages\n</a>, there are two ways to connect to a topic, <code>assign</code> and <code>subscribe</code>. After I replaced <code>subscribe</code> with the lines below, it started working.</p>\n\n<pre><code>    TopicPartition tp = new TopicPartition(\"topic1\", 0);\n    List&lt;TopicPartition&gt; tps = Arrays.asList(tp);\n    kafkaConsumer.assign(tps);\n</code></pre>\n\n<p>However the output shows arrays of numbers which is not expected (Producer sent Strings). But I guess this is a separate issue.</p>\n", "answer_id": 42500616, "last_activity_date": 1488258386, "creation_date": 1488258386, "score": 1, "owner": {"user_id": 3358927, "profile_image": "https://www.gravatar.com/avatar/1d55888f9dce36510f6f0e8e2a9a0a5e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 427, "link": "https://stackoverflow.com/users/3358927/ddd", "accept_rate": 90, "display_name": "ddd"}, "is_accepted": true, "last_edit_date": 1495541831, "question_id": 42496443}], "score": 2, "link": "https://stackoverflow.com/questions/42496443/why-consumer-hangs-while-consuming-messages-from-kafka-on-dc-os-using-client-api", "answer_count": 1, "owner": {"user_id": 3358927, "profile_image": "https://www.gravatar.com/avatar/1d55888f9dce36510f6f0e8e2a9a0a5e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 427, "link": "https://stackoverflow.com/users/3358927/ddd", "accept_rate": 90, "display_name": "ddd"}, "creation_date": 1488232330, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42496443}{"is_answered": true, "tags": ["dcos"], "title": "local-universe, mesosphere, dc/os", "last_activity_date": 1483914091, "answer_count": 1, "creation_date": 1483898503, "score": 1, "link": "https://stackoverflow.com/questions/41535932/local-universe-mesosphere-dc-os", "owner": {"user_id": 5783271, "profile_image": "https://graph.facebook.com/1008526032559430/picture?type=large", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/5783271/sandhya-km", "accept_rate": 25, "display_name": "Sandhya Km"}, "view_count": 151, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 41535932}{"body": "<p>i wanted to install dc/os on my local machine for development.</p>\n\n<p>i followed the instructions <a href=\"https://github.com/dcos/dcos-vagrant/blob/master/docs/deploy.md\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p>after calling vagrant up i got warnings:</p>\n\n<pre><code>    =&gt; m1: Running 'pre-boot' VM customizations...\n    ==&gt; m1: Booting VM...\n    ==&gt; m1: Waiting for machine to boot. This may take a few minutes...\n        m1: SSH address: 127.0.0.1:2222\n        m1: SSH username: vagrant\n        m1: SSH auth method: private key\n        m1: Warning: Connection aborted. Retrying...\n        m1: Warning: Connection reset. Retrying...\n        m1: Warning: Connection aborted. Retrying...\n        m1: Warning: Connection reset. Retrying...\n        m1: Warning: Remote connection disconnect. Retrying...\n        m1: Warning: Connection aborted. Retrying...\n        m1: Warning: Remote connection disconnect. Retrying...\n        m1: Warning: Connection aborted. Retrying...\n        m1: Warning: Connection reset. Retrying...\n        m1: Warning: Connection aborted. Retrying...\n\nsome ports where in use ?\n\n  m1:       Checking if port 42819 (required by spartan) is in use:\n    m1:       PASS\n    m1:       Checking if port 43911 (required by minuteman) is in use:\n    m1:       PASS\n    m1:       Checking if port 46839 (required by metronome) is in use:\n    m1:       PASS\n    m1:       Checking if port 61053 (required by mesos-dns) is in use:\n    m1:       PASS\n    m1:       Checking if port 61420 (required by epmd) is in use:\n    m1:       PASS\n    m1:       Checking if port 61421 (required by minuteman) is in use:\n    m1:       PASS\n    m1:       Checking if port 62053 (required by spartan) is in use:\n    m1:       PASS\n    m1:       Checking if port 62080 (required by navstar) is in use:\n    m1:       PASS\n</code></pre>\n\n<p>and at the end again two WARNINGS EDIT:  they should not be the problem <a href=\"https://stackoverflow.com/questions/39797602/warning-bridge-nf-call-iptables-is-disabled-while-starting-dcos-vagrant#\">explained here</a> </p>\n\n<pre><code>  p1:       PASS\n    p1:       Checking Docker is configured with a production storage driver:\n    a1:       Creating role file for slave\n==&gt; p1:       WARNING: bridge-nf-call-iptables is disabled\n==&gt; p1:       WARNING: bridge-nf-call-ip6tables is disabled\n    a1:       Configuring DC/OS\n    p1:       PASS (overlay)\n    p1:       Creating directories under /etc/mesosphere\n    a1:       Setting and starting DC/OS\n    p1:       Creating role file for slave_public\n    p1:       Configuring DC/OS\n    p1:       Setting and starting DC/OS\n==&gt; p1:       Created symlink from /etc/systemd/system/multi-user.target.wants/dcos-setup.service to /etc/systemd/system/dcos-setup.service.\n==&gt; a1:       Created symlink from /etc/systemd/system/multi-user.target.wants/dcos-setup.service to /etc/systemd/system/dcos-setup.service.\n==&gt; m1: DC/OS Postflight\n==&gt; a1: DC/OS Postflight\n==&gt; p1: DC/OS Postflight\n==&gt; m1: [sudo]$ dcos-postflight\n==&gt; a1: [sudo]$ dcos-postflight\n==&gt; p1: [sudo]$ dcos-postflight\n==&gt; a1: Setting Mesos Memory: 5632 (role=*)\n==&gt; a1: [sudo]$ mesos-memory 5632\n    a1:       Updating /var/lib/dcos/mesos-resources\n==&gt; a1: Restarting Mesos Agent\n==&gt; a1: [sudo]$ bash -ceu \"systemctl stop dcos-mesos-slave.service &amp;&amp; rm -f /var/lib/mesos/slave/meta/slaves/latest &amp;&amp; systemctl start dcos-mesos-slave.service --no-block\"\n==&gt; p1: Setting Mesos Memory: 1024 (role=slave_public)\n==&gt; p1: [sudo]$ mesos-memory 1024 slave_public\n    p1:       Updating /var/lib/dcos/mesos-resources\n==&gt; p1: Restarting Mesos Agent\n==&gt; p1: [sudo]$ bash -ceu \"systemctl stop dcos-mesos-slave-public.service &amp;&amp; rm -f /var/lib/mesos/slave/meta/slaves/latest &amp;&amp; systemctl start dcos-mesos-slave-public.service --no-block\"\n==&gt; boot: DC/OS Installation Complete\n==&gt; boot: Web Interface: http://m1.dcos/\n</code></pre>\n\n<p>I just followed the instution on Github, and installed virtualbox and vagrant on Windows 10. </p>\n\n<p>why cant i access the web ui at <a href=\"http://m1.dcos\" rel=\"nofollow noreferrer\">http://m1.dcos</a> ? What are the warnings? </p>\n", "is_answered": false, "tags": ["vagrant", "virtualbox", "mesos", "mesosphere", "dcos"], "last_edit_date": 1496179649, "title": "DC/OS local cluster web gui not accessible", "last_activity_date": 1496179649, "answer_count": 0, "creation_date": 1496179107, "score": 0, "link": "https://stackoverflow.com/questions/44272062/dc-os-local-cluster-web-gui-not-accessible", "owner": {"user_id": 5905678, "profile_image": "https://www.gravatar.com/avatar/fb7a1134442284c5ff6f0ba72df174e0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 311, "link": "https://stackoverflow.com/users/5905678/khan", "accept_rate": 78, "display_name": "Khan"}, "view_count": 73, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44272062}{"body": "<p>I want to take out a host (mesos-slave) from the mesos cluster in a clean manner by draining out the executors its running. Is it possible for mesos-master to not give any further work to a mesos-slave but still receive updates for the currently running executors? If thats possible, I can make mesos-master not give anymore work to this slave and once the slave is done with its currently running executors, I can take it out. Please feel free to suggest a better way of achieving the same thing.</p>\n", "is_answered": true, "tags": ["scheduler", "distributed-computing", "mesos", "mesosphere"], "last_edit_date": 1448532092, "title": "How to flush out jobs on a Mesos slave?", "last_activity_date": 1448532092, "answer_count": 1, "creation_date": 1448382660, "score": 1, "link": "https://stackoverflow.com/questions/33898947/how-to-flush-out-jobs-on-a-mesos-slave", "answers": [{"body": "<p>I think you look for maintenance primitives, which have been recently added to Mesos. A user doc is <a href=\"http://mesos.apache.org/documentation/latest/maintenance/\" rel=\"nofollow\">here</a>.</p>\n", "answer_id": 33899845, "last_activity_date": 1448385230, "creation_date": 1448385230, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 33898947}], "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 272, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33898947}{"body": "<p>We're running DC/OS + Marathon on an Azure cluster (ACS). I find myself in situations where it would be very helpful to tunnel into the master node and more specifically - agent nodes. Then I'd like to run bash commands against my services (docker images) that are running. Is this possible?</p>\n\n<p>Thanks in advance!</p>\n", "is_answered": true, "tags": ["ssh", "marathon", "dcos"], "title": "Demystify ssh tunneling into Marathon master and agents", "last_activity_date": 1467933367, "answer_count": 1, "creation_date": 1466515633, "score": 0, "link": "https://stackoverflow.com/questions/37945798/demystify-ssh-tunneling-into-marathon-master-and-agents", "answers": [{"body": "<p>There's a page on ACS's documentation regarding ssh tunneling into master nodes, it can be found here: <a href=\"https://azure.microsoft.com/en-us/documentation/articles/container-service-connect/\" rel=\"nofollow\">https://azure.microsoft.com/en-us/documentation/articles/container-service-connect/</a></p>\n\n<p>Say you have an Azure Container Service named my-acs running on the East US region, and your user name is myuser, and you would like to access the DC/OS dashboard of your cluster, </p>\n\n<pre><code>sudo ssh -L 80:localhost:80 -f -N my-user@my-acsmgmt.eastus.cloudapp.azure.com -p 2200 -i path/to/your/private/key\n</code></pre>\n\n<p>If you would like to directly access the terminal of your master, you would use:</p>\n\n<pre><code>ssh my-user@my-acsmgmt.eastus.cloudapp.azure.com -p 2200 -i path/to/your/private/key\n</code></pre>\n\n<p>However, I do not know how to connect directly into an Agent node.</p>\n", "answer_id": 38256710, "last_activity_date": 1467933367, "creation_date": 1467933367, "score": 1, "owner": {"user_id": 5228844, "profile_image": "https://lh4.googleusercontent.com/-10_kFeezFVw/AAAAAAAAAAI/AAAAAAAAAR0/eHRP_V1dako/photo.jpg?sz=128", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/5228844/jorge-s%c3%a1", "display_name": "Jorge S\u00e1"}, "is_accepted": false, "question_id": 37945798}], "owner": {"user_id": 91631, "profile_image": "https://www.gravatar.com/avatar/b6054c8740648d77b4553d60a4cd3c5f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1069, "link": "https://stackoverflow.com/users/91631/alex", "accept_rate": 44, "display_name": "Alex"}, "view_count": 140, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 37945798}{"body": "<p>I've followed the <a href=\"https://docs.mesosphere.com/1.8/usage/tutorials/deploy-on-marathon/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.8/usage/tutorials/deploy-on-marathon/</a> guide for deploying an app from jenkins to marathon on dcos. I'm using a private registry hosted inside the dcos, and jenkins as well.</p>\n\n<p>I'm getting the following output from jenkins console output, </p>\n\n<blockquote>\n  <p>[Marathon] Failed to update Marathon application:</p>\n  \n  <p>[Marathon] Unauthorized (http status: 401)</p>\n</blockquote>\n\n<p>any idea whats wrong?</p>\n\n<p>I tried to create the app manually via marathon ui and it works fine.</p>\n", "is_answered": false, "tags": ["jenkins", "jenkins-plugins", "marathon", "dcos"], "title": "Jenkins issue with marathon deployment plugin", "last_activity_date": 1479375552, "answer_count": 1, "creation_date": 1478717443, "score": 1, "link": "https://stackoverflow.com/questions/40513996/jenkins-issue-with-marathon-deployment-plugin", "answers": [{"body": "<p>Just got the url all wrong, it should be <a href=\"http://leader.mesos:8080/\" rel=\"nofollow noreferrer\">http://leader.mesos:8080/</a></p>\n", "answer_id": 40651328, "last_activity_date": 1479375552, "creation_date": 1479375552, "score": 0, "owner": {"user_id": 67505, "profile_image": "https://www.gravatar.com/avatar/094c0ec476b95ed7619d6a4cb918da78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9919, "link": "https://stackoverflow.com/users/67505/chen-kinnrot", "accept_rate": 71, "display_name": "Chen Kinnrot"}, "is_accepted": false, "question_id": 40513996}], "owner": {"user_id": 67505, "profile_image": "https://www.gravatar.com/avatar/094c0ec476b95ed7619d6a4cb918da78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9919, "link": "https://stackoverflow.com/users/67505/chen-kinnrot", "accept_rate": 71, "display_name": "Chen Kinnrot"}, "view_count": 209, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40513996}{"body": "<p>There is a lot I clearly don't understand about Spark, Spark Jobserver, and Mesosphere's DC/OS. But I very much like the Jobserver project, and also very much like our DC/OS cluster, and would really like to get them running together. </p>\n\n<p>Throwing the Docker container into marathon file, <a href=\"https://github.com/spark-jobserver/spark-jobserver/blob/master/doc/docker.md\" rel=\"nofollow\">like this example</a>, does not work. I thought maybe this was all due to me not knowing what SPARK_MASTER url to pass in (which I still don't know, any help there would be greatly appreciated), but then I tried removing that from the marathon file, which should still run the project in local mode, and that also doesn't work. Which makes me realize, beyond not knowing how to connect this jobserver to my DCOS spark dispatcher, I also just don't know why this Docker container will fail on the cluster, but not on my local machine, even when it is not passed any arguments. </p>\n\n<p>My logs do not show much, and the Docker container exits with a status of 137 after the following in stdout: </p>\n\n<pre><code>LOG_DIR empty; logging will go to /tmp/job-server\n</code></pre>\n\n<p>Which, when I run things locally, is the last log before it continues to run log4j into my stdout and tell me that the jobserver is starting up. I see the following in stderr:</p>\n\n<pre><code>app/server_start.sh: line 54:    15 Killed                  $SPARK_HOME/bin/spark-submit --class $MAIN --driver-memory $JOBSERVER_MEMORY --conf \"spark.executor.extraJavaOptions=$LOGGING_OPTS\" --driver-java-options \"$GC_OPTS $JAVA_OPTS $LOGGING_OPTS $CONFIG_OVERRIDES\" $@ $appdir/spark-job-server.jar $conffile\n</code></pre>\n\n<p>Which just seems to suggest that the server_start.sh is running from the spark jobserver docker, and that script is for some reason dying?</p>\n\n<p>I stripped my marathon file all the way down to this, which is still giving me the same errors: </p>\n\n<pre><code>{\n  \"id\": \"/jobserver\",\n  \"cpus\": 0.5,\n  \"mem\": 100,\n  \"ports\": [0],\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"velvia/spark-jobserver:0.6.2.mesos-0.28.1.spark-1.6.1\"\n    }\n  }\n}\n</code></pre>\n\n<p>Any help would be greatly appreciated. </p>\n", "is_answered": true, "title": "How to run Spark Jobserver on Mesosphere's DC/OS", "tags": ["apache-spark", "mesosphere", "spark-jobserver", "dcos"], "last_activity_date": 1465442077, "accepted_answer_id": 37716190, "creation_date": 1465417818, "answers": [{"body": "<p>The following worked for me sometime when I tried it. </p>\n\n<pre><code>{\n  \"id\": \"/spark.jobserver\",\n  \"cmd\": null,\n  \"cpus\": 2,\n  \"mem\": 2048,\n  \"disk\": 50,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"velvia/spark-jobserver:0.6.2.mesos-0.28.1.spark-1.6.1\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8090,\n          \"hostPort\": 0,\n          \"servicePort\": 10001,\n          \"protocol\": \"tcp\",\n          \"labels\": {}\n        }\n      ],\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"env\": {\n    \"SPARK_MASTER\": \"mesos://zk://10.29.83.3:2181,10.29.83.4:2181/mesos\"\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10001,\n      \"protocol\": \"tcp\",\n      \"labels\": {}\n    }\n  ]\n}\n</code></pre>\n", "answer_id": 37716190, "last_activity_date": 1465442077, "creation_date": 1465442077, "score": 3, "owner": {"user_id": 2645289, "profile_image": "https://www.gravatar.com/avatar/d7daa979a882fd5796545d30793f948c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 515, "link": "https://stackoverflow.com/users/2645289/noorul", "display_name": "noorul"}, "is_accepted": true, "question_id": 37712334}], "score": 1, "link": "https://stackoverflow.com/questions/37712334/how-to-run-spark-jobserver-on-mesospheres-dc-os", "answer_count": 1, "owner": {"user_id": 4113770, "profile_image": "https://graph.facebook.com/828394/picture?type=large", "user_type": "registered", "reputation": 68, "link": "https://stackoverflow.com/users/4113770/nandan-rao", "accept_rate": 67, "display_name": "Nandan Rao"}, "view_count": 442, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37712334}{"closed_date": 1502867515, "is_answered": true, "closed_reason": "unclear what you&#39;re asking", "tags": ["dcos"], "title": "mesosphere installation page reference /etc/defaults", "last_activity_date": 1502842954, "accepted_answer_id": 45703277, "creation_date": 1502822998, "score": -2, "link": "https://stackoverflow.com/questions/45699537/mesosphere-installation-page-reference-etc-defaults", "answer_count": 1, "owner": {"user_id": 1898535, "profile_image": "https://i.stack.imgur.com/aX8Ik.png?s=128&g=1", "user_type": "registered", "reputation": 69, "link": "https://stackoverflow.com/users/1898535/andrew-kaluzniacki", "display_name": "Andrew Kaluzniacki"}, "view_count": 28, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45699537}{"body": "<p>I have a Mesos DCOS cluster running on AWS with Spark installed via the <code>dcos package install spark</code> command. I am able to successfully execute Spark jobs using the DCOS CLI: <code>dcos spark run ...</code></p>\n\n<p>Now I would like to execute Spark jobs from a Docker container running inside the Mesos cluster, but I'm not quite sure how to reach the running instance of spark. The idea would be to have a docker container execute the <code>spark-submit</code> command to submit a job to the Spark deployment <strong><em>instead</em></strong> of executing the same job from outside the cluster with the DCOS CLI.</p>\n\n<p>Current documentation seems to be focused only on running Spark via the DCOS CLI - is there any way to reach the spark deployment from another application running inside the cluster?</p>\n", "is_answered": true, "tags": ["apache-spark", "mesos", "mesosphere", "dcos"], "title": "Spark submit from application running in Mesos DCOS cluster", "last_activity_date": 1473952250, "answer_count": 1, "creation_date": 1471372346, "score": 1, "link": "https://stackoverflow.com/questions/38982109/spark-submit-from-application-running-in-mesos-dcos-cluster", "answers": [{"body": "<p>DCOS IOT demo try something similar. <a href=\"https://github.com/amollenkopf/dcos-iot-demo\" rel=\"nofollow\">https://github.com/amollenkopf/dcos-iot-demo</a></p>\n\n<p>This guys run a spark docker and spark-submit in a marathon app. Check this Marathon descriptor: <a href=\"https://github.com/amollenkopf/dcos-iot-demo/blob/master/spatiotemporal-esri-analytics/rat01.json\" rel=\"nofollow\">https://github.com/amollenkopf/dcos-iot-demo/blob/master/spatiotemporal-esri-analytics/rat01.json</a></p>\n", "answer_id": 39514589, "last_activity_date": 1473952250, "creation_date": 1473952250, "score": 1, "owner": {"user_id": 2436237, "profile_image": "https://i.stack.imgur.com/RlWib.jpg?s=128&g=1", "user_type": "registered", "reputation": 2287, "link": "https://stackoverflow.com/users/2436237/gasparms", "display_name": "gasparms"}, "is_accepted": false, "question_id": 38982109}], "owner": {"user_id": 4557098, "profile_image": "https://i.stack.imgur.com/hPu30.jpg?s=128&g=1", "user_type": "registered", "reputation": 323, "link": "https://stackoverflow.com/users/4557098/dbernard", "display_name": "dbernard"}, "view_count": 471, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38982109}{"body": "<p>I'm running a mesos + marathon cluster and so far everything works fine. But I can't figure out how to use constraints in marathon.</p>\n\n<p>I have tagged my mesos slaves with attributes</p>\n\n<pre><code>$ cat /etc/mesos-slave/attributes/category\nSERVICE\n</code></pre>\n\n<p>To the marathon description for my container I added </p>\n\n<pre><code>\"constraints\": [[\"category\", \"CLUSTER\", \"SERVICE\"]]\n</code></pre>\n\n<p>But when I deploy my container I only get \"INFO No matching offer for \" and I can't figure out what I did wrong.</p>\n\n<pre><code>Jun 30 08:08:48 ip-172-16-3-95 marathon[13100]: [2015-06-30 08:08:48,812] INFO No matching offer for &lt;CONTAINER&gt; (need cpus=0.1, mem=3072.0, disk=0.0,\nports=List(0)) : id {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   value: \"20150616-090516-2130907308-5050-1304-O1291851\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: framework_id {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   value: \"20150330-112621-2130907308-5050-25763-0000\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: slave_id {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   value: \"20150616-090516-2130907308-5050-1304-S49\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: hostname: \"&lt;HOSTNAME&gt;\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: resources {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   name: \"cpus\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   type: SCALAR\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   scalar {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     value: 0.3999999999999999\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   role: \"*\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: resources {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   name: \"mem\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   type: SCALAR\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   scalar {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     value: 4911.0\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   role: \"*\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: resources {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   name: \"disk\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   type: SCALAR\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   scalar {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     value: 14896.0\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   role: \"*\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: resources {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   name: \"ports\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   type: RANGES\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   ranges {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     range {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:       begin: 31003\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:       end: 32000\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   role: \"*\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: attributes {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   name: \"category\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   type: TEXT\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   text {\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:     value: \"SERVICE\"\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:   }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]: }\nJun 30 08:08:48 ip-172-16-3-95 marathon[13100]:  (mesosphere.mesos.TaskBuilder:47)    \n</code></pre>\n\n<p>Is there anything I am missing?</p>\n", "is_answered": true, "tags": ["constraints", "mesos", "mesosphere", "marathon"], "last_edit_date": 1435656479, "title": "Problems using Marathon Constraints", "last_activity_date": 1435656479, "answer_count": 1, "creation_date": 1435655718, "score": 1, "link": "https://stackoverflow.com/questions/31134176/problems-using-marathon-constraints", "answers": [{"body": "<p>From the logs, it looks like your task needs mem=3072.0, but is only being offered 1903.0. You should see the same error even without the constraints. Either reduce the memory requirements on your task, or increase the memory available to Mesos/Marathon on your nodes.</p>\n", "answer_id": 31134288, "last_activity_date": 1435656026, "creation_date": 1435656026, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 31134176}], "owner": {"user_id": 4673181, "profile_image": "https://graph.facebook.com/10203776894680057/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/4673181/hammi", "display_name": "hammi"}, "view_count": 1704, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31134176}{"body": "<p>We have an existing Apache Mesos cluster and want to try DCOS in its shiny new Open Source form. However, it would be painful to do a destructive re-install of DCOS. So is it possible to just 'overlay' DCOS on an existing Mesos installation? Would any of the steps change in the DCOS installation guide or could the installer detect the existing Mesos and install DCOS components over it?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Does the DCOS installation process work the same with an existing Mesos installation or do we need to start from scratch?", "last_activity_date": 1461242388, "answer_count": 1, "creation_date": 1461214763, "score": 3, "link": "https://stackoverflow.com/questions/36760037/does-the-dcos-installation-process-work-the-same-with-an-existing-mesos-installa", "answers": [{"body": "<p>I don't think you can simply overlay DC/OS on top of your Mesos cluster. There are multiple reasons for that; one of those is that configuration is for Mesos and marathon is done differently in DC/OS as it is done for Mesos clusters.</p>\n", "answer_id": 36769935, "last_activity_date": 1461242388, "creation_date": 1461242388, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 36760037}], "owner": {"user_id": 6126172, "profile_image": "https://lh3.googleusercontent.com/-FgaFZB2rK7w/AAAAAAAAAAI/AAAAAAAACAw/DIGeCvJmxpY/photo.jpg?sz=128", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6126172/venkat-krishnamurthy", "display_name": "Venkat Krishnamurthy"}, "view_count": 160, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36760037}{"body": "<p>What's the best ways to run Druid on DC/OS?\nI see there are 2 possible options; Marathon and Docker. Which one will you recommend? Is there a better way?</p>\n", "is_answered": true, "tags": ["mesos", "dcos", "druid"], "last_edit_date": 1474456755, "title": "What's the optimal way to run Druid on DC/OS?", "last_activity_date": 1474488167, "answer_count": 1, "creation_date": 1474410597, "score": 0, "link": "https://stackoverflow.com/questions/39604713/whats-the-optimal-way-to-run-druid-on-dc-os", "answers": [{"body": "<p>As Druid has quite a number of \"moving\" parts (5 if I counted correctly, plus ZK and eventually an external Postgres instance), it's not really easy to get it running in a completely automated way.</p>\n\n<p>I started writing a framework (<a href=\"https://github.com/tobilg/druid-framework\" rel=\"nofollow\">https://github.com/tobilg/druid-framework</a>) by preparing Dockerfiles, but eventually stopped because of the complexity.</p>\n\n<p>If you are ok with starting/managing the components manually, you can probably just run the Docker images via Marathon. But please keep in mind that this is IMO not a production-ready setup...</p>\n", "answer_id": 39625591, "last_activity_date": 1474488167, "creation_date": 1474488167, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 39604713}], "owner": {"user_id": 5969981, "profile_image": "https://lh5.googleusercontent.com/-J9vQ7X0hfFQ/AAAAAAAAAAI/AAAAAAAAAZU/KEVhBieSAqk/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5969981/abdel-dridi", "display_name": "Abdel Dridi"}, "view_count": 268, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39604713}{"body": "<p>Am using mesos version 1.0.3.  Just installed mesos thru </p>\n\n<pre><code>docker pull mesosphere/mesos-master:1.0.3\ndocker pull mesosphere/mesos-salve:1.0.3\n</code></pre>\n\n<p>Using docker-compose to start mesos-master and mesos-slave.</p>\n\n<p>docker-compose file,</p>\n\n<pre><code>services:\n  #\n  # Zookeeper must be provided externally\n  #\n\n  #\n  # Mesos\n  #\n  mesos-master:\n    image: mesosphere/mesos-master:1.0.3\n    restart: always\n    privileged: true\n    network_mode: host\n    volumes:\n      - ~/mesos-data/master:/tmp/mesos\n    environment:\n      MESOS_CLUSTER: \"mesos-cluster\"\n      MESOS_QUORUM: \"1\"\n      MESOS_ZK: \"zk://localhost:2181/mesos\"\n      MESOS_PORT: 5000\n      MESOS_REGISTRY_FETCH_TIMEOUT: \"2mins\"\n      MESOS_EXECUTOR_REGISTRATION_TIMEOUT: \"2mins\"\n      MESOS_LOGGING_LEVEL: INFO\n      MESOS_INITIALIZE_DRIVER_LOGGING: \"false\"\n\n  mesos-slave1:\n    image: mesosphere/mesos-slave:1.0.3\n    depends_on: [ mesos-master ]\n    restart: always\n    privileged: true\n    network_mode: host\n    volumes:\n      - ~/mesos-data/slave-1:/tmp/mesos\n      - /sys/fs/cgroup:/sys/fs/cgroup\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      MESOS_CONTAINERIZERS: docker\n      MESOS_MASTER: \"zk://localhost:2181/mesos\"\n      MESOS_PORT: 5051\n      MESOS_WORK_DIR: \"/var/lib/mesos/slave-1\"\n      MESOS_LOGGING_LEVEL: WARNING\n      MESOS_INITIALIZE_DRIVER_LOGGING: \"false\"\n</code></pre>\n\n<p>Mesos master runs fine without any issues. But the slave is not starting with the below error. Not sure, what else is missing here.</p>\n\n<pre><code>I0811 21:38:28.952507     1 main.cpp:243] Build: 2017-02-13 08:10:42 by ubuntu\nI0811 21:38:28.952599     1 main.cpp:244] Version: 1.0.3\nI0811 21:38:28.952601     1 main.cpp:247] Git tag: 1.0.3\nI0811 21:38:28.952603     1 main.cpp:251] Git SHA: c673fdd00e7f93ab7844965435d57fd691fb4d8d\nSELinux:  Could not open policy file &lt;= /etc/selinux/targeted/policy/policy.29:  No such file or directory\n2017-08-11 21:38:29,062:1(0x7f4f78d0d700):ZOO_INFO@log_env@726: Client environment:zookeeper.version=zookeeper C client 3.4.8\n2017-08-11 21:38:29,062:1(0x7f4f78d0d700):ZOO_INFO@log_env@730: Client environment:host.name=&lt;HOST_NAME&gt;\n2017-08-11 21:38:29,062:1(0x7f4f78d0d700):ZOO_INFO@log_env@737: Client environment:os.name=Linux\n2017-08-11 21:38:29,062:1(0x7f4f78d0d700):ZOO_INFO@log_env@738: Client environment:os.arch=3.8.13-98.7.1.el7uek.x86_64\n2017-08-11 21:38:29,062:1(0x7f4f78d0d700):ZOO_INFO@log_env@739: Client environment:os.version=#2 SMP Wed Nov 25 13:51:41 PST 2015\n2017-08-11 21:38:29,063:1(0x7f4f78d0d700):ZOO_INFO@log_env@747: Client environment:user.name=(null)\n2017-08-11 21:38:29,063:1(0x7f4f78d0d700):ZOO_INFO@log_env@755: Client environment:user.home=/root\n2017-08-11 21:38:29,063:1(0x7f4f78d0d700):ZOO_INFO@log_env@767: Client environment:user.dir=/\n2017-08-11 21:38:29,063:1(0x7f4f78d0d700):ZOO_INFO@zookeeper_init@800: Initiating client connection, host=localhost:2181 sessionTimeout=10000 watcher=0x7f4f82265e50 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f4f5c000930 flags=0\n2017-08-11 21:38:29,064:1(0x7f4f74ccb700):ZOO_INFO@check_events@1728: initiated connection to server [127.0.0.1:2181]\n2017-08-11 21:38:29,067:1(0x7f4f74ccb700):ZOO_INFO@check_events@1775: session establishment complete on server [127.0.0.1:2181], sessionId=0x15dc8b48c6d0155, negotiated timeout=10000\nFailed to perform recovery: Failed to run 'docker -H unix:///var/run/docker.sock ps -a': exited with status 1; stderr='Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)\n'\nTo remedy this do as follows:\nStep 1: rm -f /var/lib/mesos/slave-1/meta/slaves/latest\n        This ensures agent doesn't recover old live executors.\n</code></pre>\n\n<p>The below command returns same version for docker client API and docker server API. Not sure what is wrong with the setup.</p>\n\n<p>docker -H unix:///var/run/docker.sock version</p>\n\n<pre><code>Client:\n Version:      1.10.1\n API version:  1.22\n Go version:   go1.5.3\n Git commit:   9e83765\n Built:        Thu Feb 11 19:18:46 2016\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.10.1\n API version:  1.22\n Go version:   go1.5.3\n Git commit:   9e83765\n Built:        Thu Feb 11 19:18:46 2016\n OS/Arch:      linux/amd64\n</code></pre>\n", "is_answered": true, "title": "Mesos Slave - Docker compose", "last_edit_date": 1502493763, "tags": ["docker", "docker-compose", "mesos", "mesosphere"], "view_count": 28, "accepted_answer_id": 45662370, "last_activity_date": 1502640768, "answers": [{"body": "<p>Meoss slave was using the client version 1.24.</p>\n\n<p>This is working after setting the environment variable for the mesos slave.</p>\n\n<pre><code>DOCKER_API_VERSION = 1.22\n</code></pre>\n\n<p>The combination of the release version and API version of Docker is as follows:</p>\n\n<p><a href=\"https://docs.docker.com/engine/api/v1.26/#section/Versioning\" rel=\"nofollow noreferrer\">https://docs.docker.com/engine/api/v1.26/#section/Versioning</a></p>\n\n<p>The other option is to update the docker version.</p>\n", "answer_id": 45662370, "last_activity_date": 1502640768, "creation_date": 1502640768, "score": 0, "owner": {"user_id": 1578872, "profile_image": "https://www.gravatar.com/avatar/80b9c8f75d350cccb189ca77db412590?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 628, "link": "https://stackoverflow.com/users/1578872/user1578872", "accept_rate": 62, "display_name": "user1578872"}, "is_accepted": true, "question_id": 45644267}], "score": 0, "link": "https://stackoverflow.com/questions/45644267/mesos-slave-docker-compose", "answer_count": 1, "owner": {"user_id": 1578872, "profile_image": "https://www.gravatar.com/avatar/80b9c8f75d350cccb189ca77db412590?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 628, "link": "https://stackoverflow.com/users/1578872/user1578872", "accept_rate": 62, "display_name": "user1578872"}, "creation_date": 1502488296, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45644267}{"body": "<p>I keep getting this error on my marathon dashboard</p>\n\n<pre><code>Framework with ID 'a5a96e8c-c3f2-4591-8eb3-43f8dc902585-0001' does not exist on slave with ID '9959ba51-f6f7-448f-99d2-289767f12179-S2'.\n</code></pre>\n\n<p>The path to make this error occur is to click \"Sandbox\" next to a task on the main marathon dashboard.</p>\n\n<p>The path looks something like this</p>\n\n<pre><code>http://mesos.dev.internal/#/slaves/9959ba51-f6f7-448f-99d2-289767f12179-S2/frameworks/a5a96e8c-c3f2-4591-8eb3-43f8dc902585-0001/executors/rabbitmq.6316bf0a-d089-11e5-b895-fa163e196ca3/browse\n</code></pre>\n\n<p>However, if I go to the slave through the slave panel, and click the framework from there, I am able to access the sandbox. The link in this case looks like the following</p>\n\n<pre><code>http://mesos.dev.internal/#/slaves/9959ba51-f6f7-448f-99d2-289767f12179-S2/browse?path=%2Ftmp%2Fmesos%2Fslaves%2Fc223b6b1-cef8-4599-8cea-b402bf20afc5-S0%2Fframeworks%2F20160108-205802-16842879-5050-1210-0001%2Fexecutors%2Frabbitmq.91b8bbf6-ceba-11e5-8047-0242ffdabb3e%2Fruns%2Fc66eb4d5-ea6d-451d-982f-6a0d29b25441\n</code></pre>\n\n<p>Any ideas on what I have misconfigured?</p>\n", "is_answered": true, "tags": ["configuration", "mesos", "mesosphere", "marathon"], "title": "Framework with ID x does not exist on slave with ID y", "last_activity_date": 1456167818, "answer_count": 1, "creation_date": 1455173305, "score": 2, "link": "https://stackoverflow.com/questions/35332589/framework-with-id-x-does-not-exist-on-slave-with-id-y", "answers": [{"body": "<p>Mesos Web UI does not proxy logs through <code>mesos-master</code> (although it would  be nice). Basically you need to be able to resolve slave's name from your browser (computer) and port <code>5051</code> needs to be open for you:</p>\n\n<pre><code>$ nc -z -w5 mesos.dev.internal 5051; echo $?\n0 # port is open\n</code></pre>\n\n<p>It's not a good idea to leave Mesos ports open for public, so either you can:</p>\n\n<ul>\n<li>connect via VPN</li>\n<li>whitelist your public IP on all slaves</li>\n<li>use CLI instead of Web UI</li>\n</ul>\n\n<p>Using CLI is quite easy, once you set master's URI. You can install it:</p>\n\n<pre><code>pip install mesos.cli mesos.interface\n</code></pre>\n\n<p>Then you can list all tasks using <code>mesos ps</code>, or fetch <code>stdout</code>:</p>\n\n<pre><code>  mesos tail -f rabbitmq.6316bf0a-d089-11e5-b895-fa163e196ca3\n</code></pre>\n\n<p>and <code>stderr</code>:</p>\n\n<pre><code>  mesos tail -f rabbitmq.6316bf0a-d089-11e5-b895-fa163e196ca3 stderr\n</code></pre>\n\n<p>Note that the mesos-cli is no longer developed, similar features and much more you should be able to do with Mesosphere's <a href=\"https://docs.mesosphere.com/administration/introcli/cli/\" rel=\"nofollow\">DCOS CLI</a>  </p>\n", "answer_id": 35561756, "last_activity_date": 1456167818, "creation_date": 1456167818, "score": 1, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": false, "question_id": 35332589}], "owner": {"user_id": 1020076, "profile_image": "https://www.gravatar.com/avatar/530c9a97e692df7a243faa511b209189?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1776, "link": "https://stackoverflow.com/users/1020076/peter-klipfel", "accept_rate": 78, "display_name": "Peter Klipfel"}, "view_count": 225, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35332589}{"is_answered": false, "tags": ["docker", "vagrant", "virtualbox", "gpu", "dcos"], "last_edit_date": 1499678025, "title": "Is there GPU support for DCOS-Vagrant and DCOS-Docker?", "last_activity_date": 1499678025, "answer_count": 0, "creation_date": 1499675824, "score": 0, "link": "https://stackoverflow.com/questions/45007344/is-there-gpu-support-for-dcos-vagrant-and-dcos-docker", "owner": {"user_id": 829361, "profile_image": "https://www.gravatar.com/avatar/f542f180e2c4e7d2f8ff0f861881ff62?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 52, "link": "https://stackoverflow.com/users/829361/ambuj", "accept_rate": 100, "display_name": "ambuj"}, "view_count": 30, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45007344}{"body": "<p>I'm having a strange issue today. First of all, every thing was still working fine yesterday when I left the office, but today when I went back to work my DC/OS dashboard showed my that there weren't any services running, or Nodes connected.</p>\n\n<p>I've ran into this issue once or twice before and was related to the marathon not being able to elect a master. One of the 3 master nodes is then also showing a lot of errors in the journal. This can be resolved by stopping / starting the dcos-marathon service on that host, which brings it back into the marathon group.</p>\n\n<p>I did see the Nodes and services again. But now it sometimes tells me there is only one Node connected and then 3 again, and just 1 again, etc..</p>\n\n<p>When I stop the dcos-mesos-master process on the conflicting host, this stops and I have a stable master cluster (but probably not really resilient).</p>\n\n<p>It looks like the failing node is trying to become the master, which causes this.. I've tried to search about rejoining a failed mesos-master.. but came up </p>\n\n<p>I'm running DC/OS on a CoreOS environment.</p>\n\n<p>Help is much appreciated..</p>\n", "is_answered": false, "tags": ["dcos"], "title": "DC/OS Mesos-Master rejoined and causes interuptions on the master agents", "last_activity_date": 1470715107, "answer_count": 1, "creation_date": 1470394655, "score": 0, "link": "https://stackoverflow.com/questions/38787573/dc-os-mesos-master-rejoined-and-causes-interuptions-on-the-master-agents", "answers": [{"body": "<p>Although a general behavior is described, you may need to provide more specifics such as the kernel version, dc/os version, specs and etc.  The simplest answer I can provide based what's been given is to reach out via their support channel on Slack ( <a href=\"https://dcos-community.slack.com/\" rel=\"nofollow\">https://dcos-community.slack.com/</a> ).</p>\n", "answer_id": 38841785, "last_activity_date": 1470715107, "creation_date": 1470715107, "score": 0, "owner": {"user_id": 3938934, "profile_image": "https://www.gravatar.com/avatar/4bd1d171d73fa1b6a9f9c506fbe083a9?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 41, "link": "https://stackoverflow.com/users/3938934/antonio-de-leon", "display_name": "Antonio De Leon"}, "is_accepted": false, "question_id": 38787573}], "owner": {"user_id": 6682136, "profile_image": "https://www.gravatar.com/avatar/0d8bbb3bcb6224854a72becfa7b2969d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/6682136/neef-roel", "display_name": "Neef Roel"}, "view_count": 68, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 38787573}{"body": "<p>I have 3 CentOS VMs and I have installed Zookeeper, Marathon, and Mesos on the master node, while only putting Mesos on the other 2 VMs. The master node has no mesos-slave running on it. I am trying to run Docker containers so i specified <code>\"docker,mesos\"</code> in the containerizes file. One of the mesos-agents starts fine with this configuration and I have been able to deploy a container to that slave. However, the second mesos-agent simply fails when I have this configuration (it works if i take out that containerizes file but then it doesn't run containers). Here are some of the logs and information that has come up:</p>\n\n<p><strong>Here are some \"messages\" in the log directory:</strong></p>\n\n<pre><code>Apr 26 16:09:12 centos-minion-3 systemd: Started Mesos Slave.\nApr 26 16:09:12 centos-minion-3 systemd: Starting Mesos Slave...\nWARNING: Logging before InitGoogleLogging() is written to STDERR\n[main.cpp:243] Build: 2017-04-12 16:39:09 by centos\n[main.cpp:244] Version: 1.2.0\n[main.cpp:247] Git tag: 1.2.0\n[main.cpp:251] Git SHA: de306b5786de3c221bae1457c6f2ccaeb38eef9f\n[logging.cpp:194] INFO level logging started!\n[systemd.cpp:238] systemd version `219` detected\n[main.cpp:342] Inializing systemd state\n[systemd.cpp:326] Started systemd slice `mesos_executors.slice`\n[containerizer.cpp:220] Using isolation: posix/cpu,posix/mem,filesystem/posix,network/cni\n[linux_launcher.cpp:150] Using /sys/fs/cgroup/freezer as the freezer hierarchy for the Linux launcher\n[provisioner.cpp:249] Using default backend 'copy'\n[slave.cpp:211] Mesos agent started on (1)@172.22.150.87:5051\n[slave.cpp:212] Flags at startup: --appc_simple_discovery_uri_prefix=\"http://\" --appc_store_dir=\"/tmp/mesos/store/appc\" --authenticate_http_readonly=\"false\" --authenticate_http_readwrite=\"false\" --authenticatee=\"crammd5\" --authentication_backoff_factor=\"1secs\" --authorizer=\"local\" --cgroups_cpu_enable_pids_and_tids_count=\"false\" --cgroups_enable_cfs=\"false\" --cgroups_hierarchy=\"/sys/fs/cgroup\" --cgroups_limit_swap=\"false\" --cgroups_root=\"mesos\" --container_disk_watch_interval=\"15secs\" --containerizers=\"docker,mesos\" --default_role=\"*\" --disk_watch_interval=\"1mins\" --docker=\"docker\" --docker_kill_orphans=\"true\" --docker_registry=\"https://registry-1.docker.io\" --docker_remove_delay=\"6hrs\" --docker_socket=\"/var/run/docker.sock\" --docker_stop_timeout=\"0ns\" --docker_store_dir=\"/tmp/mesos/store/docker\" --docker_volume_checkpoint_dir=\"/var/run/mesos/isolators/docker/volume\" --enforce_container_disk_quota=\"false\" --executor_registration_timeout=\"1mins\" --executor_shutdown_grace_period=\"5secs\" --fetcher_cache_dir=\"/tmp/mesos/fetch\" --fetcher_cache_size=\"2GB\" --frameworks_home=\"\" --gc_delay=\"1weeks\" --gc_disk_headroom=\"0.1\" --hadoop_home=\"\" --help=\"false\" --hostname_lookup=\"true\" --http_authenticators=\"basic\" --http_command_executor=\"false\" --http_heartbeat_interval=\"30secs\" --initialize_driver_logging=\"true\" --isolation=\"posix/cpu,posix/mem\" --launcher=\"linux\" --launcher_dir=\"/usr/libexec/mesos\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --max_completed_executors_per_framework=\"150\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registration_backoff_factor=\"1secs\" --revocable_cpu_low_priority=\"true\" --runtime_dir=\"/var/run/mesos\" --sandbox_directory=\"/mnt/mesos/sandbox\" --strict=\"true\" --switch_user=\"true\" --systemd_enable_support=\"true\" --systemd_runtime_directory=\"/run/systemd/system\" --version=\"false\" --work_dir=\"/var/lib/mesos\"\n[slave.cpp:541] Agent resources: cpus(*):1; mem(*):919; disk(*):2043; ports(*):[31000-32000]\n[slave.cpp:549] Agent attributes: [  ]\n[slave.cpp:554] Agent hostname: node3\n[status_update_manager.cpp:177] Pausing sending status updates\n[state.cpp:62] Recovering state from '/var/lib/mesos/meta'\n[state.cpp:706] No committed checkpointed resources found at '/var/lib/mesos/meta/resources/resources.info'\n[status_update_manager.cpp:203] Recovering status update manager\n[docker.cpp:868] Recovering Docker containers\n[containerizer.cpp:599] Recovering containerizer\n[provisioner.cpp:410] Provisioner recovery complete\n[group.cpp:340] Group process (zookeeper-group(1)@172.22.150.87:5051) connected to ZooKeeper\n[group.cpp:830] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\n[group.cpp:418] Trying to create path '/mesos' in ZooKeeper\n[detector.cpp:152] Detected a new leader: (id='15')\n[group.cpp:699] Trying to get '/mesos/json.info_0000000015' in ZooKeeper\n[zookeeper.cpp:259] A new leading master (UPID=master@172.22.150.88:5050) is detected\nFailed to perform recovery: Collect failed: Failed to run 'docker -H unix:///var/run/docker.sock ps -a': exited with status 1; stderr='Cannot connect to the Docker daemon. Is the docker daemon running on this host?'\nTo remedy this do as follows:\nStep 1: rm -f /var/lib/mesos/meta/slaves/latest\n       This ensures agent doesn't recover old live executors.\nStep 2: Restart the agent.\nApr 26 16:09:13 centos-minion-3 systemd: mesos-slave.service: main process exited, code=exited, status=1/FAILURE\nApr 26 16:09:13 centos-minion-3 systemd: Unit mesos-slave.service entered failed state.\nApr 26 16:09:13 centos-minion-3 systemd: mesos-slave.service failed.\n</code></pre>\n\n<p><strong>Logs from docker:</strong></p>\n\n<pre><code>$ sudo systemctl status docker\n\u25cf docker.service - Docker Application Container Engine Loaded: \n  loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) \n  Drop-In: /usr/lib/systemd/system/docker.service.d \n  \u2514\u2500flannel.conf Active: inactive (dead) since Tue 2017-04-25 18:00:03 CDT; \n    24h ago Docs: docs.docker.com Main PID: 872 (code=exited, status=0/SUCCESS) \n    Apr 26 18:25:25 centos-minion-3 systemd[1]: Dependency failed for Docker Application Container Engine. \n    Apr 26 18:25:25 centos-minion-3 systemd[1]: Job docker.service/start failed with result 'dependency'\n</code></pre>\n\n<p><strong>Logs from flannel:</strong></p>\n\n<pre><code>[flanneld-start: network.go:102] failed to retrieve network config: client: etcd cluster is unavailable or misconfigured\n</code></pre>\n", "is_answered": false, "tags": ["docker", "mesos", "marathon", "mesosphere", "flannel"], "last_edit_date": 1493281254, "title": "When using mesos, marathon, and zookeeper my mesos-slave doesnt start when I specify the \"containerizers\" file with \"docker,mesos\"?", "last_activity_date": 1493471512, "answer_count": 1, "creation_date": 1493165435, "score": 2, "link": "https://stackoverflow.com/questions/43622904/when-using-mesos-marathon-and-zookeeper-my-mesos-slave-doesnt-start-when-i-spe", "answers": [{"body": "<p>You have answer in your logs </p>\n\n<pre><code>Failed to perform recovery: Collect failed: \nFailed to run 'docker -H unix:///var/run/docker.sock ps -a': exited with status 1; \nstderr='Cannot connect to the Docker daemon. Is the docker daemon running on this host?'\nTo remedy this do as follows:\nStep 1: rm -f /var/lib/mesos/meta/slaves/latest\n       This ensures agent doesn't recover old live executors.\nStep 2: Restart the agent.\n</code></pre>\n\n<p>Mesos keeps it state/metadata on local disk. When it's restarted it try to load this state. If configuration changed and is not compatible with previous state it won't start. </p>\n\n<p>Just bring docker to live by fixing problems with flannel and etcd and everything will be fine.</p>\n", "answer_id": 43645213, "last_activity_date": 1493471512, "creation_date": 1493243854, "score": 0, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": false, "last_edit_date": 1493471512, "question_id": 43622904}], "owner": {"user_id": 4963990, "profile_image": "https://graph.facebook.com/835255796550778/picture?type=large", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/4963990/kmahesh3", "display_name": "kmahesh3"}, "view_count": 129, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43622904}{"body": "<h2>Summary</h2>\n\n<p>I'm trying to set up Mesos cluster using Docker containers.</p>\n\n<p>But <code>docker run</code> command fails with <code>-v</code> volume options, and succeeds without volume options.</p>\n\n<p>Message is as follows,</p>\n\n<pre><code>FATA[0008] Error response from daemon: No such image: redjack/mesos-master:latest (tag: latest)\n</code></pre>\n\n<p>despite the image <code>redjack/mesos-master:latest</code> exists.</p>\n\n<p>It's strange that adding volume options causes <code>No such image</code> error.</p>\n\n<p>Does anyone have solutions or hints for this problem?</p>\n\n<p>Thank you in advance!</p>\n\n<h2>Details</h2>\n\n<p>I'm using <a href=\"https://registry.hub.docker.com/u/redjack/mesos-master/\" rel=\"nofollow\">redjack/mesos-master</a> for master and <a href=\"https://registry.hub.docker.com/u/redjack/mesos-slave/\" rel=\"nofollow\">redjack/mesos-slave</a> for slave.</p>\n\n<p><strong>Failed Commands</strong></p>\n\n<p>Following command is for master.</p>\n\n<pre><code>$ docker run \\\n-e MESOS_LOG_DIR=/var/log \\\n-e MESOS_HOSTNAME=&lt;hostname&gt; \\\n-e MESOS_PORT=5050 \\\n-e MESOS_REGISTRY=in_memory \\\n-e MESOS_WORK_DIR=/tmp/mesosphere \\\n-e MESOS_CONTAINERIZERS=docker,mesos \\\n-v /var/log:/var/log \\\n-v /sys/cgroup:/cgroup \\\n-v /proc:/proc \\\nredjack/mesos-master:latest\n</code></pre>\n\n<p>This returns following messages.</p>\n\n<pre><code>Unable to find image 'redjack/mesos-master:latest' locally\nPulling repository redjack/mesos-master\ne43e645e4613: Download complete\ne9e06b06e14c: Download complete\na82efea989f9: Download complete\n37bea4ee0c81: Download complete\n07f8e8c5e660: Download complete\na170eebbd2bf: Download complete\n104ab0553e3a: Download complete\nd6f04b0daf32: Download complete\nbdb0fee63b5c: Download complete\n943ba7734c82: Download complete\ne8b0687de36f: Download complete\n9ae9def4d95e: Download complete\n776c4db2701b: Download complete\n63180ef60d78: Download complete\nStatus: Image is up to date for redjack/mesos-master:latest\nFATA[0008] Error response from daemon: No such image: redjack/mesos-master:latest (tag: latest)\n</code></pre>\n\n<p>Despite the message above, image <code>redjack/mesos-master</code> exists</p>\n\n<pre><code>$ docker images | grep mesos-master\nredjack/mesos-master         latest              e43e645e4613        2 weeks ago         1.092 GB\n</code></pre>\n\n<p><strong>Succeeded Commands</strong></p>\n\n<p>As mentioned above it succeeds without <code>-v</code> options </p>\n\n<pre><code>$ docker run \\\n-e MESOS_LOG_DIR=/var/log \\\n-e MESOS_HOSTNAME=&lt;hostname&gt; \\\n-e MESOS_PORT=5050 \\\n-e MESOS_REGISTRY=in_memory \\\n-e MESOS_WORK_DIR=/tmp/mesosphere \\\n-e MESOS_CONTAINERIZERS=docker,mesos \\\nredjack/mesos-master:latest\n</code></pre>\n\n<p><strong>Environments</strong></p>\n\n<p>OS:\n<code>CentOS 6.5</code></p>\n\n<p>Docker:</p>\n\n<pre><code>$ docker version\n\nClient version: 1.5.0\nClient API version: 1.17\nGo version (client): go1.3.3\nGit commit (client): a8a31ef/1.5.0\nOS/Arch (client): linux/amd64\nServer version: 1.5.0\nServer API version: 1.17\nGo version (server): go1.3.3\nGit commit (server): a8a31ef/1.5.0\n</code></pre>\n", "is_answered": true, "tags": ["centos", "docker", "mesos", "centos6.5", "mesosphere"], "title": "\"docker run\" fails with \"-v\" options on CentOS6.5", "last_activity_date": 1432260358, "answer_count": 1, "creation_date": 1432196484, "score": 1, "link": "https://stackoverflow.com/questions/30368251/docker-run-fails-with-v-options-on-centos6-5", "answers": [{"body": "<p>Thanks for user2915097, the problem was solved by changing <code>-v /sys/cgroup:/cgroup</code> to <code>-v /cgroup:/cgroup</code>.</p>\n", "answer_id": 30387266, "last_activity_date": 1432260358, "creation_date": 1432260358, "score": 1, "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "is_accepted": false, "question_id": 30368251}], "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 105, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30368251}{"body": "<p>I'm experimenting a little with ACS using the DC/OS orchestrator, and while spinning up a cluster within a single region seems simple enough, I'm not quite sure what the best practice would be for doing deployments across multiple regions.</p>\n\n<p>Azure itself does not seem to support deploying to more than one region right now. With that assumption, I guess my only other option is to create multiple, identical clusters in all the regions I wish to be available, and then use Azure Traffic Manager to route incoming traffic to the nearest available cluster.</p>\n\n<p>While this solution works, it also causes a few issues I'm not 100% sure on how I should work around.</p>\n\n<ol>\n<li>Our deployment pipelines must make sure to deploy to all regions when deploying a new version of a service. If we have a East US and North Europe region, during deployments from our CI tool I have to connect to the Marathon API in both regions to trigger the new deployments. If the deployment fails in one region, and succeeds in the other, I suddenly have a disparity between the two regions.</li>\n<li>If i have a service using local persistent volumes deployed, let's say PostgreSQL or ElasticSearch, it needs to have instances in both regions since service discovery will only find services local to the region. That brings up the problem of replication between regions to keep all state in all regions; this seem to require some/a lot of manual configuration to get to work.</li>\n</ol>\n\n<p>Has anyone ever used a setup somewhat like this using Azure Container Service (or really Amazon Container Service, as I assume the same challenges can be found there) and have some pointers on how to approach this?</p>\n", "is_answered": true, "tags": ["azure", "dcos", "azure-container-service"], "title": "Multi regional Azure Container Service DC/OS clusters", "last_activity_date": 1504116203, "answer_count": 2, "creation_date": 1479494654, "score": 7, "link": "https://stackoverflow.com/questions/40684041/multi-regional-azure-container-service-dc-os-clusters", "answers": [{"body": "<p>You are correct ACS does not currently support Multi-Region deployments.</p>\n\n<p>Your first issue is specific to Marathon in DC/OS, I'll ping some of the engineering folks over there to see if they have any input on best practice.</p>\n\n<p>Your second point is something we (I'm the ACS PM) are looking at. There are some solutions you can use in certain scenarios (e.g. ArangoDB is in the DC/OS universe and will provide replication). The DC/OS team may have something to say here too. In ACS we are evaluating the best approaches to providing solutions for this use case but I'm afraid I can't give any indication of timeline.</p>\n\n<p>An alternative solution is to have your database in a SaaS offering. This takes away all the complexity of managing redundancy and replication. </p>\n", "answer_id": 41559439, "last_activity_date": 1484009038, "creation_date": 1484009038, "score": 0, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "question_id": 40684041}, {"body": "<p>You have multiple options for spinning up across regions. I would use a custom installation together with terraform for each of them. This here is a great starting point: <a href=\"https://github.com/bernadinm/terraform-dcos\" rel=\"nofollow noreferrer\">https://github.com/bernadinm/terraform-dcos</a></p>\n\n<p>Distributing agents across different regions should be no problem, ensuring that your services will keep running despite failures.</p>\n\n<p>Distributing masters (giving you control over the services during failures) is a little more diffult as it involves distributing a zookeeper quorum across high latency links, so you should be careful in choosing the \"distance\" between regions.</p>\n\n<p>Have a look at the <a href=\"https://dcos.io/docs/1.9/installing/high-availability/\" rel=\"nofollow noreferrer\">documentation</a> for more details.</p>\n", "answer_id": 45967011, "last_activity_date": 1504116203, "creation_date": 1504116203, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 40684041}], "owner": {"user_id": 2282809, "profile_image": "https://www.gravatar.com/avatar/9d2637e5787bc7b54fd54f2c492d2783?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 516, "link": "https://stackoverflow.com/users/2282809/trond-nordheim", "accept_rate": 83, "display_name": "Trond Nordheim"}, "view_count": 288, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 40684041}{"body": "<p>I have setup Azure Container Service using DC/OS + Marathon for deploying Docker containers. So far looks good, I can connect to master node using SSH tunnel and access Mesos and Marathon WebUI as well as hit REST API.</p>\n\n<p>Next, I am trying to deploy a docker container from my private docker repository and I found following article on Marathon website.</p>\n\n<p><a href=\"https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html\" rel=\"noreferrer\">https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html</a></p>\n\n<p>Please see the \"Note\" section from above URL - </p>\n\n<p><strong>Note</strong>: The URI must be accessible by all nodes that may start your application. Approaches may include distributing the file to the local filesystem of all nodes, for example via RSYNC/SCP, or storing it on a shared network drive, for example Amazon S3. It is worth considering the security implications of your chosen approach.</p>\n\n<p>What options does Azure provides for sharing the docker.tar.gz file across all nodes?</p>\n\n<p>Thanks</p>\n", "is_answered": true, "tags": ["azure", "docker", "mesos", "marathon", "dcos"], "last_edit_date": 1462301115, "title": "How to securely share private docker repo login credentials in Azure container service with Mesos & Marathon", "last_activity_date": 1472113744, "answer_count": 3, "creation_date": 1462300950, "score": 6, "link": "https://stackoverflow.com/questions/37011980/how-to-securely-share-private-docker-repo-login-credentials-in-azure-container-s", "answers": [{"body": "<p>the way we did it is use <code>parallel-scp</code> to push the file to all our mesos agents, something like:</p>\n\n<pre><code>parallel-scp -h ~/pssh_all_ips ./docker.tar.gz /etc/docker.tar.gz\n</code></pre>\n\n<p>Where <code>pssh_all_ips</code> is a newline separated file of internal IP addresses (<code>10.0.*.*</code> or <code>10.32.*.*</code> in our case). </p>\n\n<p>You can find your agent IPs at <code>localhost:2000/mesos/#/slaves</code> if you're tunneled into your cluster).</p>\n\n<p>This makes the file available at <code>file:///etc/docker.tar.gz</code> on all agents, from there you can use marathon's URI field to make it available to the docker pull system.</p>\n", "answer_id": 37012506, "last_activity_date": 1468615691, "creation_date": 1462302677, "score": 1, "owner": {"user_id": 981464, "profile_image": "https://www.gravatar.com/avatar/1b728d6658bdbd707d9337e8447f29c4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 303, "link": "https://stackoverflow.com/users/981464/viraj-os", "display_name": "viraj_os"}, "is_accepted": false, "last_edit_date": 1468615691, "question_id": 37011980}, {"body": "<p>One method is to use a script to walk the agents in your cluster. Take a look at <a href=\"https://github.com/rgardler/acs-cli\" rel=\"nofollow\">https://github.com/rgardler/acs-cli</a> for some experiments in doing this.</p>\n", "answer_id": 37012923, "last_activity_date": 1463194030, "creation_date": 1462304153, "score": 1, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "last_edit_date": 1463194030, "question_id": 37011980}, {"body": "<p>Put your <code>docker.tar.gz</code> to Azure Storage and create a signed url. I have used Azure Storage Explorer to create one. </p>\n\n<p>Output;</p>\n\n<p><a href=\"https://xyzds.file.core.windows.net/docker/docker.tar.gz?...url-params\" rel=\"noreferrer\">https://xyzds.file.core.windows.net/docker/docker.tar.gz?...url-params</a></p>\n\n<p>You need to add file extension in order to marathon extract it. </p>\n\n<p><code>x=.tar.gz</code></p>\n\n<p><code>\n\"uris\": [\n    \"https://xyzds.file.core.windows.net/docker/docker.tar.gz?...url-params&amp;x=.tar.gz\"\n  ]\n</code></p>\n\n<p>You are good to go.</p>\n", "answer_id": 39140280, "last_activity_date": 1472113744, "creation_date": 1472113744, "score": 5, "owner": {"user_id": 1320202, "profile_image": "https://www.gravatar.com/avatar/4ad6eb32d0305d961f8184c7bb420a54?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 221, "link": "https://stackoverflow.com/users/1320202/ferhat-sobay", "display_name": "Ferhat Sobay"}, "is_accepted": false, "question_id": 37011980}], "owner": {"user_id": 5857766, "profile_image": "https://www.gravatar.com/avatar/d0353ba31c47596662df9f5e58050695?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 71, "link": "https://stackoverflow.com/users/5857766/anurag-sharma", "accept_rate": 67, "display_name": "Anurag Sharma"}, "view_count": 515, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37011980}{"body": "<p>I need to view long term utilization trends for DC/OS and be able to drill down (a la graphana/graphite) in my DC/OS dashboard, but I can't seem to find such a feature there.</p>\n\n<p>Is this available in the DCOS dashboard, in DC/OS , or if neither via some third party plugin?</p>\n", "is_answered": true, "tags": ["performance", "monitoring", "mesos", "mesosphere", "dcos"], "title": "How to View Long Term Utilization Trends (Graphs) in the DCOS Dashboard", "last_activity_date": 1479521109, "answer_count": 1, "creation_date": 1479468161, "score": 2, "link": "https://stackoverflow.com/questions/40675858/how-to-view-long-term-utilization-trends-graphs-in-the-dcos-dashboard", "answers": [{"body": "<p>DC/OS metrics, and debugging will be coming out with the release of DC/OS 1.9, which is expected to be GA on 1/26/2017 (not that long from now).</p>\n\n<p>Take a look at <a href=\"https://mesosphere.com/blog/2016/10/12/day-2-operations-metrics/\" rel=\"nofollow noreferrer\">this blog</a> which describes how metrics will work. There's another one for logging</p>\n\n<p>If you have have more questions about metrics and logging you can email jeff@mesosphere.com or hop into the <a href=\"http://chat.dcos.io/?_ga=1.95293532.1790439002.1478539864\" rel=\"nofollow noreferrer\">community slack</a> #day2ops </p>\n", "answer_id": 40688485, "last_activity_date": 1479521109, "creation_date": 1479521109, "score": 2, "owner": {"user_id": 6702425, "profile_image": "https://i.stack.imgur.com/CXJ2H.jpg?s=128&g=1", "user_type": "registered", "reputation": 86, "link": "https://stackoverflow.com/users/6702425/judith-malnick", "display_name": "Judith Malnick"}, "is_accepted": false, "question_id": 40675858}], "owner": {"user_id": 6052496, "profile_image": "https://lh5.googleusercontent.com/-a_pOtzr9DVc/AAAAAAAAAAI/AAAAAAAAAUo/2RBjf5ZEe7k/photo.jpg?sz=128", "user_type": "registered", "reputation": 53, "link": "https://stackoverflow.com/users/6052496/traiano-welcome", "accept_rate": 64, "display_name": "Traiano Welcome"}, "view_count": 47, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 40675858}{"body": "<p>I'm experimenting with DC/OS I would like to try out the native file running capabilities, run an native executable without using docker, outlined at <a href=\"https://dcos.io/docs/1.8/usage/tutorials/dcos-101/app2/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.8/usage/tutorials/dcos-101/app2/</a></p>\n\n<p>I can successfully follow the tutorial but I would like to use my own application (a self-contained executable), the online documentation says that the fetch command supports the file:// uri in addition to the https:// uri and others. (<a href=\"https://mesosphere.github.io/marathon/docs/application-basics.html\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/application-basics.html</a>)</p>\n\n<p>So if I use the app deployment manifest from the tutorial as my basis, but I've uploaded my executable to my master node at /home/core/app (in the linux filesystem)\nand change the uri to \"file:///home/core/app\" the deployment says</p>\n\n<blockquote>\n  <p>I0127 14:42:06.533756 40159 fetcher.cpp:167] Copying resource with command:cp '/home/core/app' '/var/lib/mesos/slave/slaves/a0ff5689-5816-4812-864b-b3c4b914a272-S0/frameworks/a0ff5689-5816-4812-864b-b3c4b914a272-0000/executors/dcos-101_app2.c641de8d-e49e-11e6-93c4-de7054394bed/runs/f266a00c-1179-48bb-9f1e-251f3eae1272/app'\n  cp: cannot stat '/home/core/app': No such file or directory\"</p>\n</blockquote>\n\n<p>Using DC/OS 1.8 installed on CoreOS with one master and one agent (just for dev test)</p>\n\n<p>I'm sure I'm just missing something fundamental like the mesos filesystem, but I've looked everywhere for a tutorial and they either assume your using docker, or serving via http...nothing for file://</p>\n\n<p>So when using the file:// uri is that a different location than the linux filesystem or am I missing something else.</p>\n\n<p>Little help please for a DC/OS newb</p>\n\n<p>Thanks</p>\n\n<p>EDIT</p>\n\n<p>Here is the app.json file</p>\n\n<pre><code>{\n  \"id\": \"/dcos-101/app2\",\n  \"cmd\": \"chmod u+x app &amp;&amp; ./app\",\n  \"args\": null,\n  \"user\": null,\n  \"env\": null,\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 0,\n  \"gpus\": 0,\n  \"executor\": null,\n  \"constraints\": null,\n  \"fetch\": [\n    {\n      \"uri\": \"file:///home/core/app\"\n    }\n  ],\n  \"storeUrls\": null,\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": null,\n  \"healthChecks\": null,\n  \"readinessChecks\": null,\n  \"dependencies\": null,\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 1,\n    \"maximumOverCapacity\": 1\n  },\n  \"acceptedResourceRoles\": null,\n  \"ipAddress\": null,\n  \"residency\": null,\n  \"secrets\": null,\n  \"taskKillGracePeriodSeconds\": null,\n  \"portDefinitions\": [\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 10000,\n      \"labels\": {\n        \"VIP_0\": \"/dcos-101/app2:10000\"\n      }\n    }\n  ],\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"requirePorts\": false\n}\n</code></pre>\n", "is_answered": true, "title": "Create DC/OS app deployment from native executable local file", "last_edit_date": 1485543023, "tags": ["mesos", "marathon", "dcos"], "view_count": 54, "accepted_answer_id": 41901006, "last_activity_date": 1485543023, "answers": [{"body": "<p>That won't work, unless <code>/home/core/app</code> exists on <em>each</em> of your Agent nodes or you change it to, say, an external HTTP URL. What <code>fetch</code> does is: it downloads the listed file(s) into the Mesos sandbox, depending on the URI schema in use. Since you're using the <code>file:</code> schema, Mesos tries to download it on the Agent where the task is launched (and not the Master).</p>\n", "answer_id": 41901006, "last_activity_date": 1485542933, "creation_date": 1485542933, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 41898520}], "score": 0, "link": "https://stackoverflow.com/questions/41898520/create-dc-os-app-deployment-from-native-executable-local-file", "answer_count": 1, "owner": {"user_id": 7479548, "profile_image": "https://www.gravatar.com/avatar/0fc17825ba6c746e506661fc998d23e0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 3, "link": "https://stackoverflow.com/users/7479548/sam-paioletti", "display_name": "Sam Paioletti"}, "creation_date": 1485534245, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41898520}{"is_answered": true, "tags": ["jenkins", "docker", "proxy", "mesos", "dcos"], "title": "Jenkins mesosphere/jenkins-dind:0.3.1 and proxy", "last_activity_date": 1481577460, "answer_count": 1, "creation_date": 1480867201, "score": 1, "link": "https://stackoverflow.com/questions/40960538/jenkins-mesosphere-jenkins-dind0-3-1-and-proxy", "owner": {"user_id": 3984274, "profile_image": "https://www.gravatar.com/avatar/e91f42af9e63428ef0f2ec4bfbb72148?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/3984274/a-voiry", "display_name": "A Voiry"}, "view_count": 110, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 40960538}{"is_answered": true, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1467826327, "title": "How to add additional agents to mesosphere dc/os cluster?", "last_activity_date": 1469778643, "answer_count": 1, "creation_date": 1466706349, "score": 4, "link": "https://stackoverflow.com/questions/37999133/how-to-add-additional-agents-to-mesosphere-dc-os-cluster", "accepted_answer_id": 38652889, "owner": {"user_id": 6470473, "profile_image": "https://www.gravatar.com/avatar/0fbe0b19f229ab3c8fe37ff3cf7abc1f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 33, "link": "https://stackoverflow.com/users/6470473/grayzzz", "display_name": "grayzzz"}, "view_count": 1087, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37999133}{"body": "<p>I am Trying to install DC/OS but facing issues in On-Premises</p>\n\n<p><strong>Below is the Error Log</strong></p>\n\n<pre><code>Connection to 172.XX.XXX.XX closed.\nStarting DC/OS Install Process\nRunning preflight checks\nChecking if DC/OS is already installed: PASS (Not installed)\nPASS Is SELinux disabled?\nChecking if docker is installed and in PATH: PASS \nChecking docker version requirement (&gt;= 1.6): PASS (1.11.1)\nChecking if curl is installed and in PATH: PASS \nChecking if bash is installed and in PATH: PASS \nChecking if ping is installed and in PATH: PASS \nChecking if tar is installed and in PATH: PASS \nChecking if xz is installed and in PATH: PASS \nChecking if unzip is installed and in PATH: PASS \nChecking if ipset is installed and in PATH: PASS \nChecking if systemd-notify is installed and in PATH: PASS \nChecking if systemd is installed and in PATH: PASS \nChecking systemd version requirement (&gt;= 200): PASS (219)\nChecking if group 'nogroup' exists: PASS \nChecking if port 80 (required by mesos-ui) is in use: PASS \nChecking if port 53 (required by mesos-dns) is in use: PASS \nChecking if port 15055 (required by dcos-history) is in use: PASS \nChecking if port 5050 (required by mesos-master) is in use: PASS \nChecking if port 2181 (required by zookeeper) is in use: PASS \nChecking if port 8080 (required by marathon) is in use: PASS \nChecking if port 3888 (required by zookeeper) is in use: PASS \nChecking if port 8181 (required by exhibitor) is in use: PASS \nChecking if port 8123 (required by mesos-dns) is in use: PASS \nChecking Docker is configured with a production storage driver: WARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\nPASS (overlay)\nCreating directories under /etc/mesosphere\nCreating role file for master\nConfiguring DC/OS\nSetting and starting DC/OS\nJob for dcos-setup.service failed because the control process exited with error code. See \"systemctl status dcos-setup.service\" and \"journalctl -xe\" for details.\n172.XX.XXX.XX:XX\nConnection to 172.XX.XXX.XXX closed.\nStarting DC/OS Install Process\nRunning preflight checks\nChecking if DC/OS is already installed: PASS (Not installed)\nPASS Is SELinux disabled?\nChecking if docker is installed and in PATH: PASS \nChecking docker version requirement (&gt;= 1.6): PASS (1.11.1)\nChecking if curl is installed and in PATH: PASS \nChecking if bash is installed and in PATH: PASS \nChecking if ping is installed and in PATH: PASS \nChecking if tar is installed and in PATH: PASS \nChecking if xz is installed and in PATH: PASS \nChecking if unzip is installed and in PATH: PASS \nChecking if ipset is installed and in PATH: PASS \nChecking if systemd-notify is installed and in PATH: PASS \nChecking if systemd is installed and in PATH: PASS \nChecking systemd version requirement (&gt;= 200): PASS (219)\nChecking if group 'nogroup' exists: PASS \nChecking if port 80 (required by mesos-ui) is in use: PASS \nChecking if port 53 (required by mesos-dns) is in use: PASS \nChecking if port 15055 (required by dcos-history) is in use: PASS \nChecking if port 5050 (required by mesos-master) is in use: PASS \nChecking if port 2181 (required by zookeeper) is in use: PASS \nChecking if port 8080 (required by marathon) is in use: PASS \nChecking if port 3888 (required by zookeeper) is in use: PASS \nChecking if port 8181 (required by exhibitor) is in use: PASS \nChecking if port 8123 (required by mesos-dns) is in use: PASS \nChecking Docker is configured with a production storage driver: WARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\nPASS (overlay)\nCreating directories under /etc/mesosphere\nCreating role file for slave\nConfiguring DC/OS\nSetting and starting DC/OS\nJob for dcos-setup.service failed because the control process exited with error code. See \"systemctl status dcos-setup.service\" and \"journalctl -xe\" for details.\n172.XX.XX.XXX:22\n</code></pre>\n\n<p><strong>As suggested in Error Log we looked into \"systemctl status dcos-setup.service\" and \"journalctl -xe\" but not able to determine the actual cause</strong> </p>\n\n<pre><code>[root@macXX ~]# systemctl status dcos-setup.service\n\u00e2 dcos-setup.service\n   Loaded: not-found (Reason: No such file or directory)\n   Active: inactive (dead)\n\n[root@macXX ~]# journalctl -xe\nMay 27 09:40:01 mac58 kernel: SELinux: initialized (dev overlay, type overlay), uses xattr\nMay 27 09:40:01 mac58 kernel: device veth0db88ce entered promiscuous mode\nMay 27 09:40:01 mac58 kernel: IPv6: ADDRCONF(NETDEV_UP): veth0db88ce: link is not ready\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;warn&gt;  (veth3d6605b): failed to find device 58 'veth3d6605b' with udev\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;info&gt;  (veth3d6605b): new Veth device (carrier: OFF, driver: 'veth', ifindex: 58)\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;warn&gt;  (veth0db88ce): failed to find device 59 'veth0db88ce' with udev\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;info&gt;  (veth0db88ce): new Veth device (carrier: OFF, driver: 'veth', ifindex: 59)\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;info&gt;  (docker0): bridge port veth0db88ce was attached\nMay 27 09:40:01 mac58 NetworkManager[776]: &lt;info&gt;  (veth0db88ce): enslaved to docker0\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev tmpfs, type tmpfs), uses transition SIDs\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev mqueue, type mqueue), uses transition SIDs\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev proc, type proc), uses genfs_contexts\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev tmpfs, type tmpfs), uses transition SIDs\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev devpts, type devpts), uses transition SIDs\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev sysfs, type sysfs), uses genfs_contexts\nMay 27 09:40:02 mac58 kernel: SELinux: initialized (dev tmpfs, type tmpfs), uses transition SIDs\nMay 27 09:40:02 mac58 avahi-daemon[739]: Withdrawing workstation service for veth3d6605b.\nMay 27 09:40:02 mac58 NetworkManager[776]: &lt;warn&gt;  (veth3d6605b): failed to disable userspace IPv6LL address handling\nMay 27 09:40:02 mac58 NetworkManager[776]: &lt;info&gt;  (veth0db88ce): link connected\nMay 27 09:40:02 mac58 NetworkManager[776]: &lt;info&gt;  (docker0): link connected\nMay 27 09:40:02 mac58 kernel: IPv6: ADDRCONF(NETDEV_CHANGE): veth0db88ce: link becomes ready\nMay 27 09:40:02 mac58 kernel: docker0: port 1(veth0db88ce) entered forwarding state\nMay 27 09:40:02 mac58 kernel: docker0: port 1(veth0db88ce) entered forwarding state\nMay 27 09:40:03 mac58 avahi-daemon[739]: Registering new address record for fe80::4410:e6ff:fedd:be2a on veth0db88ce.*.\nMay 27 09:40:17 mac58 kernel: docker0: port 1(veth0db88ce) entered forwarding state\nMay 27 09:47:10 mac58 kernel: traps: python3[17232] general protection ip:7f2be234423 sp:7f2beceb0394 error:0 in libc-2.22.s\nMay 27 09:47:11 mac58 kernel: docker0: port 1(veth0db88ce) entered disabled state\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;info&gt;  (veth0db88ce): link disconnected\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;warn&gt;  (veth3d6605b): failed to find device 58 'veth3d6605b' with udev\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;info&gt;  (veth3d6605b): new Veth device (carrier: OFF, driver: 'veth', ifindex: 58)\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;info&gt;  (docker0): link disconnected (deferring action for 4 seconds)\nMay 27 09:47:11 mac58 abrt-server[17352]: Executable '/opt/mesosphere/packages/python--e3169ded66609d3cb4055a3f9f8f0b1113a557\nMay 27 09:47:11 mac58 abrt-server[17352]: 'post-create' on '/var/spool/abrt/ccpp-2016-05-27-09:47:10-17214' exited with 1\nMay 27 09:47:11 mac58 abrt-server[17352]: Deleting problem directory '/var/spool/abrt/ccpp-2016-05-27-09:47:10-17214'\nMay 27 09:47:11 mac58 avahi-daemon[739]: Withdrawing address record for fe80::4410:e6ff:fedd:be2a on veth0db88ce.\nMay 27 09:47:11 mac58 kernel: docker0: port 1(veth0db88ce) entered disabled state\nMay 27 09:47:11 mac58 avahi-daemon[739]: Withdrawing workstation service for veth3d6605b.\nMay 27 09:47:11 mac58 avahi-daemon[739]: Withdrawing workstation service for veth0db88ce.\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;warn&gt;  (veth3d6605b): failed to disable userspace IPv6LL address handling\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;info&gt;  (docker0): bridge port veth0db88ce was detached\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;info&gt;  (veth0db88ce): released from master docker0\nMay 27 09:47:11 mac58 NetworkManager[776]: &lt;warn&gt;  (veth0db88ce): failed to disable userspace IPv6LL address handling\nMay 27 09:47:11 mac58 kernel: device veth0db88ce left promiscuous mode\nMay 27 09:47:11 mac58 kernel: docker0: port 1(veth0db88ce) entered disabled state\nMay 27 09:47:11 mac58 docker[10803]: time=\"2016-05-27T09:47:11.828750505+05:30\" level=error msg=\"Handler for POST /v1.23/cont\nMay 27 09:47:16 mac58 NetworkManager[776]: &lt;info&gt;  (docker0): link disconnected (calling deferred action)\n</code></pre>\n\n<p><strong>Your Help is Highly Appreciated!!!...Thank you</strong></p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1464327381, "title": "Facing issues in DC/OS Installation in On-Premises", "last_activity_date": 1464327381, "answer_count": 0, "creation_date": 1464323188, "score": 2, "link": "https://stackoverflow.com/questions/37474848/facing-issues-in-dc-os-installation-in-on-premises", "owner": {"user_id": 5461912, "profile_image": "https://www.gravatar.com/avatar/ddba86bee17e98dd55b7d65be621eb95?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 639, "link": "https://stackoverflow.com/users/5461912/bhavesh", "accept_rate": 93, "display_name": "Bhavesh"}, "view_count": 773, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37474848}{"body": "<p>I tried this both on the chronos config and in my job definition:</p>\n\n<pre><code>    \"environmentVariables\": [\n        {\n            \"name\": \"DOCKER_API_VERSION\",\n            \"value\": \"$(docker version --format '{{.Server.Version}}')\"\n        }\n    ],\n</code></pre>\n\n<p>It always fails with:</p>\n\n<pre><code>docker: Error response from daemon: 404 page not found.\nSee 'docker run --help'.\n</code></pre>\n\n<p>The reason I'm trying to set that variable is because I'm running docker in docker and the client docker API sometimes has a different version than the server docker version and it has to be started with the <code>DOCKER_API_VERSION</code> env set in order to work.</p>\n\n<p>I'm suspecting it's because of the computed value being set instead of a string value.</p>\n\n<p>In the logs I can see it runs as supposed and I don't know why it crashes to be honest:</p>\n\n<p><code>docker run ... -e DOCKER_API_VERSION=$(docker version --format '{{.Server.Version}}') ...</code></p>\n", "is_answered": false, "tags": ["mesos", "dcos", "mesos-chronos"], "title": "Chronos setting environment variable leads to error", "last_activity_date": 1481802057, "answer_count": 0, "creation_date": 1481802057, "score": 0, "link": "https://stackoverflow.com/questions/41163298/chronos-setting-environment-variable-leads-to-error", "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "view_count": 77, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 41163298}{"is_answered": true, "tags": ["mesos", "dcos", "aurora"], "title": "Integrate Apache Aurora with dcos", "last_activity_date": 1479577142, "answer_count": 1, "creation_date": 1478597633, "score": 0, "link": "https://stackoverflow.com/questions/40483367/integrate-apache-aurora-with-dcos", "owner": {"user_id": 6634951, "profile_image": "https://i.stack.imgur.com/6q1pq.jpg?s=128&g=1", "user_type": "registered", "reputation": 59, "link": "https://stackoverflow.com/users/6634951/kr0t", "display_name": "Kr0t"}, "view_count": 271, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 40483367}{"body": "<p>From the DC/OS documentation I see that one limitation when using Kafka on DC/OS is that built-in Kafka security mechanisms are not supported.</p>\n\n<p>I've previously prototyped using the built-in options for authenticating producers/consumers on a standard Kafka setup so I would like to understand how security is achieved when running on DC/OS.</p>\n\n<p>How would you authenticate a microservice connecting to the Kafka broker when both are running within the DC/OS cluster?</p>\n", "is_answered": false, "tags": ["apache-kafka", "mesos", "dcos", "confluent-kafka"], "title": "How do you secure Kafka on DC/OS?", "last_activity_date": 1502099230, "answer_count": 0, "creation_date": 1502099230, "score": 0, "link": "https://stackoverflow.com/questions/45543976/how-do-you-secure-kafka-on-dc-os", "owner": {"user_id": 70795, "profile_image": "https://www.gravatar.com/avatar/fe85bc40e37968d4ea24785740f5da6a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 21608, "link": "https://stackoverflow.com/users/70795/mark", "accept_rate": 56, "display_name": "Mark"}, "view_count": 27, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45543976}{"is_answered": false, "tags": ["metrics", "marathon", "prometheus", "dcos"], "last_edit_date": 1502012029, "title": "Gather prometheus metrics on DCOS", "last_activity_date": 1502012029, "answer_count": 0, "creation_date": 1502004409, "score": 2, "link": "https://stackoverflow.com/questions/45529646/gather-prometheus-metrics-on-dcos", "owner": {"user_id": 3744640, "profile_image": "https://i.stack.imgur.com/f6iu9.jpg?s=128&g=1", "user_type": "registered", "reputation": 3019, "link": "https://stackoverflow.com/users/3744640/ipoteka", "accept_rate": 83, "display_name": "ipoteka"}, "view_count": 94, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45529646}{"is_answered": true, "tags": ["docker", "vagrant", "mesos", "mesosphere", "dcos"], "last_edit_date": 1458660874, "title": "Mesosphere local development", "last_activity_date": 1501805575, "answer_count": 2, "creation_date": 1455895394, "score": 4, "link": "https://stackoverflow.com/questions/35508789/mesosphere-local-development", "accepted_answer_id": 35527260, "owner": {"user_id": 421085, "profile_image": "https://www.gravatar.com/avatar/c3c78ec632ab3dd2dd15716a1013a221?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 874, "link": "https://stackoverflow.com/users/421085/tim-specht", "accept_rate": 78, "display_name": "Tim Specht"}, "view_count": 790, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 35508789}{"body": "<p>from Mesos web UI under frameworks there is a list of running and terminated frameworks which I want to monitor periodically (save the list to a database ,etc.) \nI am wondering if there is a log file for such list , API , etc. ?</p>\n", "is_answered": true, "title": "how to monitor mesos frameworks", "tags": ["monitoring", "mesos", "mesosphere"], "last_activity_date": 1434276636, "accepted_answer_id": 30828146, "creation_date": 1434243295, "answers": [{"body": "<p>All events that happen in the Mesos cluster are captured in the Mesos master log. It means by parsing and analysing the log, you can reconstruct cluster state at any point of time.</p>\n\n<p>Mesos WebUI is based on a <code>/state.json</code> Master endpoint. In Mesos 0.23 a new endpoint <code>/state-summary</code> is introduced. It provides less information, but also needs less time to return. I think one of those will give you what you need.</p>\n", "answer_id": 30828146, "last_activity_date": 1434276636, "creation_date": 1434276636, "score": 4, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": true, "question_id": 30825016}], "score": 1, "link": "https://stackoverflow.com/questions/30825016/how-to-monitor-mesos-frameworks", "answer_count": 1, "owner": {"user_id": 1742406, "profile_image": "https://www.gravatar.com/avatar/bd0503195be6f7b141c0a1180ccd7236?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 520, "link": "https://stackoverflow.com/users/1742406/cruncherbigdata", "accept_rate": 60, "display_name": "CruncherBigData"}, "view_count": 403, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30825016}{"body": "<p>I loved DCOS demos on Azure. No I wonder - having a private OpenStack based clud how to install Mesos with that UI manually? Is it possible or it is a part of DCOS they do not provide as OpenSource product? </p>\n", "is_answered": true, "title": "does Mesos provide its service like cluster management UI as OSS project?", "tags": ["mesos", "mesosphere"], "last_activity_date": 1431846972, "accepted_answer_id": 30280084, "creation_date": 1431769380, "answers": [{"body": "<p>You can use Mesos and Marathon WebUI, by default they are available on ports 5050 and 8080 respectively.</p>\n", "answer_id": 30275411, "last_activity_date": 1431777732, "creation_date": 1431777732, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 30274105}, {"body": "<p>The DCOS Dashboard is pretty cool :-). Currently it is just available via the DCOS beta on AWS and Azure. There will be on prem packages later on as well, potentially even a community edition. Feel free to contact/follow <a href=\"https://mesosphere.com/contact/\" rel=\"nofollow\">Mesosphere</a> for updates.</p>\n\n<p>Until then you can use the standard Mesos, Marathon, and Chronos UIs as Alex pointed out.</p>\n", "answer_id": 30280084, "last_activity_date": 1431846972, "creation_date": 1431805818, "score": 3, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "last_edit_date": 1431846972, "question_id": 30274105}], "score": 1, "link": "https://stackoverflow.com/questions/30274105/does-mesos-provide-its-service-like-cluster-management-ui-as-oss-project", "answer_count": 2, "owner": {"user_id": 1973207, "profile_image": "https://www.gravatar.com/avatar/557d7fa74d7ec23c6726f1c16986b032?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 653, "link": "https://stackoverflow.com/users/1973207/duckqueen", "accept_rate": 43, "display_name": "DuckQueen"}, "view_count": 119, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30274105}{"body": "<p>We're in the process of migrating a microservices application to dcos. The current version of the application use nginx as a reverse proxy. In moving to dcos, we'd like to replace nginx with marathon-lb. This is working well, with one exception. Nginx returns the expected <code>Connection:keep-alive</code> http header, but marathon-lb does not.</p>\n\n<p>We have not changed the default configuration of marathon-lb in any way, and as far as I can tell haproxy has the expected defaults. Specifically, the <code>http-server-close</code> option. Here is a snippet from the config.</p>\n\n<pre><code>defaults\n  load-server-state-from-file global\n  log               global\n  retries                   3\n  backlog               10000\n  maxconn               10000\n  timeout connect          3s\n  timeout client          30s\n  timeout server          30s\n  timeout tunnel        3600s\n  timeout http-keep-alive  1s\n  timeout http-request    15s\n  timeout queue           30s\n  timeout tarpit          60s\n  option            dontlognull\n  option            http-server-close\n  option            redispatch\n</code></pre>\n\n<p>My services have labels with the following format:</p>\n\n<pre><code>  \"labels\": {\n    \"HAPROXY_0_PATH\": \"-i /alerts\",\n    \"HAPROXY_0_HTTP_BACKEND_PROXYPASS_PATH\": \"/alerts\",\n    \"HAPROXY_0_VHOST\": \"foo.bar.com\",\n    \"HAPROXY_GROUP\": \"external\"\n  }\n</code></pre>\n\n<p>What am I doing wrong?</p>\n", "is_answered": false, "tags": ["marathon", "dcos"], "title": "Marathon-lb not returning keep-alive headers", "last_activity_date": 1504574293, "answer_count": 1, "creation_date": 1495810491, "score": 0, "link": "https://stackoverflow.com/questions/44204603/marathon-lb-not-returning-keep-alive-headers", "answers": [{"body": "<p>Try use <code>option http-keep-alive</code> and <code>option prefer-last-server</code>.</p>\n\n<p>See : <a href=\"https://stackoverflow.com/questions/21550337/haproxy-netty-way-to-prevent-exceptions-on-connection-reset/40005338#40005338\">Haproxy + netty: Way to prevent exceptions on connection reset?</a></p>\n\n<p>You can override default configuration by <code>HAPROXY_GLOBAL_DEFAULT_OPTIONS</code>.</p>\n\n<p>See : <a href=\"https://github.com/mesosphere/marathon-lb#haproxy-global-default-options\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/marathon-lb#haproxy-global-default-options</a></p>\n", "answer_id": 46045745, "last_activity_date": 1504574293, "creation_date": 1504574293, "score": 0, "owner": {"user_id": 977843, "profile_image": "https://graph.facebook.com/100000843443858/picture?type=large", "user_type": "registered", "reputation": 209, "link": "https://stackoverflow.com/users/977843/mingyoo-jung", "display_name": "MinGyoo Jung"}, "is_accepted": false, "question_id": 44204603}], "owner": {"user_id": 13181, "profile_image": "https://www.gravatar.com/avatar/880df7a18a8b445d917a25b3e0254043?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1215, "link": "https://stackoverflow.com/users/13181/herbrandson", "accept_rate": 68, "display_name": "herbrandson"}, "view_count": 41, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44204603}{"body": "<p>I plan to make a proposal for a proof of concept(POC) project employing mesos/sphere targeting the  OS IBM AIX. At least for the mesos/sphere slaves.</p>\n\n<p><em>Short remark: with the term mesos/sphere i subsume both projects, mesos and mesossphere, to be the \"framework\" projects of that POC.</em></p>\n\n<p>I have read about the isolation feature and that it uses cgroups and hence a LXC environment. Referencing <a href=\"http://en.wikipedia.org/wiki/LXC\" rel=\"nofollow\">http://en.wikipedia.org/wiki/LXC</a>, IBM AIX does use an alternative approach and does NOT implement cgroups.</p>\n\n<p>So i can not expect that all features of mesos/sphere will work on IBM AIX. But on the other side i can not pre-evalute from docs and research  under which if-s which features might work or are to be configured respectively. </p>\n\n<p>So, targeting IBM AIX as the OS prospectively running mesos/sphere, is/can  mesos/sphere ...</p>\n\n<ul>\n<li>designed to work ?</li>\n<li>be expected respective to which features not to work ?</li>\n<li>be pin pointed to configuration documentation/help that is not expected to work ?</li>\n<li>expected to be supported by the community?</li>\n<li>under anyone's productive usage?</li>\n</ul>\n", "is_answered": true, "title": "Is a LXC environment a mandatory requirement for operating mesos/sphere", "tags": ["mesos", "mesosphere"], "last_activity_date": 1431664452, "accepted_answer_id": 30251578, "creation_date": 1431633833, "answers": [{"body": "<p>thanks for trying mesos under AIX!\nThere is no official support for AIX,so unfortunately also no documentation what might be potential problems.</p>\n\n<p>Did you try building mesos (make &amp;&amp; make check) on AIX? That should give a good indicator for potential problems.</p>\n\n<p>To your LXC questions: Mesos supports a number of different ways to isolate processes: See for example <a href=\"http://mesos.apache.org/documentation/latest/mesos-containerizer/\" rel=\"nofollow\" title=\"mesos-containerizer\">mesos-containerizer</a>,<a href=\"http://mesos.apache.org/documentation/latest/docker-containerizer/\" rel=\"nofollow\" title=\"docker containerizer\">docker containerizer</a> or <a href=\"http://mesos.apache.org/documentation/latest/external-containerizer/\" rel=\"nofollow\" title=\"external containerizer\">external containerizer</a>.\nSo even without cgroups Mesos will still work, it will just not be able to isolate tasks with cgroups.\nFor example I can at least test Mesos fine on my Mac Book (which does not offer cgroups).</p>\n\n<p>Hope this helped,\nJoerg</p>\n", "answer_id": 30251578, "last_activity_date": 1431664452, "creation_date": 1431664452, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "question_id": 30246325}], "score": -1, "link": "https://stackoverflow.com/questions/30246325/is-a-lxc-environment-a-mandatory-requirement-for-operating-mesos-sphere", "answer_count": 1, "owner": {"user_id": 3274229, "profile_image": "https://i.stack.imgur.com/1yN15.png?s=128&g=1", "user_type": "registered", "reputation": 18, "link": "https://stackoverflow.com/users/3274229/joerg-m", "display_name": "Joerg M."}, "view_count": 138, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30246325}{"is_answered": false, "tags": ["mesos", "marathon", "dcos"], "title": "DCOS Kafka Provisioning Failure", "last_activity_date": 1499435305, "answer_count": 0, "creation_date": 1499435305, "score": 0, "link": "https://stackoverflow.com/questions/44972470/dcos-kafka-provisioning-failure", "owner": {"user_id": 4175046, "profile_image": "https://www.gravatar.com/avatar/aab1e032261adbd0503af525909be1a4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 74, "link": "https://stackoverflow.com/users/4175046/william-hammond", "display_name": "William Hammond"}, "view_count": 10, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44972470}{"body": "<p>I know that 'servicePort' is used by marathon-lb to identify an app. Is there any other user of this setting besides marathon-lb?<br>\nIf the answer is no, why is it mandatory (omitting it well generate one for me)? I have many marathon apps which are not managed by marathon-lb, and they all take up service ports by default.</p>\n", "is_answered": true, "title": "Marathon Service Ports", "tags": ["marathon", "dcos"], "last_activity_date": 1493393954, "accepted_answer_id": 43684029, "creation_date": 1493229660, "answers": [{"body": "<p>From the documentation: \"\"servicePort\" is a helper port intended for doing service discovery using a well-known port per service. The assigned servicePort value is <strong>not used/interpreted by Marathon itself</strong> but supposed to be used by the load balancer infrastructure.\"</p>\n\n<p>So service ports seem to have no other use other than for marathon-lb.\nWhen you don't specify a servicePort, its as if you put in \"servicePort\": 0.\nSee closed issue <a href=\"https://github.com/mesosphere/marathon/issues/2521\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p><a href=\"https://github.com/mesosphere/marathon/issues/1112\" rel=\"nofollow noreferrer\">Here's</a> a discussion about the re-architected networking API.</p>\n\n<p>If you look at the <a href=\"https://jira.mesosphere.com/browse/MARATHON-4091\" rel=\"nofollow noreferrer\">Jira ticket</a>, you will see that the new API model lets you define services without servicePorts at all.</p>\n", "answer_id": 43684029, "last_activity_date": 1493393954, "creation_date": 1493393954, "score": 0, "owner": {"user_id": 1477327, "profile_image": "https://www.gravatar.com/avatar/e2dd5b9a22ef022f81517d1e67048f50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 49, "link": "https://stackoverflow.com/users/1477327/user1477327", "accept_rate": 42, "display_name": "user1477327"}, "is_accepted": true, "question_id": 43641415}], "score": 0, "link": "https://stackoverflow.com/questions/43641415/marathon-service-ports", "answer_count": 1, "owner": {"user_id": 310298, "profile_image": "https://i.stack.imgur.com/PkUnq.png?s=128&g=1", "user_type": "registered", "reputation": 1128, "link": "https://stackoverflow.com/users/310298/itaysk", "accept_rate": 63, "display_name": "itaysk"}, "view_count": 85, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43641415}{"is_answered": true, "tags": ["ignite"], "title": "Apache Ignite on DCOS marathon not working", "last_activity_date": 1496674553, "answer_count": 1, "creation_date": 1495935577, "score": 0, "link": "https://stackoverflow.com/questions/44223060/apache-ignite-on-dcos-marathon-not-working", "owner": {"user_id": 8076080, "profile_image": "https://www.gravatar.com/avatar/63eac9cd08534559e1fe860bfd9f8187?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/8076080/user8076080", "display_name": "user8076080"}, "view_count": 29, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44223060}{"body": "<p>I want to run a Mesos/Marathon cluster with a mix of public and private apps.  It seems like it should be possible to leverage roles for this, but I'm not having success.</p>\n\n<p>As a proof-of-concept, I have a Mesos cluster with <code>public</code> and <code>private</code> roles:</p>\n\n<pre><code># curl --silent localhost:5050/roles | jq '.' | grep name\n\"name\": \"*\",\n\"name\": \"public\",\n\"name\": \"private\",\n</code></pre>\n\n<p>The problem arises with Marathon and my Marathon apps.  I'm unable to set <code>default_accepted_resource_roles</code> to a value that's different from <code>mesos_role</code>.  For example, if I set <code>--mesos_role=public</code> and <code>--default_accepted_resource_roles=public</code>, I'm able to run apps, but only if they include <code>\"acceptedResourceRoles\": [ \"public\" ]</code> in the application description.  Conversely, I can set everything to <code>private</code> and run private apps.  (Although, ironically, if I set everything to <code>*</code> I'm unable to run my apps.  I don't understand that at all.)</p>\n\n<p>Ideally, I'd like to run this way:</p>\n\n<pre><code>mesos_role=*\ndefault_accepted_resource_roles=private\n</code></pre>\n\n<p>I would expect this to give Marathon access to all my roles but start apps with the <code>private</code> role unless they specifically request the <code>public</code> role.  Unfortunately, this results in this error:</p>\n\n<pre><code>Exception in thread \"main\" java.lang.IllegalArgumentException: requirement failed: --default_accepted_resource_roles contains roles for which we will not receive offers: private\n</code></pre>\n\n<p>and Marathon refuses to start.</p>\n\n<p>Is it possible to run Marathon with <code>--mesos_role=*</code> and <code>--default_accepted_resource_roles=private</code>?  If not, I don't understand why the roles exist.  But I'd rather run as much as possible in a single cluster rather than spinning up separate clusters for public and private apps.</p>\n", "is_answered": false, "tags": ["roles", "mesos", "mesosphere", "marathon"], "title": "Mesos / Marathon Roles and Applications", "last_activity_date": 1455683425, "answer_count": 1, "creation_date": 1452294472, "score": 0, "link": "https://stackoverflow.com/questions/34687573/mesos-marathon-roles-and-applications", "answers": [{"body": "<p>@aayore - as a workaround we deploy multiple marathon. main-marathon and couple of others marathons which run on the main marathon as app, typically one per role. </p>\n\n<p>Say you have 2 roles \"kafka\" and \"hdfs\" \ne.g. main marathon runs with default role (which is *)\nmarathon 2 runs on main-marathon with --mesos_role kafka (command line option)\nmarathon 3 also runs on main-marathon with --mesos_role hdfs </p>\n\n<p>for an app to use resources allocated to kafka role, you need to launch the job in kafka-marathon instead of the main marathon. </p>\n", "answer_id": 35447979, "last_activity_date": 1455683425, "creation_date": 1455683425, "score": 0, "owner": {"user_id": 3404593, "profile_image": "https://www.gravatar.com/avatar/1b49efc73576ee24798b0a1e90b3327b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/3404593/varvind", "display_name": "varvind"}, "is_accepted": false, "question_id": 34687573}], "owner": {"user_id": 4759483, "profile_image": "https://lh3.googleusercontent.com/-p_6bXlszFqU/AAAAAAAAAAI/AAAAAAAAJ7o/fDvdrwVSDzc/photo.jpg?sz=128", "user_type": "registered", "reputation": 76, "link": "https://stackoverflow.com/users/4759483/aayore", "accept_rate": 50, "display_name": "aayore"}, "view_count": 827, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 34687573}{"body": "<p>I want to install a plugin on my mesos cluster  : </p>\n\n<pre><code>http://jenkinsci.github.io/mesos-plugin/\n</code></pre>\n\n<p>The mesos-jenkins plugin require access to a mesos executor (<code>/usr/lib/libmesos.so</code>). </p>\n\n<p>I am trying to mount it on my host as a volume so I can use it in jenkins by mounting it on jenkins. </p>\n\n<p>See example <a href=\"https://carlossg.github.io/presentations/assets/mesos-plugin1.png\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p><img src=\"https://cloud.githubusercontent.com/assets/1866564/25753326/4464d8b0-31e5-11e7-93a5-df14ba7fd1f9.png\" alt=\"image\"></p>\n\n<p>It does not work, I have the following error: </p>\n\n<pre><code>ERROR: for panteras  Cannot start service panteras: oci runtime error: container_linux.go:247: starting container process caused \"process_linux.go:359: container init caused \\\"rootfs_linux.go:54: mounting \\\\\\\"/usr/lib/libmesos.so\\\\\\\" to rootfs \\\\\\\"/var/lib/docker/devicemapper/mnt/2cd649dab477b8b743a967642847a0579a733a87163a37aad94154200ebb183d/rootfs\\\\\\\" at \\\\\\\"/var/lib/docker/devicemapper/mnt/2cd649dab477b8b743a967642847a0579a733a87163a37aad94154200ebb183d/rootfs/usr/lib/libmesos-1.2.0.so\\\\\\\" caused \\\\\\\"not a directory\\\\\\\"\\\"\"\n : Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type\n</code></pre>\n\n<p>Do you know how I could get through?</p>\n", "is_answered": false, "tags": ["jenkins", "jenkins-plugins", "mesos", "mesosphere"], "title": "How do I install a mesos plugin", "last_activity_date": 1494000305, "answer_count": 0, "creation_date": 1494000305, "score": 0, "link": "https://stackoverflow.com/questions/43809369/how-do-i-install-a-mesos-plugin", "owner": {"user_id": 2127277, "profile_image": "https://www.gravatar.com/avatar/e4222dda177339b2ade17d1a36cbac90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1232, "link": "https://stackoverflow.com/users/2127277/bigdong", "accept_rate": 59, "display_name": "BigDong"}, "view_count": 56, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43809369}{"body": "<p>In order to do some POCs over Mesos, Kubernetes, DC/OS and more, I would like to build a small cluster of 3-5 nodes.\nI started to build a cluster via AWS, but it becomes expansive fastly.\nSo, I was wondering if there is a good way to build such a cluster without spending too much money on it.</p>\n", "is_answered": true, "tags": ["kubernetes", "cluster-computing", "mesos", "dcos"], "title": "Build a cheap cluster", "last_activity_date": 1501517369, "answer_count": 3, "creation_date": 1501160287, "score": -1, "link": "https://stackoverflow.com/questions/45351515/build-a-cheap-cluster", "answers": [{"body": "<p>That depends on whether you want to use the Cloud or not. Alternatives that come to mind could be:</p>\n\n<ul>\n<li>Using Virtual Machines in your own Computer using solutions like Vagrant (as @sfgroups mentioned) or handcrafted VMs directly.</li>\n<li>Building a Cluster using Raspberry Pi computers.</li>\n<li>Look for cheaper cloud providers</li>\n</ul>\n\n<p>In all of these cases, you could follow guides to build your cluster from scratch like <a href=\"https://github.com/kelseyhightower/kubernetes-the-hard-way\" rel=\"nofollow noreferrer\">https://github.com/kelseyhightower/kubernetes-the-hard-way</a> (note that this is meant for GCE but most of it is applicable to other systems)</p>\n", "answer_id": 45354195, "last_activity_date": 1501315676, "creation_date": 1501166865, "score": 1, "owner": {"user_id": 6512567, "profile_image": "https://lh6.googleusercontent.com/-dtmiMlwPbG0/AAAAAAAAAAI/AAAAAAAAACA/tb1ShyDyNG0/photo.jpg?sz=128", "user_type": "registered", "reputation": 952, "link": "https://stackoverflow.com/users/6512567/javier-salmeron", "display_name": "Javier Salmeron"}, "is_accepted": false, "last_edit_date": 1501315676, "question_id": 45351515}, {"body": "<p>There is a blog where the author gives a good explanation and open source code for a cheap 3 nodes HA production cluster. It's in Digitalocean but could be replicated in any similar host provider. It's too long to post everything here so check  this <a href=\"https://5pi.de/2016/11/20/15-producation-grade-kubernetes-cluster/\" rel=\"nofollow noreferrer\">link</a></p>\n", "answer_id": 45363943, "last_activity_date": 1501348877, "creation_date": 1501209298, "score": 1, "owner": {"user_id": 8218029, "profile_image": "https://www.gravatar.com/avatar/617ddedc59454bb294c331d2b2f8f61d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 201, "link": "https://stackoverflow.com/users/8218029/oe18", "display_name": "oe18"}, "is_accepted": false, "last_edit_date": 1501348877, "question_id": 45351515}, {"body": "<p>You can use <a href=\"https://github.com/dcos/dcos-vagrant#dcos-vagrant\" rel=\"nofollow noreferrer\">DC/OS Vagrant</a> to spin up a local DC/OS cluster. You do need a pretty burly machine for it to work since you're basically running a full DC/OS cluster, and if you plan on testing out any data services or big workloads there, you'll need an even bigger machine. (check on the requirements)</p>\n", "answer_id": 45420654, "last_activity_date": 1501517369, "creation_date": 1501517369, "score": 1, "owner": {"user_id": 6702425, "profile_image": "https://i.stack.imgur.com/CXJ2H.jpg?s=128&g=1", "user_type": "registered", "reputation": 86, "link": "https://stackoverflow.com/users/6702425/judith-malnick", "display_name": "Judith Malnick"}, "is_accepted": false, "question_id": 45351515}], "owner": {"user_id": 3812109, "profile_image": "https://www.gravatar.com/avatar/9f2759305f5a00c1aff9e286aeff2a0d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 45, "link": "https://stackoverflow.com/users/3812109/philippe-paulos", "accept_rate": 80, "display_name": "Philippe Paulos"}, "view_count": 132, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45351515}{"is_answered": true, "tags": ["mesosphere", "marathon"], "title": "Does Mesosphere Marathon run native Linux applications?", "last_activity_date": 1425281620, "answer_count": 2, "creation_date": 1425032517, "score": 0, "link": "https://stackoverflow.com/questions/28762716/does-mesosphere-marathon-run-native-linux-applications", "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 235, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 28762716}{"body": "<p>I am developing a Mesos framework, it is working perfectly fine, my only issue is that I am unable to read task stdout or stderr from inside the the Scheduler class.</p>\n\n<p>I am providing a code sample below, I would like to read the stdout and stderr of a finished task, preferably in the statusUpdate function but anywhere would be useful. How can I reach that info? I tried getting executorInfo or executorId from TaskInfo or TaskStatus objects without any luck.</p>\n\n<p>If someone can provide a code sample it would be greatly appreciated. I know that I can read the stderr and stdout from the master UI at url:master:5050 and also from the file system on the slaves, but I REALLY need to read it inside the framework, in the Java class as it will influence future scheduling decisions made in the resourceOffers function. As a last resort I was thinking of making a web call to the master by constructing the required URL, but that would be way too inconvenient. The mesos API must be providing a way to do it from inside the Scheduler class.</p>\n\n<pre><code>public class TfScheduler implements Scheduler {\n\n    public TfScheduler(String volumes, String container) {\n\n    }\n\n    @Override\n    public void registered(SchedulerDriver driver,\n            Protos.FrameworkID frameworkId,\n            Protos.MasterInfo masterInfo) {\n        System.out.println(\"Registered! ID = \" + frameworkId.getValue());\n    }\n\n    @Override\n    public void reregistered(SchedulerDriver driver, Protos.MasterInfo masterInfo) {\n    }\n\n    @Override\n    public void disconnected(SchedulerDriver driver) {\n    }\n\n    @Override\n    public void resourceOffers(SchedulerDriver driver, List&lt;Protos.Offer&gt; offers) {\n\n    }\n\n    @Override\n    public void offerRescinded(SchedulerDriver driver, Protos.OfferID offerId\n    ) {\n    }\n\n    @Override\n    public void statusUpdate(SchedulerDriver driver, Protos.TaskStatus status\n    ) {\n        System.out.println(\"Status update: task \" + status.getTaskId().getValue()\n                + \" is in state \" + status.getState().getValueDescriptor().getName());\n\n        if (status.getState() == Protos.TaskState.TASK_FINISHED) {\n\n            /* !!!!! */\n            //Can I read the task stdout here?\n            /* !!!!! */\n        }\n\n    }\n\n    @Override\n    public void frameworkMessage(SchedulerDriver driver,\n            Protos.ExecutorID executorId,\n            Protos.SlaveID slaveId,\n            byte[] data\n    ) {\n    }\n\n    @Override\n    public void slaveLost(SchedulerDriver driver, Protos.SlaveID slaveId\n    ) {\n    }\n\n    @Override\n    public void executorLost(SchedulerDriver driver,\n            Protos.ExecutorID executorId,\n            Protos.SlaveID slaveId,\n            int status\n    ) {\n    }\n\n    public void error(SchedulerDriver driver, String message) {\n        System.out.println(\"Error: \" + message);\n    }\n\n}\n</code></pre>\n\n<p>Thanks!</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1495125370, "title": "How to read mesos task stdout/stderr from Mesos framework Scheduler class?", "last_activity_date": 1495154476, "answer_count": 1, "creation_date": 1495113743, "score": 0, "link": "https://stackoverflow.com/questions/44048989/how-to-read-mesos-task-stdout-stderr-from-mesos-framework-scheduler-class", "answers": [{"body": "<p>It is not possible to access stdout/stderr of a Mesos task in the way you describe. The Mesos agent by default will write to two files named <code>stdout</code> and <code>stderr</code> within the agent sandbox path of a given task. This content is <em>only</em> be accessible by calling the agent API.</p>\n\n<p>The Mesos master UI works by making an Ajax call to the agent with a URL such as: <code>http://agent:5051/files/browse?path=/var/run/mesos/agents/0/slaves/ab49f68a-b73f-4200-a523-2886353d6450-S0/frameworks/ab49f68a-b73f-4200-a523-2886353d6450-0000/executors/53c98219-f794-4fb6-815d-8b800fc30d9a/runs/0ae1795a-e80f-4f37-ab21-8f78c1286dae/tasks/2981d2db-a218-4c86-9bb2-4371f9be151c/stdout</code>. That path can be inferred with properties that <strong>are</strong> available to your scheduler.</p>\n\n<p>The new Mesos <a href=\"http://mesos.apache.org/documentation/latest/operator-http-api/\" rel=\"nofollow noreferrer\">HTTP Operator</a> (not yet considered stable) can accomplish this via the <code>READ_FILE</code> call. I have some sample code <a href=\"https://github.com/vektorlab/mesos-cli/blob/master/pailer/pailer.go\" rel=\"nofollow noreferrer\">here</a> from a tool I developed (apologies it is not written in Java) which reads from the operator API.</p>\n\n<p>Depending on what kind of scheduling decisions you are trying to make, it might be better to propagate a message back to your scheduler loop via some external channel.</p>\n", "answer_id": 44059751, "last_activity_date": 1495154476, "creation_date": 1495154476, "score": 0, "owner": {"user_id": 1899273, "profile_image": "https://i.stack.imgur.com/HGvon.png?s=128&g=1", "user_type": "registered", "reputation": 58, "link": "https://stackoverflow.com/users/1899273/kevin-schoon", "display_name": "Kevin Schoon"}, "is_accepted": false, "question_id": 44048989}], "owner": {"user_id": 8031351, "profile_image": "https://www.gravatar.com/avatar/356e8ff612e56c8e72db23feb092982d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/8031351/thanos", "display_name": "Thanos"}, "view_count": 65, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44048989}{"body": "<p>While installing mesosphere mesos i have faced several issues Ubuntu Linux \ndistribution. I have used </p>\n\n<pre><code>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv E56151BF\nDISTRO=$(lsb_release -is | tr '[:upper:]' '[:lower:]')\nCODENAME=$(lsb_release -cs)\necho \"deb http://repos.mesosphere.io/${DISTRO} ${CODENAME} main\" | sudo tee /etc/apt/sources.list.d/mesosphere.list\n</code></pre>\n\n<p>to install mesosphere with </p>\n\n<pre><code>sudo apt-get install mesosphere\n</code></pre>\n\n<p>Now as expected mesossphere should download all dependencies like mesos,marathon and zookeeper with it. After i have installed them successfully i wanted to run the mesos as a service with</p>\n\n<pre><code>sudo service mesos-master start\n</code></pre>\n\n<p>but system says its unrecognized service. As a solution i had to download mesos separately and start them manually after building the same source code. \nwhat i am looking for is if there exist any other simple solution to install apache mesos.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1439609582, "title": "issues with installing mrsosphere mesos in ubuntu", "last_activity_date": 1439711374, "answer_count": 1, "creation_date": 1439408397, "score": -1, "link": "https://stackoverflow.com/questions/31973986/issues-with-installing-mrsosphere-mesos-in-ubuntu", "answers": [{"body": "<p>you need use</p>\n\n<pre><code>sudo apt-get -y install mesos\n</code></pre>\n\n<p>instead of </p>\n\n<pre><code>sudo apt-get install mesosphere\n</code></pre>\n\n<p>to install mesos.</p>\n", "answer_id": 32032963, "last_activity_date": 1439711374, "creation_date": 1439711374, "score": 0, "owner": {"user_id": 891145, "profile_image": "https://www.gravatar.com/avatar/221cfd6267f65ba83aaa3d5ee6271291?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 548, "link": "https://stackoverflow.com/users/891145/haosdent", "accept_rate": 80, "display_name": "haosdent"}, "is_accepted": false, "question_id": 31973986}], "owner": {"user_id": 5216670, "profile_image": "https://graph.facebook.com/1143994522296284/picture?type=large", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/5216670/pankaj-saha", "accept_rate": 0, "display_name": "Pankaj Saha"}, "view_count": 312, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31973986}{"body": "<p>I have setup a mesos cluster with two master and one slave. All are in same vlan able to communicate each other on all ports. Getting below errors continuously and if I try to switch down masters are also not working. Can someone give me the suggestions to fix this.</p>\n\n<p>I0812 12:55:11.873253  3414 slave.cpp:3732] master@10.0.0.112:5050 exited</p>\n\n<p>I0812 12:55:34.531620  3417 slave.cpp:4591] Current disk usage 24.39%. Max allowed age: 4.592973848477315days</p>\n\n<p>I0812 12:55:54.078184  3416 slave.cpp:3732] master@10.0.0.24:5050 exited</p>\n\n<p>W0812 12:55:54.078352  3416 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected</p>\n\n<p>I0812 12:56:03.940837  3412 detector.cpp:152] Detected a new leader: (id='18')</p>\n\n<p>I0812 12:56:03.941045  3412 group.cpp:706] Trying to get '/mesos/json.info_0000000018' in ZooKeeper</p>\n\n<p>I0812 12:56:03.942214  3412 zookeeper.cpp:259] A new leading master (UPID=master@10.0.0.24:5050) is detected</p>\n\n<p>I0812 12:56:03.942342  3412 slave.cpp:895] New master detected at master@10.0.0.24:5050</p>\n\n<p>I0812 12:56:03.942459  3412 slave.cpp:916] No credentials provided. Attempting to register without authentication</p>\n\n<p>I0812 12:56:03.942560  3412 slave.cpp:927] Detecting new master</p>\n\n<p>I0812 12:56:03.942441  3414 status_update_manager.cpp:174] Pausing sending \nstatus updates</p>\n\n<p>I0812 12:56:34.537866  3417 slave.cpp:4591] Current disk usage 24.39%. Max allowed age: 4.592966947819190days</p>\n\n<p>I0812 12:57:04.078191  3419 slave.cpp:3732] master@10.0.0.24:5050 exited</p>\n\n<p>W0812 12:57:04.078352  3419 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected</p>\n\n<p>I0812 12:57:11.938907  3412 detector.cpp:152] Detected a new leader: (id='19')</p>\n\n<p>I0812 12:57:11.939124  3412 group.cpp:706] Trying to get '/mesos/json.info_0000000019' in ZooKeeper</p>\n\n<p>I0812 12:57:11.940470  3412 zookeeper.cpp:259] A new leading master (UPID=master@10.0.0.24:5050) is detected</p>\n\n<p>I0812 12:57:11.940587  3412 slave.cpp:895] New master detected at master@10.0.0.24:5050</p>\n\n<p>I0812 12:57:11.940732  3412 slave.cpp:916] No credentials provided. Attempting to register without authentication</p>\n\n<p>I0812 12:57:11.940836  3412 slave.cpp:927] Detecting new master</p>\n\n<p>I0812 12:57:11.940711  3414 status_update_manager.cpp:174] Pausing sending status updates</p>\n\n<p>I0812 12:57:34.540552  3417 slave.cpp:4591] Current disk usage 24.39%. Max allowed age: 4.592966947819190days</p>\n", "is_answered": false, "tags": ["cluster-computing", "master", "mesosphere", "slave"], "last_edit_date": 1471007057, "title": "Mesos Slave : Pausing sending status updates", "last_activity_date": 1472644387, "answer_count": 1, "creation_date": 1471006712, "score": 0, "link": "https://stackoverflow.com/questions/38918587/mesos-slave-pausing-sending-status-updates", "answers": [{"body": "<p>I had the same issue, i killed/stopped the docker service and my mesos-slave came up immediately ;)</p>\n\n<p>try this</p>\n", "answer_id": 39248946, "last_activity_date": 1472644387, "creation_date": 1472644387, "score": 0, "owner": {"user_id": 5281537, "profile_image": "https://www.gravatar.com/avatar/924ff489a5b8c6325e05e84eccfca1fc?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/5281537/tauseef", "display_name": "Tauseef"}, "is_accepted": false, "question_id": 38918587}], "owner": {"user_id": 4637649, "profile_image": "https://lh4.googleusercontent.com/-6juOco5TYsM/AAAAAAAAAAI/AAAAAAAAABA/FYe_Yncky94/photo.jpg?sz=128", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/4637649/sankar-mittapally", "display_name": "sankar mittapally"}, "view_count": 117, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38918587}{"body": "<p>I have a setup on Mesosphere that uses Marathon to deploy Docker applications.\nNow each of the Docker applications is a Play application that relies heavily on Akka remoting.</p>\n\n<p>What Marathon does with Mesos DNS is that it assigns an internal DNS address to each <code>cluster</code> of tasks. </p>\n\n<p>Now, for a two of the docker containers, here's my situation:\nTask ID: <code>task-A</code>\nTask DNS: <code>task-A.mesosphere.mesos</code>\nAkka remoting configuration:</p>\n\n<pre><code>app {\n  host = ${?APP_HOST}\n  akka {\n    port = 11112\n  }\n}\nakka {\n  jvm-exit-on-fatal-error = false\n  log-dead-letters = 0\n  actor {\n    provider = \"akka.remote.RemoteActorRefProvider\"\n  }\n  remote {\n    enabled-transports = [\"akka.remote.netty.tcp\"]\n    netty.tcp {\n      hostname = ${?app.host}\n      port = ${?app.akka.port}\n    }\n  }\n}\n</code></pre>\n\n<p>Now the docker container of the application is launched with ports <code>9000</code> &amp; <code>11112</code> open on both sides:\n<code>docker run -p 11112:11112 -h task-A.marathon.mesos ...</code></p>\n\n<p>Similarly, for Task-B:\nTask ID: <code>task-A</code>\nTask DNS: <code>task-A.mesosphere.mesos</code>\nAkka remoting configuration:</p>\n\n<pre><code>app {\n  host = ${?APP_HOST}\n  akka {\n    port = 11120\n  }\n}\nakka {\n  jvm-exit-on-fatal-error = false\n  log-dead-letters = 0\n  actor {\n    provider = \"akka.remote.RemoteActorRefProvider\"\n  }\n  remote {\n    enabled-transports = [\"akka.remote.netty.tcp\"]\n    netty.tcp {\n      hostname = ${?app.host}\n      port = ${?app.akka.port}\n    }\n  }\n}\n</code></pre>\n\n<p>Now the docker container of the application is launched with port <code>11120</code> open on both sides:\n<code>docker run -p 11120:11120 -h task-B.marathon.mesos ...</code></p>\n\n<p>Now the problem is that I cannot get the two tasks to communicate with each other via Akka.\nFor example, if there's an ask from Task-B, I get exceptions:\nplay.api.Application$$anon$1: Execution exception[[AskTimeoutException: Ask timed out on [ActorSelection[Anchor(akka.tcp://application@task-A.marathon.mesos:11112/), Path(/user/CoreMaster)]] after [15000 ms]]]</p>\n\n<p>What could be wrong here?</p>\n", "is_answered": false, "tags": ["playframework", "docker", "akka", "mesosphere", "marathon"], "title": "Akka and Docker on Marathon", "last_activity_date": 1441713718, "answer_count": 0, "creation_date": 1441713718, "score": 1, "link": "https://stackoverflow.com/questions/32457321/akka-and-docker-on-marathon", "owner": {"user_id": 1360368, "profile_image": "https://www.gravatar.com/avatar/7997d33ca6f47d0e48080d6f58a72443?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1926, "link": "https://stackoverflow.com/users/1360368/ashesh", "accept_rate": 64, "display_name": "Ashesh"}, "view_count": 440, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32457321}{"body": "<p>I am currently configuring and adapting some apps to run on the DC/OS. We chose to install the HA-ThreeMaster AWS template.</p>\n\n<p>Recently I was asked to downscale the cluster during development. While removing slave nodes is trivial, I couldn't find any information on how to bring down Master nodes.</p>\n\n<p>I know that they should always have an odd number so I was thinking to remove the two non-leader ec2 instances. Can this be done without destroying the cluster? </p>\n", "is_answered": true, "title": "Is it possible to kill two masters out of three in DC/OS - Mesos?", "tags": ["amazon-web-services", "amazon-ec2", "mesos", "mesosphere", "dcos"], "last_activity_date": 1501680141, "accepted_answer_id": 45462110, "creation_date": 1500043402, "answers": [{"body": "<p>I don't think this will work. A master count of three will allow one master to fail, and the remaining two can still find a quorum. If you only have one remaining master, the quorum can't be reached. </p>\n", "answer_id": 45107726, "last_activity_date": 1500049720, "creation_date": 1500049720, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 45105776}, {"body": "<p>It depends on your setup. \nFirst check your quorum size:\ncat /etc/mesos-master/quorum</p>\n\n<p>Thank check this\n<a href=\"http://mesos.apache.org/documentation/latest/operational-guide/\" rel=\"nofollow noreferrer\">http://mesos.apache.org/documentation/latest/operational-guide/</a></p>\n\n<blockquote>\n  <p>Decreasing the quorum size</p>\n</blockquote>\n\n<pre><code>The following steps indicate how to decrement the quorum size, using 5 -&gt; 3 masters as an example (quorum size 3 -&gt; 2):\n\nInitially, 5 masters are running with --quorum=3\nRemove 2 masters from the cluster, ensure they will not be restarted (see NOTE section above). Now 3 masters are running with --quorum=3\nRestart the 3 masters with --quorum=2\nTo decrease the quorum by N, repeat this process to decrement the quorum size N times.\n</code></pre>\n", "answer_id": 45462110, "last_activity_date": 1501680141, "creation_date": 1501680141, "score": 1, "owner": {"user_id": 8405777, "profile_image": "https://www.gravatar.com/avatar/dd5d071f37563dd26a905bd5bb75ba62?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/8405777/dino-lokmic", "display_name": "Dino Lokmic"}, "is_accepted": true, "question_id": 45105776}], "score": 0, "link": "https://stackoverflow.com/questions/45105776/is-it-possible-to-kill-two-masters-out-of-three-in-dc-os-mesos", "answer_count": 2, "owner": {"user_id": 1759948, "profile_image": "https://i.stack.imgur.com/po0MK.jpg?s=128&g=1", "user_type": "registered", "reputation": 668, "link": "https://stackoverflow.com/users/1759948/r%c4%83zvan", "accept_rate": 85, "display_name": "R\u0103zvan"}, "view_count": 30, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45105776}{"body": "<p>I have DCOS running in a network without Internet access. I cannot copy files from an internet connected machine to the isolated network. There is a local universe running in DCOS.</p>\n\n<p>Is it possible to upload a package to the local universe without having to rebuild the universe completely (with all existing packages) and if so, how do I do this?</p>\n", "is_answered": true, "title": "How to upload a package to private universe (without rebuilding it)?", "last_edit_date": 1493291256, "tags": ["dcos"], "view_count": 38, "accepted_answer_id": 43651892, "last_activity_date": 1493291256, "answers": [{"body": "<p>Unfortunately this is not possible yet. You'll have to rebuild the private Universe. </p>\n", "answer_id": 43651892, "last_activity_date": 1493279882, "creation_date": 1493279882, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 43645565}], "score": 2, "link": "https://stackoverflow.com/questions/43645565/how-to-upload-a-package-to-private-universe-without-rebuilding-it", "answer_count": 1, "owner": {"user_id": 272023, "profile_image": "https://www.gravatar.com/avatar/25dbc4a263833e5a5b36f5394cfc1d01?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1708, "link": "https://stackoverflow.com/users/272023/john", "accept_rate": 66, "display_name": "John"}, "creation_date": 1493245797, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43645565}{"body": "<p>In planning out a our <a href=\"http://lambda-architecture.net/\" rel=\"nofollow noreferrer\">Lambda architecture</a>, for both real-time and batch processing, I see we will need several m3.xlarge instances (see <a href=\"https://blog.codecentric.de/en/2016/04/smack-stack-hands/\" rel=\"nofollow noreferrer\">CloudFormation SMACK stack template</a>) using DC/OS.</p>\n\n<p>As not to incur too much cost for a POC, is there an approach that would allow us to create local Docker containers then deploy them to our VPC, launching only for testing?</p>\n", "is_answered": false, "tags": ["amazon-web-services", "vpc", "dcos", "lambda-architecture"], "title": "Can we create local Docker IoT containers for a SMACK-like environment with DC/OS and push them to our AWS VPC - if so, how?", "last_activity_date": 1485274615, "answer_count": 0, "creation_date": 1485274615, "score": 1, "link": "https://stackoverflow.com/questions/41833088/can-we-create-local-docker-iot-containers-for-a-smack-like-environment-with-dc-o", "owner": {"user_id": 172359, "profile_image": "https://www.gravatar.com/avatar/5e175feb0a9092abd02950f4973d376a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6610, "link": "https://stackoverflow.com/users/172359/elhaix", "accept_rate": 93, "display_name": "ElHaix"}, "view_count": 23, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41833088}{"body": "<p>I have a use case where I have 20-30 frameworks runnings on mesos cluster that has over 200 nodes. A lot of the times mesos is offering resources to frameworks that do not want any offers at all. While doing that, it is offering little resources to frameworks that actually need them.</p>\n\n<p>I know there's a function requestResources that a framework can call to ask for resources. However, I couldn't find a function that a framework can use to tell mesos to stop sending it any offers. Is there a way of doing that? Because my frameworks keep getting offers every 100 milliseconds, which is way fast!</p>\n", "is_answered": true, "title": "How to stop mesos from offering resources to a framework?", "tags": ["distributed", "distributed-computing", "mesos", "mesosphere"], "last_activity_date": 1431012710, "accepted_answer_id": 30105607, "creation_date": 1430927406, "answers": [{"body": "<p>When you declineOffer, you can set an optional Filter with refuse_seconds longer than the default 5s. This will mean that after you decline an offer from a node, that Mesos will not offer these resources back to your framework for refuse_seconds.</p>\n\n<p>Alternatively, if your framework temporarily doesn't want any offers from any nodes, it can call driver.stop(true), and the scheduler will unregister from Mesos but its tasks will keep running for FrameworkInfo.failover_timeout. Once the framework has work to do, it can start/run the driver again to start getting offers again.</p>\n\n<p>(FYI, requestResources doesn't actually do anything yet.)</p>\n", "answer_id": 30105607, "last_activity_date": 1431012710, "creation_date": 1431012710, "score": 3, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 30081665}], "score": 1, "link": "https://stackoverflow.com/questions/30081665/how-to-stop-mesos-from-offering-resources-to-a-framework", "answer_count": 1, "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 749, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30081665}{"body": "<p>I am new in Mesos and Marathon services. I have setup 3 master and 3 slave server as per <a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04\" rel=\"nofollow\">www.digitalocean.com</a>. Configured as it is in master servers as well as slaves. Finally I done setup of Mesos, Marathon, Zookeeper and Chronos. Mesos is able to listing with 5050, Marathon is 8080 and Chronos 4400. After few hours my Marthon instances are showing like Error 503 </p>\n\n<pre><code>HTTP ERROR: 503\nProblem accessing /. Reason:\n    Could not determine the current leader\nPowered by Jetty:// 9.3.z-SNAPSHOT.\n</code></pre>\n\n<p>But mesos is working fine. Every time i am facing this problem and if i restart the marathon service and zookeeper service its working fine.</p>\n\n<ul>\n<li><p>Marathon</p>\n\n<pre><code>Jun 15 06:19:20 master3 marathon[1054]: INFO Waiting for consistent leadership state. Are we leader?: false, leader: Some(192.168.4.78:8080 (mesosphere.marathon.api.LeaderProxyFilter$:qtp522188921-35)\nJun 15 06:19:20 master3 marathon[1054]: INFO Waiting for consistent leadership state. Are we leader?: false, leader: Some(192.168.4.78:8080 (mesosphere.marathon.api.LeaderProxyFilter$:qtp522188921-35) \n</code></pre></li>\n<li><p>Zookeeper</p>\n\n<pre><code>2016-06-15 03:41:13,797 - INFO [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /192.168.4.78:38339 \n2016-06-15 03:41:13,798 - WARN [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@354] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running\n</code></pre></li>\n</ul>\n", "is_answered": false, "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_edit_date": 1465997724, "title": "Mesos-marthon cluster issue Could not determine the current leader", "last_activity_date": 1465997724, "answer_count": 0, "creation_date": 1465886373, "score": 0, "link": "https://stackoverflow.com/questions/37804675/mesos-marthon-cluster-issue-could-not-determine-the-current-leader", "owner": {"user_id": 6441706, "profile_image": "https://www.gravatar.com/avatar/d0633e9ba7ca402eb74e1c4a705d76f7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6441706/anilkumar", "display_name": "Anilkumar"}, "view_count": 434, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37804675}{"is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "Mesosphere inter-service communication using Marathon", "last_activity_date": 1455831440, "answer_count": 1, "creation_date": 1455829861, "score": 0, "link": "https://stackoverflow.com/questions/35492484/mesosphere-inter-service-communication-using-marathon", "accepted_answer_id": 35492902, "owner": {"user_id": 421085, "profile_image": "https://www.gravatar.com/avatar/c3c78ec632ab3dd2dd15716a1013a221?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 874, "link": "https://stackoverflow.com/users/421085/tim-specht", "accept_rate": 78, "display_name": "Tim Specht"}, "view_count": 162, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 35492484}{"closed_date": 1478798710, "is_answered": true, "closed_reason": "off-topic", "title": "What's the best distributed file system for Apache Mesos beside HDFS?", "last_edit_date": 1446205210, "tags": ["filesystems", "distributed-computing", "mesos", "mesosphere"], "body": "<p>I found lot of documentation for using HDFS on MESOS, but I'm looking for a non JVM file system. My goal is to decrease resources consumption.</p>\n", "view_count": 1490, "answers": [{"body": "<p>You could give <a href=\"https://github.com/quobyte/mesos-framework\" rel=\"nofollow\">Quobyte</a> a try; it's written in C++ and soon also <a href=\"https://docs.mesosphere.com/reference/servicestatus/\" rel=\"nofollow\">available</a> via the DCOS.</p>\n\n<p>As a general intro I suggest to check out the MesosCon Europe 2015 presentation <a href=\"http://events.linuxfoundation.org/sites/events/files/slides/Mesoscon%202015%20-%20Mesos%20Filesystems.pdf\" rel=\"nofollow\">Apache Mesos Storage Now and Future</a>.</p>\n", "answer_id": 33434333, "last_activity_date": 1446202629, "creation_date": 1446202629, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 33426063}, {"body": "<p>Have a look at <a href=\"https://github.com/vivint-smarthome/ceph-on-mesos\" rel=\"nofollow noreferrer\">https://github.com/vivint-smarthome/ceph-on-mesos</a>; This framework targets Mesos directly and can be used with or without DCOS.</p>\n", "answer_id": 40533424, "last_activity_date": 1478798041, "creation_date": 1478798041, "score": 1, "owner": {"user_id": 183863, "profile_image": "https://www.gravatar.com/avatar/63f259ca39670e260cd50dd71013663c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2091, "link": "https://stackoverflow.com/users/183863/tim-harper", "accept_rate": 67, "display_name": "Tim Harper"}, "is_accepted": true, "question_id": 33426063}], "last_activity_date": 1478798041, "score": 0, "link": "https://stackoverflow.com/questions/33426063/whats-the-best-distributed-file-system-for-apache-mesos-beside-hdfs", "answer_count": 2, "owner": {"user_id": 592319, "profile_image": "https://www.gravatar.com/avatar/c7696e7930a885001be95fb59a3eb8cd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/592319/christian-kakesa", "display_name": "Christian Kakesa"}, "accepted_answer_id": 40533424, "creation_date": 1446159399, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 33426063}{"body": "<p>I have install DC/OS (3master and 7slave server - all Centos7)</p>\n\n<p>I saw problem - when one of slave server shut down - mesos/marathon start killed instance of application after 5 minutes. </p>\n\n<p>For example - I run in mesos/marathon 8 instance simple web application. When I shut down or deactivate network interface of one slave server marathon show that some instancje are killed. <strong>From this moment mesos/marathon wait 5 minutes and start killed instance to another online slave server.</strong></p>\n\n<p>My question is - how can I change this time? 5 minutes is to long. I read documentation of DC/OS but I can't find variable responsible for this.</p>\n\n<p>I will be very thankful for your help. </p>\n", "is_answered": true, "tags": ["mesos", "marathon", "dcos"], "title": "DC/OS (mesos/marathon) how set time to start killed instance of aplication", "last_activity_date": 1469601933, "answer_count": 1, "creation_date": 1469564980, "score": 0, "link": "https://stackoverflow.com/questions/38599312/dc-os-mesos-marathon-how-set-time-to-start-killed-instance-of-aplication", "answers": [{"body": "<p>You can have a at the <a href=\"https://mesosphere.github.io/marathon/docs/command-line-flags.html\" rel=\"nofollow\">Marathon command-line flags</a>. Based on your description, I guess the default for either <code>task_launch_timeout</code> or <code>scale_apps_interval</code> could be responsible for this.</p>\n\n<p>I'm unsure though if this can be configured on the fly, or during installation in DC/OS. I saw that there's a quite recent enhancement request to <a href=\"https://dcosjira.atlassian.net/browse/DCOS-253\" rel=\"nofollow\">Make Marathon flags passable via environment variables</a>.</p>\n", "answer_id": 38605594, "last_activity_date": 1469601933, "creation_date": 1469601933, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 38599312}], "owner": {"user_id": 6464173, "profile_image": "https://lh4.googleusercontent.com/-ysDEIwtaQ4w/AAAAAAAAAAI/AAAAAAAAA90/TDjOH69Mf8k/photo.jpg?sz=128", "user_type": "registered", "reputation": 29, "link": "https://stackoverflow.com/users/6464173/arek", "accept_rate": 0, "display_name": "Arek"}, "view_count": 44, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 38599312}{"body": "<p>I want to run docker container through marathon on mesos cluster so I added docker in mesos-slave containerizers configuration with below command.</p>\n\n<pre><code>echo 'docker,mesos' &gt; /etc/mesos-slave/containerizers\n</code></pre>\n\n<p>After change mesos-slave its not starting. I am getting error </p>\n\n<blockquote>\n  <p>Insufficient version of Docker! Please upgrade to >= 1.0.0' in slave logs while restarting: Here below is complete log</p>\n</blockquote>\n\n<pre><code>May 19 15:24:09 flo-doc-nfr-b2b-27 mesos-slave[18055]: W0519 15:24:04.174897 18055 logging.cpp:81] RAW: Received signal SIGTERM from process 19232 of user 0; exiting\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: I0519 15:24:10.360828 19275 logging.cpp:172] INFO level logging started!\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: I0519 15:24:10.361471 19275 main.cpp:156] Build: 2015-05-05 06:16:58 by root\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: I0519 15:24:10.361518 19275 main.cpp:158] Version: 0.22.1\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: I0519 15:24:10.361543 19275 main.cpp:161] Git tag: 0.22.1\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: I0519 15:24:10.361565 19275 main.cpp:165] Git SHA: d6309f92a7f9af3ab61a878403e3d9c284ea87e0\nMay 19 15:24:10 flo-doc-nfr-b2b-27 mesos-slave[19275]: Failed to create a containerizer: Could not create DockerContainerizer: Insufficient version of Docker! Please upgrade to &gt;= 1.0.0\n</code></pre>\n\n<p>Below is docker version details on mesos-slave:</p>\n\n<p>Client:</p>\n\n<ul>\n<li>Version:      1.11.1</li>\n<li>API version:  1.23</li>\n<li>Go version:   go1.5.4</li>\n<li>Git commit:   5604cbe</li>\n<li>Built:        Tue Apr 26 23:20:46 2016</li>\n<li>OS/Arch:      linux/amd64</li>\n</ul>\n\n<p>Server:</p>\n\n<ul>\n<li>Version:      1.11.1</li>\n<li>API version:  1.23</li>\n<li>Go version:   go1.5.4</li>\n<li>Git commit:   5604cbe</li>\n<li>Built:        Tue Apr 26 23:20:46 2016</li>\n<li>OS/Arch:      linux/amd64</li>\n</ul>\n\n<p>Mesos version on slave:\n0.22.1</p>\n\n<p>If I remove containerizers configuration from slave then its working fine. Mesos, Marathon, Docker are running as service on nodes.</p>\n\n<p>I even tried downgrading mesos to 0.21.1 &amp; docker to 1.9.0 but getting same error.</p>\n\n<p>Can someone please help me on this?</p>\n\n<p>Thanks!!\nSumit</p>\n", "is_answered": true, "title": "Unable to start mesos-slave after adding containerizer setting on slave", "last_edit_date": 1463680392, "tags": ["docker", "mesos", "mesosphere", "marathon"], "view_count": 363, "accepted_answer_id": 37331077, "last_activity_date": 1463745515, "answers": [{"body": "<p>I think you need to use one of 0.24.1, 0.23.1, 0.22.2 or 0.21.2 due to <a href=\"https://issues.apache.org/jira/browse/MESOS-2986\" rel=\"nofollow\">MESOS-2986</a>.</p>\n\n<p>Try to build mesos from source rather than using debs. <a href=\"http://mesos.apache.org/gettingstarted/\" rel=\"nofollow\">Here</a> is pretty straightforward tutorial how to do it.</p>\n\n<pre><code># Install the packages.\nsudo apt-get install -qq tar wget openjdk-7-jdk build-essential python-dev libcurl4-nss-dev libsasl2-dev libsasl2-modules maven libapr1-dev libsvn-dev\n# Download the source\nwget http://www.apache.org/dist/mesos/0.28.1/mesos-0.28.1.tar.gz\ntar -zxf mesos-0.28.1.tar.gz\n# Build Mesos\ncd mesos-0.28.1\nmkdir build\ncd build\n../configure\nmake -j 8\n</code></pre>\n\n<hr>\n\n<p><strong>EDIT:</strong></p>\n\n<p>Marathon require <code>libmesos</code> to be placed in the system so after building Mesos from source ensure proper lib will be used. Below extract from <a href=\"https://mesosphere.github.io/marathon/docs/\" rel=\"nofollow\">documentation</a></p>\n\n<blockquote>\n  <p><code>MESOS_NATIVE_JAVA_LIBRARY: bin/start</code> searches the common\n  installation paths, <code>/usr/lib</code> and <code>/usr/local/lib</code>, for the Mesos native\n  library. If the library lives elsewhere in your configuration, set the\n  environment variable <code>MESOS_NATIVE_JAVA_LIBRARY</code> to its full path.</p>\n  \n  <p>For example:</p>\n  \n  <p><code>$ MESOS_NATIVE_JAVA_LIBRARY=/Users/bob/libmesos.dylib ./bin/start --master local --zk zk://localhost:2181/marathon</code></p>\n</blockquote>\n", "answer_id": 37331077, "last_activity_date": 1463745515, "creation_date": 1463681509, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "last_edit_date": 1463745515, "question_id": 37325458}], "score": 0, "link": "https://stackoverflow.com/questions/37325458/unable-to-start-mesos-slave-after-adding-containerizer-setting-on-slave", "answer_count": 1, "owner": {"user_id": 4551655, "profile_image": "https://i.stack.imgur.com/5Vcos.jpg?s=128&g=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/4551655/sumit-nagariya", "display_name": "Sumit Nagariya"}, "creation_date": 1463666179, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37325458}{"body": "<p>We have DC/OS running on AWS with a fixed number of master nodes and agent nodes as part of a POC. However, we'd like to have the cluster (agent nodes) autoscale according to load. So far, we've been unable to find any information about scaling on DC/OS docs. I've also had no luck so far in my web-searches. </p>\n\n<p>If someone's got this working already, please let us know how you did it.\nThanks for your help!</p>\n", "is_answered": true, "tags": ["amazon-web-services", "dcos"], "title": "Autoscaling DC/OS agents on AWS", "last_activity_date": 1489399174, "answer_count": 2, "creation_date": 1475679059, "score": 2, "link": "https://stackoverflow.com/questions/39877268/autoscaling-dc-os-agents-on-aws", "answers": [{"body": "<p>Autoscaling the number of service instances by cpu, memory, or network load is possible: <a href=\"https://docs.mesosphere.com/1.8/usage/tutorials/autoscaling/\" rel=\"nofollow\">https://docs.mesosphere.com/1.8/usage/tutorials/autoscaling/</a></p>\n\n<p>Autoscaling the number of DC/OS nodes by adding/removing nodes, however, is outside of the scope of DC/OS and specific to the IaaS it is deployed on. You can imagine that this wouldn't work on bare metal for obvious reasons. It's hypothetically possible, of course, but I haven't seen any existing automation for it.</p>\n\n<p>The DC/OS AWS templates use easily scaled node groups, but it's not automatic. You might try looking for IaaS specific autoscalers that aren't DC/OS specific.</p>\n", "answer_id": 39877556, "last_activity_date": 1475681642, "creation_date": 1475679748, "score": 3, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "last_edit_date": 1475681642, "question_id": 39877268}, {"body": "<p>If you have an autoscaling group for your \"private agent\" nodes and you want to scale the number of nodes in times of heavy load, pick a CloudWatch metric that suits your needs (e.g. traffic on ELB) and scale by an autoscaling scaling policy:\n<a href=\"http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html\" rel=\"nofollow noreferrer\">http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html</a>\nThen you can use one of the two ways described in <a href=\"https://docs.mesosphere.com/1.8/usage/tutorials/autoscaling/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.8/usage/tutorials/autoscaling/</a> to scale your apps within DC/OS (on scheduler level). </p>\n", "answer_id": 42729332, "last_activity_date": 1489399174, "creation_date": 1489187979, "score": 2, "owner": {"user_id": 6375384, "profile_image": "https://i.stack.imgur.com/X09tt.jpg?s=128&g=1", "user_type": "registered", "reputation": 109, "link": "https://stackoverflow.com/users/6375384/andr%c3%a9-veelken", "display_name": "Andr\u00e9 Veelken"}, "is_accepted": false, "last_edit_date": 1489399174, "question_id": 39877268}], "owner": {"user_id": 2669052, "profile_image": "https://www.gravatar.com/avatar/d01d2c722e975c27682f2da0c10ae6db?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 149, "link": "https://stackoverflow.com/users/2669052/urover", "accept_rate": 33, "display_name": "urover"}, "view_count": 218, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39877268}{"is_answered": false, "tags": ["apache-spark", "hdfs", "dcos"], "title": "Running Spark on DCOS with an external HDFS", "last_activity_date": 1487958758, "answer_count": 1, "creation_date": 1487922073, "score": 2, "link": "https://stackoverflow.com/questions/42433176/running-spark-on-dcos-with-an-external-hdfs", "owner": {"user_id": 4240857, "profile_image": "https://www.gravatar.com/avatar/934177aae4354e0e13dd12de67bd79c4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 71, "link": "https://stackoverflow.com/users/4240857/swamoch", "accept_rate": 0, "display_name": "swamoch"}, "view_count": 97, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42433176}{"body": "<p>I have been working through the Mesosphere DCOS Tutorial and can't seem to get <a href=\"https://docs.mesosphere.com/tutorials/deploy-load-balanced/\" rel=\"nofollow\">Part II</a> to work. To the best of my knowledge, I have followed their instructions exactly and Part I went just fine.</p>\n\n<p>The problem seems to be in the router, so I posted my router code to Github at <a href=\"https://github.com/tnbeatty/dcos-tutorial-2\" rel=\"nofollow\">tnbeatty/dcos-tutorial-2</a>. I built this container image and pushed it to Docker Hub, as the tutorial suggests.</p>\n\n<p>The container JSON object in nginx-router.json contains the following:</p>\n\n<pre><code>    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"mesosphere/simple-docker-router\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n          {\n              \"containerPort\": 8080,\n              \"hostPort\": 80,\n              \"protocol\": \"tcp\"\n          }\n      ]\n    }\n</code></pre>\n\n<p>When I change the image to \"mesosphere/simple-docker-router,\" my load-balanced app works and scales just fine. When I try to use my image ('tnbeatty/simple-docker-router'), the page does not load.</p>\n\n<p>I am at a loss at this point because the app seems to deploy just fine on Mesosphere DCOS - no discernible errors or warnings to be found. Any thoughts or pointers would be greatly appreciated.</p>\n", "is_answered": false, "tags": ["nginx", "load-balancing", "mesosphere"], "title": "DCOS simple load balancing tutorial Part 2 erroring", "last_activity_date": 1453081806, "answer_count": 1, "creation_date": 1452456061, "score": 1, "link": "https://stackoverflow.com/questions/34710170/dcos-simple-load-balancing-tutorial-part-2-erroring", "answers": [{"body": "<p>I thknk what your nginx-router is missing:</p>\n\n<pre><code>\"acceptedResourceRoles\": [\"slave_public\"]\n</code></pre>\n\n<p>Which will make it so that your container will launch on the \"public slaves\" and therefore be available when you go to the \"Public Load Balancer\" address on your DCOS cluster.</p>\n", "answer_id": 34846098, "last_activity_date": 1453081806, "creation_date": 1453081806, "score": 0, "owner": {"user_id": 2803594, "profile_image": "https://www.gravatar.com/avatar/b63e00c0b20b57650d77a1b6beb43ead?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/2803594/firebird347", "display_name": "Firebird347"}, "is_accepted": false, "question_id": 34710170}], "owner": {"user_id": 845108, "profile_image": "https://www.gravatar.com/avatar/970db0df54964c08a8df2916f8482b17?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 120, "link": "https://stackoverflow.com/users/845108/tnbeatty", "accept_rate": 50, "display_name": "tnbeatty"}, "view_count": 129, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34710170}{"body": "<p>From the <a href=\"http://mesos.apache.org/documentation/latest/maintenance/\" rel=\"nofollow\">documentation</a>, it seems that when a node goes into mesos node goes into maintenance mode, it sends inverse offers to all of the frameworks. My interpretation of that is that frameworks, such as Marathon, should receive those inverse offers and work to migrate tasks off of the node scheduled for maintence.</p>\n\n<p>I schedule maintenance for 60 seconds from now using the API:</p>\n\n<pre><code>curl -X POST leader.mesos:5050/maintenance/schedule \\\n  --data '{\"windows\": [{\"machine_ids\":[{\"hostname\": \"host43.local\"}], \"unavailability\": {\"start\": {\"nanoseconds\": '$(($(date +%s) + 60))'000000000}, \"duration\": {\"nanoseconds\": 3600000000000}}}]}'\n</code></pre>\n\n<p>Then, I query the maintenance status and can confirm that it is draining:</p>\n\n<pre><code>$ curl leader.mesos:5050/maintenance/status | jq .\n{\n  \"draining_machines\": [\n    {\n      \"id\": {\n        \"hostname\": \"host43.local\"\n      }\n    }\n  ]\n}\n</code></pre>\n\n<p>Finally, once the window approaches, I down it:</p>\n\n<pre><code>curl -X POST leader.mesos:5050/machine/down --data '[{\"hostname\": \"host43.local\"}]'\n</code></pre>\n\n<p>I confirm that it took effect:</p>\n\n<pre><code>$ curl leader.mesos:5050/maintenance/status | jq .\n{\n  \"down_machines\": [\n    {\n      \"hostname\": \"hsot43.local\"\n    }\n  ]\n}\n</code></pre>\n\n<p>Then, I check marathon (via the UI), and see that there are still tasks running on <code>host43.local</code>.</p>\n\n<p>I see this error message in the marathon logs, and I wonder if it is related:</p>\n\n<pre><code>May 12 11:46:02 host43.local start[126170]: [2016-05-12 11:46:02,581] ERROR not currently active (Actor[akka://marathon/user/taskTracker#-1732573467]) (akka.actor.OneForOneStrategy:marathon-akka.actor.default-dispatcher-17)\nMay 12 11:46:02 host43.local start[126170]: java.lang.IllegalStateException: not currently active (Actor[akka://marathon/user/taskTracker#-1732573467])\nMay 12 11:46:02 host43.local start[126170]: at mesosphere.marathon.core.leadership.impl.WhenLeaderActor$$anonfun$1.applyOrElse(WhenLeaderActor.scala:38) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.actor.Actor$class.aroundReceive(Actor.scala:465) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at mesosphere.marathon.core.leadership.impl.WhenLeaderActor.aroundReceive(WhenLeaderActor.scala:20) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.actor.ActorCell.invoke(ActorCell.scala:487) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.dispatch.Mailbox.run(Mailbox.scala:221) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at akka.dispatch.Mailbox.exec(Mailbox.scala:231) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ~[marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [marathon-assembly-1.1.1.jar:1.1.1]\nMay 12 11:46:02 host43.local start[126170]: [2016-05-12 11:46:02,581] INFO Killing 1 instances from 1 (mesosphere.marathon.upgrade.TaskKillActor:marathon-akka.actor.default-dispatcher-17)\n</code></pre>\n\n<p>If I manually kill the tasks with marathon, they don't appear to get allocated on the node undergoing maintenance. It seems like the behavior should be that nodes are automatically migrated off, and I don't know what I'm doing wrong, or if I've encountered a bug, or if I am misinterpreting the documentation and the expected behavior.</p>\n\n<p>Running Marathon 1.1.1 and Mesos 0.28</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "title": "Marathon tasks not migrating off mesos node goes into draining mode", "last_activity_date": 1490653711, "answer_count": 1, "creation_date": 1463075363, "score": 0, "link": "https://stackoverflow.com/questions/37194123/marathon-tasks-not-migrating-off-mesos-node-goes-into-draining-mode", "answers": [{"body": "<p>Received an answer from the DC/OS slack chat room and posting it here for the benefit of others. Marathon does not yet support Mesos maintenance primitives.</p>\n\n<p>The following JIRA ticket tracks the feature:</p>\n\n<p><a href=\"https://jira.mesosphere.com/browse/MARATHON-3216\" rel=\"nofollow noreferrer\">https://jira.mesosphere.com/browse/MARATHON-3216</a></p>\n", "answer_id": 37194176, "last_activity_date": 1490653711, "creation_date": 1463075549, "score": 1, "owner": {"user_id": 183863, "profile_image": "https://www.gravatar.com/avatar/63f259ca39670e260cd50dd71013663c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2091, "link": "https://stackoverflow.com/users/183863/tim-harper", "accept_rate": 67, "display_name": "Tim Harper"}, "is_accepted": false, "last_edit_date": 1490653711, "question_id": 37194123}], "owner": {"user_id": 183863, "profile_image": "https://www.gravatar.com/avatar/63f259ca39670e260cd50dd71013663c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2091, "link": "https://stackoverflow.com/users/183863/tim-harper", "accept_rate": 67, "display_name": "Tim Harper"}, "view_count": 676, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 37194123}{"body": "<p>I see two options:</p>\n\n<ol>\n<li><p>Use the the HDFS Mesos repository which is currently deprecated and is suggested not to be used for production workloads. </p></li>\n<li><p>Use the dc/os HDFS which is fully supported by Mesosphere.</p></li>\n</ol>\n\n<p>I wonder if there is a way to use the Mesosphere/community supported HDFS without DC/OS. </p>\n", "is_answered": true, "title": "How to run HDFS on Mesos in production environment?", "last_edit_date": 1495658265, "tags": ["mesos", "mesosphere"], "view_count": 51, "accepted_answer_id": 44225537, "last_activity_date": 1495962317, "answers": [{"body": "<p>Running Mesosphere supported HDFS without DC/OS is not easily possible, due to the Service Package approach. I would suggest deploy your own HDFS from Cloudera stack. The Datanode should run on Mesos slaves, the Namenode master should run on Master server, follow <a href=\"https://github.com/mesos/hadoop\" rel=\"nofollow noreferrer\">https://github.com/mesos/hadoop</a>. Job Tracker should be running on Master node, Mesos should be able to start the task with HDFS underlying.</p>\n", "answer_id": 44225537, "last_activity_date": 1495962317, "creation_date": 1495962317, "score": 1, "owner": {"user_id": 2555634, "profile_image": "https://i.stack.imgur.com/i5eug.jpg?s=128&g=1", "user_type": "registered", "reputation": 89, "link": "https://stackoverflow.com/users/2555634/subodh-pachghare", "display_name": "Subodh Pachghare"}, "is_accepted": true, "question_id": 44137117}], "score": 1, "link": "https://stackoverflow.com/questions/44137117/how-to-run-hdfs-on-mesos-in-production-environment", "answer_count": 1, "owner": {"user_id": 1240201, "profile_image": "https://www.gravatar.com/avatar/596b5622315bc3a1292856819e529e80?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 157, "link": "https://stackoverflow.com/users/1240201/saiteja", "accept_rate": 83, "display_name": "saiteja"}, "creation_date": 1495548473, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44137117}{"is_answered": false, "tags": ["apache-spark", "dcos"], "title": "Unable to install apache spark on DCOS", "last_activity_date": 1501571603, "answer_count": 1, "creation_date": 1501228667, "score": 1, "link": "https://stackoverflow.com/questions/45367966/unable-to-install-apache-spark-on-dcos", "owner": {"user_id": 8380303, "profile_image": "https://www.gravatar.com/avatar/7e6757ebc6e64762fb966808e0d0517d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/8380303/t-k", "display_name": "T.K"}, "view_count": 47, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45367966}{"body": "<p>I have a mesos cluster running. I want to register new agent nodes to mesos cluster via HTTP APIs.  Please let me know the url path and post values to send across to the master nodes endpoint.</p>\n\n<p>thanks</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "title": "Mesos agent registration via http api", "last_activity_date": 1487057259, "answer_count": 0, "creation_date": 1487057259, "score": 0, "link": "https://stackoverflow.com/questions/42220198/mesos-agent-registration-via-http-api", "owner": {"user_id": 186418, "profile_image": "https://www.gravatar.com/avatar/5a418915642e4ea8d9550c3e1c02cb34?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 508, "link": "https://stackoverflow.com/users/186418/santhosh-s", "accept_rate": 55, "display_name": "Santhosh S"}, "view_count": 29, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42220198}{"body": "<p>I have a bunch of marathon docker tasks that are run on our test deployment machines.</p>\n\n<p>There is a Jenkins CI job, that triggers the deployment a whole bunch of docker containers that are run on marathon-mesos cluster. (3 mesos-slaves, 1 master and 1 marathon.)</p>\n\n<p>There is another downstream jenkins job (a automated test suite) that is triggered after above job. Presently, we wait for sufficient time, so that deployment gets completed then only we proceed with this automation testsuite. I want to change this behavior. I know marathon exposes rest APIs using which I can determine if I am good to go - after all the containers are deployed and all health checks are passing - for running the automation test suite. </p>\n\n<p>Question is: Is there any library already out there for marathon, that I can reuse to accomplish above task ? I do not want to reinvent the wheel.</p>\n", "is_answered": true, "tags": ["mesos", "marathon", "mesosphere"], "title": "any library to check marathon deployment status", "last_activity_date": 1481609629, "answer_count": 2, "creation_date": 1481527063, "score": 1, "link": "https://stackoverflow.com/questions/41095848/any-library-to-check-marathon-deployment-status", "answers": [{"body": "<p>I've successfully been using the two following libs:</p>\n\n<ul>\n<li>Go: <a href=\"https://github.com/gambol99/go-marathon\" rel=\"nofollow noreferrer\">gambol99/go-marathon</a></li>\n<li>Python: <a href=\"https://github.com/thefactory/marathon-python\" rel=\"nofollow noreferrer\">thefactory/marathon-python</a>  </li>\n</ul>\n", "answer_id": 41100160, "last_activity_date": 1481543188, "creation_date": 1481543188, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 41095848}, {"body": "<p>When I posted this question, I had java library actually in mind, but forgot to mention that. I find @michael 's libraries are also very good. But this is what I settled upon. Marathon-client. I think I saw this, while browsing through <a href=\"https://github.com/mesosphere\" rel=\"nofollow noreferrer\">mesosphere</a> repositories but somehow missed it.</p>\n\n<p>This is the library: <a href=\"https://github.com/mesosphere/marathon-client\" rel=\"nofollow noreferrer\">marathon-client</a></p>\n", "answer_id": 41114709, "last_activity_date": 1481609629, "creation_date": 1481609629, "score": 1, "owner": {"user_id": 1229355, "profile_image": "https://graph.facebook.com/727850431/picture?type=large", "user_type": "registered", "reputation": 366, "link": "https://stackoverflow.com/users/1229355/tyagi-akhilesh", "accept_rate": 50, "display_name": "Tyagi Akhilesh"}, "is_accepted": false, "question_id": 41095848}], "owner": {"user_id": 1229355, "profile_image": "https://graph.facebook.com/727850431/picture?type=large", "user_type": "registered", "reputation": 366, "link": "https://stackoverflow.com/users/1229355/tyagi-akhilesh", "accept_rate": 50, "display_name": "Tyagi Akhilesh"}, "view_count": 94, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41095848}{"body": "<p>I am using Cassandra framework on Mesosphere which is launching Cassandra nodes on Mesos containers. I was wondering if I can log into the mesos container? </p>\n\n<p>Initially I was running cassandra on mesosphere using docker container and I could log into the containers.</p>\n\n<p>I want to know if its feasible to log in to the mesos container just like what we can do for dockers.</p>\n\n<p>P.S - I aware of logging into the slave/agent nodes</p>\n", "is_answered": false, "tags": ["docker", "cassandra", "mesos", "mesosphere"], "title": "Cassandra on Mesos Container", "last_activity_date": 1487197117, "answer_count": 0, "creation_date": 1487197117, "score": 0, "link": "https://stackoverflow.com/questions/42261161/cassandra-on-mesos-container", "owner": {"user_id": 5045323, "profile_image": "https://www.gravatar.com/avatar/7b66336f1600c65cd0e6e0a62366af22?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 139, "link": "https://stackoverflow.com/users/5045323/nahush", "accept_rate": 50, "display_name": "Nahush"}, "view_count": 39, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42261161}{"body": "<p>I have mesos installed in some docker containers and when ever I bring the container up, the <code>mesos-master</code> process starts by default on all these containers. Even on those that I have <code>mesos-agents</code> running on. \nI have no idea why this is happening and this is rather annoying. </p>\n\n<p>I am installing mesos the following way</p>\n\n<pre><code>RUN rpm -i http://repos.mesosphere.io/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm &amp;&amp; \\\nyum -y install mesos-0.28.2\n</code></pre>\n\n<p>Any ideas on why this is happening? Is this the expected behavior? \nPlease let me know what I can do to stop this.</p>\n", "is_answered": true, "title": "Mesos master keeps starting automatically", "tags": ["docker", "mesos", "mesosphere"], "last_activity_date": 1472678546, "accepted_answer_id": 39259212, "creation_date": 1472532746, "answers": [{"body": "<p><strong>This is expected behavior</strong></p>\n\n<p>You need to explicit disable Mesos Master (and ZooKeeper if you installed it). Depending on your system version it can be done as follow:</p>\n\n<ul>\n<li><p>On RedHat 6 / CentOS 6:</p>\n\n<pre><code>sudo stop mesos-master\nsudo sh -c \"echo manual &gt; /etc/init/mesos-master.override\"\n</code></pre></li>\n<li><p>On RedHat 7 / CentOS 7:</p>\n\n<pre><code>sudo systemctl stop mesos-master.service\nsudo systemctl disable mesos-master.service \n</code></pre></li>\n</ul>\n\n<p>For more take a look at <a href=\"https://open.mesosphere.com/getting-started/install/#slave-setup\" rel=\"nofollow\">slave-setup tutorial</a>.</p>\n", "answer_id": 39259212, "last_activity_date": 1472678546, "creation_date": 1472678546, "score": 0, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 39218973}], "score": 0, "link": "https://stackoverflow.com/questions/39218973/mesos-master-keeps-starting-automatically", "answer_count": 1, "owner": {"user_id": 3542989, "profile_image": "https://i.stack.imgur.com/lf9Hn.jpg?s=128&g=1", "user_type": "registered", "reputation": 192, "link": "https://stackoverflow.com/users/3542989/durga-swaroop", "accept_rate": 42, "display_name": "Durga Swaroop"}, "view_count": 76, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39218973}{"body": "<p>I'm evaluating Apache Zeppelin with the current release version <a href=\"https://github.com/apache/incubator-zeppelin/releases\" rel=\"nofollow\">v0.5</a>. I have a mesos cluster with spark registered as framework, then I need configure Zeppelin to connect to the remote spark cluster on mesos. </p>\n\n<p>My config in <strong>conf/zeppelin-env.sh</strong>  it's:</p>\n\n<pre><code>export MASTER=mesos://&lt;mesos_ip&gt;:5050\nexport MESOS_NATIVE_JAVA_LIBRARY=/usr/lib/libmesos.so\nexport ZEPPELIN_JAVA_OPTS=\"-Dspark.executor.uri=http://&lt;public_host_url&gt;/spark-1.4.0-bin-hadoop2.6.tgz\" \n</code></pre>\n\n<p>But when I execute the boot command and run the demo notebook the log show some errors and the query don't work:</p>\n\n<pre><code>------ Create new SparkContext mesos://172.23.0.135:5050 -------\nFailed to load native Mesos library from /usr/lib/libmesos.so\n------ Create new SparkContext mesos://172.23.0.135:5050 -------\nFailed to load native Mesos library from /usr/lib/libmesos.so\n</code></pre>\n\n<p>I can't find any documentation or source code about this erros message. And I don't understand the reason because I have libmesos.so on /usr/lib and when I execute separatly spark-submmit all work fine from my host.</p>\n", "is_answered": true, "tags": ["apache-spark", "mesos", "mesosphere", "apache-zeppelin"], "last_edit_date": 1440693944, "title": "Apache Zeppelin not load libmesos.so", "last_activity_date": 1440748208, "answer_count": 2, "creation_date": 1440692139, "score": 1, "link": "https://stackoverflow.com/questions/32254641/apache-zeppelin-not-load-libmesos-so", "answers": [{"body": "<p>Can you try setting something like below? </p>\n\n<pre><code>export MESOS_NATIVE_LIBRARY=/usr/lib/libmesos.so\nexport SPARK_EXECUTOR_URI=http://&lt;public_host_url&gt;/spark-1.4.0-bin-hadoop2.6.tgz\n</code></pre>\n", "answer_id": 32263880, "last_activity_date": 1440739650, "creation_date": 1440739650, "score": 0, "owner": {"user_id": 5275532, "profile_image": "https://www.gravatar.com/avatar/c404873c7b798338d0a59d18e4407117?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 49, "link": "https://stackoverflow.com/users/5275532/%ec%8b%ac%ed%98%95%ec%84%b1-hyung-sung-shim", "display_name": "\uc2ec\ud615\uc131 Hyung Sung Shim"}, "is_accepted": false, "question_id": 32254641}, {"body": "<p>According to the <a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html#client-mode\" rel=\"nofollow\">docs</a> you should set the <code>MESOS_NATIVE_JAVA_LIBRARY</code> and <code>SPARK_EXECUTOR_URI</code> environment variables.</p>\n\n<pre><code>export MESOS_NATIVE_JAVA_LIBRARY=/usr/lib/libmesos.so\nexport SPARK_EXECUTOR_URI={YOUR_SPARK_DOWNLOAD_LOCATION}\n</code></pre>\n", "answer_id": 32265949, "last_activity_date": 1440748208, "creation_date": 1440748208, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 32254641}], "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "view_count": 670, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32254641}{"body": "<p>I'm running a bunch of services in dockers in Mesos(v0.22.1) via Marathon (v0.9.0) and sometimes Mesos killing tasks. Usually it happens for multiple services at once</p>\n\n<p>Log line related to this issue from mesos-slave.ERROR log: </p>\n\n<pre><code>Failed to update resources for container 949b1491-2677-43c6-bfcf-bae6b40534fc \nof executor production-app-emails.15437359-a95e-11e5-a046-e24e30c7374f running task production-app-emails.15437359-a95e-11e5-a046-e24e30c7374f \non status update for terminal task, \ndestroying container: Failed to determine cgroup for the 'cpu' subsystem: \nFailed to read /proc/21292/cgroup: \nFailed to open file '/proc/21292/cgroup': No such file or directory\n</code></pre>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1450882697, "title": "Mesos killing tasks. Failed to determine cgroup for the 'cpu' subsystem", "last_activity_date": 1450889074, "answer_count": 1, "creation_date": 1450880870, "score": 1, "link": "https://stackoverflow.com/questions/34437810/mesos-killing-tasks-failed-to-determine-cgroup-for-the-cpu-subsystem", "answers": [{"body": "<p>I'd strongly suggest to update your stack. Mesos 0.22.1 and Marathon 0.9.0 are quite outdated as of today. Mesos 0.26.0 and Marathon 0.13.0 are out.</p>\n\n<p>Concerning your problem, have a look at</p>\n\n<ul>\n<li><a href=\"https://issues.apache.org/jira/browse/MESOS-1837\" rel=\"nofollow\">https://issues.apache.org/jira/browse/MESOS-1837</a></li>\n<li><a href=\"https://github.com/mesosphere/marathon/issues/994\" rel=\"nofollow\">https://github.com/mesosphere/marathon/issues/994</a></li>\n</ul>\n\n<p>The first one suggests fixes on the Mesos side (post 0.22.1), and the second indicates a lack of resources of the started containers.</p>\n\n<p>Maybe try to increase the RAM for the specific containers, and if that doesn't help, update the Mesos stack IMHO.</p>\n", "answer_id": 34440199, "last_activity_date": 1450889074, "creation_date": 1450889074, "score": 4, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 34437810}], "owner": {"user_id": 2170491, "profile_image": "https://i.stack.imgur.com/mhDM9.jpg?s=128&g=1", "user_type": "registered", "reputation": 504, "link": "https://stackoverflow.com/users/2170491/ihar-krasnik", "accept_rate": 31, "display_name": "Ihar Krasnik"}, "view_count": 693, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34437810}{"body": "<p>I have a container that will be deployed several times upon request from my application, the difference between containers relies on the environment variables, they point to a different bd (PostgreSQL) and a different table (the table represents the path property of the health check). When I deploy the first service on my DC/OS 1.8 it works like a charm, however, the rest of the deployments don't work. </p>\n\n<p>My <code>app.json</code> looks as follows:</p>\n\n<pre><code>{\n  \"volumes\": null,\n  \"id\": \"/data-microservices/ms1\",\n  \"cmd\": null,\n  \"args\": null,\n  \"user\": null,\n  \"env\": {\n    \"DATABASE_URL\": \"postgres://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:5432/&lt;dbname&gt;\",\n    \"TABLE\": \"&lt;thetable&gt;\"\n  },\n  \"instances\": 1,\n  \"cpus\": 0.1,\n  \"mem\": 65,\n  \"disk\": 0,\n  \"gpus\": 0,\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"imtachu/data-microservice\",\n      \"forcePullImage\": true,\n      \"privileged\": false,\n      \"portMappings\": [\n        {\n          \"containerPort\": 8080,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"network\": \"BRIDGE\"\n    }\n  },\n  \"healthChecks\": [\n    {\n      \"protocol\": \"HTTP\",\n      \"path\": \"/api/&lt;thetable&gt;\",\n      \"gracePeriodSeconds\": 10,\n      \"intervalSeconds\": 2,\n      \"timeoutSeconds\": 10,\n      \"maxConsecutiveFailures\": 10,\n      \"ignoreHttp1xx\": false\n    }\n  ],\n  \"readinessChecks\": null,\n  \"dependencies\": null,\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 1,\n    \"maximumOverCapacity\": 1\n  },\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\",\n    \"HAPROXY_0_VHOST\": \"dcos2-PublicSlaveL-KWSCFODW1ME5-878889582.us-east-1.elb.amazonaws.com\"\n  },\n  \"acceptedResourceRoles\": null,\n  \"residency\": null,\n  \"secrets\": null,\n  \"taskKillGracePeriodSeconds\": null,\n  \"portDefinitions\": [\n    {\n      \"protocol\": \"tcp\",\n      \"labels\": {}\n    }\n  ],\n  \"requirePorts\": false\n}\n</code></pre>\n\n<p>So far, I have tried to modify the <code>hostPort</code> property and changing the <code>HAPROXY_0_VHOST</code> to <code>HAPROXY_1_VHOST</code> also the <code>requirePorts</code> so maybe I can have each container running on a different port. </p>\n\n<p>I have tried deploying first a service pointing to table A and then another pointing to table B and viceversa, and the behavior is the same: First deployed service always work, the rest doesn't.</p>\n", "is_answered": false, "tags": ["containers", "mesos", "marathon", "dcos"], "last_edit_date": 1478336174, "title": "Dockers on DC/OS 1.8: First one works, the rest are dead", "last_activity_date": 1478336174, "answer_count": 0, "creation_date": 1478296850, "score": 2, "link": "https://stackoverflow.com/questions/40432315/dockers-on-dc-os-1-8-first-one-works-the-rest-are-dead", "owner": {"user_id": 1535071, "profile_image": "https://i.stack.imgur.com/5ETaX.jpg?s=128&g=1", "user_type": "registered", "reputation": 1480, "link": "https://stackoverflow.com/users/1535071/lorena-salamanca", "accept_rate": 100, "display_name": "Lorena Salamanca"}, "view_count": 48, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40432315}{"body": "<p><strong>Background</strong></p>\n\n<p>In <code>spark/resource-managers/mesos/src/main/scala/org/apache/spark/scheduler/cluster/mesos/MesosSchedulerUtils.scala</code> around line 100 I see code like this:</p>\n\n<pre><code> if (credBuilder.hasPrincipal) {\n   new MesosSchedulerDriver(\n     scheduler, fwInfoBuilder.build(), masterUrl, credBuilder.build())\n } else {\n   new MesosSchedulerDriver(scheduler, fwInfoBuilder.build(), masterUrl)\n }\n</code></pre>\n\n<p>The documentation of <code>mesos-http-adapter</code> basically says that you just need to replace <code>MesosScheduleDriver</code> by <code>MesosScheduleDriverAdapter</code>:</p>\n\n<pre><code>// Before:\n\nMesosSchedulerDriver driver =\n    new MesosSchedulerDriver(scheduler, frameworkInfo, masterUrl);\n\n// After:\n\nMesosSchedulerDriver driver =\n    new MesosToSchedulerDriverAdapter(scheduler, frameworkInfo, masterUrl);\n</code></pre>\n\n<p><strong>Question</strong></p>\n\n<p>Can I simply download Spark, replace <code>MesosSchedulerDriver</code> by <code>MesosSchedulerDriverAdapter</code>, recompile Spark and expect that it talks to a Mesos cluster via HTTP, keeping the same behavior as it would using the binary <code>libmesos.so</code>?</p>\n\n<p>A side question is: why Spark have not embraced such thing yet?</p>\n", "is_answered": false, "tags": ["scala", "apache-spark", "mesos", "mesosphere"], "last_edit_date": 1496842812, "title": "How to replace Mesos binaries by mesos-http-adapter in Spark?", "last_activity_date": 1496842812, "answer_count": 0, "creation_date": 1496766170, "score": 0, "link": "https://stackoverflow.com/questions/44395199/how-to-replace-mesos-binaries-by-mesos-http-adapter-in-spark", "owner": {"user_id": 62131, "profile_image": "https://i.stack.imgur.com/asMh7.png?s=128&g=1", "user_type": "registered", "reputation": 2909, "link": "https://stackoverflow.com/users/62131/richard-gomes", "accept_rate": 73, "display_name": "Richard Gomes"}, "view_count": 17, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44395199}{"body": "<p>I set up and haproxy on a mesosphere cluster and set up three web servers using marathon. Now I am trying to load balance between them using this config</p>\n\n<pre><code>global\n  daemon\n  log 127.0.0.1 local0\n  log 127.0.0.1 local1 notice\n  maxconn 4096\n\ndefaults\n  log         global\n  retries     3\n  maxconn     2000\n  timeout connect  5000\n  timeout client  50000\n  timeout server  50000\n\nlisten stats\n  bind 127.0.0.1:9090\n  balance\n  mode http\n\nlisten apiserver\n  bind 0.0.0.0:80\n  mode tcp\n  balance leastconn\n  server apiserver-3 10.132.62.240:31000 check\n  server apiserver-2 10.132.62.243:31000 check\n  server apiserver-1 10.132.62.242:31000 check\n</code></pre>\n\n<p>Now if I am in the VPN I can connect to the server normally - however externally I am unable to do that.Other Services manage to use the ports without problems (both local and global) but haproxy can't seem to work. If I put haproxy in a docker container it works , however I don't want to do that</p>\n", "is_answered": false, "tags": ["haproxy", "mesos", "mesosphere", "marathon"], "last_edit_date": 1427659838, "title": "haproxy not allowing external traffic through", "last_activity_date": 1427659838, "answer_count": 0, "creation_date": 1427498144, "score": 1, "link": "https://stackoverflow.com/questions/29311685/haproxy-not-allowing-external-traffic-through", "owner": {"user_id": 1199314, "profile_image": "https://www.gravatar.com/avatar/c9e1ec8f4a89feba3039ac3df45af767?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 82, "link": "https://stackoverflow.com/users/1199314/nadi-hassan-hassan", "accept_rate": 36, "display_name": "Nadi Hassan Hassan"}, "view_count": 139, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29311685}{"body": "<p>We are using spark framework in Mesos from universe and running drivers &amp; executors as docker containers by setting the </p>\n\n<pre><code>SPARK_JAVA_OPTS=\"-Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.8-2.1.0-1-hadoop-2.6\". \n</code></pre>\n\n<p>We are able to submit a job in cluster mode via</p>\n\n<pre><code>./bin/spark-submit --deploy-mode cluster --class org.apache.spark.examples.SparkPi --master mesos://xx.xx.xx.xxx:xxxx --executor-memory 2G --total-executor-cores 12 --driver-memory 1G https://s3-us-west-2.amazonaws.com/xxxxx/spark-examples_2.11-2.1.0.jar 20000\n</code></pre>\n\n<p>This successfully launched spark executors &amp; tasks on multiple mesos nodes as docker containers.</p>\n\n<p>In our mesos, we have container scoped roles inspired from lyft (<a href=\"https://github.com/lyft/metadataproxy\" rel=\"nofollow noreferrer\">https://github.com/lyft/metadataproxy</a>). </p>\n\n<p>Now I would like to run spark executors and tasks with their own container roles and essentially it requires us to set an environment variable IAM_ROLE=xxx for docker run command.\nex: </p>\n\n<pre><code>docker run -d -e IAM_ROLE=xxxx alpine:xxx\n</code></pre>\n\n<p>How can I launch a spark application using ./bin/spark-submit and give IAM_ROLE as an environment variable for all executors &amp; tasks that start as docker run commands on mesos nodes.</p>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere"], "title": "Spark on Mesos: How to give an environment variable for driver and executor docker run", "last_activity_date": 1489603633, "answer_count": 0, "creation_date": 1489603633, "score": 0, "link": "https://stackoverflow.com/questions/42818251/spark-on-mesos-how-to-give-an-environment-variable-for-driver-and-executor-dock", "owner": {"user_id": 1569602, "profile_image": "https://www.gravatar.com/avatar/dc2c984e0e0d5db7ce2bd8cd198af69f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 126, "link": "https://stackoverflow.com/users/1569602/nari", "accept_rate": 31, "display_name": "Nari"}, "view_count": 122, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42818251}{"body": "<p>I have got a cluster with gpu nodes (nvidia) and deployed DC/OS 1.8. I'd like to enable to schedule jobs (batch and spark) on gpu nodes using gpu isolation.\nDC/OS is based on mesos 1.0.1 that supports gpu isolation.</p>\n", "is_answered": true, "tags": ["gpu", "mesos", "dcos"], "title": "Enable GPU resources (CUDA) on DC/OS", "last_activity_date": 1477934554, "answer_count": 2, "creation_date": 1477930990, "score": 0, "link": "https://stackoverflow.com/questions/40346321/enable-gpu-resources-cuda-on-dc-os", "answers": [{"body": "<p>In order to enable supporting gpu resources in DC/OS cluster the next steps are needed:</p>\n\n<ol>\n<li><p>Configure mesos agents on gpu nodes:<br>\n1.1. Stop <em>dcos-mesos-slave.service</em>:</p>\n\n<p><code>systemctl stop dcos-mesos-slave.service</code></p>\n\n<p>1.2. Add the next parameters into <em>/var/lib/dcos/mesos-slave-common</em> file:</p>\n\n<p><code># a comma separated list of GPUs (id), as determined by running nvidia-smi on the host where the agent is to be launched\nMESOS_NVIDIA_GPU_DEVICES=\"0,1\"</code></p>\n\n<p><code># value of the gpus resource must be complied with  number of ids above\nMESOS_RESOURCES= [ {\"name\":\"ports\",\"type\":\"RANGES\",\"ranges\": {\"range\": [{\"begin\": 1025, \"end\": 2180},{\"begin\": 2182, \"end\": 3887},{\"begin\": 3889, \"end\": 5049},{\"begin\": 5052, \"end\": 8079},{\"begin\": 8082, \"end\": 8180},{\"begin\": 8182, \"end\": 32000}]}} ,{\"name\": \"gpus\",\"type\": \"SCALAR\",\"scalar\": {\"value\": 2}}]</code>     </p>\n\n<p><code>MESOS_ISOLATION=cgroups/cpu,cgroups/mem,disk/du,network/cni,filesystem/linux,docker/runtime,docker/volume,cgroups/devices,gpu/nvidia</code></p>\n\n<p>1.3. Start <em>dcos-mesos-slave.service</em>:</p>\n\n<p><code>systemctl start dcos-mesos-slave.service</code></p></li>\n<li><p>Enable the GPU_RESOURCES capability in mesos frameworks:</p>\n\n<p>2.1. <em>Marathon</em> framework should be launched with the option \n<code>--enable_features \"gpu_resources\"</code></p>\n\n<p>2.2. Aurora scheduler should be launched with the option <code>-allow_gpu_resource</code>      </p></li>\n</ol>\n\n<p><strong>Note.</strong> </p>\n\n<blockquote>\n  <p>Any host running a Mesos agent with Nvidia GPU support MUST have a valid Nvidia kernel driver installed. It is also highly recommended to install the corresponding user-level libraries and tools available as part of the Nvidia CUDA toolkit. Many jobs that use Nvidia GPUs rely on CUDA and not including it will severely limit the type of GPU-aware jobs you can run on Mesos.</p>\n</blockquote>\n", "answer_id": 40347189, "last_activity_date": 1477934304, "creation_date": 1477934304, "score": 2, "owner": {"user_id": 6634951, "profile_image": "https://i.stack.imgur.com/6q1pq.jpg?s=128&g=1", "user_type": "registered", "reputation": 59, "link": "https://stackoverflow.com/users/6634951/kr0t", "display_name": "Kr0t"}, "is_accepted": false, "question_id": 40346321}, {"body": "<p>Unfortunately, DC/OS doesn't officially support GPUs in 1.8 (<em>experimental</em> support for GPUs will be coming in the next release as mentioned here: <a href=\"https://github.com/dcos/dcos/pull/766\" rel=\"nofollow\">https://github.com/dcos/dcos/pull/766</a> ).</p>\n\n<p>In this next release, only Marathon will officially be able to launch GPU services (Metronome (i.e. batch jobs) will not).</p>\n\n<p>Regarding spark, the spark version bundled with Universe probably doesn't have GPU support for Mesos built in yet. Spark itself has it coming soon though: <a href=\"https://github.com/apache/spark/pull/14644\" rel=\"nofollow\">https://github.com/apache/spark/pull/14644</a></p>\n", "answer_id": 40347268, "last_activity_date": 1477934554, "creation_date": 1477934554, "score": 3, "owner": {"user_id": 7096338, "profile_image": "https://lh4.googleusercontent.com/-pBkFQ07_QKQ/AAAAAAAAAAI/AAAAAAAAGbU/AqMURnQmYwg/photo.jpg?sz=128", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/7096338/kevin-klues", "display_name": "Kevin Klues"}, "is_accepted": false, "question_id": 40346321}], "owner": {"user_id": 6634951, "profile_image": "https://i.stack.imgur.com/6q1pq.jpg?s=128&g=1", "user_type": "registered", "reputation": 59, "link": "https://stackoverflow.com/users/6634951/kr0t", "display_name": "Kr0t"}, "view_count": 582, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40346321}{"body": "<p>Im trying to automate my mesos cluster with only vagrant (so no chef, puppet, ansible or whatever). \nThe vagrantfile I now have does not modify /etc/mesos/zk. I've tried to echo it in with <code>cmd: \"echo zk://192.168.3.2:2181,192.168.3.3:2181/mesos &gt; /etc/mesos/zk\"</code> and <code>srv.vm.provision \"shell\", inline: \"docker exec -t mesoscloud-mesos-master 'echo zk://192.168.3.2:2181,192.168.3.3:2181/mesos &gt; /etc/mesos/zk\"</code>  but non of those work. Maybe the MESOS_ZK variable is used wrong, but I am out of ideas. This is (the relevant part) of my Vagrantfile:</p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\">\r\n<div class=\"snippet-code\">\r\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code># -*- mode: ruby -*-\r\n# vi: set ft=ruby :this\r\n\r\nrequire 'fileutils'\r\nrequire 'yaml'\r\n\r\nservers = YAML.load_file('servers.yml')\r\n\r\n$HOST_IP_1='192.168.3.2'\r\n$HOST_IP_2='192.168.3.3'\r\n\r\n\r\nVagrant.configure(2) do |config|\r\n\tconfig.ssh.insert_key = false\r\n\tconfig.ssh.forward_agent = true\r\n\t#\tconfig.vm.provision \"docker\"\r\n\tservers.each do |server|\r\n\t\tconfig.vm.define server[\"name\"] do |srv|\r\n\t\t\tsrv.vm.box_check_update = false\r\n\t\t\tsrv.vm.hostname = server[\"name\"]\r\n\t\t\tsrv.vm.box = \"centos/7\" \r\n\t\t\tsrv.vm.network \"private_network\", ip: server[\"priv_ip\"]\r\n\t\t\tsrv.vm.network \"public_network\", bridge: \"en2: Thunderbolt 1\", ip: server[\"pub_ip\"]\r\n\t\t\tsrv.vm.synced_folder \".\", \"/vagrant\", disabled: true\r\n\t\t\tif srv.vm.hostname == \"melisandre\"\r\n\r\n\t\t\t\t# ZOOKEEPER\r\n\t\t\t\tsrv.vm.provision \"docker\" do |d|\r\n\t\t\t\t\td.run \"mesoscloud/zookeeper\",\r\n\t\t\t\t\t\targs: \"--net='host' -e SERVER_ID=1 -e ADDITIONAL_ZOOKEEPER_1=server.1=192.168.3.2:2888:3888 -e ADDITIONAL_ZOOKEEPER_2=server.2=192.168.3.3:2888:3888\"\r\n\t\t\t\tend\r\n\r\n\r\n\t\t\t\t# MESOS-MASTER\r\n\t\t\t\tsrv.vm.provision \"docker\" do |d|\r\n\t\t\t\t\td.run \"mesoscloud/mesos-master\",\r\n\t\t\t\t\t\targs: \"--net='host' -p 5050:5050 -e MESOS_HOSTNAME=192.168.3.2 -e MESOS_IP=192.168.3.2 -e MESOS_ZK='zk://192.168.3.2:2181,192.178.3.3:2181/mesos' -e MESOS_PORT=5050 -e MESOS_LOG_DIR=/var/log/mesos -e MESOS_QUORUM=1 -e MESOS_REGISTRY=in_memory -e MESOS_WORK_DIR=/var/lib/mesos\"#,cmd: \"echo zk://192.168.3.2:2181,192.168.3.3:2181/mesos &gt; /etc/mesos/zk\"\r\n\r\n\t\t\t\tend</code></pre>\r\n</div>\r\n</div>\r\n</p>\n\n<p>Thanks in advance</p>\n", "is_answered": true, "tags": ["vagrant", "apache-zookeeper", "mesos", "mesosphere"], "title": "Vagrant + Mesos : /etc/mesos/zk does not change", "last_activity_date": 1459002173, "answer_count": 2, "creation_date": 1458825472, "score": 1, "link": "https://stackoverflow.com/questions/36201170/vagrant-mesos-etc-mesos-zk-does-not-change", "answers": [{"body": "<p>If you replace the <code>cmd</code> of a <code>docker run</code> execution it disables the default command. So you'd have to make it a compound command (joined with <code>;</code> or <code>&amp;&amp;</code>) that also does what the default command does.</p>\n\n<p>That said, you should probably be using the mesosphere docker images (<a href=\"https://hub.docker.com/r/mesosphere/mesos-master\" rel=\"nofollow\">https://hub.docker.com/r/mesosphere/mesos-master</a> and <a href=\"https://hub.docker.com/r/mesosphere/mesos-slave\" rel=\"nofollow\">https://hub.docker.com/r/mesosphere/mesos-slave</a>) instead of the deprecated mesoscloud ones.</p>\n", "answer_id": 36206274, "last_activity_date": 1458840111, "creation_date": 1458840111, "score": 2, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 36201170}, {"body": "<p>If you want a preconfigured Vagrant solution (which can be adapted), have a look at <a href=\"https://github.com/tobilg/coreos-mesos-cluster\" rel=\"nofollow\">tobilg/coreos-mesos-cluster</a>.</p>\n\n<p>By default, this will launch a 3 node CoreOS cluster with ZooKeeper, Mesos Masters &amp; Slaves and Marathon.</p>\n", "answer_id": 36236385, "last_activity_date": 1459002173, "creation_date": 1459002173, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 36201170}], "owner": {"user_id": 4579132, "profile_image": "https://i.stack.imgur.com/jPQeA.jpg?s=128&g=1", "user_type": "registered", "reputation": 141, "link": "https://stackoverflow.com/users/4579132/zwadderich", "accept_rate": 0, "display_name": "Zwadderich"}, "view_count": 77, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 36201170}{"body": "<p>I have Mesos cluster consists of 3 CentOS6.5 machines.</p>\n\n<p>ZooKeeper and Mesos-Master is running on one of the machines and Mesos-Slave is running on each machine.</p>\n\n<p>Also, Marathon is running on master node.</p>\n\n<p>Then, I am trying to run docker containers on Marathon, following <a href=\"https://mesosphere.com/blog/2014/09/25/marathon-0-7-0-released/\" rel=\"nofollow\">this instruction</a> by Mesosphere.</p>\n\n<p><code>job.json</code> is like as follows,</p>\n\n<pre><code>{\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"libmesos/ubuntu\"\n    }\n  },\n  \"id\": \"ubuntu\",\n  \"instances\": 1,\n  \"cpus\": 0.5,\n  \"mem\": 512,\n  \"uris\": [],\n  \"cmd\": \"date -u +%T\"\n}\n</code></pre>\n\n<p>Then I run following command,</p>\n\n<pre><code>curl -X POST -H \"Accept: application/json\" -H \"Content-Type: application/json\" &lt;master-hostname&gt;:8080/v2/apps -d@job.json\n</code></pre>\n\n<p>Then on Marathon Web UI, I can see the Docker container is \"Deploying\" status even after long time.</p>\n\n<p>And on Mesos-Master Web UI, I can see the Task is in \"STAGING\" status after long time.</p>\n\n<p>On Sandbox pane, I can see the stdout and the command seems to completed successfly. No problem.</p>\n\n<p>stderr is like this,</p>\n\n<pre><code>I0416 19:19:49.254998 29178 exec.cpp:132] Version: 0.22.0\nI0416 19:19:49.257824 29193 exec.cpp:206] Executor registered on slave 20150416-160950-109643786-5050-30728-S0\n</code></pre>\n\n<p>stdout is like this,</p>\n\n<pre><code>Registered executor on master-hostname\n10:19:49\n</code></pre>\n\n<p><strong>But I expect the container(TASK) to finish after completed the command.</strong>\n<strong>Is it possible?</strong>\n<strong>If possible, how to do that way?</strong></p>\n\n<p>Thank you.</p>\n", "is_answered": true, "title": "Docker container on Marathon doesn't finish", "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_activity_date": 1456127890, "accepted_answer_id": 29672371, "creation_date": 1429180493, "answers": [{"body": "<p>The task will finish (you should be able to see in the Mesos completed tasks) but the container will be restarted by Marathon. Marathon is for long-running apps. </p>\n\n<p>If you don't want your application to be running continuously, you should take a look at another framework like Chronos. </p>\n", "answer_id": 29672371, "last_activity_date": 1429182186, "creation_date": 1429181119, "score": 5, "owner": {"user_id": 2339082, "profile_image": "https://www.gravatar.com/avatar/16dcbdda62178dd82d4599393bdd590f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4411, "link": "https://stackoverflow.com/users/2339082/c%c3%a9line-aussourd", "display_name": "C\u00e9line Aussourd"}, "is_accepted": true, "last_edit_date": 1429182186, "question_id": 29672152}, {"body": "<p>Marathon is for long running processes. Even if you remove the containers, marathon will try to restart these. One more thing that I observed is that Marathon tries to launch containers and continue to do that till you are left with no memory and CPU. When you are out of resources your task will go in stage state.</p>\n", "answer_id": 35548458, "last_activity_date": 1456127890, "creation_date": 1456127890, "score": 0, "owner": {"user_id": 4886861, "profile_image": "https://lh5.googleusercontent.com/-slVOeDBqQ3I/AAAAAAAAAAI/AAAAAAAAAHw/vg0TVHkB0AQ/photo.jpg?sz=128", "user_type": "registered", "reputation": 465, "link": "https://stackoverflow.com/users/4886861/yogesh-jilhawar", "accept_rate": 48, "display_name": "Yogesh Jilhawar"}, "is_accepted": false, "question_id": 29672152}], "score": 1, "link": "https://stackoverflow.com/questions/29672152/docker-container-on-marathon-doesnt-finish", "answer_count": 2, "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 866, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 29672152}{"body": "<p>I'm using mesos and marathon to deploy a container of Kibana 4. The JSON to deploy is:</p>\n\n<pre><code>{\n    \"id\": \"/org/products/kibana/webapp\",\n    \"instances\": 1,\n    \"cpus\": 1,\n    \"mem\": 768,\n    \"uris\": [],\n    \"constraints\": [\n        [\"hostname\", \"UNIQUE\"]\n    ],\n    \"upgradeStrategy\": {\n        \"minimumHealthCapacity\": 0.5\n    },\n    \"healthChecks\": [\n        {\n            \"protocol\": \"HTTP\",\n            \"path\": \"/\",\n            \"portIndex\": 0,\n            \"initialDelaySeconds\": 600,\n            \"gracePeriodSeconds\": 10,\n            \"intervalSeconds\": 30,\n            \"timeoutSeconds\": 120,\n            \"maxConsecutiveFailures\": 10\n        }\n    ],\n    \"env\": {\n        \"ES_HOST\":\"172.23.10.23\",\n        \"ES_PORT\":\"9200\"\n    },\n    \"container\": {\n        \"type\": \"DOCKER\",\n        \"docker\": {\n            \"image\": \"myregistry.local.com:5000/org/kibana:4.0.0\",\n            \"network\": \"BRIDGE\",\n            \"portMappings\": [\n                {\n                    \"containerPort\": 5601,\n                    \"hostPort\": 0,\n                    \"servicePort\": 50061,\n                    \"protocol\": \"tcp\"\n                }\n            ]\n        },\n        \"volumes\": [\n          {\n            \"containerPath\": \"/etc/localtime\",\n            \"hostPath\": \"/etc/localtime\",\n            \"mode\": \"RO\"\n          }\n        ]\n    }\n}\n</code></pre>\n\n<p>But when I post it, the kibana app never wake up and the stderr log is:</p>\n\n<pre><code>I0227 12:22:44.666357  1149 exec.cpp:132] Version: 0.21.1\nI0227 12:22:44.669059  1178 exec.cpp:206] Executor registered on slave 20150225-040104-1124079532-5050-952-S0\n\n/kibana/src/index.js:58\n      throw error;\n            ^\nError: listen EADDRNOTAVAIL\n  at errnoException (net.js:905:11)\n  at Server._listen2 (net.js:1024:19)\n  at listen (net.js:1065:10)\n  at net.js:1147:9\n  at asyncCallback (dns.js:68:16)\n  at Object.onanswer [as oncomplete] (dns.js:121:9)\n</code></pre>\n\n<p>After that I try to eliminate a port mapping, because I found some references indicating that it's an port or network configuration problem. Then my Kibana 4 web app wake up fine, but I need configure a port-mapping to access via HTTP. I have not idea at about why marathon has problem with <strong>network</strong> and <strong>portMappings</strong> config. Some help will be appreciated.</p>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon", "kibana-4"], "title": "Deploying docker container of Kibana 4 with port-mapping on Mesos/Marathon", "last_activity_date": 1425307206, "answer_count": 1, "creation_date": 1425058570, "score": 1, "link": "https://stackoverflow.com/questions/28771033/deploying-docker-container-of-kibana-4-with-port-mapping-on-mesos-marathon", "answers": [{"body": "<p>This is a nasty problem, and I encountered it as well (running Kibana 4 on Mesos + Marathon).</p>\n\n<p><strong>The short answer:</strong> </p>\n\n<p>If you use current master of the Kibana repository, this won't happen - the relevant code has changed in the 4.1.0 snapshot which is master at the time of writing.</p>\n\n<p><strong>The long answer:</strong></p>\n\n<p>4.0.0 has this chunk of code in <code>src/server/index.js</code>:</p>\n\n<pre><code>var port = parseInt(process.env.PORT, 10) || config.port || 3000;\nvar host = process.env.HOST || config.host || '127.0.0.1';\n</code></pre>\n\n<p>Marathon supplies <code>HOST</code> and <code>POST</code> environment variables by default, and the <code>HOST</code> variable is set to the Mesos slave's hostname. The above code makes Kibana try to bind to the IP address of the Mesos slave (which Marathon has placed in <code>HOST</code>), which will fail, as it's running inside a Docker container.</p>\n\n<p>If you want to run 4.0.0, you can just patch these lines to:</p>\n\n<pre><code>var port = config.port || 3000;\nvar host = config.host || '127.0.0.1';\n</code></pre>\n\n<p>The code looks like this in master at the moment.</p>\n", "answer_id": 28812456, "last_activity_date": 1425307206, "creation_date": 1425307206, "score": 1, "owner": {"user_id": 4617521, "profile_image": "https://www.gravatar.com/avatar/4e92a899760c59ddff53720f4fce4de7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/4617521/andy-sykes", "display_name": "Andy Sykes"}, "is_accepted": false, "question_id": 28771033}], "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "view_count": 956, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28771033}{"body": "<p>I have a 1/1 master/slave setup with the slave having 8gb ram 8 cpus.  I am trying to use marathon to deploy a docker container with 1gb mem and 1 cpu but it just hangs on waiting</p>\n\n<p>I believe this is usually caused by marathon not getting the resources it wants for the task\nwhen I look at my logs I see </p>\n\n<blockquote>\n  <p>Sending 1 offers to framework\n  8bb1a298-cc23-426e-ad43-d440a2a560c4-0000 (marathon) at\n  scheduler-d4a993b4-69ea-4ac3-9e98-b54afe1e790b@127.0.0.1:52016 I0127\n  23:07:37.396546  2471 master.cpp:3297] Processing DECLINE call for\n  offers: [ 5271fcb3-4d77-4b12-af85-d94fd9172514-O127 ] for framework\n  8bb1a298-cc23-426e-ad43-d440a2a560c4-0000 (marathon) at\n  scheduler-d4a993b4-69ea-4ac3-9e98-b54afe1e790b@127.0.0.1:52016 I0127\n  23:07:37.396917  2466 hierarchical.cpp:744] Recovered cpus(\u200b<em>):6;\n  mem(</em>\u200b):5968; disk(\u200b<em>):156020; ports(</em>\u200b):[31000-31056, 31058-32000]\n  (total: cpus(\u200b<em>):8; mem(</em>\u200b):6992; disk(\u200b<em>):156020;\n  ports(</em>\u200b):[31000-32000], allocated: cpus(\u200b<em>):2; mem(</em>\u200b):1024;\n  ports(*):[31057-31057]) on slave\n  8bb1a298-cc23-426e-ad43-d440a2a560c4-S0 from framework\n  8bb1a298-cc23-426e-ad43-d440a2a560c4-0000</p>\n</blockquote>\n\n<p>so it looks like marathon is declining the offer it gets?  the next line in the logs say that mesos is reclaiming the offered resources and what its reclaiming looks like its plenty for my task?</p>\n\n<p>any ideas on how to trouble shoot this further?</p>\n\n<p>edit: so got to dig into this a bit further and found the marathon logs. </p>\n\n<p>Basically the deployment works if we do not enter any information for port mapping in the marathon docker section.  The docker container deploys successfully and I can ping it successfully from its host but I cannot access it from elsewhere.</p>\n\n<p>if we set the container port as 8081 (which is what the docker container exposes are its application listens on) we get further in the deployment process but the app within the container fails to build with error</p>\n\n<blockquote>\n  <p>Error: listen EADDRINUSE :::8081\n     at Object.exports._errnoException (util.js:856:11)\n     at exports._exceptionWithHostPort (util.js:879:20)\n     at Server._listen2 (net.js:1234:14)\n     at listen (net.js:1270:10)\n     at Server.listen (net.js:1366:5)\n     at EventEmitter.listen (/usr/src/app/node_modules/express/lib/application.js:617:24)\n     at Object. (/usr/src/app/index.js:16:18)\n     at Module._compile (module.js:425:26)\n     at Object.Module._extensions..js (module.js:432:10)\n     at Module.load (module.js:356:32)\n     at Function.Module._load (module.js:313:12)\n     at Function.Module.runMain (module.js:457:10)\n     at startup (node.js:138:18)\n     at node.js:974:3</p>\n</blockquote>\n\n<p>So I think we are further along than we were but we are still having some port issues.  I dont know why the container would build successfully on its own and with marathon with no port settings but not with marathon with port settings</p>\n", "is_answered": true, "title": "Marathon won't launch docker container", "last_edit_date": 1454437139, "tags": ["docker", "mesos", "marathon", "mesosphere"], "view_count": 2103, "accepted_answer_id": 35208682, "last_activity_date": 1454610134, "answers": [{"body": "<p>There are few things to check:</p>\n\n<ol>\n<li><p>On you slave: <code>ps aux | grep sbin/mesos-slave</code> should contain something like:</p>\n\n<p><code>--containerizers=docker,mesos --executor_registration_timeout=5mins</code></p></li>\n<li><p>Again on slave check that there's a Docker Daemon running:</p>\n\n<p><code>ps aux | grep \"docker daemon\"</code></p></li>\n<li><p>Make sure you've configured Docker network (in Marathon) as <code>BRIDGE</code>. With <code>HOST</code> mode you might get in collision with ports already used on host. This will allow mapping <code>slave:32001 -&gt; docker:8080</code>.</p>\n\n<pre><code>...\n\"network\": \"BRIDGE\",\n\"portMappings\": [\n  {\n    \"containerPort\": 8080,\n    \"hostPort\": $PORT0,\n    \"protocol\": \"tcp\"\n  }\n],\n...\n</code></pre></li>\n<li><p>When the task starts in Marathon you'll see the app ID like <code>myapp.a72db5b0-ca16-11e5-ba5f-fea9945fabaf</code>. Use Mesos CLI (<code>pip install mesos.cli mesos.interface</code>) to fetch the logs. There's a command similar to Unix's <code>tail</code> for fetching <code>stdout</code> logs (<code>-f</code> follow logs):</p>\n\n<pre><code>mesos tail -f -i myapp.a72db5b0-ca16-11e5-ba5f-fea9945fabaf\n</code></pre>\n\n<p>and <code>stderr</code>:</p>\n\n<pre><code>mesos tail -f -i myapp.a72db5b0-ca16-11e5-ba5f-fea9945fabaf stderr\n</code></pre>\n\n<p><code>-i</code> allows you to get logs from inactive tasks (in case that the task is crashing quickly). If you don't catch the ID in Marathon, use <code>mesos ps -i</code>.</p></li>\n<li><p>In case that the task is not starting, there's either not enough resources or some problem with Marathon. Navigate your browser to <code>http://{marathon URI:8080]/logging</code> and increase verbosity for task allocation. Then check Marathon logs.</p></li>\n</ol>\n", "answer_id": 35208682, "last_activity_date": 1454610134, "creation_date": 1454610134, "score": 3, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": true, "question_id": 35050202}], "score": 1, "link": "https://stackoverflow.com/questions/35050202/marathon-wont-launch-docker-container", "answer_count": 1, "owner": {"user_id": 2535126, "profile_image": "https://www.gravatar.com/avatar/9ba5862bd06ed58daef0b0592e2971b9?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1325, "link": "https://stackoverflow.com/users/2535126/ir1sh", "accept_rate": 88, "display_name": "Ir1sh"}, "creation_date": 1453937506, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35050202}{"body": "<p>I wanted to run a simple python framework on my Mesos Cluster (0.23) which runs on CentOS 7.1. I installed Mesos over the <a href=\"https://mesosphere.com/downloads/\" rel=\"nofollow\">mesosphere packages</a> everything works fine (I'm running some Marathon jobs). But when I wanted to start develop my own framework with Python I got stuck. I used this <a href=\"http://jamesporter.me/2014/11/15/hello-mesos.html\" rel=\"nofollow\">example</a> from James J Porter, I know he tested it on mesos 0.20.0 but I thought I could run it with little effort on Mesos 0.23.</p>\n\n<p>At first I got an import error from python which said that mesos.native and mesos.interface are not available. Then I tried to do an easy_install but I could not find mesos.native and trying to isntall \"mesos\" results in the following:</p>\n\n<pre><code>$ pip install mesos\nCollecting mesos\n/usr/lib/python2.7/site-packages/pip-7.1.0-py2.7.egg/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n  InsecurePlatformWarning\n  Could not find a version that satisfies the requirement mesos (from versions: )\nNo matching distribution found for mesos\n$ easy_install mesos\nSearching for mesos\nReading https://pypi.python.org/simple/mesos/\nNo local packages or download links found for mesos\nerror: Could not find suitable distribution for Requirement.parse('mesos')\n</code></pre>\n\n<p>Then I thought it would be a good idea to build everything by myself according to the <a href=\"https://mesos.apache.org/gettingstarted/\" rel=\"nofollow\">getting started guide</a>. But know I get the following error:</p>\n\n<pre><code>$ python hello_mesos.py \nTraceback (most recent call last):\n  File \"hello_mesos.py\", line 7, in &lt;module&gt;\n    from mesos.native import MesosExecutorDriver, MesosSchedulerDriver\n  File \"/usr/lib/python2.7/site-packages/mesos.native-0.23.0-py2.7.egg/mesos/native/__init__.py\", line 17, in &lt;module&gt;\n    from ._mesos import MesosExecutorDriverImpl\nImportError: libsvn_delta-1.so.1: cannot open shared object file: No such file or directory\n</code></pre>\n\n<p>When I tried to built it from source I got this warning and the following error:</p>\n\n<p>../configure</p>\n\n<pre><code>checking whether we can build usable Python eggs... In file included from /usr/include/limits.h:26:0,\n                 from /usr/lib/gcc/x86_64-redhat-linux/4.8.3/include/limits.h:168,\n                 from /usr/lib/gcc/x86_64-redhat-linux/4.8.3/include/syslimits.h:7,\n                 from /usr/lib/gcc/x86_64-redhat-linux/4.8.3/include/limits.h:34,\n                 from /usr/include/python2.7/Python.h:19,\n                 from testpyegg.cpp:1:\n/usr/include/features.h:330:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]\n #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)\n    ^\n</code></pre>\n\n<p>make:</p>\n\n<pre><code>g++: internal compiler error: Killed (program cc1plus)\nPlease submit a full bug report,\nwith preprocessed source if appropriate.\nSee &lt;http://bugzilla.redhat.com/bugzilla&gt; for instructions.\nmake[2]: *** [master/libmesos_no_3rdparty_la-master.lo] Error 1\nmake[2]: Leaving directory `/root/mesos-0.23.0/build/src'\nmake[1]: *** [all] Error 2\nmake[1]: Leaving directory `/root/mesos-0.23.0/build/src'\nmake: *** [all-recursive] Error 1\n</code></pre>\n\n<p>Did I missed something?</p>\n", "is_answered": true, "title": "Run own python framework on Mesos 0.23.0 on CentOS 7.1", "last_edit_date": 1440085044, "tags": ["python", "python-2.7", "mesos", "mesosphere"], "view_count": 871, "accepted_answer_id": 32122483, "last_activity_date": 1440085044, "answers": [{"body": "<p>I suppose your packages are broken, and you better to install things from packages. I had used the following sequence to mitigate problem:</p>\n\n<pre><code># Fetch the Apache Maven repo file.\n$ sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo\n\n# 'Mesos &gt; 0.21.0' requires 'subversion &gt; 1.8' devel package, which is\n# not available in the default repositories.\n# Add the WANdisco SVN repo file: '/etc/yum.repos.d/wandisco-svn.repo' with content:\n\n  [WANdiscoSVN]\n  name=WANdisco SVN Repo 1.9\n  enabled=1\n  baseurl=http://opensource.wandisco.com/centos/7/svn-1.9/RPMS/$basearch/\n  gpgcheck=1\n  gpgkey=http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco\n\n# Install essential development tools.\n$ sudo yum groupinstall -y \"Development Tools\"\n\n# Install other Mesos dependencies.\n$ sudo yum install -y apache-maven python-devel java-1.7.0-openjdk-devel zlib-devel libcurl-devel openssl-devel cyrus-sasl-devel cyrus-sasl-md5 apr-devel subversion-devel apr-util-devel\n</code></pre>\n", "answer_id": 32117607, "last_activity_date": 1440071740, "creation_date": 1440071740, "score": 0, "owner": {"user_id": 1879431, "profile_image": "https://www.gravatar.com/avatar/4a8f0f1d55d90f2fc3a7d946729f8981?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 132, "link": "https://stackoverflow.com/users/1879431/vast-academician", "accept_rate": 50, "display_name": "Vast Academician"}, "is_accepted": false, "question_id": 32115419}, {"body": "<p>I found my mistake. I just missed to install to install the python egg from mesosphere:</p>\n\n<pre><code>wget http://downloads.mesosphere.io/master/centos/7/mesos-0.23.0-py2.7-linux-x86_64.egg\neasy_install mesos-0.23.0-py2.7-linux-x86_64.egg\n</code></pre>\n\n<p>Here ist a <a href=\"http://open.mesosphere.com/downloads/mesos/#apache-mesos-0.23.0\" rel=\"nofollow\">Link</a> to all eggs.</p>\n", "answer_id": 32122483, "last_activity_date": 1440084932, "creation_date": 1440084932, "score": 1, "owner": {"user_id": 2773236, "profile_image": "https://www.gravatar.com/avatar/422d5807a237247f84e06948eaa3b7ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 441, "link": "https://stackoverflow.com/users/2773236/joh-scheuer", "accept_rate": 80, "display_name": "joh.scheuer"}, "is_accepted": true, "question_id": 32115419}], "score": 0, "link": "https://stackoverflow.com/questions/32115419/run-own-python-framework-on-mesos-0-23-0-on-centos-7-1", "answer_count": 2, "owner": {"user_id": 2773236, "profile_image": "https://www.gravatar.com/avatar/422d5807a237247f84e06948eaa3b7ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 441, "link": "https://stackoverflow.com/users/2773236/joh-scheuer", "accept_rate": 80, "display_name": "joh.scheuer"}, "creation_date": 1440065354, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 32115419}{"is_answered": false, "tags": ["load-balancing", "haproxy", "marathon", "dcos", "internal-load-balancer"], "title": "Can&#39;t Connect to Service via Marathon-lb using DCOS", "last_activity_date": 1497647124, "answer_count": 0, "creation_date": 1497647124, "score": 0, "link": "https://stackoverflow.com/questions/44597980/cant-connect-to-service-via-marathon-lb-using-dcos", "owner": {"user_id": 7436386, "profile_image": "https://www.gravatar.com/avatar/3a0addf9439fc316497027d8f5800c34?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7436386/st33l3rf4n", "display_name": "st33l3rf4n"}, "view_count": 35, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44597980}{"is_answered": true, "tags": ["azure", "apache-spark", "cassandra", "mesos", "dcos"], "last_edit_date": 1481280765, "title": "How to run spark + cassandra + mesos (dcos) with dynamic resource allocation?", "last_activity_date": 1481551604, "answer_count": 2, "creation_date": 1481267471, "score": 1, "link": "https://stackoverflow.com/questions/41054952/how-to-run-spark-cassandra-mesos-dcos-with-dynamic-resource-allocation", "accepted_answer_id": 41102677, "owner": {"user_id": 1617419, "profile_image": "https://www.gravatar.com/avatar/0c8e55efd0452509a6de89349023ddbd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 263, "link": "https://stackoverflow.com/users/1617419/jan-pavtel", "display_name": "Jan Pavtel"}, "view_count": 393, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41054952}{"body": "<p>I have an Azure Container Service (ACS) cluster that's been provisioned using the Mesosphere DC/OS orchestration option. I can create an application within the Marathon UI just fine.</p>\n\n<p>However, when I go through the Marathon UI to \"Scale Application\" and attempt to increase the instance count it give me the following error message:</p>\n\n<pre><code>Error Scaling Application\nError scaling /app: Please specify data in JSON format\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/qse7S.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/qse7S.png\" alt=\"enter image description here\"></a></p>\n\n<p>I can not seem to find any documentation for Marathon that specifies what this error means. The Marathon UI only allows you to enter a number of instances and it handles the rest for you in an automated fashion.</p>\n\n<p>What JSON is it referring to?\nIs there something that might be messed up with the install? I did use Azure to provision this for me so it's not something I messed up manually...</p>\n\n<p>I would really appreciate the help. Thanks!</p>\n", "is_answered": true, "title": "Marathon gives Error Scaling Application, says \"please specify data in JSON format\"", "last_edit_date": 1466226739, "tags": ["azure", "mesos", "marathon", "dcos", "azure-container-service"], "view_count": 95, "accepted_answer_id": 37893468, "last_activity_date": 1466226739, "answers": [{"body": "<p>The JSON Marathon is referring to above is called the Marathon app specification, see <a href=\"https://mesosphere.github.io/marathon/docs/application-basics.html\" rel=\"nofollow noreferrer\">here</a> for a basic example. This app spec defines what and how many instances of it you want to launch, with which required resources, placement constraints, what health checking and deployment strategies, etc. </p>\n\n<p>You can see that app spec in raw mode when switching to JSON mode:\n<a href=\"https://i.stack.imgur.com/FitgS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FitgS.png\" alt=\"enter image description here\"></a></p>\n\n<p>The semantics as well as all schema-level things are implicitly defined via the <a href=\"https://mesosphere.github.io/marathon/docs/generated/api.html\" rel=\"nofollow noreferrer\">HTTP API</a> and there's also tooling available to <a href=\"https://github.com/dcos-labs/marathon-validate\" rel=\"nofollow noreferrer\">validate the JSON schema</a>.</p>\n", "answer_id": 37893468, "last_activity_date": 1466226557, "creation_date": 1466226557, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 37890796}], "score": 0, "link": "https://stackoverflow.com/questions/37890796/marathon-gives-error-scaling-application-says-please-specify-data-in-json-form", "answer_count": 1, "owner": {"user_id": 7831, "profile_image": "https://www.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 18301, "link": "https://stackoverflow.com/users/7831/chris-pietschmann", "accept_rate": 96, "display_name": "Chris Pietschmann"}, "creation_date": 1466199873, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 37890796}{"body": "<p>I have a dc/os cluster deployed to azure. I have deployed to the cluster a container with my java application. But I can't access it via jmx.</p>\n\n<p>Let's take the example of deploying a standart tomcat image:</p>\n\n<p>1) I opened a port 8081 according the next instruction: <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access#open-a-port-portal\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access#open-a-port-portal</a>.</p>\n\n<p>2) I deployed service using the next json:</p>\n\n<pre><code>{\n  \"id\": \"/tomcat\",\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 512,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"tomcat:8.0\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"protocol\": \"tcp\", \"hostPort\": 8080   , \"containerPort\": 8080 },\n        { \"protocol\": \"tcp\", \"hostPort\": 8081   , \"containerPort\": 8081 }\n      ]\n    }\n  },\n  \"requirePorts\": true,\n  \"acceptedResourceRoles\": [\n    \"slave_public\"\n  ],\n  \"env\": {      \n    \"JAVA_OPTS\": \"-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=10.0.0.4 -Dcom.sun.management.jmxremote.port=8081 -Dcom.sun.management.jmxremote.rmi.port=8081 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n  },\n  \"healthChecks\": [\n    {\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 30,\n      \"maxConsecutiveFailures\": 3,\n      \"path\": \"/\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    }\n  ]\n}\n</code></pre>\n\n<p>To connect I use Oracle Java Mission Control. I fill fields 'Host' and 'Port' as 'prefixagents.westeurope.cloudapp.azure.com' and '8081'. But I can't connect and I get a message: 'Unable to connect'.</p>\n\n<p>But for all that I can succesfully connect to this port using telnet client: </p>\n\n<p><code>telnet prefixagents.westeurope.cloudapp.azure.com 8081</code></p>\n\n<p>Also I can connect to port 8080 and I can open tomcat web console at the following URL: http://agents.westeurope.cloudapp.azure.com:8080</p>\n\n<p>I installed one more jmx command line client - <a href=\"http://wiki.cyclopsgroup.org/jmxterm/\" rel=\"nofollow noreferrer\">http://wiki.cyclopsgroup.org/jmxterm/</a> and tried to connect to the service:</p>\n\n<pre><code>java -jar jmxterm-1.0-alpha-4-uber.jar  --url service:jmx:rmi:///jndi/rmi://&lt;prefix&gt;agents.westeurope.cloudapp.azure.com:8081/jmxrmi\n</code></pre>\n\n<p>I got the next exception: \"java.rmi.ConnectException: Connection refused to host: 10.0.0.4\". And 10.0.0.4 is hostname of my public agents node.</p>\n\n<p>I connected to my dc/os cluster ( master node ) using <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-connect\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-connect</a>. I also installed there jmxterm and tried to connect to the service via jmx:</p>\n\n<pre><code>java -jar jmxterm.jar --url service:jmx:rmi:///jndi/rmi://10.0.0.4:8081/jmxrmi\n</code></pre>\n\n<p>And I connected succesfully.</p>\n\n<p>Does anybody have any ideas why I can connect to the service via jmx from my master node but I can't from my local machine? Port 8081 is opened.</p>\n", "is_answered": true, "title": "DC/OS JMX Access", "tags": ["java", "azure", "docker", "jmx", "dcos"], "last_activity_date": 1496803297, "accepted_answer_id": 44390261, "creation_date": 1496677768, "answers": [{"body": "<blockquote>\n  <p>Does anybody have any ideas why I can connect to the service via jmx\n  from my master node but I can't from my local machine? Port 8081 is\n  opened.</p>\n</blockquote>\n\n<p>You should connect jmx as the following command.</p>\n\n<pre><code>java -jar jmxterm.jar --url service:jmx:rmi:///jndi/rmi://&lt;agent public IP&gt;:8081/jmxrmi \n</code></pre>\n\n<p>Update:</p>\n\n<p>hostname should be <code>public agent ip</code>, then you could connect jmx from your local PC.</p>\n", "answer_id": 44380854, "last_activity_date": 1496803297, "creation_date": 1496719024, "score": 1, "owner": {"user_id": 6997262, "profile_image": "https://www.gravatar.com/avatar/fbad57a52de9c231e494995eebd51f2a?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6138, "link": "https://stackoverflow.com/users/6997262/walter-msft", "display_name": "Walter - MSFT"}, "is_accepted": false, "last_edit_date": 1496803297, "question_id": 44372719}, {"body": "<p>I changed a value of property -Djava.rmi.server.hostname in JAVA_OPTS string: -Djava.rmi.server.hostname=\"public agent ip\". And it works for me.\nWorking configuration for a standart tomcat container in case that port 8081 is open:</p>\n\n<pre><code>{\n  \"id\": \"/tomcat\",\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 512,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"tomcat:8.0\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"protocol\": \"tcp\", \"hostPort\": 8080   , \"containerPort\": 8080 },\n        { \"protocol\": \"tcp\", \"hostPort\": 8081   , \"containerPort\": 8081 }\n      ]\n    }\n  },\n  \"requirePorts\": true,\n  \"acceptedResourceRoles\": [\n    \"slave_public\"\n  ],\n  \"env\": {      \n    \"JAVA_OPTS\": \"-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=&lt;public agent ip&gt; -Dcom.sun.management.jmxremote.port=8081 -Dcom.sun.management.jmxremote.rmi.port=8081 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n  },\n  \"healthChecks\": [\n    {\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 30,\n      \"maxConsecutiveFailures\": 3,\n      \"path\": \"/\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    }\n  ]\n}\n</code></pre>\n\n<p>And I can connect to tomcat via jmx using from local machine: host=\"public agent ip\" and port=8081</p>\n\n<p>public agent ip = \"prefix\"agents.westeurope.cloudapp.azure.com</p>\n", "answer_id": 44390261, "last_activity_date": 1496752763, "creation_date": 1496752763, "score": 2, "owner": {"user_id": 1762235, "profile_image": "https://www.gravatar.com/avatar/dc7c67de0d402c845d12fbdc58967dd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 57, "link": "https://stackoverflow.com/users/1762235/andryusha2006", "accept_rate": 83, "display_name": "Andryusha2006"}, "is_accepted": true, "question_id": 44372719}], "score": 2, "link": "https://stackoverflow.com/questions/44372719/dc-os-jmx-access", "answer_count": 2, "owner": {"user_id": 1762235, "profile_image": "https://www.gravatar.com/avatar/dc7c67de0d402c845d12fbdc58967dd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 57, "link": "https://stackoverflow.com/users/1762235/andryusha2006", "accept_rate": 83, "display_name": "Andryusha2006"}, "view_count": 102, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44372719}{"is_answered": true, "tags": ["docker", "mesos", "mesosphere"], "last_edit_date": 1433830763, "title": "How to install docker daemon when resizing data center cluster size in Mesosphere?", "last_activity_date": 1435211512, "answer_count": 1, "creation_date": 1433758360, "score": 0, "link": "https://stackoverflow.com/questions/30706419/how-to-install-docker-daemon-when-resizing-data-center-cluster-size-in-mesospher", "accepted_answer_id": 31042206, "owner": {"user_id": 398441, "profile_image": "https://www.gravatar.com/avatar/a8950160c2b3d7d0bf948d8c1f937e7f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 8502, "link": "https://stackoverflow.com/users/398441/johan", "accept_rate": 86, "display_name": "Johan"}, "view_count": 187, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 30706419}{"body": "<p>Docker Volume plugins are released with Docker 1.8. I am trying to run a Docker container using Mesos/Marathon and I am able to run Docker container with volumes. What I am not able to do is connecting an external volume plugin. </p>\n\n<p>As per marathon documentation any external parameter for Docker run can be passed as key value pair in the \"parameter\" tag of Marathon API POST. </p>\n\n<p>The Docker container does come up but is not connecting to my plugin for volume. The JSON file is as below. I am using curl connecting to Marathon. Any help is appreciated.</p>\n\n<pre><code>curl -X POST http://A.B.C.D:8080/v2/apps -d @mygoserver.json -H \"Content-type: application/json\"\n\n\n{\n  \"id\": \"basic1\",\n  \"cmd\": \"/mygoserver\",\n  \"cpus\": 1,\n  \"mem\": 2.0,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"mygoserver\"\n    },\n    \"parameters\": [\n                { \"key\": \"volume-driver\", \"value\": \"testplugin\" }\n    ],\n   \"volumes\": [\n      {\n        \"containerPath\": \"/data\",\n        \"hostPath\": \"mygoserver\",\n        \"mode\": \"RW\"\n      }\n    ]\n  }\n}\n</code></pre>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1440484893, "title": "Docker volume plugin marathon", "last_activity_date": 1440513584, "answer_count": 1, "creation_date": 1440440741, "score": 0, "link": "https://stackoverflow.com/questions/32189172/docker-volume-plugin-marathon", "answers": [{"body": "<p>As per <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">Marathon doc</a>, the <code>parameters</code> have to be specified as a child of <code>docker</code>, so in your case it would be:</p>\n\n<pre><code>\"container\": {\n\"type\": \"DOCKER\",\n\"docker\": {\n  \"image\": \"mygoserver\"\n  \"parameters\": [\n    { \"key\": \"volume-driver\", \"value\": \"testplugin\" }\n  ],\n},\n</code></pre>\n\n<p>...</p>\n", "answer_id": 32207037, "last_activity_date": 1440513584, "creation_date": 1440513584, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 32189172}], "owner": {"user_id": 5054802, "profile_image": "https://graph.facebook.com/851031298321131/picture?type=large", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/5054802/vaibhav-khanduja", "accept_rate": 11, "display_name": "Vaibhav Khanduja"}, "view_count": 623, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32189172}{"is_answered": false, "tags": ["cassandra", "mesosphere", "dcos"], "last_edit_date": 1463082124, "title": "Mesosphere DC/OS with existing Cassandra cluster", "last_activity_date": 1463082124, "answer_count": 0, "creation_date": 1463076592, "score": 2, "link": "https://stackoverflow.com/questions/37194488/mesosphere-dc-os-with-existing-cassandra-cluster", "owner": {"user_id": 2542922, "profile_image": "https://i.stack.imgur.com/tYjvN.png?s=128&g=1", "user_type": "registered", "reputation": 891, "link": "https://stackoverflow.com/users/2542922/cscan", "accept_rate": 73, "display_name": "cscan"}, "view_count": 56, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37194488}{"body": "<p>I've been tasked with evaluating container management solutions. I'm aware there is a large number or options, but we need production ready, on premises solution. What are the options?</p>\n", "is_answered": true, "title": "What on premises container management solutions are there?", "tags": ["docker", "kubernetes", "mesosphere", "docker-swarm"], "last_activity_date": 1447522726, "accepted_answer_id": 33711326, "creation_date": 1447506944, "answers": [{"body": "<p>In descending order, from most mature and battle-tested at scale to less so:</p>\n\n<ul>\n<li><a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">Marathon</a>, a Apache Mesos framework</li>\n<li><a href=\"http://kubernetes.io/v1.1/\" rel=\"nofollow\">Kubernetes</a></li>\n<li><a href=\"http://blog.docker.com/2015/11/swarm-1-0/\" rel=\"nofollow\">Docker Swarm</a></li>\n<li>HashiCorp's <a href=\"https://www.nomadproject.io/\" rel=\"nofollow\">Nomad</a></li>\n</ul>\n", "answer_id": 33711326, "last_activity_date": 1447522726, "creation_date": 1447522726, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 33708797}], "score": 1, "link": "https://stackoverflow.com/questions/33708797/what-on-premises-container-management-solutions-are-there", "answer_count": 1, "owner": {"user_id": 1055223, "profile_image": "https://www.gravatar.com/avatar/8ef9b246d584f59d86baf4ff12c88627?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 496, "link": "https://stackoverflow.com/users/1055223/alex-collins", "accept_rate": 92, "display_name": "Alex Collins"}, "view_count": 107, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33708797}{"body": "<p>After setting 3 controllers to include mesos-master, mesos-slave and zookeeper. Marathon was started in last after 3 services run completed. I found INFO message at Marathon log as below</p>\n\n<pre><code>[2017-04-07 15:48:32,291] INFO Acknowledge status update for task service-dev_mysql-serv.a396a075-1ba9-11e7-ab7a-0242ac120004: TASK_FAILED (Failed to run docker container: Port mappings are only supported for bridge and user-defined networks) (mesosphere.marathon.core.task.update.impl.TaskStatusUpdateProcessorImpl:ForkJoinPool-3-worker-13)\n</code></pre>\n\n<p>Start for starting application on Zookeeper.</p>\n\n<p>Zookeeper</p>\n\n<pre><code>$sudo docker run -it --net=host --name=zookeeper netflixoss/exhibitor:1.5.2\n</code></pre>\n\n<p>Mesos-master connects to Zookeeper by command line.</p>\n\n<pre><code>$sudo docker run -it --net=host \\\n--name jdb-network-mesos-master \\\n-e MESOS_PORT=5050 \\\n-e MESOS_ZK=zk://192.168.1.68:2181/mesos \\\n-e MESOS_QUORUM=1 \\\n-e MESOS_REGISTRY=in_memory \\\n-e MESOS_LOG_DIR=/var/log/mesos \\\n-e MESOS_WORK_DIR=/var/tmp/mesos \\\n-v \"$(pwd)/log/mesos:/var/log/mesos\" \\\n-v \"$(pwd)/tmp/mesos:/var/tmp/mesos\" \\\n-p 15050:5050 \\\n-p 12181:2181 \\\ndocker.io/mesosphere/mesos-master:1.1.1-rc2\n</code></pre>\n\n<p>Mesos-Slave runing to prepare states for Marathon by specified the resource port <code>ports:[2000-9000,20000-34000]</code>. </p>\n\n<p>*MESOS-SALVE</p>\n\n<pre><code>$sudo docker run -it --net=host --privileged \\\n--name jdb-network-mesos-slave \\\n-e MESOS_PORT=5051 \\\n-e MESOS_MASTER=zk://192.168.1.68:2181/mesos \\\n-e MESOS_SWITCH_USER=0 \\\n-e MESOS_CONTAINERIZERS=docker,mesos \\\n-e MESOS_LOG_DIR=/var/log/mesos-slave \\\n-e MESOS_WORK_DIR=/var/tmp/mesos-slave \\\n-e MESOS_executor_registration_timeout=10mins \\\n-e MESOS_resources='ports:[2000-9000,20000-34000]' \\\n-e MESOS_launcher=posix \\\n-v \"$(pwd)/log/mesos-slave:/var/log/mesos\" \\\n-v \"$(pwd)/tmp/mesos-slave:/var/tmp/mesos\" \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-v /sys:/sys \\\n-v /cgroup:/cgroup \\\n-v /usr/local/bin/docker:/usr/local/bin/docker \\\n-v /lib64/libdevmapper.so.1.02:/lib/libdevmapper.so.1.02:ro \\\n-p 25051:5051 \\\n-p 22181:2181 \\\nmesosphere/mesos-slave:1.1.1-rc2\n</code></pre>\n\n<p>Application can connect completed between master and slave services. Zookeeper show is normal logs. Marathon run with command line below.</p>\n\n<pre><code>$sudo docker run -it \\\n                 --name jdb-network-marathon \\\n                 --rm \\\n                 --net=host \\\n                 -e MESOS_WORK_DIR=/var/lib/mesos \\\n                 -p 7070:7070 -p 32181:2181 \\\n                 --entrypoint=bash mesosphere/marathon:latest-dev\nroot-marathon(docker-container)$./bin/start \\\n                 --master zk://192.168.1.68:2181/mesos \\\n                 --zk zk://192.168.1.68:2181/marathon \\\n                 --http_port=7070\n</code></pre>\n\n<p>Json for creating container in docker is</p>\n\n<pre><code>{\n   \"id\":\"/service-dev/mysql-service\",\n   \"cmd\":null,\n   \"cpus\":1,\n   \"mem\":512,\n   \"disk\":512,\n   \"instances\":1,\n   \"container\":{\n      \"docker\":{\n         \"image\":\"mysql\",\n         \"network\":\"BRIDGE\",\n         \"portMappings\":[\n            {\n               \"containerPort\":3306,\n               \"hostPort\":31036,\n               \"protocol\":\"tcp\",\n               \"name\":null,\n               \"labels\":null\n            }\n         ]\n      },\n      \"type\":\"DOCKER\"\n   }\n}\n</code></pre>\n\n<p>Marathon-UI run on port localhost:7070/ui/ show <em>Delayed</em> and <em>Wait</em> status of application. I attach full message information creates by Marathon is</p>\n\n<pre><code>[2017-04-07 15:48:26,563] INFO Computed new deployment plan:\nDeploymentPlan id=f210ab3f-c143-4aad-b051-186646b44e26,2017-04-07T15:48:26.558Z\nstep 1:\nRestart(App(/service-dev/mysql-serv, image=\"mysql\"List())))\n(mesosphere.marathon.core.group.impl.GroupManagerImpl:ForkJoinPool-3-worker-1)\n[2017-04-07 15:48:26,582] INFO Deploy plan with force=false:\nDeploymentPlan id=f210ab3f-c143-4aad-b051-186646b44e26,2017-04-07T15:48:26.558Z\nstep 1:\nRestart(App(/service-dev/mysql-serv, image=\"mysql\"List())))\n(mesosphere.marathon.MarathonSchedulerService:ForkJoinPool-3-worker-39)\n[2017-04-07 15:48:26,582] INFO Received new deployment plan f210ab3f-c143-4aad-b051-186646b44e26, no conflicts detected (mesosphere.marathon.core.deployment.impl.DeploymentManagerActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:26,586] INFO Stored new deployment plan f210ab3f-c143-4aad-b051-186646b44e26 (mesosphere.marathon.core.deployment.impl.DeploymentManagerActor:marathon-akka.actor.default-dispatcher-23)\n[2017-04-07 15:48:26,586] INFO Launching DeploymentActor for f210ab3f-c143-4aad-b051-186646b44e26 (mesosphere.marathon.core.deployment.impl.DeploymentManagerActor:marathon-akka.actor.default-dispatcher-23)\n[2017-04-07 15:48:26,595] INFO Updated groups/apps/pods according to plan f210ab3f-c143-4aad-b051-186646b44e26 (mesosphere.marathon.core.group.impl.GroupManagerImpl:ForkJoinPool-3-worker-21)\n[2017-04-07 15:48:26,595] INFO Deployment acknowledged. Waiting to get processed:\nDeploymentPlan id=f210ab3f-c143-4aad-b051-186646b44e26,2017-04-07T15:48:26.558Z\nstep 1:\nRestart(App(/service-dev/mysql-serv, image=\"mysql\"List())))\n(mesosphere.marathon.core.group.impl.GroupManagerImpl:ForkJoinPool-3-worker-27)\n[2017-04-07 15:48:26,595] INFO 192.168.1.70 - - [07/Apr/2017:15:48:26 +0000] \"PUT //192.168.1.68:7070/v2/apps//service-dev/mysql-serv HTTP/1.1\" 200 92 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" 4 (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-459)\n[2017-04-07 15:48:26,596] INFO For minimumHealthCapacity 1.0 of /service-dev/mysql-serv leave 1 instances running, maximum capacity 2, killing 0 of 0 running instances immediately. (RunSpec version 2017-04-07T15:48:26.558Z) (mesosphere.marathon.core.deployment.impl.TaskReplaceActor$:marathon-akka.actor.default-dispatcher-6)\n[2017-04-07 15:48:26,601] INFO reconcile: found 0 already started instances and 0 old instances (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:26,602] INFO Reconciling instances during app /service-dev/mysql-serv restart: queuing 1 new instances (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:26,602] INFO Started instanceLaunchActor for /service-dev/mysql-serv version 2017-04-07T15:48:26.558Z with initial count 1 (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:26,603] INFO activating matcher ActorOfferMatcher(Actorakka://marathon/user/launchQueue/1/9-service-dev_mysql-serv#1478068544). (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,603] INFO Resetting the backoff delay before restarting the runSpec (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,603] INFO Received offers WANTED notification (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,603] INFO =&gt; revive offers NOW, canceling any scheduled revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,604] INFO 2 further revives still needed. Repeating reviveOffers according to --revive_offers_repetitions 3 (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,604] INFO =&gt; Schedule next revive at 2017-04-07T15:48:31.603Z in 5000 milliseconds, adhering to --min_revive_offers_interval 5000 (ms) (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,608] INFO No tasks left to launch. Stop receiving offers for /service-dev/mysql-serv, 2017-04-07T15:48:26.558Z (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,608] INFO removing matcher ActorOfferMatcher(Actorakka://marathon/user/launchQueue/1/9-service-dev_mysql-serv#1478068544) (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:26,608] INFO Received offers NOT WANTED notification, canceling 2 revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-6)\n[2017-04-07 15:48:26,608] INFO =&gt; Suppress offers NOW (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-6)\n[2017-04-07 15:48:26,609] INFO Finished processing 285ef74b-aaa3-44cf-b650-d687fc6e2923-O156 from dc00cb3b8dbd. Matched 1 ops after 2 passes. ports 2000-&gt;9000,20000-&gt;31035,31037-&gt;34000; cpus 15.0; mem 70771.0; disk 4599.0 left. (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:26,609] INFO Processing LaunchEphemeral(Instance(instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004],AgentInfo(dc00cb3b8dbd,Some(285ef74b-aaa3-44cf-b650-d687fc6e2923-S1),Vector()),InstanceState(Created,2017-04-07T15:48:26.608Z,None,None),Map(task [service-dev_mysql-serv.a396a075-1ba9-11e7-ab7a-0242ac120004] -&gt; LaunchedEphemeral(task [service-dev_mysql-serv.a396a075-1ba9-11e7-ab7a-0242ac120004],2017-04-07T15:48:26.558Z,Status(2017-04-07T15:48:26.608Z,None,None,Created,NetworkInfo(dc00cb3b8dbd,Vector(31036),List())))),2017-04-07T15:48:26.558Z,UnreachableEnabled(300 seconds,600 seconds))) for instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004] (mesosphere.marathon.core.launcher.impl.OfferProcessorImpl:ForkJoinPool-3-worker-9)\n[2017-04-07 15:48:26,735] INFO 192.168.1.70 - - [07/Apr/2017:15:48:26 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions HTTP/1.1\" 200 119 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-268)\n[2017-04-07 15:48:26,881] INFO 192.168.1.70 - - [07/Apr/2017:15:48:26 +0000] \"GET //192.168.1.68:7070/v2/queue HTTP/1.1\" 200 32 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-226)\n[2017-04-07 15:48:26,881] INFO 192.168.1.70 - - [07/Apr/2017:15:48:26 +0000] \"GET //192.168.1.68:7070/v2/deployments HTTP/1.1\" 200 228 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-483)\n[2017-04-07 15:48:26,882] INFO 192.168.1.70 - - [07/Apr/2017:15:48:26 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv?embed=app.taskStats&amp;embed=app.readiness HTTP/1.1\" 200 898 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-477)\n[2017-04-07 15:48:27,061] INFO 192.168.1.70 - - [07/Apr/2017:15:48:27 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions HTTP/1.1\" 200 119 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-513)\n[2017-04-07 15:48:27,062] INFO 192.168.1.70 - - [07/Apr/2017:15:48:27 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions/2017-04-07T15:48:26.558Z HTTP/1.1\" 200 472 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-498)\n[2017-04-07 15:48:31,758] INFO 192.168.1.70 - - [07/Apr/2017:15:48:31 +0000] \"GET //192.168.1.68:7070/v2/queue HTTP/1.1\" 200 32 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-226)\n[2017-04-07 15:48:31,759] INFO 192.168.1.70 - - [07/Apr/2017:15:48:31 +0000] \"GET //192.168.1.68:7070/v2/deployments HTTP/1.1\" 200 228 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-459)\n[2017-04-07 15:48:31,759] INFO 192.168.1.70 - - [07/Apr/2017:15:48:31 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv?embed=app.taskStats&amp;embed=app.readiness HTTP/1.1\" 200 898 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-268)\n[2017-04-07 15:48:31,805] INFO 192.168.1.70 - - [07/Apr/2017:15:48:31 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions/2017-04-07T15:48:26.558Z HTTP/1.1\" 200 472 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-477)\n[2017-04-07 15:48:31,808] INFO 192.168.1.70 - - [07/Apr/2017:15:48:31 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions HTTP/1.1\" 200 119 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-483)\n[2017-04-07 15:48:32,285] INFO Received status update for task service-dev_mysql-serv.a396a075-1ba9-11e7-ab7a-0242ac120004: TASK_FAILED (Failed to run docker container: Port mappings are only supported for bridge and user-defined networks) (mesosphere.marathon.MarathonScheduler:Thread-407)\n[2017-04-07 15:48:32,287] INFO all tasks of instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004] are terminal, requesting to expunge (mesosphere.marathon.core.instance.update.InstanceUpdater$:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:32,289] INFO Removed app [/service-dev/mysql-serv] from tracker (mesosphere.marathon.core.task.tracker.InstanceTracker$InstancesBySpec$:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:32,290] INFO Increasing delay. Task launch delay for [/service-dev/mysql-serv] changed from [0 milliseconds] to [1 seconds]. (mesosphere.marathon.core.launchqueue.impl.RateLimiter$:marathon-akka.actor.default-dispatcher-19)\n[2017-04-07 15:48:32,290] INFO receiveInstanceUpdate: instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004] was deleted (Failed) (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-25)\n[2017-04-07 15:48:32,291] INFO initiating a scale check for runSpec [/service-dev/mysql-serv] due to [instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004]] Failed (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:32,291] INFO Acknowledge status update for task service-dev_mysql-serv.a396a075-1ba9-11e7-ab7a-0242ac120004: TASK_FAILED (Failed to run docker container: Port mappings are only supported for bridge and user-defined networks) (mesosphere.marathon.core.task.update.impl.TaskStatusUpdateProcessorImpl:ForkJoinPool-3-worker-13)\n[2017-04-07 15:48:32,296] ERROR New instance instance [service-dev_mysql-serv.marathon-a396a075-1ba9-11e7-ab7a-0242ac120004] failed on agent Some(285ef74b-aaa3-44cf-b650-d687fc6e2923-S1) during app /service-dev/mysql-serv restart (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-27)\n[2017-04-07 15:48:32,297] INFO Reconciling instances during app /service-dev/mysql-serv restart: queuing 1 new instances (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-27)\n[2017-04-07 15:48:32,297] INFO add 1 instances to 0 instances to launch (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-27)\n[2017-04-07 15:48:33,307] INFO activating matcher ActorOfferMatcher(Actorakka://marathon/user/launchQueue/1/9-service-dev_mysql-serv#1478068544). (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:33,307] INFO Received offers WANTED notification (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:33,307] INFO =&gt; revive offers NOW, canceling any scheduled revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:33,307] INFO 2 further revives still needed. Repeating reviveOffers according to --revive_offers_repetitions 3 (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:33,307] INFO =&gt; Schedule next revive at 2017-04-07T15:48:38.307Z in 5000 milliseconds, adhering to --min_revive_offers_interval 5000 (ms) (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:33,311] INFO No tasks left to launch. Stop receiving offers for /service-dev/mysql-serv, 2017-04-07T15:48:26.558Z (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:33,311] INFO removing matcher ActorOfferMatcher(Actorakka://marathon/user/launchQueue/1/9-service-dev_mysql-serv#1478068544) (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-7)\n[2017-04-07 15:48:33,311] INFO Received offers NOT WANTED notification, canceling 2 revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-4)\n[2017-04-07 15:48:33,311] INFO =&gt; Suppress offers NOW (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-4)\n[2017-04-07 15:48:33,312] INFO Finished processing 285ef74b-aaa3-44cf-b650-d687fc6e2923-O157 from dc00cb3b8dbd. Matched 1 ops after 2 passes. ports 2000-&gt;9000,20000-&gt;31035,31037-&gt;34000; cpus 15.0; mem 70771.0; disk 4599.0 left. (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-4)\n[2017-04-07 15:48:33,312] INFO Processing LaunchEphemeral(Instance(instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004],AgentInfo(dc00cb3b8dbd,Some(285ef74b-aaa3-44cf-b650-d687fc6e2923-S1),Vector()),InstanceState(Created,2017-04-07T15:48:33.311Z,None,None),Map(task [service-dev_mysql-serv.a7956c66-1ba9-11e7-ab7a-0242ac120004] -&gt; LaunchedEphemeral(task [service-dev_mysql-serv.a7956c66-1ba9-11e7-ab7a-0242ac120004],2017-04-07T15:48:26.558Z,Status(2017-04-07T15:48:33.311Z,None,None,Created,NetworkInfo(dc00cb3b8dbd,Vector(31036),List())))),2017-04-07T15:48:26.558Z,UnreachableEnabled(300 seconds,600 seconds))) for instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004] (mesosphere.marathon.core.launcher.impl.OfferProcessorImpl:ForkJoinPool-3-worker-31)\n[2017-04-07 15:48:36,753] INFO 192.168.1.70 - - [07/Apr/2017:15:48:36 +0000] \"GET //192.168.1.68:7070/v2/queue HTTP/1.1\" 200 32 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-498)\n[2017-04-07 15:48:36,753] INFO 192.168.1.70 - - [07/Apr/2017:15:48:36 +0000] \"GET //192.168.1.68:7070/v2/deployments HTTP/1.1\" 200 228 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-513)\n[2017-04-07 15:48:36,754] INFO 192.168.1.70 - - [07/Apr/2017:15:48:36 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv?embed=app.taskStats&amp;embed=app.readiness HTTP/1.1\" 200 891 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-226)\n[2017-04-07 15:48:36,810] INFO 192.168.1.70 - - [07/Apr/2017:15:48:36 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions HTTP/1.1\" 200 119 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-268)\n[2017-04-07 15:48:36,811] INFO 192.168.1.70 - - [07/Apr/2017:15:48:36 +0000] \"GET //192.168.1.68:7070/v2/apps//service-dev/mysql-serv/versions/2017-04-07T15:48:26.558Z HTTP/1.1\" 200 472 \"http://192.168.1.68:7070/ui/\" \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\" (mesosphere.chaos.http.ChaosRequestLog:qtp731256267-459)\n[2017-04-07 15:48:39,015] INFO Received status update for task service-dev_mysql-serv.a7956c66-1ba9-11e7-ab7a-0242ac120004: TASK_FAILED (Failed to run docker container: Port mappings are only supported for bridge and user-defined networks) (mesosphere.marathon.MarathonScheduler:Thread-409)\n[2017-04-07 15:48:39,016] INFO all tasks of instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004] are terminal, requesting to expunge (mesosphere.marathon.core.instance.update.InstanceUpdater$:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:39,018] INFO Removed app [/service-dev/mysql-serv] from tracker (mesosphere.marathon.core.task.tracker.InstanceTracker$InstancesBySpec$:marathon-akka.actor.default-dispatcher-4)\n[2017-04-07 15:48:39,018] INFO Increasing delay. Task launch delay for [/service-dev/mysql-serv] changed from [-728 milliseconds] to [1 seconds 150 milliseconds]. (mesosphere.marathon.core.launchqueue.impl.RateLimiter$:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:39,019] INFO receiveInstanceUpdate: instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004] was deleted (Failed) (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:39,019] ERROR New instance instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004] failed on agent Some(285ef74b-aaa3-44cf-b650-d687fc6e2923-S1) during app /service-dev/mysql-serv restart (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:39,019] INFO Reconciling instances during app /service-dev/mysql-serv restart: queuing 1 new instances (mesosphere.marathon.core.deployment.impl.TaskReplaceActor:marathon-akka.actor.default-dispatcher-16)\n[2017-04-07 15:48:39,019] INFO initiating a scale check for runSpec [/service-dev/mysql-serv] due to [instance [service-dev_mysql-serv.marathon-a7956c66-1ba9-11e7-ab7a-0242ac120004]] Failed (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl:marathon-akka.actor.default-dispatcher-23)\n[2017-04-07 15:48:39,019] INFO add 1 instances to 0 instances to launch (mesosphere.marathon.core.launchqueue.impl.TaskLauncherActor:marathon-akka.actor.default-dispatcher-4)\n[2017-04-07 15:48:39,019] INFO Acknowledge status update for task service-dev_mysql-serv.a7956c66-1ba9-11e7-ab7a-0242ac120004: TASK_FAILED (Failed to run docker container: Port mappings are only supported for bridge and user-defined networks) (mesosphere.marathon.core.task.update.impl.TaskStatusUpdateProcessorImpl:ForkJoinPool-3-worker-1)\n[2017-04-07 15:48:40,187] INFO activating matcher ActorOfferMatcher(Actorakka://marathon/user/launchQueue/1/9-service-dev_mysql-serv#1478068544). (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-10)\n[2017-04-07 15:48:40,187] INFO Received offers WANTED notification (mesosphere.marathon.core.flo\n</code></pre>\n\n<p>Mesos-slave still run in port ranges <code>-e MESOS_resources='ports:[2000-9000,20000-34000]'</code>. JSON define container port 3306 and host port is 31036. It's stay on ranges of port specific number. <strong>What's error meaning in</strong>: <em>\"Port mappings are only supported for bridge and user-defined networks\"</em>?</p>\n", "is_answered": false, "tags": ["mesos", "marathon", "mesosphere"], "last_edit_date": 1491802435, "title": "Marathon show TASK_FAILED Failed to run docker container: Port mappings are only supported for bridge and user-defined networks", "last_activity_date": 1491802435, "answer_count": 0, "creation_date": 1491734206, "score": 0, "link": "https://stackoverflow.com/questions/43305727/marathon-show-task-failed-failed-to-run-docker-container-port-mappings-are-only", "owner": {"user_id": 49462, "profile_image": "https://i.stack.imgur.com/Whscs.jpg?s=128&g=1", "user_type": "registered", "reputation": 52, "link": "https://stackoverflow.com/users/49462/r-chatsiri", "accept_rate": 30, "display_name": "R.Chatsiri"}, "view_count": 56, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43305727}{"body": "<p>I have a streaming job that runs on DC/OS on AWS. When i run the job for the first time, and specify checkpoint folder to be AWS S3, everything goes well.</p>\n\n<p>After I stop it, and start it again, I expect streaming to recover from checkpoint, but I get following error:</p>\n\n<blockquote>\n  <p>ERROR SparkContext: Error initializing SparkContext.\n  java.lang.Exception: spark.executor.extraJavaOptions is not allowed to set Spark options (was '-Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.0-1.6.1-2 '). Set them directly on a SparkConf or in a properties file when using ./bin/spark-submit.</p>\n</blockquote>\n\n<p>I have set recoverable streaming using example from <a href=\"https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\" rel=\"nofollow noreferrer\">https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala</a>,</p>\n\n<p>and connection to S3 for check pointing from: <a href=\"https://stackoverflow.com/questions/33475931/spark-streaming-checkpoint-to-amazon-s3\">Spark Streaming checkpoint to amazon s3</a></p>\n\n<p>Problem that seems to be is that when recreating spark context from checkpoint file, it tries to change <em>spark.mesos.executor.docker.image</em> property, but I do not set this at all.</p>\n\n<p>My spark configuration  is quite simple and looks like this:</p>\n\n<pre><code>val conf = new SparkConf()\n    .setAppName(\"wattio-pipeline\")\n</code></pre>\n\n<p>Did anyone encounter similar issue.</p>\n\n<p><strong>EDITED</strong></p>\n\n<p>I tried setting spark conf in all these ways:</p>\n\n<pre><code>val conf = new SparkConf()\n    .setAppName(\"wattio-pipeline\")\n    .setExecutorEnv(\"SPARK_JAVA_OPTS\",\"\")\n      .remove(\"spark.executor.extraJavaOptions\")\n      .remove(\"spark.mesos.executor.docker.image\")\n    //.set(\"spark.executor.extraJavaOptions\",\"\")\n    //.set(\"spark.mesos.executor.docker.image\",\"mesosphere/spark:1.0.0-1.6.1-2\")\n</code></pre>\n\n<p>But same error appears.</p>\n\n<p><strong>EDITED 2</strong></p>\n\n<p>I have tested the same AWS S3 checkpoint configuration on my local development machine (our own installation of SMACK stack) and streaming recovers correctly. This means that there is error in DCOS spark parameters and properties.</p>\n\n<p>I have also filed JIRA issue: <a href=\"https://dcosjira.atlassian.net/browse/DCOS-131\" rel=\"nofollow noreferrer\">https://dcosjira.atlassian.net/browse/DCOS-131</a> </p>\n", "is_answered": false, "tags": ["apache-spark", "spark-streaming", "mesos", "mesosphere", "dcos"], "last_edit_date": 1495542705, "title": "Spark on DC/OS recover streaming from checkpoint fails", "last_activity_date": 1464279209, "answer_count": 0, "creation_date": 1464000093, "score": 0, "link": "https://stackoverflow.com/questions/37388834/spark-on-dc-os-recover-streaming-from-checkpoint-fails", "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "view_count": 186, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37388834}{"body": "<p><strong>Environment</strong></p>\n\n<p><code>Mesos: 0.26\nKubernetes: 1.3.0\n</code></p>\n\n<p>Anyone out there using Kubernetes-Mesos framework?</p>\n\n<p>Kubernetes-Mesos Question: Does current Kubernetes-Mesos support Kubernetes in HA configuration ? Having multiple Kubernetes masters talking to leader.mesos ? I tried to use it but I've got the following error on my secondary kubernetes master (trying to start <code>km scheduler</code>)</p>\n\n<p><code>\"mesos-master[25014]: I0405 09:54:07.523236 25020 master.cpp:2324] Framework a979cde6-aa86-4286-b07f-e83e9ae4076e-0005 (Kubernetes) at scheduler(1)@10.9.158.237:42819 failed over\"</code></p>\n", "is_answered": true, "title": "Kubernetes-Mesos in HA Configuraiton", "tags": ["kubernetes", "mesos", "mesosphere"], "last_activity_date": 1459866923, "accepted_answer_id": 36429440, "creation_date": 1459865679, "answers": [{"body": "<p>It not supported; only one k8sm scheduler should talk to mesos master. One option is to use Marathon to manage k8sm-xxx daemons, it will re-start k8sm master for failover.</p>\n", "answer_id": 36429440, "last_activity_date": 1459866923, "creation_date": 1459866923, "score": 1, "owner": {"user_id": 5459095, "profile_image": "https://lh6.googleusercontent.com/-GXVoHKG4x18/AAAAAAAAAAI/AAAAAAAAABE/atHidsy_iF0/photo.jpg?sz=128", "user_type": "registered", "reputation": 30, "link": "https://stackoverflow.com/users/5459095/klaus-ma", "accept_rate": 60, "display_name": "Klaus Ma"}, "is_accepted": true, "question_id": 36428928}], "score": 1, "link": "https://stackoverflow.com/questions/36428928/kubernetes-mesos-in-ha-configuraiton", "answer_count": 1, "owner": {"user_id": 2362699, "profile_image": "https://www.gravatar.com/avatar/72ff3403c968926e53a05eb04f35a357?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/2362699/user2362699", "accept_rate": 43, "display_name": "user2362699"}, "view_count": 89, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36428928}{"body": "<p>We built dcos 1.7 cluster in aws using cloud formation template by following \"launch dc/os\" instructions here <a href=\"https://dcos.io/docs/1.7/administration/installing/cloud/aws/\" rel=\"nofollow\">https://dcos.io/docs/1.7/administration/installing/cloud/aws/</a></p>\n\n<p>I tried to run the following query using curl</p>\n\n<pre><code>curl --header \" Authorization: token=xxxxx\" https://{dcos-elb}/service/chronos/scheduler/jobs \n</code></pre>\n\n<p>but got </p>\n\n<pre><code>&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Unauthorized&lt;/title&gt;\n&lt;noscript&gt;&lt;meta http-equiv=\"refresh\" content=\"5; url=/#/login\"&gt;&lt;/noscript&gt;\n&lt;script&gt;\n  (function () {\n    var location = window.location;\n    location.href = \"/#/login?redirect=\" + encodeURIComponent(location.href);\n  }())\n&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n   &lt;h1&gt;Unauthorized&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n\n<p>I obtained the token by following these instructions\n<a href=\"https://dcos.io/docs/1.7/administration/security/managing-authentication/#log-in-cli\" rel=\"nofollow\">https://dcos.io/docs/1.7/administration/security/managing-authentication/#log-in-cli</a></p>\n\n<p>i.e. in browser paste this url: https:///login?redirect_uri=urn:ietf:wg:oauth:2.0:oob, login with google creds and then copy the token</p>\n\n<p>adminrouter logs in master node has following lines</p>\n\n<pre><code>[notice] 31915#0: *8026 [lua] auth.lua:119: validate_jwt_or_exit(): Invalid token. Reason: not enough data, client: xx.xx.xx.xx, server: dcos.*, request: \"GET /service/chronos/scheduler/jobs HTTP/1.1\", host: \"xxxxx\"\n</code></pre>\n\n<p>How can I resolve this issue ?. Do I have to include any extra payload with curl query ?</p>\n\n<p>Any suggestions would be much appreciated. Thanks </p>\n", "is_answered": true, "title": "DCOS 1.7 authentication failure with Invalid token. Reason: not enough data", "tags": ["mesos", "mesosphere", "dcos"], "last_activity_date": 1463602925, "accepted_answer_id": 37309414, "creation_date": 1463548907, "answers": [{"body": "<p>First do,  <code>dcos config show</code>  and check the variable value for <code>core.dcos_url</code> , make sure you are hitting \"HTTP\"  and <strong>NOT</strong> \"HTTPS\".</p>\n\n<p>To make the change, follow the below procedure,</p>\n\n<p>1:) <code>dcos config unset core.dcos_url</code></p>\n\n<p>2:) <code>dcos config set core.dcos_url  &lt;CLuster_URL_Only_HTTP&gt;</code></p>\n\n<p>3:) Finally you can do , <code>dcos auth login</code> </p>\n\n<p>4:) Step (3) will return URL, which you have to paste in Browser and get the Token and paste it on the Cli, where it's waiting for Token.</p>\n", "answer_id": 37309414, "last_activity_date": 1463602925, "creation_date": 1463602925, "score": 2, "owner": {"user_id": 6349265, "profile_image": "https://www.gravatar.com/avatar/ff7698b0440acf9fd725a723b887fe1c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/6349265/himay-desai", "display_name": "Himay Desai"}, "is_accepted": true, "question_id": 37290896}], "score": 1, "link": "https://stackoverflow.com/questions/37290896/dcos-1-7-authentication-failure-with-invalid-token-reason-not-enough-data", "answer_count": 1, "owner": {"user_id": 1569602, "profile_image": "https://www.gravatar.com/avatar/dc2c984e0e0d5db7ce2bd8cd198af69f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 126, "link": "https://stackoverflow.com/users/1569602/nari", "accept_rate": 31, "display_name": "Nari"}, "view_count": 467, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37290896}{"body": "<p>I have a Marathon task that starts a Docker container.  It consistently starts, then exits after about 10 seconds.  I can't figure out why it's exiting.  If I run the exact same Docker command-line directly, the container stays up.  I'd appreciate any debugging tips. I am attaching Mesos Master, Slave , Kernel &amp; Marathon Logs.</p>\n\n<p><strong>Mesos Version:</strong> 0.28.1\n<strong>Marathon:</strong> 1.1.1</p>\n\n<p><strong>Task Details:</strong> cpu 0.5, Memory: 32 MB, Disk Space: 32 MB</p>\n\n<p><strong>Mesos Slave Logs</strong></p>\n\n<pre><code>I0729 13:27:57.324440 12645 slave.cpp:1361] Got assigned task basic-3.29606d60-5562-11e6-82c4-02010a552889 for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:57.327953 12644 gc.cpp:83] Unscheduling '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000' from gc\nI0729 13:27:57.328632 12644 gc.cpp:83] Unscheduling '/tmp/mesos/meta/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000' from gc\nI0729 13:27:57.329421 12645 slave.cpp:1480] Launching task basic-3.29606d60-5562-11e6-82c4-02010a552889 for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:57.330699 12645 paths.cpp:528] Trying to chown '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889/runs/4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8' to user 'root'\nI0729 13:27:57.339612 12645 slave.cpp:5367] Launching executor basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 with resources cpus(*):0.1; mem(*):32 in work directory '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889/runs/4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8'\nI0729 13:27:57.341789 12645 slave.cpp:1698] Queuing task 'basic-3.29606d60-5562-11e6-82c4-02010a552889' for executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:57.350003 12652 docker.cpp:1041] Starting container '4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8' for executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' and framework '09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000'\nE0729 13:27:58.646698 12651 slave.cpp:3773] Container '4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8' for executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 failed to start: Container exited on error: exited with status 1\nI0729 13:27:58.648016 12645 slave.cpp:3879] Executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 has terminated with unknown status\nI0729 13:27:58.648771 12645 slave.cpp:3002] Handling status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 from @0.0.0.0:0\nW0729 13:27:58.650879 12645 docker.cpp:1302] Ignoring updating unknown container: 4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8\nI0729 13:27:58.652117 12651 status_update_manager.cpp:320] Received status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.653165 12651 status_update_manager.cpp:824] Checkpointing UPDATE for status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.658000 12643 slave.cpp:3400] Forwarding the update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 to master@xx.xx.xx.xxx:5050\nI0729 13:27:58.751868 12650 status_update_manager.cpp:392] Received status update acknowledgement (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.752244 12650 status_update_manager.cpp:824] Checkpointing ACK for status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.757303 12652 slave.cpp:3990] Cleaning up executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.757876 12650 gc.cpp:55] Scheduling '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889/runs/4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8' for gc 6.99999123038222days in the future\nI0729 13:27:58.758280 12650 gc.cpp:55] Scheduling '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889' for gc 6.99999122602074days in the future\nI0729 13:27:58.758572 12650 gc.cpp:55] Scheduling '/tmp/mesos/meta/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889/runs/4e7f7e96-0318-4699-9fb1-8f0a4b3eb0e8' for gc 6.99999122381926days in the future\nI0729 13:27:58.758597 12652 slave.cpp:4078] Cleaning up framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.758901 12650 gc.cpp:55] Scheduling '/tmp/mesos/meta/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000/executors/basic-3.29606d60-5562-11e6-82c4-02010a552889' for gc 6.99999122165333days in the future\nI0729 13:27:58.759013 12646 status_update_manager.cpp:282] Closing status update streams for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.759237 12650 gc.cpp:55] Scheduling '/tmp/mesos/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000' for gc 6.99999121670222days in the future\nI0729 13:27:58.759496 12650 gc.cpp:55] Scheduling '/tmp/mesos/meta/slaves/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7/frameworks/09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000' for gc 6.99999121438518days in the future\n</code></pre>\n\n<p><strong>Marathon Logs</strong></p>\n\n<pre><code>[2016-07-29 13:27:56,985] INFO Received offers WANTED notification (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:56,986] INFO =&gt; revive offers NOW, canceling any scheduled revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:56,986] INFO 2 further revives still needed. Repeating reviveOffers according to --revive_offers_repetitions 3 (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:56,986] INFO =&gt; Schedule next revive at 2016-07-29T07:58:01.983Z in 4999 milliseconds, adhering to --min_revive_offers_interval 5000 (ms) (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,191] INFO Request Launch for task 'basic-3.29606d60-5562-11e6-82c4-02010a552889', version '2016-07-29T07:57:56.450Z'. 1 tasksToLaunch, 0 in flight, 0 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,193] INFO No tasks left to launch. Stop receiving offers for /basic-3, 2016-07-29T07:57:56.450Z (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,194] INFO removing matcher ActorOfferMatcher(Actor[akka://marathon/user/launchQueue/2/0-basic-3#-1947978475]) (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,194] INFO Received offers NOT WANTED notification, canceling 2 revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,221] INFO Processing LaunchEphemeral(LaunchedEphemeral(task [basic-3.29606d60-5562-11e6-82c4-02010a552889],AgentInfo(xx.xx.xx.xxx,Some(09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7),Buffer()),2016-07-29T07:57:56.450Z,Status(2016-07-29T07:57:57.163Z,None,None),Vector(31623))) for task [basic-3.29606d60-5562-11e6-82c4-02010a552889] (mesosphere.marathon.core.launcher.impl.OfferProcessorImpl:ForkJoinPool-2-worker-41)\n[2016-07-29 13:27:57,221] INFO Finished processing b2501f80-c821-4b1a-9f67-c008739a4e06-O1. Matched 1 ops after 2 passes. cpus(*) 11.5; mem(*) 23106.0; disk(*) 4942.0; ports(*) 31000-&gt;31622,31624-&gt;32000 left. (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:57,293] INFO receiveTaskUpdate: updating status of task [basic-3.29606d60-5562-11e6-82c4-02010a552889] (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-19)\n[2016-07-29 13:27:57,312] INFO Task launch for 'task [basic-3.29606d60-5562-11e6-82c4-02010a552889]' was accepted. 0 tasksToLaunch, 0 in flight, 1 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:58,667] INFO Received status update for task basic-3.29606d60-5562-11e6-82c4-02010a552889: TASK_FAILED (Failed to launch container: Container exited on error: exited with status 1) (mesosphere.marathon.MarathonScheduler$$EnhancerByGuice$$9250fa1f:Thread-37)\n[2016-07-29 13:27:58,723] INFO Removed app [/basic-3] from tracker (mesosphere.marathon.core.task.tracker.TaskTracker$TasksByApp$:marathon-akka.actor.default-dispatcher-3)\n[2016-07-29 13:27:58,735] INFO receiveTaskUpdate: task [basic-3.29606d60-5562-11e6-82c4-02010a552889] finished (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-3)\n[2016-07-29 13:27:58,739] INFO Sending event notification for task [basic-3.29606d60-5562-11e6-82c4-02010a552889] of app [/basic-3]: TASK_FAILED (mesosphere.marathon.core.task.update.impl.steps.PostToEventStreamStepImpl$$EnhancerByGuice$$42a76347:marathon-akka.actor.default-dispatcher-3)\n[2016-07-29 13:27:58,740] INFO Increasing delay. Task launch delay for [/basic-3] changed from [0 milliseconds] to [1 seconds]. (mesosphere.marathon.core.launchqueue.impl.RateLimiter$:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:58,743] INFO initiating a scale check for app [/basic-3] after task [basic-3.29606d60-5562-11e6-82c4-02010a552889] terminated (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl$$EnhancerByGuice$$78bdbf3a:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:58,743] INFO schedulerActor: Actor[akka://marathon/user/MarathonScheduler#1328539013] (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl$$EnhancerByGuice$$78bdbf3a:marathon-akka.actor.default-dispatcher-8)\n[2016-07-29 13:27:58,747] WARN New task [task [basic-3.29606d60-5562-11e6-82c4-02010a552889]] failed during app /basic-3 scaling, queueing another task (mesosphere.marathon.upgrade.TaskStartActor:marathon-akka.actor.default-dispatcher-8)\n</code></pre>\n\n<p><strong>Mesos Master Logs</strong></p>\n\n<pre><code>I0729 13:27:56.987308 20184 master.cpp:3720] Processing REVIVE call for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704\nI0729 13:27:56.987633 20184 hierarchical.cpp:988] Removed offer filters for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:56.989745 20176 master.cpp:5324] Sending 1 offers to framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704\nI0729 13:27:57.314573 20183 master.cpp:3104] Processing ACCEPT call for offers: [ b2501f80-c821-4b1a-9f67-c008739a4e06-O1 ] on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 at slave(1)@xx.xx.xx.xxx:5051 (xx.xx.xx.xxx) for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704\nI0729 13:27:57.321236 20180 master.hpp:177] Adding task basic-3.29606d60-5562-11e6-82c4-02010a552889 with resources cpus(*):0.5; mem(*):32; disk(*):32; ports(*):[31623-31623] on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 (xx.xx.xx.xxx)\nI0729 13:27:57.321815 20180 master.cpp:3589] Launching task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704 with resources cpus(*):0.5; mem(*):32; disk(*):32; ports(*):[31623-31623] on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 at slave(1)@xx.xx.xx.xxx:5051 (xx.xx.xx.xxx)\nI0729 13:27:57.554368 20177 master.cpp:5324] Sending 1 offers to framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704\nI0729 13:27:57.561040 20181 master.cpp:3641] Processing DECLINE call for offers: [ b2501f80-c821-4b1a-9f67-c008739a4e06-O2 ] for framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704\nW0729 13:27:58.653374 20181 master.cpp:4859] Ignoring unknown exited executor 'basic-3.29606d60-5562-11e6-82c4-02010a552889' of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 at slave(1)@xx.xx.xx.xxx:5051 (xx.xx.xx.xxx)\nI0729 13:27:58.660586 20181 master.cpp:4763] Status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 from slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 at slave(1)@xx.xx.xx.xxx:5051 (xx.xx.xx.xxx)\nI0729 13:27:58.660701 20181 master.cpp:4811] Forwarding status update TASK_FAILED (UUID: 7cb5dc80-8c90-4933-83a1-c68e4a1369bf) for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000\nI0729 13:27:58.661497 20181 master.cpp:6421] Updating the state of task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (latest state: TASK_FAILED, status update state: TASK_FAILED)\nI0729 13:27:58.749291 20181 master.cpp:3918] Processing ACKNOWLEDGE call 7cb5dc80-8c90-4933-83a1-c68e4a1369bf for task basic-3.29606d60-5562-11e6-82c4-02010a552889 of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 (marathon) at scheduler-88ef4a70-96ae-4294-a286-ba0a955b193a@xx.xx.xx.xxx:54704 on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7\nI0729 13:27:58.749658 20181 master.cpp:6487] Removing task basic-3.29606d60-5562-11e6-82c4-02010a552889 with resources cpus(*):0.5; mem(*):32; disk(*):32; ports(*):[31623-31623] of framework 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-0000 on slave 09894fa6-e1fa-4d26-aaca-0ea6c8fb06da-S7 at slave(1)\n</code></pre>\n\n<p><strong>Mesos Slave Kernel logs:</strong></p>\n\n<pre><code>Jul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.110000] IPv6: ADDRCONF(NETDEV_UP): vethe4b2f1c: link is not ready\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.110012] docker0: port 1(vethe4b2f1c) entered forwarding state\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.110028] docker0: port 1(vethe4b2f1c) entered forwarding state\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.111114] docker0: port 1(vethe4b2f1c) entered disabled state\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.505747] IPv6: ADDRCONF(NETDEV_CHANGE): vethe4b2f1c: link becomes ready\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.505810] docker0: port 1(vethe4b2f1c) entered forwarding state\nJul 29 13:28:07 test-lab-test-infra-reserved-4001279 kernel: [175212.505824] docker0: port 1(vethe4b2f1c) entered forwarding state\nJul 29 13:28:08 test-lab-test-infra-reserved-4001279 kernel: [175212.979072] docker0: port 1(vethe4b2f1c) entered disabled state\nJul 29 13:28:08 test-lab-test-infra-reserved-4001279 kernel: [175212.980744] device vethe4b2f1c left promiscuous mode\nJul 29 13:28:08 test-lab-test-infra-reserved-4001279 kernel: [175212.980783] docker0: port 1(vethe4b2f1c) entered disabled state\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.043575] aufs au_opts_verify:1570:docker[8836]: dirperm1 breaks the protection by the permission bits on the lower branch\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.081090] aufs au_opts_verify:1570:docker[8836]: dirperm1 breaks the protection by the permission bits on the lower branch\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.128271] aufs au_opts_verify:1570:docker[8836]: dirperm1 breaks the protection by the permission bits on the lower branch\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.149756] device vethb70e796 entered promiscuous mode\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.150008] IPv6: ADDRCONF(NETDEV_UP): vethb70e796: link is not ready\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.576723] IPv6: ADDRCONF(NETDEV_CHANGE): vethb70e796: link becomes ready\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.576805] docker0: port 1(vethb70e796) entered forwarding state\nJul 29 13:28:12 test-lab-test-infra-reserved-4001279 kernel: [175217.576819] docker0: port 1(vethb70e796) entered forwarding state\nJul 29 13:28:13 test-lab-test-infra-reserved-4001279 kernel: [175218.107877] docker0: port 1(vethb70e796) entered disabled state\nJul 29 13:28:13 test-lab-test-infra-reserved-4001279 kernel: [175218.109620] device vethb70e796 left promiscuous mode\nJul 29 13:28:13 test-lab-test-infra-reserved-4001279 kernel: [175218.109662] docker0: port 1(vethb70e796) entered disabled state\n</code></pre>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "Docker task starting then stopping without any error", "last_activity_date": 1470046638, "answer_count": 1, "creation_date": 1469782985, "score": 0, "link": "https://stackoverflow.com/questions/38654731/docker-task-starting-then-stopping-without-any-error", "answers": [{"body": "<p>Thanks all, finally got the solution here:</p>\n\n<p><a href=\"https://github.com/mesos/elasticsearch/issues/276\" rel=\"nofollow\">https://github.com/mesos/elasticsearch/issues/276</a></p>\n\n<p>Sumit</p>\n", "answer_id": 38696333, "last_activity_date": 1470046638, "creation_date": 1470046638, "score": 0, "owner": {"user_id": 4551655, "profile_image": "https://i.stack.imgur.com/5Vcos.jpg?s=128&g=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/4551655/sumit-nagariya", "display_name": "Sumit Nagariya"}, "is_accepted": false, "question_id": 38654731}], "owner": {"user_id": 4551655, "profile_image": "https://i.stack.imgur.com/5Vcos.jpg?s=128&g=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/4551655/sumit-nagariya", "display_name": "Sumit Nagariya"}, "view_count": 117, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38654731}{"body": "<p>I am actually doing a POC on mesosphere where I tried stopping, the mesos-slave, mesos-master, zookeeper and docker container to check whether the failover of the running application is properly addressed or not. In all the mentioned scenarios, my applications is working fine. But when the docker demon is down in the mesos-slave, marathon is changing the application instance status as unhealthy but it is not running the container in another slave where the docker demon is properly running. Is there any way to address this issue ?</p>\n", "is_answered": false, "tags": ["mesosphere"], "title": "Mesos - Marathon - Zookeeper - docker container failover testing", "last_activity_date": 1481267600, "answer_count": 0, "creation_date": 1481267600, "score": 0, "link": "https://stackoverflow.com/questions/41054988/mesos-marathon-zookeeper-docker-container-failover-testing", "owner": {"user_id": 3848047, "profile_image": "https://www.gravatar.com/avatar/f7c2e27db9eb11d3d639a3b4e7262a31?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/3848047/manoj-prabhakar", "display_name": "Manoj Prabhakar"}, "view_count": 62, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41054988}{"is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1486485077, "title": "Mesosphere (dc/os) agent re-connection failure", "last_activity_date": 1486485077, "answer_count": 0, "creation_date": 1486399106, "score": 3, "link": "https://stackoverflow.com/questions/42072846/mesosphere-dc-os-agent-re-connection-failure", "owner": {"user_id": 4388698, "profile_image": "https://www.gravatar.com/avatar/b72b49d0397e457b54977aaf999a618d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 303, "link": "https://stackoverflow.com/users/4388698/purple", "accept_rate": 100, "display_name": "Purple"}, "view_count": 74, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 42072846}{"body": "<p>I would like to reserve some slaves to run only one framework (for example Chronos).</p>\n\n<p>So on the Slave I edit file /var/lib/dcos/mesos-resources and I put this information:</p>\n\n<pre><code>MESOS_DEFAULT_ROLE='testrole'\n</code></pre>\n\n<p>next I restarted Slaves:</p>\n\n<pre><code>sudo systemctl stop dcos-mesos-slave\nsudo rm -f /var/lib/mesos/slave/meta/slaves/latest\nsudo systemctl start dcos-mesos-slave\n</code></pre>\n\n<p>Slave logs after restart:</p>\n\n<pre><code>\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --port=\"5051\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registration_backoff_factor=\"1secs\" --resources=\"[{\"name\":\"ports\",\"type\":\"RANGES\",\"ranges\": {\"range\": [{\"begin\": 1025, \"end\": 2180},{\"begin\": 2182, \"end\": 3887},{\"begin\": 3889, \"end\": 5049},{\"begin\": 5052, \"end\": 8079},{\"begin\": 8082, \"end\": 8180},{\"begin\": 8182, \"end\": 32000}]}}]\" --revocable_cpu_low_priority=\"true\" --sandbox_directory=\"/mnt/mesos/sandbox\" --slave_subsystems=\"cpu,memory\" --strict=\"true\" --switch_user=\"true\" --systemd_enable_support=\"true\" --systemd_runtime_directory=\"/run/systemd/system\" --version=\"false\" --work_dir=\"/var/lib/mesos/slave\"\nI0206 09:33:03.642778 42136 slave.cpp:214] Moving slave process into its own cgroup for subsystem: cpu\nI0206 09:33:03.659202 42136 slave.cpp:214] Moving slave process into its own cgroup for subsystem: memory\nI0206 09:33:03.683498 42136 slave.cpp:464] Slave resources: ports(testrole):[1025-2180, 2182-3887, 3889-5049, 5052-8079, 8082-8180, 8182-32000]; cpus(testrole):2; mem(testrole):5943; disk(testrole):45148\n</code></pre>\n\n<p>After this operation indeed any task and any framework don't run on this Slave.</p>\n\n<p>Then I try restart Chronos with  </p>\n\n<pre><code>\"acceptedResourceRoles\": [\n   \"testrole\"\n ]\n</code></pre>\n\n<p>and Chronos dosen't start, has error: Waiting for resources.</p>\n\n<p>I also tried add <code>--mesos_role=\"testrole\"</code>, I tried both, mesos_role and acceptedResourceRoles, but effect still was the same.</p>\n\n<p>We use Azure with DC/OS, Mesos (0.28.1)</p>\n", "is_answered": false, "tags": ["azure", "mesos", "marathon", "dcos"], "title": "How to set static resources in Mesos / Marathon on DC/OS (Azure)?", "last_activity_date": 1486374398, "answer_count": 0, "creation_date": 1486374398, "score": 0, "link": "https://stackoverflow.com/questions/42064671/how-to-set-static-resources-in-mesos-marathon-on-dc-os-azure", "owner": {"user_id": 4177392, "profile_image": "https://www.gravatar.com/avatar/e7c07b81e01fb23aac3aded1373e2b3a?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/4177392/limaadd", "display_name": "LimaAdd"}, "view_count": 58, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 42064671}{"body": "<p>I am setting up a multi container application on mesos cluster on Azure using azure container service and currently stuck in linking containers.</p>\n\n<p>My setup brief info:\n- Mesos cluster is deployed on Azure using Azure container service\n- It's a 3 container application - A, B and C\n- B is dependent on A and C is dependent on A &amp; B- \n- A is deployed currently</p>\n\n<p>How can I link the above containers? </p>\n\n<p>Thanks,\nSuraj</p>\n", "is_answered": true, "title": "How can I link docker containers in mesos cluster (dc/os) running on Azure?", "last_edit_date": 1497488228, "tags": ["azure", "docker", "hyperlink", "containers", "dcos"], "view_count": 62, "accepted_answer_id": 44553629, "last_activity_date": 1497488228, "answers": [{"body": "<p>If by linking you mean Docker's <code>--link</code> then <a href=\"https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/\" rel=\"nofollow noreferrer\">thats deprecated</a> practice and inter-container communication should be done using Docker networks and port mappings.</p>\n\n<p>For DC/OS - you have some different ways to achieve this (also called Service Discovery). I have written a blog post explaining these different tools by examples: <a href=\"http://blog.itaysk.com/2017/04/28/dcos-service-discovery-and-load-balancing-by-example\" rel=\"nofollow noreferrer\">http://blog.itaysk.com/2017/04/28/dcos-service-discovery-and-load-balancing-by-example</a></p>\n\n<p>If you don't want to read through that long post and looking for a recommendation: Try using VIPs.</p>\n\n<p>When creating the application (either from Marathon or DC/OS UI), look for the 'VIP' setting. Enter an IP there (it can be a made up IP) and port. Your service will be discoverable under this IP:Port.  </p>\n\n<p>More on VIPs: <a href=\"https://dcos.io/docs/1.9/networking/load-balancing-vips/virtual-ip-addresses/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.9/networking/load-balancing-vips/virtual-ip-addresses/</a></p>\n", "answer_id": 44553629, "last_activity_date": 1497470110, "creation_date": 1497470110, "score": 1, "owner": {"user_id": 310298, "profile_image": "https://i.stack.imgur.com/PkUnq.png?s=128&g=1", "user_type": "registered", "reputation": 1128, "link": "https://stackoverflow.com/users/310298/itaysk", "accept_rate": 63, "display_name": "itaysk"}, "is_accepted": true, "question_id": 44552992}], "score": 0, "link": "https://stackoverflow.com/questions/44552992/how-can-i-link-docker-containers-in-mesos-cluster-dc-os-running-on-azure", "answer_count": 1, "owner": {"user_id": 7938883, "profile_image": "https://graph.facebook.com/1342101695872554/picture?type=large", "user_type": "registered", "reputation": 8, "link": "https://stackoverflow.com/users/7938883/suraj-naik", "display_name": "Suraj Naik"}, "creation_date": 1497467875, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44552992}{"is_answered": false, "tags": ["cassandra-2.1", "dcos"], "title": "DCOS Cassandra - Run cassandraDemon with non-root user", "last_activity_date": 1491432504, "answer_count": 1, "creation_date": 1488803713, "score": 0, "link": "https://stackoverflow.com/questions/42625827/dcos-cassandra-run-cassandrademon-with-non-root-user", "owner": {"user_id": 5036266, "profile_image": "https://lh6.googleusercontent.com/-AGH2lHh10Ms/AAAAAAAAAAI/AAAAAAAAAaE/GxdM-1phOTM/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5036266/arun-kumar", "display_name": "Arun kumar"}, "view_count": 31, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42625827}{"body": "<p>I am working on integrating Mesos with Kafka, as per the git hub documentation scheduler can be run on a independent machine which has mesos and kafka installed and with the help of configuration registration to mesos-master can be done.</p>\n\n<p>How do we run brokers on slave, from scheduler and what configuration is required to run broker on slave.</p>\n\n<p>how to configure slave as broker.</p>\n", "is_answered": true, "tags": ["apache-kafka", "mesos", "mesosphere"], "title": "Apache Mesos with Kafka", "last_activity_date": 1468590305, "answer_count": 2, "creation_date": 1444856026, "score": 0, "link": "https://stackoverflow.com/questions/33135402/apache-mesos-with-kafka", "answers": [{"body": "<p>If you're already using Docker, you can make use of the Docker image as described in </p>\n\n<ul>\n<li><a href=\"https://github.com/mesos/kafka/tree/master/src/docker#intro\" rel=\"nofollow\">https://github.com/mesos/kafka/tree/master/src/docker#intro</a></li>\n</ul>\n\n<p>You can launch the Kafka Scheduler image with Marathon, and then either use the REST API or CLI to start brokers/topics.</p>\n\n<p>The dispatching of the actual brokers will then be done by the Mesos software itself. Using the brokers is done via the defined Zookeeper node name.</p>\n", "answer_id": 33198691, "last_activity_date": 1445176238, "creation_date": 1445176238, "score": 2, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 33135402}, {"body": "<p>Thanks, I was able to run the scheduler through shell and as well as docker.\nI had two questions though</p>\n\n<pre><code>sudo docker run -t -p 5900:5900 --net=host root/kafka-mesos ./kafka-mesos.sh \\ \n  scheduler --master=192.168.1.115:5050 --zk=192.168.1.115:2181 \\\n  --api=http://192.168.1.118:5900 --storage=zk:/kafka-mesos \\\n  --log=/var/log/mesos.log --debug=true\n</code></pre>\n\n<p>I have used above command in marathon to run the container, if I remove <code>--net=host</code> the schedule registers with docker containers ip with the master but after adding <code>--net=host</code> it uses the slave's ip and port forwards it to docker container. Is there any better way?</p>\n\n<p>The second question is how many schedulers can we bring up in the one mesos cluster say 3 master 5 slaves i.e. can we scale or support  scheduler cluster?</p>\n", "answer_id": 33270739, "last_activity_date": 1468590305, "creation_date": 1445468764, "score": 0, "owner": {"user_id": 404524, "profile_image": "https://www.gravatar.com/avatar/c14eb006f0d30a0e53d17b5ba5314a36?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 20, "link": "https://stackoverflow.com/users/404524/rohit-singh", "accept_rate": 0, "display_name": "rohit singh"}, "is_accepted": false, "last_edit_date": 1468590305, "question_id": 33135402}], "owner": {"user_id": 404524, "profile_image": "https://www.gravatar.com/avatar/c14eb006f0d30a0e53d17b5ba5314a36?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 20, "link": "https://stackoverflow.com/users/404524/rohit-singh", "accept_rate": 0, "display_name": "rohit singh"}, "view_count": 1165, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 33135402}{"body": "<p>I have been exploring Mesos, Marathon framework to deploy applications. I have a doubt that how Marathon handle application files when an application is killed . </p>\n\n<p>For example we are using Jenkins which is run through Marathon and if Jenkins server fails and it will be restarted again by Marathon but this time old jobs defined will be lost . </p>\n\n<p>Now my question is how can I ensure that if a application restarts, those old application jobs should be available ? </p>\n\n<p>Thanks.</p>\n", "is_answered": true, "title": "How Mesos Marathon handle application data persistence?", "tags": ["jenkins", "mesos", "application-restart", "mesosphere", "marathon"], "last_activity_date": 1494072806, "accepted_answer_id": 31041902, "creation_date": 1434972589, "answers": [{"body": "<p>As of right now mesos/marathon is great at supporting stateless applications, but the support for stateful applications is increasing.\nBy default the task data is written into sandbox and hence will be lost when a task is failed/restarted. Note that usually only a small percentage of tasks fails (e.g. only the tasks being on the failed node).</p>\n\n<p>Now let us have a look at different failure scenarios.</p>\n\n<ol>\n<li><p>Recovering from slave process failures:\nWhen only the Mesos slave process fails (or is upgraded) the framework can use <a href=\"http://mesos.apache.org/documentation/latest/slave-recovery/\" rel=\"nofollow noreferrer\">slave checkpointing</a> for reconnecting to the running executors.</p></li>\n<li><p>Executor failures (e.g. Jenkins process failures):\nIn this case the framework could persist it own metadata on some persistent media and use it to restart. Note, that this is highly application specific and hence mesos/marathon can not offer a generic way to do this (and I am actually not sure how that could look like in case of jenkins). Persistent data could either be written to HDFS, Cassandra or you could have a look at the <a href=\"https://issues.apache.org/jira/browse/MESOS-2018\" rel=\"nofollow noreferrer\">concept of dynamic reservations</a>. </p></li>\n</ol>\n", "answer_id": 31041902, "last_activity_date": 1494072806, "creation_date": 1435210179, "score": 2, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "last_edit_date": 1494072806, "question_id": 30978863}], "score": 1, "link": "https://stackoverflow.com/questions/30978863/how-mesos-marathon-handle-application-data-persistence", "answer_count": 1, "owner": {"user_id": 3107358, "profile_image": "https://graph.facebook.com/100000796363715/picture?type=large", "user_type": "registered", "reputation": 122, "link": "https://stackoverflow.com/users/3107358/pardeep-singh", "accept_rate": 73, "display_name": "Pardeep Singh"}, "view_count": 307, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 30978863}{"body": "<p>I deployed a number of services using Marathon framework in dockers (via mesosphere) and sometimes Marathon kills running tasks.</p>\n\n<p>Services use HTTP health checks (<code>intervalSeconds = 30, maxConsecutiveFailures = 3, timeoutSeconds = 20</code>).</p>\n\n<p>It happens randomly and sometimes I even can see when task turns red at Marathon UI even so http check works well in browser (so service is healthy) and then Marathon kills and restart service that impacts overall system performance.</p>\n\n<p>Any advice will be helpful</p>\n\n<p><em>Mesos (v0.22.1), Marathon (v0.9.0)</em></p>\n\n<p>Logs:</p>\n\n<pre><code>I1223 12:23:45.058763 32718 slave.cpp:1581] Asked to kill task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e\n30c7374f of framework 20150527-135958-3712123914-5050-2238-0000\n\nI1223 12:23:45.189750 32720 slave.cpp:2531] Handling status update TASK_KILLED (UUID: 09e76bce-f24c-4999-8933-270baf023c62\n) for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework 20150527-135958-3712123914-505\n0-2238-0000 from executor(1)@10.132.66.219:33503\n\nI1223 12:23:45.214113 32718 docker.cpp:1009] Updated 'cpu.shares' to 102 at /sys/fs/cgroup/cpu/docker/9e0bc3b40ad9b37c4a0f\n6133ca1316c2addd2e2c5a7941e56a4e1770d7afd3a2 for container 9dad82a5-34e1-4bf9-a641-17129464a226\n\nW1223 12:23:45.214740 32718 docker.cpp:1021] Container 9dad82a5-34e1-4bf9-a641-17129464a226 does not appear to be a member\n of a cgroup where the 'memory' subsystem is mounted\n\nI1223 12:23:45.216114 32724 status_update_manager.cpp:317] Received status update TASK_KILLED (UUID: 09e76bce-f24c-4999-89\n33-270baf023c62) for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework 20150527-135958\n-3712123914-5050-2238-0000\n\nI1223 12:23:45.216359 32724 status_update_manager.hpp:346] Checkpointing UPDATE for status update TASK_KILLED (UUID: 09e76\nbce-f24c-4999-8933-270baf023c62) for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework\n 20150527-135958-3712123914-5050-2238-0000\n\nI1223 12:23:45.221278 32720 slave.cpp:2776] Forwarding the update TASK_KILLED (UUID: 09e76bce-f24c-4999-8933-270baf023c62)\n for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework 20150527-135958-3712123914-5050\n-2238-0000 to master@10.132.8.65:5050\n\nI1223 12:23:45.222024 32720 slave.cpp:2709] Sending acknowledgement for status update TASK_KILLED (UUID: 09e76bce-f24c-499\n9-8933-270baf023c62) for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework 20150527-13\n5958-3712123914-5050-2238-0000 to executor(1)@10.132.66.219:33503\n\nI1223 12:23:45.233886 32725 status_update_manager.cpp:389] Received status update acknowledgement (UUID: 09e76bce-f24c-499\n9-8933-270baf023c62) for task prod-tracker-backend-processor.63dbfa9b-a965-11e5-a046-e24e30c7374f of framework 20150527-13\n5958-3712123914-5050-2238-0000\n</code></pre>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1450882643, "title": "Marathon treats healthy tasks as unhealthy and kills them", "last_activity_date": 1450882643, "answer_count": 0, "creation_date": 1450874261, "score": 1, "link": "https://stackoverflow.com/questions/34435890/marathon-treats-healthy-tasks-as-unhealthy-and-kills-them", "owner": {"user_id": 2170491, "profile_image": "https://i.stack.imgur.com/mhDM9.jpg?s=128&g=1", "user_type": "registered", "reputation": 504, "link": "https://stackoverflow.com/users/2170491/ihar-krasnik", "accept_rate": 31, "display_name": "Ihar Krasnik"}, "view_count": 135, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34435890}{"body": "<p>I have scala application with akka steams. So the flow of my application is like this:</p>\n\n<pre><code>1. Check if file exists on FTP - I'm doing it with the org.apache.commons.net.ftp.FTPClient\n2. If it exists stream it via alpakka library(and make some stream transformations)\n</code></pre>\n\n<p>My application works locally and it can connect to the server.</p>\n\n<p>The problem is when it is being deployed to dcos/mesos. I get an issue:</p>\n\n<pre><code>java.io.IOException: /path/file.txt: No such file or directory\n</code></pre>\n\n<p>I can say for sure that file still exists there. Also when I try to connect from docker container locally through the ftp I've got something like this: </p>\n\n<pre><code>ftp&gt; open some.ftp.address.com\nConnected to some.ftp.address.com.\n220 Microsoft FTP Service\nName (some.ftp.address.com:root): USER\n331 Password required\nPassword:\n230 User logged in.\nRemote system type is Windows_NT.\nftp&gt; dir\n501 Server cannot accept argument.\nftp: bind: Address already in use\nftp&gt; \n</code></pre>\n", "is_answered": true, "tags": ["scala", "docker", "ftp", "akka-stream", "dcos"], "title": "FTP does not work from mesos docker container", "last_activity_date": 1485941360, "answer_count": 1, "creation_date": 1485867400, "score": 4, "link": "https://stackoverflow.com/questions/41958195/ftp-does-not-work-from-mesos-docker-container", "answers": [{"body": "<p>So my problem was really weird. But I've managed to fix this way.\nQuick answer: I was using alpakka ftp lib this way:</p>\n\n<pre><code>Ftp\n  .fromPath(url, user, pass, Paths.get(s\"/path/$fileName\"))\n</code></pre>\n\n<p>But using this way it works:</p>\n\n<pre><code>val ftpSettings = FtpSettings(\n  host = InetAddress.getByName(url),\n  port = 21,\n  NonAnonFtpCredentials(user, pass),\n  binary = true,\n  passiveMode = true\n)\nFtp\n  .fromPath(Paths.get(s\"/path/$fileName\"), ftpSettings)\n</code></pre>\n\n<p>Longer answer: I started investigating alpakka lib and I've discovered that it uses the same lib that works for me during checking if file exists!</p>\n\n<pre><code>https://github.com/akka/alpakka/blob/master/ftp/src/main/scala/akka/stream/alpakka/ftp/impl/FtpOperations.scala\n</code></pre>\n\n<p>So I've started digging and it seems that most likely tahat setting passive mode to true was the solution. But it's weird because I've read that windows ftp server does not support passive mode...\nI hope someone could clarify my doubts one day, but at the moment I'm happy because it works :)</p>\n", "answer_id": 41976180, "last_activity_date": 1485941360, "creation_date": 1485941360, "score": 1, "owner": {"user_id": 5201261, "profile_image": "https://lh4.googleusercontent.com/-MDJPvyahbHs/AAAAAAAAAAI/AAAAAAAAAAA/a813nXg0NCY/photo.jpg?sz=128", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/5201261/fr3ak", "accept_rate": 75, "display_name": "fr3ak"}, "is_accepted": false, "question_id": 41958195}], "owner": {"user_id": 5201261, "profile_image": "https://lh4.googleusercontent.com/-MDJPvyahbHs/AAAAAAAAAAI/AAAAAAAAAAA/a813nXg0NCY/photo.jpg?sz=128", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/5201261/fr3ak", "accept_rate": 75, "display_name": "fr3ak"}, "view_count": 120, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41958195}{"body": "<p>I have followed <a href=\"https://mesos.github.io/chronos/docs/#example-run-scripts\" rel=\"nofollow\">https://mesos.github.io/chronos/docs/#example-run-scripts</a> .<br>\n What is the url of the web ui?</p>\n", "is_answered": true, "tags": ["apache", "mesos", "mesosphere"], "title": "Apache chronos: how to access web ui", "last_activity_date": 1468976013, "answer_count": 1, "creation_date": 1457933026, "score": 2, "link": "https://stackoverflow.com/questions/35980085/apache-chronos-how-to-access-web-ui", "answers": [{"body": "<p>The Chronos Web UI is available via port <code>4400</code> (same as the REST API) on the host you've launched it via <code>java -cp chronos.jar ...</code>. See also the tutorial <a href=\"https://open.mesosphere.com/advanced-course/advanced-usage-of-chronos/\" rel=\"nofollow\">Exercise 18 \u2013 Advanced Usage of Chronos</a> for more ways to use Chronos.</p>\n", "answer_id": 35980393, "last_activity_date": 1457934784, "creation_date": 1457934784, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 35980085}], "owner": {"user_id": 482711, "profile_image": "https://www.gravatar.com/avatar/654c42ba9749282615644c55ad3ccdbe?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 5083, "link": "https://stackoverflow.com/users/482711/rockscience", "accept_rate": 78, "display_name": "RockScience"}, "view_count": 294, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 35980085}{"body": "<p><a href=\"https://github.com/apache/mesos/blob/master/include/mesos/module.hpp#L56\" rel=\"nofollow noreferrer\">https://github.com/apache/mesos/blob/master/include/mesos/module.hpp#L56</a></p>\n\n<p>The mesos modules all derive from the struct ModuleBase, and when create different module instances they use template.\nI am curious about that, why they prefer template than heritage? Is that because of running time speed?</p>\n\n<p>I also have noticed that so many open source projects in C++ prefer to use a lot of template which cause the code hard to read and understand, why?</p>\n", "is_answered": true, "tags": ["c++", "open-source", "mesos", "mesosphere"], "title": "why mesos code prefer template than heritage?", "last_activity_date": 1488803669, "answer_count": 1, "creation_date": 1488797820, "score": -3, "link": "https://stackoverflow.com/questions/42623799/why-mesos-code-prefer-template-than-heritage", "answers": [{"body": "<p>It seems that there are some general discuss maybe help to someone who are here later:</p>\n\n<p><a href=\"https://stackoverflow.com/questions/6663666/when-should-i-use-templates-instead-of-inheritance-and-vice-versa\">When should I use templates instead of inheritance, and vice versa?</a></p>\n\n<p><a href=\"https://stackoverflow.com/questions/7264402/when-to-use-template-vs-inheritance\">When to use template vs inheritance</a></p>\n\n<p><a href=\"http://www.gotw.ca/publications/mill06.htm\" rel=\"nofollow noreferrer\">http://www.gotw.ca/publications/mill06.htm</a></p>\n\n<p><a href=\"http://people.cs.uchicago.edu/~jacobm/pubs/templates.html\" rel=\"nofollow noreferrer\">http://people.cs.uchicago.edu/~jacobm/pubs/templates.html</a></p>\n\n<p>template is faster than inheritance since it choose the right function to be called at the compiling time rather than at running time.</p>\n\n<p>also they have very similar function that they both support interfaces and polymorphism.</p>\n", "answer_id": 42625809, "last_activity_date": 1488803669, "creation_date": 1488803669, "score": 1, "owner": {"user_id": 5978133, "profile_image": "https://www.gravatar.com/avatar/396576ed3ae974588c36a437c12691eb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 78, "link": "https://stackoverflow.com/users/5978133/liu-weibo", "accept_rate": 0, "display_name": "Liu Weibo"}, "is_accepted": false, "last_edit_date": 1495539968, "question_id": 42623799}], "owner": {"user_id": 5978133, "profile_image": "https://www.gravatar.com/avatar/396576ed3ae974588c36a437c12691eb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 78, "link": "https://stackoverflow.com/users/5978133/liu-weibo", "accept_rate": 0, "display_name": "Liu Weibo"}, "view_count": 31, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42623799}{"body": "<p>I am relatively new to all these, but I'm having troubles getting a clear picture among the listed technologies. </p>\n\n<p>Though, all of these try to solve different problems, but do have things in common too. I would like to understand what are the things that are common and what is different. It is likely that the combination of few would be great fit, if so what are they?</p>\n\n<p>I am listing a few of them along with questions, but it would be great if someone lists all of them in detail and answers the questions.</p>\n\n<ol>\n<li><p>Kubernetes vs Mesos: </p>\n\n<p>This link </p>\n\n<blockquote>\n  <p><a href=\"https://stackoverflow.com/questions/26705201/whats-the-difference-between-\">What&#39;s the difference between Apache&#39;s Mesos and Google&#39;s Kubernetes</a></p>\n</blockquote>\n\n<p>provides a good insight into the differences, but I'm unable to understand as to why Kubernetes should run on top of Mesos. Is it more to do with coming together of two opensource solutions?</p></li>\n<li><p>Kubernetes vs Core-OS Fleet: </p>\n\n<p>If I use kubernetes, is fleet required? </p></li>\n<li><p>How does Docker-Swarm fit into all the above?</p></li>\n</ol>\n", "is_answered": true, "title": "Docker-Swarm, Kubernetes, Mesos & Core-OS Fleet", "last_edit_date": 1495541398, "tags": ["cluster-computing", "docker", "coreos", "kubernetes", "mesosphere"], "view_count": 29362, "accepted_answer_id": 29017596, "last_activity_date": 1504659136, "answers": [{"body": "<p>I think the simplest answer is that there is no simple answer. The swift rise to power of containers, and Docker in particular has left a power vacuum for \"container scheduling and orchestration\", whatever that might mean. In reality, that means you have a number of technologies that can work in harmony on some levels, but with certain aspects in competition. For example, Kubernetes can be used as a one stop shop for deploying and managing containers on a compute cluster (as Google originally designed it), but could also sit atop Fleet, making use of the resilience tier that Fleet provides on CoreOS.</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=tsk0pWf4ipw\">As this Google vid states</a> Kubernetes is not a complete out the box container scaling solution, but is a good statement to start from. In the same way, you would at some stage expect Apache Mesos to be able to work with Kubernetes, but not with Marathon, in as much as Marathon appears to fulfil the same role as Kubernetes. Somewhere I think I've read these could become part of the same effort, but I could be wrong about that - it's really about the strategic direction of Mesosphere and the corresponding adoption of Kubernetes principles.</p>\n\n<p>In the DockerCon keynote, Solomon Hykes suggested Swarm would be a tier that could provide a common interface onto the many orchestration and scheduling frameworks. From what I can see, Swarm is designed to provide a smooth Docker deployment workflow, working with some existing container workflow frameworks such as Deis, but flexible enough to yield to \"heavyweight\" deployment and resource management such as Mesos. </p>\n\n<p>Hope this helps - this could be an enormous post. I think the key is that these are young, evolving services that will likely merge and become interoperable, but we need to ride out the next 12 months to see how it plays out. There's some very clever people on the problem, so the future looks very bright.</p>\n", "answer_id": 27821203, "last_activity_date": 1429522665, "creation_date": 1420639441, "score": 29, "owner": {"user_id": 1059526, "profile_image": "https://www.gravatar.com/avatar/17f1856bd905e04e31e31ae5f35adadb?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 439, "link": "https://stackoverflow.com/users/1059526/mikeb", "accept_rate": 40, "display_name": "MikeB"}, "is_accepted": false, "last_edit_date": 1429522665, "question_id": 27640633}, {"body": "<p>As far as I understand it:</p>\n\n<p>Mesos, Kubernetes and Fleet are all trying to solve a very similar problem. The idea is that you abstract away all your hardware from developers and the 'cluster management tool' sorts it all out for you. Then all you need to do is give a container to the cluster, give it some info (keep it running permanently, scale up if X happens etc) and the cluster manager will make it happen.</p>\n\n<p>With Mesos, it does all the cluster management for you, but it doesn't include the scheduler. The scheduler is the bit that says, ok this process needs 2 procs and 512MB RAM, and I have a machine over there with that free, so I'll run it on that machine. There are some plugin schedulers available for Mesos: Marathon and Chronos and you can write your own. This gives you a lot of power of resource distribution and cluster scaling etc.</p>\n\n<p>Fleet and Kubernetes seem to abstract away those sorts of details (so you don't have to write your own scheduler basically). This means you have to define your tasks and submit them in the format/manner defined by Fleet or Kubernetes and then they take over and schedule the tasks (containers) for you.</p>\n\n<p>So I guess: Using Mesos may mean a bit more work in writing your own scheduler, but potentially provides more flexibility if required.</p>\n\n<p>I think the idea of running Kubernetes on top of Mesos is that Kubernetes acts as the scheduler for Mesos. Personally I'm not sure what benefits this brings over running one or the other on its own though (hopefully someone will jump in and explain!)</p>\n\n<p>As MikeB said.. it's early days, and it's all up for grabs (keep an eye on Amazon's ECS as well) so there are many competing standards and a lot of overlap!</p>\n\n<p>-edit- I didn't mention Docker swarm as I don't really have much experience with it.</p>\n", "answer_id": 28719423, "last_activity_date": 1424868425, "creation_date": 1424868425, "score": 20, "owner": {"user_id": 2851943, "profile_image": "https://www.gravatar.com/avatar/7356c8ed45eb90f9ecc92912ceccbef5?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 527, "link": "https://stackoverflow.com/users/2851943/user2851943", "accept_rate": 80, "display_name": "user2851943"}, "is_accepted": false, "question_id": 27640633}, {"body": "<p><strong>Disclosure: I'm a lead engineer on Kubernetes</strong></p>\n\n<p>I think that Mesos and Kubernetes are largely aimed at solving similar problems of running clustered applications, they have different histories and different approaches to solving the problem.</p>\n\n<p>Mesos focuses its energy on very generic scheduling, and plugging in multiple different schedulers.  This means that it enables systems like Hadoop and Marathon to co-exist in the same scheduling environment.  Mesos is less focused on running containers.  Mesos existed prior to widespread interest in containers and has been re-factored in parts to support containers.</p>\n\n<p>In contrast, Kubernetes was designed from the ground up to be an environment for building distributed applications from containers.  It includes primitives for replication and service discovery as core primitives, where-as such things are added via frameworks in Mesos.  The primary goal of Kubernetes is a system for building, running and managing distributed systems.</p>\n\n<p>Fleet is a lower-level task distributor.  It is useful for bootstrapping a cluster system, for example CoreOS uses it to distribute the kubernetes agents and binaries out to the machines in a cluster in order to turn-up a kubernetes cluster.  It is not really intended to solve the same distributed application development problems, think of it more like systemd/init.d/upstart for your cluster.  It's not required if you run kubernetes, you can use other tools (e.g. Salt, Puppet, Ansible, Chef, ...) to accomplish the same binary distribution.</p>\n\n<p>Swarm is an effort by Docker to extend the existing Docker API to make a cluster of machines look like a single Docker API.  Fundamentally, our experience at Google and elsewhere indicates that the node API is insufficient for a cluster API.  You can see a bunch of discussion on this here: <a href=\"https://github.com/docker/docker/pull/8859\">https://github.com/docker/docker/pull/8859</a> and here: <a href=\"https://github.com/docker/docker/issues/8781\">https://github.com/docker/docker/issues/8781</a></p>\n\n<p>Hope that helps!  Join us on IRC @ #google-containers if you want to talk more.</p>\n", "answer_id": 29017596, "last_activity_date": 1426184987, "creation_date": 1426184987, "score": 129, "owner": {"user_id": 4175029, "profile_image": "https://www.gravatar.com/avatar/c2ff012ca59db545fb777ea41917504c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2753, "link": "https://stackoverflow.com/users/4175029/brendan", "display_name": "brendan"}, "is_accepted": true, "question_id": 27640633}, {"body": "<p>For anyone coming to this after 2017 fleet is deprecated. Do not use it anymore. </p>\n\n<p><a href=\"https://coreos.com/fleet/docs/latest/\" rel=\"nofollow noreferrer\">Fleet docs</a> say \"fleet is no longer actively developed or maintained by CoreOS\" and link to <a href=\"https://coreos.com/blog/migrating-from-fleet-to-kubernetes.html\" rel=\"nofollow noreferrer\">Container orchestration: Moving from fleet to Kubernetes</a>. Fleet was removed from Container Linux (<a href=\"https://coreos.com/blog/tectonic-self-driving.html\" rel=\"nofollow noreferrer\">formerly known as CoreOS Linux</a>) and replaced with Kubernetes kubelet (agent). This coincided with a corporate pivot to offer <a href=\"https://coreos.com/tectonic/\" rel=\"nofollow noreferrer\">Tectonic</a> (a Kubernetes distro) as their primary product.</p>\n", "answer_id": 45852536, "last_activity_date": 1504659136, "creation_date": 1503545894, "score": 1, "owner": {"user_id": 583485, "profile_image": "https://www.gravatar.com/avatar/801fe213cdb250491b89b962d1fa2876?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 39, "link": "https://stackoverflow.com/users/583485/jpweber", "display_name": "jpweber"}, "is_accepted": false, "last_edit_date": 1504659136, "question_id": 27640633}], "score": 122, "link": "https://stackoverflow.com/questions/27640633/docker-swarm-kubernetes-mesos-core-os-fleet", "answer_count": 4, "owner": {"user_id": 4240774, "profile_image": "https://www.gravatar.com/avatar/e2a49f40d7a889fe063ae99f601ce09b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 748, "link": "https://stackoverflow.com/users/4240774/b-b", "accept_rate": 50, "display_name": "B_B"}, "creation_date": 1419443701, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 27640633}{"is_answered": true, "tags": ["azure", "dns", "marathon", "dcos"], "last_edit_date": 1500117459, "title": "How to configure subdomain for Azure DCOS?", "last_activity_date": 1500131221, "answer_count": 1, "creation_date": 1500107797, "score": 2, "link": "https://stackoverflow.com/questions/45116219/how-to-configure-subdomain-for-azure-dcos", "accepted_answer_id": 45119646, "owner": {"user_id": 3744640, "profile_image": "https://i.stack.imgur.com/f6iu9.jpg?s=128&g=1", "user_type": "registered", "reputation": 3019, "link": "https://stackoverflow.com/users/3744640/ipoteka", "accept_rate": 83, "display_name": "ipoteka"}, "view_count": 31, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45116219}{"is_answered": true, "tags": ["apache-spark", "dcos"], "title": "Passing multiple jar files in dcos spark-submit, jars with comma separated not suitable", "last_activity_date": 1493132970, "answer_count": 3, "creation_date": 1483665068, "score": -1, "link": "https://stackoverflow.com/questions/41497410/passing-multiple-jar-files-in-dcos-spark-submit-jars-with-comma-separated-not-s", "owner": {"user_id": 6679867, "profile_image": "https://www.gravatar.com/avatar/5927b9523649911cd6afc0665d0aef87?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/6679867/cloudvar", "accept_rate": 25, "display_name": "cloudvar"}, "view_count": 259, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 41497410}{"body": "<p>I'm new to docker and dc/os. I have deployed dc/os cluster in the microsoft azure. I need to set access via a jmx to my java applications but I can't.\nLet's take the example of deploying a standart tomcat image.\nI have docker installed on my local machine. To run a tomcat container with jmx access I use this command:</p>\n\n<pre><code>docker run -e \n     JAVA_OPTS= \"-Dcom.sun.management.jmxremote \n                -Djava.rmi.server.hostname=127.0.0.1 \n                -Dcom.sun.management.jmxremote.port=8081 \n                -Dcom.sun.management.jmxremote.rmi.port=8081 \n                -Dcom.sun.management.jmxremote.local.only=false \n                -Dcom.sun.management.jmxremote.authenticate=false \n                -Dcom.sun.management.jmxremote.ssl=false\" \n     -p 8080:8080 -p 8081:8081 tomcat:8.0   \n</code></pre>\n\n<p>And I can connect to Tomcat via port 8081.</p>\n\n<p>I try to do the same in dc/os cluster. I use the below json configuration to deploy:</p>\n\n<pre><code>{\n  \"id\": \"/tomcat\",\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 512,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"tomcat:8.0\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"protocol\": \"tcp\", \"hostPort\": 8080, \"containerPort\": 8080 },\n        { \"protocol\": \"tcp\", \"hostPort\": 8081, \"containerPort\": 8081 }\n      ]\n    }\n  },\n  \"requirePorts\": true,\n  \"acceptedResourceRoles\": [\n    \"slave_public\"\n  ],\n  \"env\": {      \n    \"JAVA_OPTS\": \"-Dcom.sun.management.jmxremote -Djava.rmi.server.hostname=10.0.0.4 -Dcom.sun.management.jmxremote.port=8081 -Dcom.sun.management.jmxremote.rmi.port=8081 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n  },\n  \"healthChecks\": [\n    {\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 30,\n      \"maxConsecutiveFailures\": 3,\n      \"path\": \"/\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    }\n  ]\n}\n</code></pre>\n\n<p>After that I have access to tomcat webconsole but I can't connnect via jmx. \nI tried variouse values for \"-Djava.rmi.server.hostname\": 127.0.0.1, 10.0.0.4( agent ip ), agents.westeurope.cloudapp.azure.com.\nPlease help me understand what I do wrong.</p>\n\n<p>UPDATE: Thank Walter - MSFT who pointed out a fact which ports are opened by default on azure. I really forgot about it. But an issue with connecting via jmx is still actual for me. I opened new discussion where I give more details. <a href=\"https://stackoverflow.com/questions/44372719/dc-os-jmx-access\">DC/OS JMX Access</a></p>\n", "is_answered": true, "title": "DC/OS JMX Access to java application", "last_edit_date": 1496678331, "tags": ["java", "azure", "docker", "jmx", "dcos"], "view_count": 97, "accepted_answer_id": 44297367, "last_activity_date": 1496678331, "answers": [{"body": "<p>You could read <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access#open-a-port-portal\" rel=\"nofollow noreferrer\">Azure official article</a>:</p>\n\n<blockquote>\n  <p>Any DC/OS container in the ACS public agent pool is automatically\n  exposed to the internet. By default, ports 80, 443, 8080 are opened,\n  and any (public) container listening on those ports are accessible.</p>\n</blockquote>\n\n<p>According to your description, it seems that port 8081 is not open. You could open port 8081 on Azure Portal.</p>\n\n<p>More information about please refer to this link: <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access#open-a-port-portal\" rel=\"nofollow noreferrer\">Enable public access to an Azure Container Service application</a>.</p>\n\n<p>Update:</p>\n\n<p>I test in my lab with your json file, it works for me, you don't change it. You should open port on Azure NSG and Load Balance.</p>\n\n<p>NSG:\n<a href=\"https://i.stack.imgur.com/QCVgP.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QCVgP.gif\" alt=\"\"></a></p>\n\n<p>LoadBalncer<a href=\"https://i.stack.imgur.com/yVYK3.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yVYK3.gif\" alt=\"enter image description here\"></a></p>\n\n<p>I test in my lab, I could open 8080 Web UI. When I test port 8081, I notice that the port is listening, I could access the port with Public IP.</p>\n\n<pre><code>azureuser@dcos-master-01234567-0:~$ netcat -z -v 13.84.176.235 8081\nConnection to 13.84.176.235 8081 port [tcp/tproxy] succeeded!\n</code></pre>\n\n<p>You also could use curl to test, I get the following result.</p>\n\n<pre><code>azureuser@dcos-master-01234567-0:~$ curl 13.84.176.235:8081\ncurl: (52) Empty reply from server\n</code></pre>\n\n<p>If you could not access 8081 Web UI, I suggest you had better check docker container.</p>\n", "answer_id": 44297367, "last_activity_date": 1496378579, "creation_date": 1496282779, "score": 1, "owner": {"user_id": 6997262, "profile_image": "https://www.gravatar.com/avatar/fbad57a52de9c231e494995eebd51f2a?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6138, "link": "https://stackoverflow.com/users/6997262/walter-msft", "display_name": "Walter - MSFT"}, "is_accepted": true, "last_edit_date": 1496378579, "question_id": 44290883}], "score": 0, "link": "https://stackoverflow.com/questions/44290883/dc-os-jmx-access-to-java-application", "answer_count": 1, "owner": {"user_id": 1762235, "profile_image": "https://www.gravatar.com/avatar/dc7c67de0d402c845d12fbdc58967dd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 57, "link": "https://stackoverflow.com/users/1762235/andryusha2006", "accept_rate": 83, "display_name": "Andryusha2006"}, "creation_date": 1496250571, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44290883}{"body": "<p>I am trying to test docker port mapping by specifying parameters in the chronos job definition. The parameters options doesn't seem to take any effect on the docker run.</p>\n\n<p>Job definition as follows:</p>\n\n<pre><code>{\n  \"schedule\": \"R0//P\",\n  \"name\": \"testjob\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"image\": \"path_to_image\",\n    \"network\": \"BRIDGE\",\n     \"parameters\" : [\n        {\"key\" : \"-p\", \"value\": \"8888:4400\"}\n   ]\n},\n  \"cpus\": \"4\",\n  \"mem\": \"512\",\n  \"uris\": [\"path to dockercfg.tar.gz\"],\n  \"command\" : \"./command-to-execute\"\n}\n</code></pre>\n\n<p>1) Docker run on the node doesn't take parameters into consideration. Any suggestions on the correct way to include parameters as part of docker run will be highly appreciated?</p>\n\n<p>2) The Docker Image I am trying to run has ENTRYPOINT specified in it. So technically, the ENTRYPOINT should run when the docker runs the container. With the way Chronos is set up, I am forced to provide \"command\" option in the job JSON (skipping command option during job submission throws back error). When the container is actually scheduled on the target node then instead of using the ENTRYPOINT from the dockerfile, it actually tries to run the command specified in the job definition JSON. \n<strong>Can someone provide a way for using Chronos to run ENTRYPOINT instead of command from Chronos job JSON definition?</strong>\nNotes:\nSetting command to blank doesn't help. \nENTRYPOINT can be specified as a command in JSON job definition and that should fix the problem with command. But don't have access to ENTRYPOINT for all the containers.</p>\n\n<p>***Edit 1: Modified question with some more context and clarity</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1460749606, "title": "Chronos docker parameters ignored", "last_activity_date": 1487805194, "answer_count": 2, "creation_date": 1460707609, "score": 2, "link": "https://stackoverflow.com/questions/36641609/chronos-docker-parameters-ignored", "answers": [{"body": "<p>You should have a look at the <a href=\"http://mesos.github.io/chronos/docs/api.html#adding-a-docker-job\" rel=\"nofollow\">official docs</a> regarding how to run a Docker job. </p>\n\n<blockquote>\n  <p>A docker job takes the same format as a scheduled job or a dependency job and runs on a Docker container. To configure it, an additional container argument is required, which contains a <strong>type</strong> (required), an <strong>image</strong> (required), a <strong>network</strong> mode (optional), mounted <strong>volumes</strong> (optional) and whether Mesos should always <strong>(force)Pull(Image)</strong> the latest image before executing or not (optional).</p>\n</blockquote>\n\n<p><strong>Concerning 1)</strong><br>\nThere's no way IMHO to set the parameters like you're trying to. Also, port mappings are specified differently (with Marathon), but as I understand the docs it's not possible at all. And probably not necessary for a batch job. </p>\n\n<p>If you want to run longrunning services, use Marathon.</p>\n\n<p><strong>Concerning 2)</strong><br>\nNot sure if I understand you correctly, but normally this would be implemented via specifying an <a href=\"https://docs.docker.com/engine/reference/builder/#entrypoint\" rel=\"nofollow\">ENTRYPOINT</a> in the Dockerfile</p>\n\n<p><strong>Concerning 3)</strong><br>\nNot sure if I understand you correctly, but I think you should be able to omit the <code>command</code> property with Docker jobs.</p>\n", "answer_id": 36643187, "last_activity_date": 1460712097, "creation_date": 1460712097, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 36641609}, {"body": "<p>To use the docker container entrypoint you must set \"shell\" false, and command has to be blank. If command is different than blank, chronos will pass it as an argument to the entrypoint. Your json would be like below. </p>\n\n<p>I don't know if you should use the \"uris\" field, it is deprecated, and, if it is what I think it is, it seems not required anymore to start docker apps. </p>\n\n<p>About the docker parameters, I think the problem is with the key name that you used. It seems you must omit the - symbol. Try as below.</p>\n\n<pre><code>{\n\n \"schedule\": \"R0//P\",\n  \"name\": \"testjob\",\n  \"shell\": false,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"image\": \"path_to_image\",\n    \"network\": \"BRIDGE\",\n     \"parameters\" : [\n        {\"key\" : \"p\", \"value\": \"8888:4400\"}\n   ]\n  },\n  \"cpus\": \"4\",\n  \"mem\": \"512\",\n  \"command\" : \"\"\n}\n</code></pre>\n", "answer_id": 42404067, "last_activity_date": 1487805194, "creation_date": 1487805194, "score": 0, "owner": {"user_id": 2836301, "profile_image": "https://www.gravatar.com/avatar/76faa07f7dd2943d904f5283c5f290cb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/2836301/tonsic", "display_name": "Tonsic"}, "is_accepted": false, "question_id": 36641609}], "owner": {"user_id": 1825838, "profile_image": "https://www.gravatar.com/avatar/c2df4865825b5abb2590be7fe20236a7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/1825838/user1825838", "display_name": "user1825838"}, "view_count": 410, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 36641609}{"is_answered": true, "tags": ["mesosphere", "dcos"], "last_edit_date": 1469312364, "title": "Mesosphere DC/OS installation: Post-Flight Failed", "last_activity_date": 1469312364, "answer_count": 1, "creation_date": 1461140512, "score": 0, "link": "https://stackoverflow.com/questions/36737869/mesosphere-dc-os-installation-post-flight-failed", "owner": {"user_id": 6208258, "profile_image": "https://www.gravatar.com/avatar/032a28a7609b67a637c17f2e591b6235?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/6208258/sun-zhe", "display_name": "Sun.zhe"}, "view_count": 1086, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 36737869}{"is_answered": true, "tags": ["apache-kafka", "mesos", "marathon", "dcos"], "title": "Mesos DCOS doesn&#39;t install Kafka", "last_activity_date": 1458751957, "answer_count": 1, "creation_date": 1458748409, "score": 3, "link": "https://stackoverflow.com/questions/36182864/mesos-dcos-doesnt-install-kafka", "accepted_answer_id": 36183765, "owner": {"user_id": 3349257, "profile_image": "https://www.gravatar.com/avatar/f37b803a3616d628a6ec3ff4e646cf70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 287, "link": "https://stackoverflow.com/users/3349257/cheeko", "accept_rate": 78, "display_name": "Cheeko"}, "view_count": 618, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 36182864}{"body": "<p>I'm using using Mesos and Marathon to manage application deployments, and have run into this bug in Marathon <a href=\"https://github.com/mesosphere/marathon/issues/3783\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/marathon/issues/3783</a> , which is to say that a leader election during a deployment scales instances down to 0. Leader elections were happening very frequently (approximately once every 30 minutes), and so I'm hitting this issue fairly often. </p>\n\n<p>I know once every 30 minutes is highly irregular, because I've since upgrading to Marathon 1.3.10 and have been election-free for past 2 days, but <strong>how often is \"normal\"</strong>? Does leader abdication / election happen under normal conditions, or should I expect 0 elections unless there is an underlying issue? It was suggested to me by a colleague that \"leader elections are normal\" and that a \"certain number of elections are normal and to be expected\". I just don't believe that, and would like to know for sure.</p>\n", "is_answered": true, "title": "What conditions cause a Marathon leader election?", "tags": ["apache-zookeeper", "mesos", "marathon", "mesosphere"], "last_activity_date": 1493190722, "accepted_answer_id": 43591966, "creation_date": 1493037913, "answers": [{"body": "<p><strong>This is not normal if your Marathon reelects every 30 minutes.</strong> In normal circumstances Marathon should not abdicate or reelect new leader until maintenance occurs (update or restart). Although if this happens it could be caused by 4 main problems (all results in timeouts):</p>\n\n<ol>\n<li>Marathon performance \u2014 when marathon has a performance problem, one of the symptom is loosing leadership. This is because Marathon does not responds to Zookeeper in given interval and is marked as gone.</li>\n<li>Marathon Zookeeper connection issues \u2014 when network delay are too high (e.g., Zookeeper cluster is located in different DC than Marathon) then some updates can timeout. This will result in loosing leadership.</li>\n<li>Zookeeper performance \u2014 when Zookeeper has to much job to do it will timeout some requests causing Marathon to loose leadership.</li>\n<li>Marathon forced to abdicated by <code>DELETE /v2/leader</code></li>\n</ol>\n\n<p>To fix performance problems follow below steps described <a href=\"http://allegro.tech/2017/03/hitting-the-wall.html\" rel=\"nofollow noreferrer\">here</a></p>\n\n<blockquote>\n  <ol>\n  <li>Shard your marathon.</li>\n  <li>Monitor \u2014 enable metrics but remember to configure them.</li>\n  <li>Update to 1.3.10 or later.</li>\n  <li>Minimize Zookeeper communication latency and object size.</li>\n  <li>Tune JVM \u2014 add more heap and CPUs :).</li>\n  <li>Do not use the event bus \u2014 if you really need to, use filtered SSE, and accept it is asynchronous and events are delivered at most once.</li>\n  <li>If you need task life cycle events, use a custom executor.</li>\n  <li>Prefer batch deployments to many individual ones.</li>\n  </ol>\n</blockquote>\n", "answer_id": 43591966, "last_activity_date": 1493190722, "creation_date": 1493047359, "score": 5, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "last_edit_date": 1493190722, "question_id": 43588434}], "score": 3, "link": "https://stackoverflow.com/questions/43588434/what-conditions-cause-a-marathon-leader-election", "answer_count": 1, "owner": {"user_id": 260528, "profile_image": "https://www.gravatar.com/avatar/a123410cfb9ea6510294a295bb548530?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9015, "link": "https://stackoverflow.com/users/260528/mike-sherov", "accept_rate": 87, "display_name": "Mike Sherov"}, "view_count": 116, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43588434}{"is_answered": false, "tags": ["dcos"], "title": "DCOS 1.8 cluster built on IBM z (s390x) platform does not show stats on DCOS-UI", "last_activity_date": 1494330555, "answer_count": 0, "creation_date": 1494330555, "score": 2, "link": "https://stackoverflow.com/questions/43869023/dcos-1-8-cluster-built-on-ibm-z-s390x-platform-does-not-show-stats-on-dcos-ui", "owner": {"user_id": 7985311, "profile_image": "https://www.gravatar.com/avatar/27b2679bcfe70f6b66654982884be3cf?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/7985311/ntamhank", "display_name": "ntamhank"}, "view_count": 27, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43869023}{"body": "<p>I have consul running on Consul v0.5.2 version &amp; services running in Mesos. Services keep moving from 1 server to another.</p>\n\n<p>Is there way to deregister services in consul that are in 'failing' state? I am able to get the list of services in failing state using this curl</p>\n\n<pre><code>curl http://localhost:8500/v1/health/state/critical\n</code></pre>\n\n<p>Issue that we are seeing is over a period of time in consul UI we have stale data &amp; making the whole UI unusable</p>\n", "is_answered": true, "title": "Consul deregister 'failing' services", "last_edit_date": 1499150338, "tags": ["microservices", "mesos", "mesosphere", "consul", "consul-template"], "view_count": 300, "accepted_answer_id": 40022565, "last_activity_date": 1499150338, "answers": [{"body": "<p>Consul by default do not deregister unhealthy services instead marks them as critical.\nFrom Consul 0.7 there is special option (<code>deregister_critical_service_after</code>) that allows you to define time after unhealthy service will be deregstered</p>\n\n<p>From Consul <a href=\"https://github.com/hashicorp/consul/blob/v0.7.0/CHANGELOG.md\" rel=\"noreferrer\">0.7 Changelog</a></p>\n\n<blockquote>\n  <p><strong>Automatic Service Deregistration:</strong> Added a new\n  <code>deregister_critical_service_after</code> timeout field for health checks\n  which will cause the service associated with that check to get\n  deregistered if the check is critical for longer than the timeout.\n  This is useful for cleanup of health checks registered natively by\n  applications, or in other situations where services may not always be\n  cleanly shutdown. <a href=\"https://github.com/hashicorp/consul/issues/679\" rel=\"noreferrer\">GH-679</a></p>\n</blockquote>\n\n<p>If you are usign Marathon then you can consider using <a href=\"https://github.com/allegro/marathon-consul\" rel=\"noreferrer\">allegro/marathon-consul</a> it will deregister task when its dead</p>\n", "answer_id": 40022565, "last_activity_date": 1476365768, "creation_date": 1476365768, "score": 5, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 40010594}, {"body": "<p>Along with what janisz said, you can also run your services in Nomad and Nomad will automatically register and deregister your services for you.  See the <a href=\"https://www.nomadproject.io/docs/service-discovery/index.html\" rel=\"nofollow noreferrer\">Nomad Service Discovery</a> docs for additional details.</p>\n", "answer_id": 41278269, "last_activity_date": 1482393382, "creation_date": 1482393382, "score": 0, "owner": {"user_id": 736571, "profile_image": "https://www.gravatar.com/avatar/032f0832fef7fa016de14a756fa8ac65?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 7087, "link": "https://stackoverflow.com/users/736571/sean", "accept_rate": 62, "display_name": "Sean"}, "is_accepted": false, "question_id": 40010594}], "score": 1, "link": "https://stackoverflow.com/questions/40010594/consul-deregister-failing-services", "answer_count": 2, "owner": {"user_id": 6012980, "profile_image": "https://www.gravatar.com/avatar/9dec89a5fc4eccb77ccdb36248600ea5?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/6012980/devopsnewb", "accept_rate": 40, "display_name": "DevOpsNewB"}, "creation_date": 1476319864, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 40010594}{"body": "<p>For docker orchestration, we are currently using mesos and chronos to schedule job runs.</p>\n\n<p>Now, we dropped chronos and try to set it up via DCOs, using mesos and metronome.</p>\n\n<p>In chronos, I could activate force pulling a docker image via its yml config:</p>\n\n<pre><code>container:\n  type: docker\n  image: registry.example.com:5001/the-app:production\n  forcePullImage: true\n</code></pre>\n\n<p>Now, in DC/OS using metronome and mesos, I also want it to force it to always pull the up-to-date image from the registry, instead of relying on its cached version.</p>\n\n<p>Yet the json config for docker seems limited:</p>\n\n<pre><code>\"docker\": {\n  \"image\": \"registry.example.com:5001/the-app:production\"\n},\n</code></pre>\n\n<p>If I push a new image to the <code>production</code> tag, the old image is used for the job run on mesos.</p>\n\n<p>Just for the sake of it, I tried adding the flag:</p>\n\n<pre><code>\"docker\": {\n  \"image\": \"registry.example.com:5001/my-app:staging\",\n  \"forcePullImage\": true\n},\n</code></pre>\n\n<p>yet on the put request, I get an error:</p>\n\n<pre><code>http PUT example.com/service/metronome/v1/jobs/the-app &lt; app-config.json \n\nHTTP/1.1 422 Unprocessable Entity\nConnection: keep-alive\nContent-Length: 147\nContent-Type: application/json\nDate: Fri, 12 May 2017 09:57:55 GMT\nServer: openresty/1.9.15.1\n\n{\n    \"details\": [\n        {\n            \"errors\": [\n                \"Additional properties are not allowed but found 'forcePullImage'.\"\n            ],\n            \"path\": \"/run/docker\"\n        }\n    ],\n    \"message\": \"Object is not valid\"\n}\n</code></pre>\n\n<p>How can I achieve that the DC OS always pulls the up-to-date image? Or do I have to always update the job definition via a unique image tag?</p>\n", "is_answered": true, "tags": ["docker", "mesos", "dcos", "metronome"], "last_edit_date": 1494606463, "title": "How to force pull docker images in DC OS?", "last_activity_date": 1502358968, "answer_count": 3, "creation_date": 1494514068, "score": 0, "link": "https://stackoverflow.com/questions/43918822/how-to-force-pull-docker-images-in-dc-os", "answers": [{"body": "<p>I think the <code>\"forcePullImage\": true</code> should work with the <code>docker</code> dictionary.</p>\n\n<p>Check:\n<a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/native-docker.html</a></p>\n\n<p>Look at the \"force pull option\".</p>\n", "answer_id": 43927300, "last_activity_date": 1494546632, "creation_date": 1494546632, "score": -2, "owner": {"user_id": 2623798, "profile_image": "https://www.gravatar.com/avatar/f60f4104430fcbdde4f9c5da7b6bf8c9?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 125, "link": "https://stackoverflow.com/users/2623798/anaken78", "display_name": "anaken78"}, "is_accepted": false, "question_id": 43918822}, {"body": "<p>As this is currently not possible I created a <a href=\"https://jira.mesosphere.com/browse/DCOS_OSS-1479\" rel=\"nofollow noreferrer\">feature request</a> asking for this feature.</p>\n\n<hr>\n\n<p>In the meantime, I created workaround to be able to update the image tag for all the registered jobs using typescript and request-promise library.</p>\n\n<p>Basically I fetch all the jobs from the <a href=\"https://dcos.github.io/metronome/docs/generated/api.html\" rel=\"nofollow noreferrer\">metronome api</a>, filter them by id starting with my app name, and then change the docker image, and issue for each changed job a PUT request to the metronome api to update the config.</p>\n\n<p>Here's my solution:</p>\n\n<pre><code>const targetTag = 'stage-build-1501'; // currently hardcoded, should be set via jenkins run\nconst app = 'my-app';\nconst dockerImage = `registry.example.com:5001/${app}:${targetTag}`;\n\ninterface JobConfig {\n    id: string;\n    description: string;\n    labels: object;\n    run: {\n        cpus: number,\n        mem: number,\n        disk: number,\n        cmd: string,\n        env: any,\n        placement: any,\n        artifacts: any[];\n        maxLaunchDelay: 3600;\n        docker: { image: string };\n        volumes: any[];\n        restart: any;\n    };\n}\n\nconst rp = require('request-promise');\n\nconst BASE_URL = 'http://example.com';\nconst METRONOME_URL = '/service/metronome/v1/jobs';\nconst JOBS_URL = BASE_URL + METRONOME_URL;\n\nconst jobsOptions = {\n    uri: JOBS_URL,\n    headers: {\n        'User-Agent': 'Request-Promise',\n    },\n    json: true,\n};\n\nconst createJobUpdateOptions = (jobConfig: JobConfig) =&gt; {\n    return {\n        method: 'PUT',\n        body: jobConfig,\n        uri: `${JOBS_URL}/${jobConfig.id}`,\n        headers: {\n            'User-Agent': 'Request-Promise',\n        },\n        json: true,\n    };\n};\n\nrp(jobsOptions).then((jobs: JobConfig[]) =&gt; {\n    const filteredJobs = jobs.filter((job: any) =&gt; {\n        return job.id.includes('job-prefix.'); // I don't want to change the image of all jobs, only for the same application\n    });\n\n    filteredJobs.map((job: JobConfig) =&gt; {\n        job.run.docker.image = dockerImage;\n    });\n\n    filteredJobs.map((updateJob: JobConfig) =&gt; {\n        console.log(`${updateJob.id} to be updated!`);\n        const requestOption = createJobUpdateOptions(updateJob);\n        rp(requestOption).then((response: any) =&gt; {\n            console.log(`Updated schedule for ${updateJob.id}`);\n        });\n    });\n\n});\n</code></pre>\n", "answer_id": 43942410, "last_activity_date": 1502358968, "creation_date": 1494606287, "score": 0, "owner": {"user_id": 457268, "profile_image": "https://i.stack.imgur.com/ha0Fa.jpg?s=128&g=1", "user_type": "registered", "reputation": 10350, "link": "https://stackoverflow.com/users/457268/k0pernikus", "accept_rate": 63, "display_name": "k0pernikus"}, "is_accepted": false, "last_edit_date": 1502358968, "question_id": 43918822}, {"body": "<p>The Metronome API doesn't support this yet, see <a href=\"https://github.com/dcos/metronome/blob/master/api/src/main/resources/public/api/v1/schema/jobspec.schema.json\" rel=\"nofollow noreferrer\">https://github.com/dcos/metronome/blob/master/api/src/main/resources/public/api/v1/schema/jobspec.schema.json</a></p>\n", "answer_id": 44685865, "last_activity_date": 1498077494, "creation_date": 1498077494, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 43918822}], "owner": {"user_id": 457268, "profile_image": "https://i.stack.imgur.com/ha0Fa.jpg?s=128&g=1", "user_type": "registered", "reputation": 10350, "link": "https://stackoverflow.com/users/457268/k0pernikus", "accept_rate": 63, "display_name": "k0pernikus"}, "view_count": 284, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43918822}{"body": "<p>Can Apache Mesos 'master' nodes be co-located on the same machine as Mesos 'slave' nodes? Similarly (for high-availability (HA) deploys), can the Apache Zookeeper nodes used in Mesos 'master' election be deployed on the same machines as Mesos 'slave' nodes?</p>\n\n<p>Mesos recommends 3 'masters' be used for HA deploys, and Zookeeper recommends 5 nodes be used for its quorum election system. It would be nice to have these services running along side Mesos 'slave' processes instead of committing 8 machines to effectively 'non-productive' tasks.</p>\n\n<p>If such a setup is feasible, what are the pros/cons of such a setup?</p>\n\n<p>Thanks!</p>\n", "is_answered": true, "title": "Can Mesos 'master' and 'slave' nodes be deployed on the same machines?", "last_edit_date": 1419089091, "tags": ["apache-zookeeper", "mesos", "mesosphere"], "view_count": 4396, "accepted_answer_id": 26647706, "last_activity_date": 1419089091, "answers": [{"body": "<p>You can definitely run a master, slave, and zk process all on the same node. You can even run multiple master and slave processes on the same node, provided you give them each unique ports, but that's only useful for a test cluster.</p>\n\n<p>Typically we recommend running ZK on the same nodes as your masters, but if you have extra ZKs, you can certainly run them on slaves, or mix-and-match as you see fit, as long as all master/slave/framework nodes can reach the ZK nodes, and all slaves can reach the masters.</p>\n\n<p>For a smaller cluster (&lt;10 nodes) it could make sense to run a slave process on each master, especially since the standby masters won't be doing much. Even an active master for a small cluster uses only a small amount of cpu, memory, and network resources. Just make sure you adjust the --resources on that slave to account for the master's resource usage.</p>\n\n<p>Once your cluster grows larger (especially >100 nodes) the network traffic to/from the master as well as its cpu/memory utilization becomes significant enough that you wouldn't want to run a mesos slave on the same node as the master. It should be fine to co-locate ZK with your master even at large scale.</p>\n\n<p>You didn't specifically ask, but I'll also discuss where to run your framework schedulers (e.g. Spark, Marathon, or Chronos). These could be co-located with any of the other components, but they only really need to be able to reach the master and zk nodes, since all communication to slaves goes through the master. Some customers run the schedulers on master nodes, some run them on edge nodes (so users don't have access to the slaves), and others use meta-frameworks like Marathon to run other schedulers on slaves as Mesos tasks.</p>\n", "answer_id": 26647706, "last_activity_date": 1414655851, "creation_date": 1414655851, "score": 30, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 26597521}], "score": 16, "link": "https://stackoverflow.com/questions/26597521/can-mesos-master-and-slave-nodes-be-deployed-on-the-same-machines", "answer_count": 1, "owner": {"user_id": 336019, "profile_image": "https://i.stack.imgur.com/evr7Y.jpg?s=128&g=1", "user_type": "registered", "reputation": 2886, "link": "https://stackoverflow.com/users/336019/ethan", "accept_rate": 73, "display_name": "Ethan"}, "creation_date": 1414446886, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 26597521}{"body": "<p>I have an query, If we can use Mesos Cluster by directly installing master and slave nodes. Then why do we need DCOS , is it  that DCOS provides additional support along with mesos cluster. Please elaborate on this part.</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1444692485, "title": "Why is DCOS required if we can deploy Mesos Cluster directly", "last_activity_date": 1444692485, "answer_count": 1, "creation_date": 1444251687, "score": 1, "link": "https://stackoverflow.com/questions/33002346/why-is-dcos-required-if-we-can-deploy-mesos-cluster-directly", "answers": [{"body": "<p>Depends on your needs :-):\nHere what in my opinion the Community Edition (the Enterprise Edition includes more proprietary features such as security) of DCOS adds to self setup of Mesos:</p>\n\n<ul>\n<li>Easy setup, including <a href=\"https://github.com/mesosphere/marathon\" rel=\"nofollow\">Marathon</a> and <a href=\"https://github.com/mesosphere/mesos-dns\" rel=\"nofollow\">MesosDNS</a>.</li>\n<li><a href=\"https://github.com/mesosphere/dcos-cli\" rel=\"nofollow\">Command Line Interface</a> with one Click install from the <a href=\"https://github.com/mesosphere/universe\" rel=\"nofollow\">Universe</a>. I personally especially like the simple installs of these services as it is really simple to install for example HDFS or cassandra in your cluster. <strong>Note</strong>: As with the above you can probably with some effort configure such setup yourself as both projects are on Github. </li>\n<li>Very nice UI </li>\n</ul>\n\n<p>So overall I would summarize DCOS provides a very easy and tested best-practice setup of Mesos and its ecosystem.</p>\n\n<p>Hope this helps! </p>\n", "answer_id": 33057581, "last_activity_date": 1444502158, "creation_date": 1444502158, "score": 2, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 33002346}], "owner": {"user_id": 404524, "profile_image": "https://www.gravatar.com/avatar/c14eb006f0d30a0e53d17b5ba5314a36?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 20, "link": "https://stackoverflow.com/users/404524/rohit-singh", "accept_rate": 0, "display_name": "rohit singh"}, "view_count": 220, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 33002346}{"body": "<p>I have Apache Mesos 0.22.1 cluster (3 masters &amp; 5 slaves), running Cloudera HDFS  (2.5.0-cdh5.3.1) in HA configuration and Spark 1.5.1 framework.</p>\n\n<p>When I try to spark-submit compiled HdfsTest.scala example app (from Spark 1.5.1 sources) - it fails with <code>java.lang.IllegalArgumentException: java.net.UnknownHostException: hdfs</code> error in executor logs. This error is only observed when I pass HDFS HA Path as an argument <code>hdfs://hdfs/&lt;file&gt;</code>, when I pass <code>hdfs://namenode1.hdfs.mesos:50071/tesfile</code> - everything works fine.</p>\n\n<p>What I've found after enabling TRACE logging is that Spark driver actually reads <code>hdfs://hdfs</code> URL correctly, but Spark executor - doesn't.</p>\n\n<p>My Scala app code:</p>\n\n<pre><code>import org.apache.spark._\nobject HdfsTest {\n  def main(args: Array[String]) {\n    val sparkConf = new SparkConf().setAppName(\"HdfsTest\")\n    val sc = new SparkContext(sparkConf)\n    val file = sc.textFile(args(0))\n    val mapped = file.map(s =&gt; s.length).cache()\n    for (iter &lt;- 1 to 10) {\n      val start = System.currentTimeMillis()\n      for (x &lt;- mapped) { x + 2 }\n      val end = System.currentTimeMillis()\n      println(\"Iteration \" + iter + \" took \" + (end-start) + \" ms\")\n    }\n    sc.stop()\n   }\n  }\n</code></pre>\n\n<p>I compile this code and submit jar file to Spark in cluster mode:</p>\n\n<pre><code>/opt/spark/bin/spark-submit --deploy-mode cluster --class com.cisco.hdfs.HdfsTest http://1.2.3.4/HdfsTest-0.0.1.jar hdfs://hdfs/testfile\n</code></pre>\n\n<p>My spark-defaults.conf file:</p>\n\n<pre><code>spark.master                     spark://1.2.3.4:7077\nspark.eventLog.enabled           true\nspark.driver.memory              1g\n</code></pre>\n\n<p>My spark-env.sh file:</p>\n\n<pre><code>export HADOOP_HOME=/opt/spark\nexport HADOOP_CONF_DIR=/opt/spark/conf\n</code></pre>\n\n<p>I have spark deployed on each slave in /opt/spark directory.</p>\n\n<p>I can accesses HDFS using \"hdfs dfs -ls hdfs://hdfs/\" command in console, without the need to specify active namenode address and port. </p>\n\n<pre><code>core-site.xml:\n----------------------------------------------------------------------\n&lt;configuration&gt;\n &lt;property&gt;\n  &lt;name&gt;fs.default.name&lt;/name&gt;\n  &lt;value&gt;hdfs://hdfs&lt;/value&gt;\n &lt;/property&gt;\n&lt;/configuration&gt;\n\nhdfs-site.xml:\n----------------------------------------------------------------------\n&lt;configuration&gt;\n &lt;property&gt;\n  &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n  &lt;value&gt;true&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.nameservice.id&lt;/name&gt;\n  &lt;value&gt;hdfs&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.nameservices&lt;/name&gt;\n  &lt;value&gt;hdfs&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt;\n  &lt;value&gt;nn1,nn2&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.rpc-address.hdfs.nn1&lt;/name&gt;\n  &lt;value&gt;namenode1.hdfs.mesos:50071&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.http-address.hdfs.nn1&lt;/name&gt;\n  &lt;value&gt;namenode1.hdfs.mesos:50070&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.rpc-address.hdfs.nn2&lt;/name&gt;\n  &lt;value&gt;namenode2.hdfs.mesos:50071&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.http-address.hdfs.nn2&lt;/name&gt;\n  &lt;value&gt;namenode2.hdfs.mesos:50070&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt;\n  &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider      &lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;\n     &lt;value&gt;qjournal://journalnode1.hdfs.mesos:8485;journalnode2.hdfs.mesos:8485;journalnode3.hdfs.mesos:8485/hdfs&lt;/value&gt;\n   &lt;/property&gt;\n\n &lt;property&gt;\n   &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;\n   &lt;value&gt;master.mesos:2181&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;\n  &lt;value&gt;/var/lib/hdfs/data/jn&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n   &lt;value&gt;file:///var/lib/hdfs/data/name&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n   &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n   &lt;value&gt;file:///var/lib/hdfs/data/data&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;\n  &lt;value&gt;shell(/bin/true)&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.permissions&lt;/name&gt;\n  &lt;value&gt;false&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.datanode.du.reserved&lt;/name&gt;\n  &lt;value&gt;10485760&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt;\n  &lt;value&gt;41943040&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n   &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt;\n   &lt;value&gt;0.90&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt;\n  &lt;value&gt;60000&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt;\n  &lt;value&gt;10&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;\n  &lt;value&gt;20&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.image.compress&lt;/name&gt;\n  &lt;value&gt;true&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.image.compression.codec&lt;/name&gt;\n  &lt;value&gt;org.apache.hadoop.io.compress.SnappyCodec&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt;\n  &lt;value&gt;0.35f&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt;\n  &lt;value&gt;4&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;\n  &lt;value&gt;false&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n   &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;\n   &lt;value&gt;true&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt;\n  &lt;value&gt;1000&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt;\n   &lt;value&gt;1000&lt;/value&gt;\n &lt;/property&gt;\n\n &lt;property&gt;\n  &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;\n  &lt;value&gt;/var/run/hadoop-hdfs/dn._PORT&lt;/value&gt;\n &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n", "is_answered": true, "tags": ["scala", "apache-spark", "hdfs", "mesos", "mesosphere"], "last_edit_date": 1445024066, "title": "Accessing HDFS HA from spark job (UnknownHostException error)", "last_activity_date": 1504070189, "answer_count": 5, "creation_date": 1445009838, "score": 4, "link": "https://stackoverflow.com/questions/33174386/accessing-hdfs-ha-from-spark-job-unknownhostexception-error", "answers": [{"body": "<p><code>java.net.UnknownHostException</code> indicates that the host with provide name <code>hdfs</code> in this case can not be resolved to an IP Address.</p>\n\n<p><a href=\"https://stackoverflow.com/questions/6484275/what-causes-the-error-java-net-unknownhostexception\">What causes the error - java.net.UnknownHostException</a></p>\n\n<p>You could try to check if does resolve to an IP address <code>ping hdfs</code>.</p>\n", "answer_id": 33178330, "last_activity_date": 1445024165, "creation_date": 1445024165, "score": -2, "owner": {"user_id": 1119997, "profile_image": "https://www.gravatar.com/avatar/4a485e339c4de35684dfe31dc758041e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4679, "link": "https://stackoverflow.com/users/1119997/tuxdna", "accept_rate": 68, "display_name": "tuxdna"}, "is_accepted": false, "question_id": 33174386}, {"body": "<p>I've found the solution - adding </p>\n\n<pre><code>spark.files file:///opt/spark/conf/hdfs-site.xml,file:///opt/spark/conf/core-site.xml\n</code></pre>\n\n<p>to <code>conf/spark-defaults.conf</code> on each slave solves the problem.</p>\n\n<p>After that executors successfully download <code>core-site.xml</code> and <code>hdfs-site.xml</code> from driver program to executor program.</p>\n", "answer_id": 33256076, "last_activity_date": 1481155699, "creation_date": 1445421059, "score": 4, "owner": {"user_id": 1348356, "profile_image": "https://www.gravatar.com/avatar/cd8edcfb0bfc69a8249fb1afbd5027e4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 73, "link": "https://stackoverflow.com/users/1348356/kyarovoy", "display_name": "kyarovoy"}, "is_accepted": false, "last_edit_date": 1481155699, "question_id": 33174386}, {"body": "<p>It is necessary to invoke spark-submit using the following:</p>\n\n<pre><code>HADOOP_CONF_DIR=/etc/hadoop/conf spark-submit\n</code></pre>\n\n<p>This configures spark correctly.</p>\n", "answer_id": 41029584, "last_activity_date": 1481155642, "creation_date": 1481155599, "score": 0, "owner": {"user_id": 1337387, "profile_image": "https://i.stack.imgur.com/wrmhl.jpg?s=128&g=1", "user_type": "registered", "reputation": 526, "link": "https://stackoverflow.com/users/1337387/akshat-thakar", "display_name": "akshat thakar"}, "is_accepted": false, "last_edit_date": 1481155642, "question_id": 33174386}, {"body": "<p>Spark internally will use default conf available for <strong>fs.defaultFS</strong>, which is your local <code>file://</code>. </p>\n\n<p>in-order it to honor HDFS HA you need to pass both <code>core-site.xml</code> and <code>hdfs-site.xml</code> to the <code>SparkContext</code> via the CLASSPATH, or as below (make sure these files available in the local slave nodes in the same location eg: <code>/config/core-site.xml</code> </p>\n\n<p>For example, Spark 1.x</p>\n\n<pre><code>val sc = new SparkContext(sparkConf)\n</code></pre>\n\n<p>Spark 2.x</p>\n\n<pre><code>SparkSession sparkSession = SparkSession.builder().config(sparkConf).getOrCreate();\nval sc = sparkSession.sparkContext()\n</code></pre>\n\n<p>In either case, </p>\n\n<pre><code>sc.hadoopConfiguration().addResource(new org.apache.hadoop.fs.Path(\"/config/core-site.xml\"));\nsc.hadoopConfiguration().addResource(new org.apache.hadoop.fs.Path(\"/config/hdfs-site.xml\"));\n</code></pre>\n", "answer_id": 45225521, "last_activity_date": 1504070189, "creation_date": 1500586142, "score": 1, "owner": {"user_id": 6759736, "profile_image": "https://www.gravatar.com/avatar/981b7f1c3f41389761c38b056a689e9c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/6759736/kiran-n", "display_name": "Kiran N"}, "is_accepted": false, "last_edit_date": 1504070189, "question_id": 33174386}, {"body": "<p>From a very basic IntelliJ project (not using <code>spark-submit</code>) , I verified these are the only settings you need on the CLASSPATH of your application. </p>\n\n<p><strong>core-site.xml</strong></p>\n\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://hdfscluster&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n\n<p><strong>hdfs-site.xml</strong></p>\n\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.client.failover.proxy.provider.hdfscluster&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.nameservices&lt;/name&gt;\n        &lt;value&gt;hdfscluster&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.ha.namenodes.hdfscluster&lt;/name&gt;\n        &lt;value&gt;nn1,nn2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.hdfscluster.nn1&lt;/name&gt;\n        &lt;value&gt;namenode1.fqdn:8020&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.rpc-address.hdfscluster.nn2&lt;/name&gt;\n        &lt;value&gt;namenode2.fqdn:8020&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>\n\n<p><strong>Main.java</strong></p>\n\n<pre><code>public static void main( String[] args ) {\n\n    SparkSession spark = SparkSession.builder()\n            .master(\"local[*]\") // \"yarn-client\"\n            .getOrCreate();\n\n    spark.read().text(\"hdfs:///tmp/sample.txt\");\n}\n</code></pre>\n\n<p>You'll also need a <code>yarn-site.xml</code> if you want to submit via YARN, but I see your question mentions Mesos</p>\n", "answer_id": 45949828, "last_activity_date": 1504050129, "creation_date": 1504050129, "score": 0, "owner": {"user_id": 2308683, "profile_image": "https://www.gravatar.com/avatar/eac16c9fc481cb6825f8b3a35f916b5c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 47972, "link": "https://stackoverflow.com/users/2308683/cricket-007", "accept_rate": 90, "display_name": "cricket_007"}, "is_accepted": false, "question_id": 33174386}], "owner": {"user_id": 1348356, "profile_image": "https://www.gravatar.com/avatar/cd8edcfb0bfc69a8249fb1afbd5027e4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 73, "link": "https://stackoverflow.com/users/1348356/kyarovoy", "display_name": "kyarovoy"}, "view_count": 5095, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 33174386}{"body": "<p>I have an ArangoDB 3.0 cluster set-up through DC/OS 1.7, as shown here:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Fqg6d.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Fqg6d.png\" alt=\"ArangoDB 3.0 cluster via DC/OS 1.7\"></a></p>\n\n<p>I tried two queries on this 3x co-ord, 6x server set-up. Each node has the following specs:</p>\n\n<ul>\n<li>15GB RAM (4GB assigned per DB Primary via DC/OS)</li>\n<li>8 cores</li>\n<li>CoreOS</li>\n</ul>\n\n<p>I tried two queries to test performance against the <code>coins</code> collection. No indices were added. The config of the collection is:</p>\n\n<pre><code>Wait for sync:  false\nType:   document\nStatus: loaded\nShards: 16\nReplication factor: 1\nIndex buckets:  8\n</code></pre>\n\n<p><strong>Write:</strong></p>\n\n<pre><code>FOR i IN 1..1000000 INSERT {flip:RAND() &gt; 0.5 ? 'h' : 't'} IN coins\n</code></pre>\n\n<p>Result:</p>\n\n<p><a href=\"https://i.stack.imgur.com/kIaES.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kIaES.png\" alt=\"Executed in 13.894 seconds\"></a></p>\n\n<p>Execution plan:</p>\n\n<pre><code> Id   NodeType            Site          Est.   Comment\n  1   SingletonNode       COOR             1   * ROOT\n  2   CalculationNode     COOR             1     - LET #2 = 1 .. 1000000   /* range */   /* simple expression */\n  3   EnumerateListNode   COOR       1000000     - FOR i IN #2   /* list iteration */\n  4   CalculationNode     COOR       1000000       - LET #4 = { \"flip\" : ((RAND() &gt; 0.5) ? \"h\" : \"t\") }   /* v8 expression */\n  6   DistributeNode      COOR       1000000       - DISTRIBUTE\n  7   RemoteNode          DBS        1000000       - REMOTE\n  5   InsertNode          DBS              0       - INSERT #4 IN coins\n  8   RemoteNode          COOR             0       - REMOTE\n  9   GatherNode          COOR             0       - GATHER\n\nIndexes used:\n none\n\nOptimization rules applied:\n Id   RuleName\n  1   remove-data-modification-out-variables\n  2   distribute-in-cluster\n\nWrite query options:\n Option                   Value\n ignoreErrors             false\n waitForSync              false\n nullMeansRemove          false\n mergeObjects             true\n ignoreDocumentNotFound   false\n readCompleteInput        false\n</code></pre>\n\n<p><strong>Read:</strong></p>\n\n<pre><code>FOR coin IN coins COLLECT flip = coin.flip WITH COUNT INTO total RETURN {flip, total}\n</code></pre>\n\n<p>Result:</p>\n\n<p><a href=\"https://i.stack.imgur.com/gHinm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gHinm.png\" alt=\"Executed in 1.157 seconds\"></a></p>\n\n<p>Execution plan:</p>\n\n<pre><code> Id   NodeType                  Site          Est.   Comment\n  1   SingletonNode             DBS              1   * ROOT\n  2   EnumerateCollectionNode   DBS        1000000     - FOR coin IN coins   /* full collection scan */\n  3   CalculationNode           DBS        1000000       - LET #3 = coin.`flip`   /* attribute expression */   /* collections used: coin : coins */\n 10   RemoteNode                COOR       1000000       - REMOTE\n 11   GatherNode                COOR       1000000       - GATHER\n  4   CollectNode               COOR        800000       - COLLECT flip = #3 WITH COUNT INTO total   /* hash*/\n  7   SortNode                  COOR        800000       - SORT flip ASC\n  5   CalculationNode           COOR        800000       - LET #5 = { \"flip\" : flip, \"total\" : total }   /* simple expression */\n  6   ReturnNode                COOR        800000       - RETURN #5\n\nIndexes used:\n none\n\nOptimization rules applied:\n Id   RuleName\n  1   move-calculations-up\n  2   move-calculations-down\n  3   scatter-in-cluster\n  4   distribute-filtercalc-to-cluster\n  5   remove-unnecessary-remote-scatter\n</code></pre>\n\n<p>Then I scaled down to just 1x co-ordinator, and 1x server - reducing available RAM from 90GB / 48 cores, down to 15GB / 8 cores.</p>\n\n<p>I expected write and read to show some difference. Here are the results of the same queries (after truncating the collection, and re-running):</p>\n\n<p><strong>Write:</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/P0ca7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/P0ca7.png\" alt=\"Executed in 13.763 seconds\"></a></p>\n\n<p><strong>Read:</strong></p>\n\n<p><a href=\"https://i.stack.imgur.com/IqfC0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/IqfC0.png\" alt=\"Executed in 1.127 seconds\"></a></p>\n\n<p><strong>Result - Almost identical execution times.</strong></p>\n\n<p>Questions:</p>\n\n<ul>\n<li><p>Am I missing some kind of step re: explicit replication? (I tried 'rebalancing shards' - which caused some of the additional DB servers to be labeled as followers, but didn't make a difference to execution speed)</p></li>\n<li><p>Is my collection config optimal? I opted for 16 shards based on a 'DBPrimary squared' recommendation in docs (my original set-up used 4x servers, and saw equivalent performance)</p></li>\n<li><p>Are the queries I tried able to cluster effectively? Ranged loops, etc.</p></li>\n<li><p>Are there sample queries I can try that will test whether the cluster is configured correctly, and should definitively prove read/write performance differences between 1x nodes vs. n nodes?</p></li>\n</ul>\n", "is_answered": true, "title": "ArangoDB 3.0 cluster - zero improvement on read/write speeds?", "tags": ["performance", "cluster-computing", "mesos", "arangodb", "dcos"], "last_activity_date": 1467205914, "accepted_answer_id": 38100651, "creation_date": 1467119657, "answers": [{"body": "<p>I think I can shed some light on these questions (being one of the core developers of ArangoDB and responsible for the distributed mode). The following comments consider ArangoDB Version 3.0.</p>\n\n<p>A single AQL query in 3.0 and before uses only a single coordinator. Therefore deploying more coordinators does not speed up a single query, be it a writing or a reading query.</p>\n\n<p>This is very hard to change because AQL organises a data pipeline across the cluster and it is difficult to involve more than one coordinator.</p>\n\n<p>If you do writing queries, we currently still have an exclusive write lock on the involved collections in 3.0. Therefore, more shards or DBservers do not help to scale up the performance of AQL write queries. We will work on this restriction for 3.1 but this is not particularly easy either.</p>\n\n<p>More DBservers and coordinators will speed up the throughput of single document reads and writes (when not using AQL), as has been shown in <a href=\"https://mesosphere.com/blog/2015/11/30/arangodb-benchmark-dcos/\" rel=\"nofollow\">this blog post</a>. Therefore, your write query can probably be performed much faster by using the standard document API with the new batch extensions.</p>\n\n<p>For reading AQL queries, you will in general see a speedup if you use more servers, if the query can be parallelised across the shards, or if you measure the throughput of many such queries.</p>\n\n<p>For your particular reading query with the aggregation, we are missing an AQL query optimizer rule with its accompanying infrastructure that can move the aggregations to the individual shards and then combine the results. This is planned but not yet implemented in 3.0, and therefore you do not see a speedup in your reading query. The explain output shows that the COLLECT with its SORT is executed on the coordinator and therefore all data has to be moved through the single coordinator.</p>\n\n<p>As to your first question, replication will not help here either. If you set up synchronous replication, then in 3.0, all reads and writes go through a single server for each shard. Therefore, a higher replication factor does at this stage not increase your read performance.</p>\n\n<p>We will be able to get around this limitation once we have proper cluster wide transactions, which is also planned but hasn't landed in 3.0.</p>\n", "answer_id": 38100651, "last_activity_date": 1467205914, "creation_date": 1467205914, "score": 1, "owner": {"user_id": 3041996, "profile_image": "https://www.gravatar.com/avatar/4b6907682e991835c5ef6d97561ecfdf?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1097, "link": "https://stackoverflow.com/users/3041996/max-neunh%c3%b6ffer", "display_name": "Max Neunh\u00f6ffer"}, "is_accepted": true, "question_id": 38077301}], "score": 1, "link": "https://stackoverflow.com/questions/38077301/arangodb-3-0-cluster-zero-improvement-on-read-write-speeds", "answer_count": 1, "owner": {"user_id": 216012, "profile_image": "https://www.gravatar.com/avatar/e80bdb7a7d2f6be1f039b83b365e03ee?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3092, "link": "https://stackoverflow.com/users/216012/lee-benson", "accept_rate": 80, "display_name": "Lee Benson"}, "view_count": 384, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 38077301}{"is_answered": true, "tags": ["cassandra", "mesos", "dcos", "dbeaver"], "title": "How to connect Cassandra running on DCOS from dbeaver", "last_activity_date": 1498574550, "answer_count": 1, "creation_date": 1498560374, "score": 0, "link": "https://stackoverflow.com/questions/44778358/how-to-connect-cassandra-running-on-dcos-from-dbeaver", "owner": {"user_id": 5684969, "profile_image": "https://lh3.googleusercontent.com/-qb3ugL50gyo/AAAAAAAAAAI/AAAAAAAAAj4/uZEg1norkM0/photo.jpg?sz=128", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/5684969/guda-uma-shanker", "display_name": "Guda uma shanker"}, "view_count": 47, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44778358}{"body": "<p>I am currently setting up a POC network of dockerised services using DC/OS. As this is a POC, I have had to make many revisions to the containers in order to get things working.  </p>\n\n<p>Consequently, when drilling into some services using the DC/OS (v1.8.7) web UI, I can see hundreds of old tasks - the vast majority of which have a status of 'finished'.  </p>\n\n<p>I realise that I can filter out and just see the 'active' containers by clicking on the appropriate tab, but this is not what I am after because I would like to be able to see when a container is staging, and also - all the history for the finished tasks is worthless to me.  </p>\n\n<p><strong>How do I purge DC/OS of these finished tasks, as they are clogging up the UI?</strong>  </p>\n\n<p>Is there a CLI command for this, or do I have to clear out stuff on the master nodes... or is there an handy plug-in that will manage this for me? I've been looking around both on the web and the master nodes, but can't work out what I need to do.</p>\n", "is_answered": true, "title": "Clearing out 'finished' service history in DC/OS", "tags": ["user-interface", "marathon", "dcos"], "last_activity_date": 1480676296, "accepted_answer_id": 40930594, "creation_date": 1480675027, "answers": [{"body": "<p>In DC/OS 1.8.x there is no UI or CLI method to influence garbage collection. You can however, with a custom install, influence some parameter, such as <code>gc_delay</code> (default value: 2 days in DC/OS) and others are using the <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow noreferrer\">Mesos defaults</a>, like <code>gc_disk_headroom</code> (which is unchanged set to <code>0.1</code>, which means, Mesos targets to have 10% of the assigned disk as free space).</p>\n\n<p>For parameters you can change at install time see the <a href=\"https://dcos.io/docs/1.8/administration/installing/custom/configuration-parameters/#-a-name-gc-delay-a-gc_delay\" rel=\"nofollow noreferrer\">Install Configuration Parameters</a> docs for more details.</p>\n", "answer_id": 40930594, "last_activity_date": 1480676296, "creation_date": 1480676296, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 40930170}], "score": 1, "link": "https://stackoverflow.com/questions/40930170/clearing-out-finished-service-history-in-dc-os", "answer_count": 1, "owner": {"user_id": 685341, "profile_image": "https://www.gravatar.com/avatar/60164718921efb89bfff0212de34f177?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 2612, "link": "https://stackoverflow.com/users/685341/jay", "accept_rate": 90, "display_name": "Jay"}, "view_count": 42, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40930170}{"body": "<p>I have installed and configured Mesos and Marathon. Whenever I try to schedule an application, it remains in 'Waiting' state which seems to indicate that Marathon is waiting for offers from Mesos.</p>\n\n<p>When I check the logs in Mesos, I see the following:</p>\n\n<pre><code>I0425 20:22:10.313910  4279 master.cpp:2231] Received SUBSCRIBE call for framework 'chronos-2.4.0' at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892\nI0425 20:22:10.313987  4279 master.cpp:2302] Subscribing framework chronos-2.4.0 with checkpointing enabled and capabilities [  ]\nI0425 20:22:10.313994  4279 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0001 (chronos-2.4.0) at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892 already subscribed, resending acknowledgement\nW0425 20:22:10.314007  4279 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0001 (chronos-2.4.0) at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892\nE0425 20:22:10.314193  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\nI0425 20:22:11.226884  4284 master.cpp:2231] Received SUBSCRIBE call for framework 'marathon' at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nI0425 20:22:11.226959  4284 master.cpp:2302] Subscribing framework marathon with checkpointing enabled and capabilities [  ]\nI0425 20:22:11.226969  4284 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928 already subscribed, resending acknowledgement\nW0425 20:22:11.226982  4284 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nE0425 20:22:11.227226  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\nI0425 20:22:12.113598  4281 http.cpp:312] HTTP GET for /master/state from 192.0.2.1:49698 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'\nI0425 20:22:12.314221  4286 master.cpp:2231] Received SUBSCRIBE call for framework 'chronos-2.4.0' at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892\nI0425 20:22:12.314304  4286 master.cpp:2302] Subscribing framework chronos-2.4.0 with checkpointing enabled and capabilities [  ]\nI0425 20:22:12.314312  4286 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0001 (chronos-2.4.0) at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892 already subscribed, resending acknowledgement\nW0425 20:22:12.314337  4286 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0001 (chronos-2.4.0) at scheduler-07d9654e-5c40-4172-a25d-97c565b5765d@127.0.1.1:50892\nE0425 20:22:12.314524  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\nI0425 20:22:13.081887  4284 master.cpp:2231] Received SUBSCRIBE call for framework 'marathon' at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nI0425 20:22:13.081964  4284 master.cpp:2302] Subscribing framework marathon with checkpointing enabled and capabilities [  ]\nI0425 20:22:13.081987  4284 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928 already subscribed, resending acknowledgement\nW0425 20:22:13.082005  4284 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nE0425 20:22:13.082314  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\nI0425 20:22:13.221590  4282 master.cpp:2231] Received SUBSCRIBE call for framework 'marathon' at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nI0425 20:22:13.221664  4282 master.cpp:2302] Subscribing framework marathon with checkpointing enabled and capabilities [  ]\nI0425 20:22:13.221674  4282 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928 already subscribed, resending acknowledgement\nW0425 20:22:13.221688  4282 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nE0425 20:22:13.222162  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\nI0425 20:22:14.412215  4286 master.cpp:2231] Received SUBSCRIBE call for framework 'marathon' at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nI0425 20:22:14.412281  4286 master.cpp:2302] Subscribing framework marathon with checkpointing enabled and capabilities [  ]\nI0425 20:22:14.412289  4286 master.cpp:2312] Framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928 already subscribed, resending acknowledgement\nW0425 20:22:14.412302  4286 master.hpp:1764] Master attempted to send message to disconnected framework c16a5bfb-838e-4d43-bf3c-21bf94358ab5-0000 (marathon) at scheduler-d998dfb4-9cc2-4d22-9cb7-416433c2fb57@127.0.1.1:35928\nE0425 20:22:14.412495  4287 process.cpp:1958] Failed to shutdown socket with fd 39: Transport endpoint is not connected\n</code></pre>\n\n<p>Any idea as to why it mentions a 'disconnected' framework. In Mesos, I can see the 3 slaves and the Marathon (and Chronos) framework are mentioned in the 'active frameworks'.</p>\n\n<p>The /etc/hosts mention the following entries:</p>\n\n<pre><code>192.0.2.11  master1  # VAGRANT: cd38e81ab8742b23dfbcb913468368ea (master1) / 1b611425-dbad-4bd0-8727-4169c09ec045\n192.0.2.51  slave1  # VAGRANT: 94630539b67d178dddffda29a0313a75 (slave1) / 1a1694de-2bd2-4d96-bdf2-dd6767d1f310\n192.0.2.52  slave2  # VAGRANT: 306e67b33b327b3d1c9990bf1316a321 (slave2) / bdbd677e-5298-4d49-90a8-e521139dd127\n192.0.2.12  master2  # VAGRANT: fb338e9e9c001a5bfab605387ba88d02 (master2) / bdccfd80-b1e6-48a0-8986-b24c7cbd7a25\n192.0.2.53  slave3  # VAGRANT: 3913b3358eadc90c622859ddb90bfede (slave3) / 786cbe69-2af5-43b7-8e70-d6cc07d4ddf4\n192.0.2.13  master3  # VAGRANT: 92cdd6e36a6c0391e2a66f73661e56fe (master3) / 03bb2c16-f474-4412-b8f4-fce82e12955c\n</code></pre>\n\n<p>Note: in case more info is needed on how the cluster was installed, please refer to <a href=\"http://www.wapptastic.com/mesos-marathon-installation-using-vagrant/\" rel=\"nofollow\">this</a> </p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1461675167, "title": "Why do I get \"disconnected framework\"?", "last_activity_date": 1469440910, "answer_count": 2, "creation_date": 1461616471, "score": 2, "link": "https://stackoverflow.com/questions/36850555/why-do-i-get-disconnected-framework", "answers": [{"body": "<p>I guess you need to make sure that the hostnames are resolvable to actual IP addresses.</p>\n\n<p>That's at least what fixed my problems when Marathon etc. tried to bind to <code>127.0.1.1</code> on Ubuntu. I.e. you should add on each host the IP to hostname mappings, e.g.</p>\n\n<pre><code>192.0.2.11 master1\n</code></pre>\n\n<p>entry in the <code>/etc/hosts</code> file either before the mapping of the <code>127.0.1.1</code> to the hostname, or remove the <code>127.0.1.1</code> entry entirely. The Vagrant plugin <a href=\"https://github.com/cogitatio/vagrant-hostsupdater\" rel=\"nofollow\">vagrant-hostsupdater</a> might help.</p>\n", "answer_id": 36858953, "last_activity_date": 1461662223, "creation_date": 1461658072, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "last_edit_date": 1461662223, "question_id": 36850555}, {"body": "<p>You can also set <code>LIBPROCESS_IP</code> as environment variable. I think this is better than changing the <code>/etc/hosts</code>.</p>\n\n<p>Found the solution here: <a href=\"https://groups.google.com/forum/#!topic/marathon-framework/1qboeZTOLU4\" rel=\"nofollow\">https://groups.google.com/forum/#!topic/marathon-framework/1qboeZTOLU4</a></p>\n", "answer_id": 38564779, "last_activity_date": 1469440910, "creation_date": 1469440910, "score": 2, "owner": {"user_id": 369236, "profile_image": "https://www.gravatar.com/avatar/d54c738742e8d2553ba5ebb008e6efda?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 785, "link": "https://stackoverflow.com/users/369236/tooangel", "display_name": "TooAngel"}, "is_accepted": false, "question_id": 36850555}], "owner": {"user_id": 2722090, "profile_image": "https://www.gravatar.com/avatar/6616f475c2d64abf158151192d8e0a7d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 363, "link": "https://stackoverflow.com/users/2722090/wiwa1978", "accept_rate": 46, "display_name": "wiwa1978"}, "view_count": 683, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 36850555}{"is_answered": false, "tags": ["cassandra", "vagrant", "dcos"], "last_edit_date": 1499694870, "title": "vagrant dcos install cassandra error", "last_activity_date": 1499822099, "answer_count": 1, "creation_date": 1499682799, "score": 0, "link": "https://stackoverflow.com/questions/45009789/vagrant-dcos-install-cassandra-error", "owner": {"user_id": 8262820, "profile_image": "https://www.gravatar.com/avatar/4a217f6ead96631cc99b3b87e2f2637d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/8262820/webss", "display_name": "webss"}, "view_count": 32, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45009789}{"body": "<p>can someone who has successfully settup a mesos development cluster on google cluster help me out.. i have the clutser running however I am having a hard time creating a vpn to conect to the clutser even though I have openvpn installed on my machine and I have downloded the openvpn file provided by mesos. I am using ubuntu 14. basically i have followed instruction to create the cluster but in order to access mesos, marathon I need to configure a vpn connection by using the openvpn file provided by mesosphere but I do not how to do it on ubuntu 14..</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "connecting to a mesos development cluster on ubuntu 14 machine via opevpn", "last_activity_date": 1431939599, "answer_count": 1, "creation_date": 1431694518, "score": 0, "link": "https://stackoverflow.com/questions/30260099/connecting-to-a-mesos-development-cluster-on-ubuntu-14-machine-via-opevpn", "answers": [{"body": "<p>Have you tried <code>openvpn --config &lt;file.ovpn&gt;</code>?</p>\n", "answer_id": 30298926, "last_activity_date": 1431939599, "creation_date": 1431939599, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 30260099}], "owner": {"user_id": 4903873, "profile_image": "https://www.gravatar.com/avatar/190e0727fb748c5fa428845424b3ede3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/4903873/hernino", "display_name": "hernino"}, "view_count": 114, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30260099}{"body": "<p>I'm trying to deploy marathon-lb to a Mesos role that I have created on a public agent in my cluster. My custom role is visible in the cluster, but when marathon-lb is deployed to my role, it ends up waiting forever.</p>\n\n<p>I'm not handy enough with Mesos to figure out what the deployment is waiting for. I've looked at the master/agent logs but nothing jumps out as relevant. Any pointers in this regard are appreciated.</p>\n\n<p>The masters are not configured to whitelist any specific roles (via <code>--roles</code>), so I should be able to introduce arbitrary roles to the cluster. Indeed, masters can see the <code>\"slave_public_tools\"</code> role:</p>\n\n<pre><code>[centos@ip-10-0-1-25 ~]$ curl -s master.mesos:5050/roles | jq\n{\n  \"roles\": [\n    {\n      \"frameworks\": [\n        \"2a2b67f7-1440-4594-9cb9-bb86d3cbc110-0002\",\n        \"2a2b67f7-1440-4594-9cb9-bb86d3cbc110-0001\"\n      ],\n      \"name\": \"*\",\n      \"resources\": {\n        \"cpus\": 0,\n        \"disk\": 0,\n        \"gpus\": 0,\n        \"mem\": 0\n      },\n      \"weight\": 1\n    },\n    {\n      \"frameworks\": [\n        \"2a2b67f7-1440-4594-9cb9-bb86d3cbc110-0000\"\n      ],\n      \"name\": \"slave_public\",\n      \"resources\": {\n        \"cpus\": 0,\n        \"disk\": 0,\n        \"gpus\": 0,\n        \"mem\": 0\n      },\n      \"weight\": 1\n    },\n    {\n      \"frameworks\": [\n        \"2a2b67f7-1440-4594-9cb9-bb86d3cbc110-0004\",\n        \"2a2b67f7-1440-4594-9cb9-bb86d3cbc110-0003\"\n      ],\n      \"name\": \"slave_public_tools\",\n      \"resources\": {\n        \"cpus\": 0,\n        \"disk\": 0,\n        \"gpus\": 0,\n        \"mem\": 0\n      },\n      \"weight\": 1\n    }\n  ]\n}\n</code></pre>\n\n<p>In case it matters, I created the <code>\"slave_public_tools\"</code> role by setting <code>MESOS_DEFAULT_ROLE=slave_public_tools</code> in <code>/var/lib/dcos/mesos-slave-common</code> on a public agent before the agent is started for the first time. The mesos agent seems to recognize the default role setting, and the role has resources:</p>\n\n<pre><code>[centos@ip-10-0-1-25 ~]$ url -s 10.0.1.14:5051/state | jq '{ default_role : .flags.default_role }, .reserved_resources_full'\n{\n  \"default_role\": \"slave_public_tools\"\n}\n{\n  \"slave_public_tools\": [\n    {\n      \"name\": \"ports\",\n      \"type\": \"RANGES\",\n      \"ranges\": {\n        \"range\": [\n          {\n            \"begin\": 1,\n            \"end\": 21\n          },\n          {\n            \"begin\": 23,\n            \"end\": 5050\n          },\n          {\n            \"begin\": 5052,\n            \"end\": 32000\n          }\n        ]\n      },\n      \"role\": \"slave_public_tools\"\n    },\n    {\n      \"name\": \"disk\",\n      \"type\": \"SCALAR\",\n      \"scalar\": {\n        \"value\": 51042\n      },\n      \"role\": \"slave_public_tools\",\n      \"disk\": {\n        \"source\": {\n          \"type\": \"MOUNT\",\n          \"mount\": {\n            \"root\": \"/dcos/volume0\"\n          }\n        }\n      }\n    },\n    {\n      \"name\": \"disk\",\n      \"type\": \"SCALAR\",\n      \"scalar\": {\n        \"value\": 51042\n      },\n      \"role\": \"slave_public_tools\"\n    },\n    {\n      \"name\": \"cpus\",\n      \"type\": \"SCALAR\",\n      \"scalar\": {\n        \"value\": 2\n      },\n      \"role\": \"slave_public_tools\"\n    },\n    {\n      \"name\": \"mem\",\n      \"type\": \"SCALAR\",\n      \"scalar\": {\n        \"value\": 6037\n      },\n      \"role\": \"slave_public_tools\"\n    }\n  ]\n}\n</code></pre>\n\n<p>I use the following options.json when deploying marathon-lb:</p>\n\n<pre><code>{\n  \"marathon-lb\":{\n    \"name\":\"marathon-lb-tools\",\n    \"haproxy-group\":\"public-tools\",\n    \"bind-http-https\":true,\n    \"role\":\"slave_public_tools\"\n  }\n}\n</code></pre>\n\n<p>By the way I'm doing this because I want to two marathon-lb deployments in my cluster. Both of the LBs need to be externally accessible, but one will proxy a high-throughput application and will need to scale accordingly, and the other will be used for various low-bandwidth apps.</p>\n\n<p>Maybe there's a better way to achieve these goals, but creating a separate Mesos role that is available to a marathon-lb configured with a specific haproxy group seemed obvious to me.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1491306111, "title": "Tasks deployed to custom Mesos role waiting forever", "last_activity_date": 1503493355, "answer_count": 1, "creation_date": 1491234922, "score": 1, "link": "https://stackoverflow.com/questions/43189136/tasks-deployed-to-custom-mesos-role-waiting-forever", "answers": [{"body": "<p>Thanks everyone for your suggestions. I learned that my marathon-lb was not deploying because the marathon cluster that dc/os runs by default only accept offers from the '*' and 'slave_public' roles.</p>\n\n<p>I needed to start another marathon instance with <code>mesos_role</code> set to \"slave_public_tools\" to make this work. </p>\n", "answer_id": 45840542, "last_activity_date": 1503493355, "creation_date": 1503493355, "score": 0, "owner": {"user_id": 7808399, "profile_image": "https://www.gravatar.com/avatar/b1bd7fd8b8159004d3207b1ff8db0b8e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/7808399/shawn-carey", "display_name": "Shawn Carey"}, "is_accepted": false, "question_id": 43189136}], "owner": {"user_id": 7808399, "profile_image": "https://www.gravatar.com/avatar/b1bd7fd8b8159004d3207b1ff8db0b8e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/7808399/shawn-carey", "display_name": "Shawn Carey"}, "view_count": 56, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43189136}{"body": "<p>I have created a cluster on Digital Ocean (DC/OS 1.9) using terraform following these instructions <a href=\"https://dcos.io/docs/1.9/administration/installing/cloud/digitalocean/\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p>Everything seems to have installed correctly, to pull from a private docker repo, I need to add a compressed <code>.docker</code> file to my <code>/core/home/</code> and fetch it during deployment by including it in my JSON. </p>\n\n<pre><code>\"fetch\":[  \n   {  \n      \"uri\":\"file:///home/core/docker.tar.gz\"\n   }\n]\n</code></pre>\n\n<p>Based on these instructions: <a href=\"https://docs.mesosphere.com/1.9/deploying-services/momee/docker-creds-agent/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.9/deploying-services/momee/docker-creds-agent/</a></p>\n\n<p>And I'm still getting errors:</p>\n\n<pre><code>Failed to launch container: \nFailed to fetch all URIs for container 'abc123-xxxxx' with exit status: 256\n</code></pre>\n\n<p>Upon looking at the logs of one of the agents:</p>\n\n<pre><code>Starting container '123-abc-xxx' for task 'my-docker-image-service.321-dfg-xxx' (and executor 'my-docker-image-service.397d20cb-1\nBegin fetcher log (stderr in sandbox) for container 123-abc-xxx from running command: /opt/mesosphere/packages/mesos--aaedd03eee0d57f5c0d49c\nFetcher Info: {\"cache_directory\":\"\\/tmp\\/mesos\\/fetch\\/slaves\\/94af100c-4dc2-416d-b6d7-eec0d947a1a6-S11\",\"items\":[{\"action\":\"BYPASS_CACHE\",\"uri\":{\"cache\":false,\"executable\":false,\"extract\":true,\"value\":\"file:\\/\\/\\/home\\/core\\/docker.tar.gz\"}}],\"sandbox_directory\":\"\\/var\\/lib\\/mesos\\/slave\\/slaves\\/94af100c-4dc2-416d-b6d7-eec0d947a1a6-S11\\/frameworks\\/94af100c-4dc2-416...\nFetching URI 'file:///home/core/docker.tar.gz'\nFetching directly into the sandbox directory\nFetching URI 'file:///home/core/docker.tar.gz'\nCopied resource '/home/core/docker.tar.gz' to '/var/lib/mesos/slave/slaves/94af100c-4dc2-416d-b6d7-eec0d947a1a6-S11/frameworks/94af100c-4dc2-416d-b6d7-eec0d947a1a6-0\nFailed to obtain the IP address for 'digitalocean-dcos-agent-20'; the DNS service may not be able to resolve it: Name or service not known\nEnd fetcher log for container 123-abc-xxx\nFailed to run mesos-fetcher: Failed to fetch all URIs for container '123-abc-xxx' with exit status: 256\n</code></pre>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "terraform", "dcos"], "last_edit_date": 1493222347, "title": "Why do containers fail to fetch URIs in DC/OS?", "last_activity_date": 1493924562, "answer_count": 1, "creation_date": 1491940346, "score": 4, "link": "https://stackoverflow.com/questions/43355032/why-do-containers-fail-to-fetch-uris-in-dc-os", "answers": [{"body": "<p>You are missing the extract instruction:</p>\n\n<pre><code>\"fetch\":[  \n   {  \n      \"uri\":\"file:///home/core/docker.tar.gz\",\n      \"extract\":true\n   }\n]\n</code></pre>\n", "answer_id": 43790881, "last_activity_date": 1493924562, "creation_date": 1493924562, "score": 1, "owner": {"user_id": 310298, "profile_image": "https://i.stack.imgur.com/PkUnq.png?s=128&g=1", "user_type": "registered", "reputation": 1128, "link": "https://stackoverflow.com/users/310298/itaysk", "accept_rate": 63, "display_name": "itaysk"}, "is_accepted": false, "question_id": 43355032}], "owner": {"user_id": 5020268, "profile_image": "https://i.stack.imgur.com/5SNRr.png?s=128&g=1", "user_type": "registered", "reputation": 185, "link": "https://stackoverflow.com/users/5020268/dominic-cabral", "accept_rate": 25, "display_name": "Dominic Cabral"}, "view_count": 285, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43355032}{"body": "<p>Is there any way to get the IP of current leading Mesos-master from the quorum? Does any variable stores that value?</p>\n", "is_answered": true, "title": "How to get the IP of current leader master from the quorum?", "last_edit_date": 1448531914, "tags": ["apache-zookeeper", "mesos", "mesosphere"], "view_count": 882, "accepted_answer_id": 33930141, "last_activity_date": 1452032492, "answers": [{"body": "<p>yes. Master information stored in zk as json format. You could get the leader master from zk. Please refer to this article <a href=\"http://codetrips.com/2015/08/16/apache-mesos-leader-master-discovery-using-zookeeper-part-2/\" rel=\"nofollow\">http://codetrips.com/2015/08/16/apache-mesos-leader-master-discovery-using-zookeeper-part-2/</a> to see how to get it. Macro is the author of add Mesos master json format to zk.\nYou could use the libray <a href=\"https://github.com/massenz/zk-mesos\" rel=\"nofollow\">https://github.com/massenz/zk-mesos</a> to get leader maste from zk directly.</p>\n", "answer_id": 33930141, "last_activity_date": 1448508893, "creation_date": 1448508893, "score": 3, "owner": {"user_id": 891145, "profile_image": "https://www.gravatar.com/avatar/221cfd6267f65ba83aaa3d5ee6271291?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 548, "link": "https://stackoverflow.com/users/891145/haosdent", "accept_rate": 80, "display_name": "haosdent"}, "is_accepted": true, "question_id": 33915807}, {"body": "<p>You can also query the <code>http://{any mesos master}/master/redirect</code> endpoint and parse the current leading master's IP address out of the <code>Location</code> header that is returned.</p>\n", "answer_id": 34622273, "last_activity_date": 1452032492, "creation_date": 1452032492, "score": 1, "owner": {"user_id": 43269, "profile_image": "https://www.gravatar.com/avatar/b465e4f922fb4fab7ea208c638971078?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1987, "link": "https://stackoverflow.com/users/43269/iz", "accept_rate": 29, "display_name": "iZ."}, "is_accepted": false, "question_id": 33915807}], "score": 5, "link": "https://stackoverflow.com/questions/33915807/how-to-get-the-ip-of-current-leader-master-from-the-quorum", "answer_count": 2, "owner": {"user_id": 2693578, "profile_image": "https://www.gravatar.com/avatar/1ed37a7c52640324c4e5b68f84a3ed59?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 143, "link": "https://stackoverflow.com/users/2693578/maddy25", "accept_rate": 73, "display_name": "Maddy25"}, "creation_date": 1448452257, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33915807}{"body": "<p>Mesos and Marathon mention checkpointing from time to time, but I couldn't find a good explanation of how it works anywhere. Also, what does it mean in practice?</p>\n\n<pre><code>1) Is the Task current state continuously being stored, or is only the Task ID stored? Where is it stored and what does it contain?\n2) There are two Marathon instances. Marathon has been running Nginx for a week, then goes down. Does that mean that the actual Nginx application state continues running on the second Marathon instance, or does it just restart the task from beginning? If the Task actual state is copied, isn't there a lot of data to be continuously persisted and passed around between slaves? \n</code></pre>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "title": "Mesos/Marathon checkpointing and HA", "last_activity_date": 1426846026, "answer_count": 1, "creation_date": 1426768632, "score": 0, "link": "https://stackoverflow.com/questions/29144797/mesos-marathon-checkpointing-and-ha", "answers": [{"body": "<p><i><br>\nSlave recovery is a feature of Mesos that allows:</p>\n\n<ul>\n<li>Executors/tasks to keep running when the slave process is down and  </li>\n<li>Allows a restarted slave process to reconnect with running executors/tasks on the slave.</i>\n(<a href=\"http://mesos.apache.org/documentation/latest/slave-recovery/\" rel=\"nofollow\" title=\"Slave recovery\">Mesos Slave recovery</a>).</li>\n</ul>\n\n<p>So regarding you questions this means:</p>\n\n<ol>\n<li><p>Enough information (a little more than TaskID) is stored in order that a new slave process can reconnect to the still running executor/task.</p></li>\n<li><p>As the task state is not checkpointed, it would start the task from the beginning. </p></li>\n</ol>\n\n<p>Hope this helps, \nJoerg</p>\n", "answer_id": 29163938, "last_activity_date": 1426846026, "creation_date": 1426846026, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 29144797}], "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 289, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29144797}{"body": "<p>I'm working with Apache mesos and marathon. I have 3 master nodes and 3 slave nodes. I configure mesos with quorum 2. Later I post a JSON to run one job with marathon and all look fine.</p>\n\n<p>Then I try a shutdown of two master nodes to break the quorum, after this, mesos unregister all slave and all look ok, but when I inspect the slaves I found that the started job was continue running...<strong>it is normal? I was supposing that marathon stop all job after the quorum is lost</strong>.</p>\n", "is_answered": true, "title": "Why marathon does not terminate jobs after the quorum is lost?", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1423741943, "accepted_answer_id": 28476756, "creation_date": 1423667918, "answers": [{"body": "<p>Part of the Mesos philosophy, especially for long-running services, is that a failure in one or more Mesos components should not need to stop the user application.</p>\n\n<p>If a slave shuts down and the framework has checkpointing enabled, the executor driver will wait for the slave's <code>--recovery_timeout</code> (default 15min) before shutting down the executor/tasks. To prevent this, disable checkpointing on your framework (in Marathon, just set <code>--checkpoint=false</code> when starting Marathon). See also Marathon's <code>--failover_timeout</code> on <a href=\"https://mesosphere.github.io/marathon/docs/command-line-flags.html\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/command-line-flags.html</a></p>\n\n<p>On the other hand, if it's just the Masters/ZKs that shut down, and the Slaves are still up and running, the slaves can still monitor the tasks and queue up status updates, so the tasks can stay alive. If ZK loses quorum, then there is no leading master, and each slave will continue to operate independently until a new leader is detected, at which point it will reregister with the master and send any queued status updates.</p>\n", "answer_id": 28476756, "last_activity_date": 1423741943, "creation_date": 1423741943, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 28457891}], "score": 0, "link": "https://stackoverflow.com/questions/28457891/why-marathon-does-not-terminate-jobs-after-the-quorum-is-lost", "answer_count": 1, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "view_count": 584, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28457891}{"body": "<p>I'm new on Hadoop world, and I need install mesos with Hadoop HDFS to make a fault-tolerant distributed file system, but all installation references include necessary components for my scenario as for example: MapReduce.</p>\n\n<p>Do you have any idea or references about this?</p>\n", "is_answered": true, "title": "It's possible only install Hadoop HDFS?", "tags": ["hadoop", "mapreduce", "hdfs", "mesos", "mesosphere"], "last_activity_date": 1421865738, "accepted_answer_id": 28074486, "creation_date": 1421859959, "answers": [{"body": "<p>Absolutely possible. Don't think Hadoop as an installable program, it's just composed by a bunch of java processes running on different nodes inside a cluster. </p>\n\n<p>If you use hadoop tar ball, you can just run NameNode and DataNodes processes if you only want HDFS. </p>\n\n<p>If you use other hadoop distros (HDP for instance), I think HDFS and mapreduce come from different rpm packages, but it does harm to install both rpm packages. Again just run NameNode and DataNodes if you only need HDFS.</p>\n", "answer_id": 28074486, "last_activity_date": 1421865738, "creation_date": 1421865738, "score": 1, "owner": {"user_id": 553653, "profile_image": "https://i.stack.imgur.com/9IaeD.jpg?s=128&g=1", "user_type": "registered", "reputation": 3574, "link": "https://stackoverflow.com/users/553653/zhutoulala", "accept_rate": 45, "display_name": "zhutoulala"}, "is_accepted": true, "question_id": 28072868}], "score": 0, "link": "https://stackoverflow.com/questions/28072868/its-possible-only-install-hadoop-hdfs", "answer_count": 1, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "view_count": 843, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 28072868}{"body": "<p>The following error appeared while installing Apache mesos can you please help me</p>\n\n<pre><code>configure: error: failed to determine linker flags for using Java (bad JAVA_HOME or missing support for your architecture?)\n\nfile:///home/ccompl06-14/Pictures/Screenshot%20from%202015-05-28%2009:24:42.png\n</code></pre>\n", "is_answered": true, "tags": ["java", "mesos", "mesosphere"], "last_edit_date": 1433046659, "title": "bad JAVA_HOME or missing support for your architecture?", "last_activity_date": 1442904310, "answer_count": 2, "creation_date": 1432789925, "score": 2, "link": "https://stackoverflow.com/questions/30497701/bad-java-home-or-missing-support-for-your-architecture", "answers": [{"body": "<p>It appears that you do not have a JDK installed on your system.  Have a look at <a href=\"http://jugnu-life.blogspot.com/2013/08/building-mesos-from-source.html\" rel=\"nofollow\">this site which answers your question</a>:</p>\n\n<pre><code>Download JDK\nset env variable as\nexport JAVA_HOME=C:/path/to/your/jdk\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre>\n", "answer_id": 30497772, "last_activity_date": 1432790303, "creation_date": 1432790303, "score": 0, "owner": {"user_id": 1863229, "profile_image": "https://i.stack.imgur.com/4sh1l.png?s=128&g=1", "user_type": "registered", "reputation": 116807, "link": "https://stackoverflow.com/users/1863229/tim-biegeleisen", "accept_rate": 61, "display_name": "Tim Biegeleisen"}, "is_accepted": false, "question_id": 30497701}, {"body": "<p>This is how to set JAVA_HOME on Unix and Linux:</p>\n\n<ol>\n<li>export JAVA_HOME=/opt/java/jdk_1.6</li>\n<li>export $PATH= ${PATH}:{JAVA_HOME}/bin</li>\n</ol>\n\n<p>For more details refer</p>\n\n<p><a href=\"http://javarevisited.blogspot.in/2012/02/how-to-set-javahome-environment-in.html\" rel=\"nofollow\">http://javarevisited.blogspot.in/2012/02/how-to-set-javahome-environment-in.html</a> </p>\n", "answer_id": 30498359, "last_activity_date": 1442904310, "creation_date": 1432792845, "score": 2, "owner": {"user_id": 4898237, "profile_image": "https://i.stack.imgur.com/Kx1kg.jpg?s=128&g=1", "user_type": "registered", "reputation": 526, "link": "https://stackoverflow.com/users/4898237/sagar-panda", "display_name": "Sagar Panda"}, "is_accepted": false, "last_edit_date": 1442904310, "question_id": 30497701}], "owner": {"user_id": 2925052, "profile_image": "https://www.gravatar.com/avatar/b26b6d9ffb2c386f46de43701b2fc173?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/2925052/roshan", "accept_rate": 0, "display_name": "Roshan"}, "view_count": 1073, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 30497701}{"body": "<p>I'm using the jenkins mesos plugin for CI.\nInitially, I followed the following tutorial: <a href=\"http://www.ebaytechblog.com/2014/05/12/delivering-ebays-ci-solution-with-apache-mesos-part-ii/\" rel=\"nofollow\">http://www.ebaytechblog.com/2014/05/12/delivering-ebays-ci-solution-with-apache-mesos-part-ii/</a></p>\n\n<p>but the jenkins itself was not being setup via this. (I got error could not load config.xml file, even there was one)</p>\n\n<p>Then I followed <a href=\"https://rogerignazio.com/blog/scaling-jenkins-mesos-marathon/\" rel=\"nofollow\">https://rogerignazio.com/blog/scaling-jenkins-mesos-marathon/</a> \n, and I was able to run jenkins master (jenkin framework/scheduler), but when I define the scripts to run, the jenkins-slaves are not being created. I think I'm missing some configuration regarding slaves. Can you tell me, what's the reason that the slaves are not being created to run jobs.</p>\n\n<p>On the jenkins build page, I'm getting :</p>\n\n<pre><code>(pending\u2014Waiting for next available executor)\n</code></pre>\n\n<p>And in the jenkins-logs, i'm getting following error:</p>\n\n<pre><code>INFO: Provisioning Jenkins Slave on Mesos with 1 executors. Remaining excess workload: 0 executors)\nJun 19, 2015 4:02:55 PM hudson.slaves.NodeProvisioner$StandardStrategyImpl apply\nINFO: Started provisioning MesosCloud from MesosCloud with 1 executors. Remaining excess workload: 0\nJun 19, 2015 4:02:55 PM org.jenkinsci.plugins.mesos.MesosComputerLauncher &lt;init&gt;\nINFO: Constructing MesosComputerLauncher\nJun 19, 2015 4:02:55 PM org.jenkinsci.plugins.mesos.MesosSlave &lt;init&gt;\nINFO: Constructing Mesos slave mesos-jenkins-1f8691df-9918-4175-87b3-bcc3de80b258 from cloud \nJun 19, 2015 4:03:05 PM org.jenkinsci.plugins.mesos.MesosComputerLauncher launch\nINFO: Launching slave computer mesos-jenkins-1f8691df-9918-4175-87b3-bcc3de80b258\nJun 19, 2015 4:03:05 PM org.jenkinsci.plugins.mesos.MesosComputerLauncher launch\nINFO: Sending a request to start jenkins slave mesos-jenkins-1f8691df-9918-4175-87b3-bcc3de80b258\nJun 19, 2015 4:03:05 PM org.jenkinsci.plugins.mesos.JenkinsScheduler requestJenkinsSlave\nINFO: Enqueuing jenkins slave request\nJun 19, 2015 4:03:05 PM hudson.slaves.NodeProvisioner update\nINFO: MesosCloud provisioning successfully completed. We have now 2 computer(s)\njava.lang.NullPointerException\n    at org.jenkinsci.plugins.mesos.JenkinsScheduler.matches(JenkinsScheduler.java:306)\n    at org.jenkinsci.plugins.mesos.JenkinsScheduler.resourceOffers(JenkinsScheduler.java:252)\nJun 19, 2015 4:03:06 PM org.jenkinsci.plugins.mesos.JenkinsScheduler$1 run\nSEVERE: The Mesos driver was aborted! Status code: 3\n</code></pre>\n\n<p>Edit: I think I'm getting error, because I've not defined any container port mappings.\nCan anyone tell me how to do so?</p>\n\n<p>Update : Actually there were many problems with 0.7 version of mesos plugin. So, I simply downgraded to 0.6 version.</p>\n", "is_answered": false, "tags": ["jenkins", "mesos", "mesosphere", "marathon"], "last_edit_date": 1435217568, "title": "Jenkins slave not working on mesos", "last_activity_date": 1435217568, "answer_count": 1, "creation_date": 1434728337, "score": 0, "link": "https://stackoverflow.com/questions/30942118/jenkins-slave-not-working-on-mesos", "answers": [{"body": "<p>For port mappings on marathon have a look <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">here</a>.</p>\n\n<p>Hope this helps!</p>\n", "answer_id": 31042417, "last_activity_date": 1435212404, "creation_date": 1435212404, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 30942118}], "owner": {"user_id": 3785351, "profile_image": "https://www.gravatar.com/avatar/a72b0ec1f103492e225ef9fd893bd21f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 396, "link": "https://stackoverflow.com/users/3785351/manish", "accept_rate": 9, "display_name": "manish"}, "view_count": 615, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30942118}{"body": "<p>I have been using Mesos for over a year now but recently got this issue where mesos doesn't include disk resource in a lot of its offers (the slave/host does register 140GB of disk when it registers with mesos master). Is that something expected? Shouldn't mesos always offer disk if the host has some available?\nIt does offer disk for some offers though.</p>\n", "is_answered": false, "tags": ["distributed-computing", "mesos", "distributed-system", "mesosphere"], "title": "Mesos not offering disk in its offers", "last_activity_date": 1455041416, "answer_count": 0, "creation_date": 1454566412, "score": 0, "link": "https://stackoverflow.com/questions/35193771/mesos-not-offering-disk-in-its-offers", "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 68, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35193771}{"is_answered": true, "tags": ["amazon-ec2", "ubuntu-14.04", "mesos", "mesosphere"], "last_edit_date": 1420598967, "title": "Unable to get Mesos to run from tutorial: Setting up a Single Node Mesosphere Cluster", "last_activity_date": 1423212356, "answer_count": 2, "creation_date": 1420593018, "score": 2, "link": "https://stackoverflow.com/questions/27809950/unable-to-get-mesos-to-run-from-tutorial-setting-up-a-single-node-mesosphere-cl", "accepted_answer_id": 27815857, "owner": {"user_id": 3324804, "profile_image": "https://www.gravatar.com/avatar/1968ec323e44be0c555bfa7d0bbb32a2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 587, "link": "https://stackoverflow.com/users/3324804/alexfvolk", "accept_rate": 60, "display_name": "alexfvolk"}, "view_count": 2438, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 27809950}{"body": "<p>I'm using DC/OS 1.8 when i installed Cassandra Service from the DC/OS Universe.</p>\n\n<p>If i stop &amp; start my cluster (master and all nodes) the service doesn't start and i have to uninstall the service, delete all file in the agents node and after install Cassandra service.</p>\n\n<p>P.S. My Cassandra Cluster is installed on Azure with Azure Container Service.</p>\n\n<p>Do you have any idea?</p>\n", "is_answered": false, "tags": ["azure", "cassandra", "mesosphere", "dcos"], "title": "DC/OS Cassandra Service Doesn't work after Restart Cluster", "last_activity_date": 1491501902, "answer_count": 1, "creation_date": 1491381436, "score": 0, "link": "https://stackoverflow.com/questions/43226045/dc-os-cassandra-service-doesnt-work-after-restart-cluster", "answers": [{"body": "<p>Few questions before we even go further investigation.\n1. Have you seen tried to reproduce the issue ?  How it is like ?\n2. Have you explored DC/OS 1.8 without Azure ? Maybe it is DC/OS issue.</p>\n\n<p>In general, we (Azure Container Service) will have the issue if DC/OS itself is buggy. It is always worth to mine the known issues on DC/OS github first. And yes, we need log</p>\n", "answer_id": 43262665, "last_activity_date": 1491501902, "creation_date": 1491501902, "score": 0, "owner": {"user_id": 7828573, "profile_image": "https://lh3.googleusercontent.com/-K_tUrt58CiI/AAAAAAAAAAI/AAAAAAAAAiM/_tpbXrkULvM/photo.jpg?sz=128", "user_type": "registered", "reputation": 9, "link": "https://stackoverflow.com/users/7828573/jingtao-ren", "display_name": "Jingtao Ren"}, "is_accepted": false, "question_id": 43226045}], "owner": {"user_id": 6677495, "profile_image": "https://graph.facebook.com/649171945229787/picture?type=large", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/6677495/tommy-jimmy-emiliano", "display_name": "Tommy Jimmy Emiliano"}, "view_count": 46, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43226045}{"body": "<p>We have a Mesos cluster and launches tasks by Marathon on Mesos-Slave with Docker container. </p>\n\n<p>The whole system runs very well but a very strange problem occurred from time to time: when we try to destroy/re-deploy a task through Marathon, the mesos-slave got killed by the exiting of the target Docker container. This is the error log I got:</p>\n\n<pre><code>Feb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.465544  4094 docker.cpp:1592] Executor for container 'eadfb756-b653-42eb-977a-c16c78b1a7c5' has exited\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.465736  4094 docker.cpp:1390] Destroying container 'eadfb756-b653-42eb-977a-c16c78b1a7c5'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.465812  4094 docker.cpp:1494] Running docker stop on container 'eadfb756-b653-42eb-977a-c16c78b1a7c5'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.466089  4098 slave.cpp:3440] Executor 'prod-xxxxxxx-data-collector-writer.6d832d68-d519-11e5-acca-00505692154c' of framework 8d26b713-c3cd-4e9b-956d-24f63b1320e0-0000 exited with status 0\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.466167  4098 slave.cpp:3544] Cleaning up executor 'prod-xxxxxxx-data-collector-writer.6d832d68-d519-11e5-acca-00505692154c' of framework 8d26b713-c3cd-4e9b-956d-24f63b1320e0-0000\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: F0229 19:31:51.470055  4098 slave.cpp:3570] CHECK_SOME(os::touch(path)): Failed to open file: No such file or directory\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: *** Check failure stack trace: ***\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c2144dd  google::LogMessage::Fail()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c21621c  google::LogMessage::SendToLog()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.566812  4099 docker.cpp:1592] Executor for container 'e2d9c750-88b7-4247-b696-6589665d6a66' has exited\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c2140cc  google::LogMessage::Flush()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.569646  4099 docker.cpp:1390] Destroying container 'e2d9c750-88b7-4247-b696-6589665d6a66'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.569757  4099 docker.cpp:1592] Executor for container 'f51c68b8-c64d-47ea-a629-8516dcc90dba' has exited\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.569787  4099 docker.cpp:1390] Destroying container 'f51c68b8-c64d-47ea-a629-8516dcc90dba'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.569818  4099 docker.cpp:1494] Running docker stop on container 'e2d9c750-88b7-4247-b696-6589665d6a66'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: I0229 19:31:51.569849  4099 docker.cpp:1494] Running docker stop on container 'f51c68b8-c64d-47ea-a629-8516dcc90dba'\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c216b19  google::LogMessageFatal::~LogMessageFatal()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3bc99f2e  mesos::internal::slave::Slave::removeExecutor()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3bcaca60  mesos::internal::slave::Slave::executorTerminated()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c1c6541  process::ProcessManager::resume()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3c1c683f  process::internal::schedule()\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3ad4a1e0  (unknown)\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3afa3df5  start_thread\nFeb 29 19:31:51 mesos-slave3.ourcompany.com mesos-slave[4093]: @     0x7f8c3a7b41ad  __clone\nFeb 29 19:31:51 mesos-slave3.ourcompany.com systemd[1]: mesos-slave.service: main process exited, code=killed, status=6/ABRT\nFeb 29 19:31:51 mesos-slave3.ourcompany.com systemd[1]: Unit mesos-slave.service entered failed state.\nFeb 29 19:32:11 mesos-slave3.ourcompany.com systemd[1]: mesos-slave.service holdoff time over, scheduling restart.\n</code></pre>\n\n<p>The task launched in Docker container is a AKKA application, and the environment info for the whole system is:</p>\n\n<p>OS: </p>\n\n<p><code>CentOS Linux release 7.1.1503 (Core)</code></p>\n\n<p>Kernel: </p>\n\n<p><code>3.10.0-229.el7.x86_64</code></p>\n\n<p>JDK on all machine:</p>\n\n<pre><code>java version \"1.7.0_91\"\nOpenJDK Runtime Environment (rhel-2.6.2.1.el7_1-x86_64 u91-b00)\nOpenJDK 64-Bit Server VM (build 24.91-b01, mixed mode)\n</code></pre>\n\n<p>Mesos: </p>\n\n<pre><code>0.25, installed by yum from mesosphere repo\n</code></pre>\n\n<p>Mesos-Master config:</p>\n\n<pre><code>--zk=zk://zk-node1:2181,zk-node2:2181,zk-node3:2181,zk-node4:2181,zk-node5:2181/mesos-cluster --port=5050 --log_dir=/var/log/mesos --cluster=mesos-prod-cluster --hostname=&lt;real hostname&gt; --ip=&lt;real ip&gt; --quorum=3 --registry_fetch_timeout=5mins --work_dir=/var/lib/mesos\n</code></pre>\n\n<p>Mesos-Slave config:</p>\n\n<pre><code>--master=zk://zk-node1:2181,zk-node2:2181,zk-node3:2181,zk-node4:2181,zk-node5:2181/mesos-cluster --log_dir=/var/log/mesos --attributes=env:prod --containerizers=docker,mesos --docker_remove_delay=2weeks --executor_registration_timeout=30mins --hostname=&lt;real slave hostname&gt;\n</code></pre>\n\n<p>Marathon info:</p>\n\n<pre><code>{\n\"name\": \"marathon\",\n\"version\": \"0.11.1\",\n\"elected\": true,\n\"leader\": \"&lt;leader_ip&gt;:8080\",\n\"frameworkId\": \"8d26b713-c3cd-4e9b-956d-24f63b1320e0-0000\",\n\"marathon_config\": {\n    \"master\": \"zk-node1:2181,zk-node2:2181,zk-node3:2181,zk-node4:2181,zk-node5:2181/mesos-cluster\",\n    \"failover_timeout\": 604800,\n    \"framework_name\": \"marathon\",\n    \"ha\": true,\n    \"checkpoint\": true,\n    \"local_port_min\": 10000,\n    \"local_port_max\": 20000,\n    \"executor\": \"//cmd\",\n    \"hostname\": \"&lt;hostname&gt;\",\n    \"webui_url\": null,\n    \"mesos_role\": null,\n    \"task_launch_timeout\": 600000,\n    \"reconciliation_initial_delay\": 15000,\n    \"reconciliation_interval\": 300000,\n    \"marathon_store_timeout\": 2000,\n    \"mesos_user\": \"root\",\n    \"leader_proxy_connection_timeout_ms\": 5000,\n    \"leader_proxy_read_timeout_ms\": 10000,\n    \"mesos_leader_ui_url\": \"http://&lt;leader_ip&gt;:5050/\"\n},\n\"zookeeper_config\": {\n    \"zk\": \"zk-node1:2181,zk-node2:2181,zk-node3:2181,zk-node4:2181,zk-node5:2181/marathon-cluster\",\n    \"zk_timeout\": 10000,\n    \"zk_session_timeout\": 1800000,\n    \"zk_max_versions\": 25\n},\n\"event_subscriber\": {\n    \"type\": \"http_callback\",\n    \"http_endpoints\": null\n},\n\"http_config\": {\n    \"assets_path\": null,\n    \"http_port\": 8080,\n    \"https_port\": 8443\n}\n</code></pre>\n\n<p>}</p>\n\n<p>Docker version:</p>\n\n<pre><code>Client:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.2\n Git commit:   a34a1d5\n Built:        Fri Nov 20 13:25:01 UTC 2015\n OS/Arch:      linux/amd64\n\nServer:\n Version:      1.9.1\n API version:  1.21\n Go version:   go1.4.2\n Git commit:   a34a1d5\n Built:        Fri Nov 20 13:25:01 UTC 2015\n OS/Arch:      linux/amd64\n</code></pre>\n\n<p>Docker info:</p>\n\n<pre><code>Containers: 330\nImages: 509\nServer Version: 1.9.1\nStorage Driver: devicemapper\n Pool Name: docker-253:0-68977907-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 107.4 GB\n Backing Filesystem:\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 23.68 GB\n Data Space Total: 107.4 GB\n Data Space Available: 27.51 GB\n Metadata Space Used: 63.75 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.084 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.93-RHEL7 (2015-01-28)\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.10.0-229.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nCPUs: 4\nTotal Memory: 15.67 GiB\nName: mesos-slave3.gz.yougola.com\nID: QB4G:C2HK:CBPR:G5ID:6OCU:DFEC:USBP:ECLQ:FWOQ:ZGHS:JIU5:JNN4\n</code></pre>\n\n<p>Services including Docker, Mesos-Master, Mesos-Slave, Marathon are all managed by systemd. </p>\n", "is_answered": true, "title": "Destroy Docker container from Marathon kills Mesos slave", "tags": ["docker", "centos", "mesos", "mesosphere", "marathon"], "last_activity_date": 1456825828, "accepted_answer_id": 35719583, "creation_date": 1456802022, "answers": [{"body": "<p>That is strange and unfortunate. Looks like it's failing this check:\n<a href=\"https://github.com/apache/mesos/blob/0.25.0/src/slave/slave.cpp#L3570\" rel=\"nofollow\">https://github.com/apache/mesos/blob/0.25.0/src/slave/slave.cpp#L3570</a>\nbecause it could not find the path to the executor sentinel file.</p>\n\n<p>Could you please file a new JIRA at <a href=\"https://issues.apache.org/jira/browse/MESOS\" rel=\"nofollow\">https://issues.apache.org/jira/browse/MESOS</a> so we can track and resolve this issue for you?</p>\n", "answer_id": 35719583, "last_activity_date": 1456825828, "creation_date": 1456825828, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 35713985}], "score": 1, "link": "https://stackoverflow.com/questions/35713985/destroy-docker-container-from-marathon-kills-mesos-slave", "answer_count": 1, "owner": {"user_id": 1000254, "profile_image": "https://www.gravatar.com/avatar/e1621f7d5eef73c430632061efdc97b0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3856, "link": "https://stackoverflow.com/users/1000254/shizhz", "accept_rate": 100, "display_name": "shizhz"}, "view_count": 515, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35713985}{"body": "<p>We have a 5 node cassandra ring (2.2.5) and using mesosphere's framework on top of mesos. I started the restore snapshot using the framework, which indirectly calls bulk load of sstableloader. Command is running from three days now still on first node, today morning I checked tpstats on first node and all tasks are completed then what can be the possible reason sstable is not returning successfully?</p>\n", "is_answered": false, "tags": ["cassandra", "mesosphere"], "last_edit_date": 1474318956, "title": "restore snapshot using sstableloader running infinitely on first node itself", "last_activity_date": 1474318956, "answer_count": 0, "creation_date": 1474305100, "score": 0, "link": "https://stackoverflow.com/questions/39578569/restore-snapshot-using-sstableloader-running-infinitely-on-first-node-itself", "owner": {"user_id": 1726183, "profile_image": "https://www.gravatar.com/avatar/e052c9c68ad2978015d389b4c00513f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 674, "link": "https://stackoverflow.com/users/1726183/varun-gupta", "accept_rate": 55, "display_name": "Varun Gupta"}, "view_count": 35, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39578569}{"body": "<p>I'm looking for some pros and cons of whether to go with Marathon and Chronos, Docker Swarm or Kubernetes when running Docker containers on DC/OS. </p>\n\n<p>For example, when is it better to use Marathon/Chronos than Kubernetes and vice versa? </p>\n\n<p>Right now I'm mostly into experimenting but hopefully we'll start using one of these services in production after the summer. This may disqualify Docker Swarm since I'm not sure if it'll be production ready by then. </p>\n\n<p>What I like about Docker Swarm is that it's essentially just \"Docker commands\" and you don't have to learn something completely new. We're already using <code>docker-compose</code> and that will work out of the box with Docker Swarm (at least in theory) so that would be a big plus. My main concern with Docker Swarm is if it'll cover all use cases required to run a system in production.</p>\n", "is_answered": true, "title": "Marathon vs Kubernetes vs Docker Swarm on DC/OS with Docker containers", "last_edit_date": 1475406440, "tags": ["docker", "kubernetes", "marathon", "docker-swarm", "dcos"], "view_count": 28235, "accepted_answer_id": 29815033, "last_activity_date": 1475406440, "answers": [{"body": "<p>Though it's a bit outdated, it may be helpful to read <a href=\"https://stackoverflow.com/questions/26705201/whats-the-difference-between-apaches-mesos-and-googles-kubernetes\">What's the difference between Apache's Mesos and Google's Kubernetes</a>, to get some of the basics right. Also, note that Mesos operates on a different level than Kubernetes/Marathon/Chronos. Last but not least, see <a href=\"https://speakerdeck.com/tnachen/docker-swarm-plus-mesos\" rel=\"nofollow noreferrer\">Docker Swarm + Mesos</a> by Timothy Chen, keeping in mind that Marathon and Swarm can operate simultaneously on the same Mesos cluster.</p>\n", "answer_id": 29203094, "last_activity_date": 1468786707, "creation_date": 1427083382, "score": 12, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "last_edit_date": 1495540509, "question_id": 29198840}, {"body": "<p>I'll try to break down the unique aspects of each container orchestration framework on Mesos.</p>\n\n<p>Use <a href=\"https://github.com/docker/swarm/\">Docker Swarm</a> if:</p>\n\n<ul>\n<li>You want to use the familiar Docker API to launch Docker containers on Mesos.</li>\n<li>Swarm may eventually provide an API to talk to Kubernetes (even K8s-Mesos) too.</li>\n<li>See: <a href=\"http://www.techrepublic.com/article/docker-and-mesos-like-peanut-butter-and-jelly/\">http://www.techrepublic.com/article/docker-and-mesos-like-peanut-butter-and-jelly/</a></li>\n</ul>\n\n<p>Use <a href=\"https://github.com/mesosphere/kubernetes-mesos\">Kubernetes-Mesos</a> if:</p>\n\n<ul>\n<li>You want to launch K8s Pods, which are groups of containers co-scheduled and co-located together, sharing resources.</li>\n<li>You want to launch a service alongside one or more sidekick containers (e.g. log archiver, metrics monitor) that live next to the parent container.</li>\n<li>You want to use the K8s label-based service-discovery, load-balancing, and replication control.</li>\n<li>See <a href=\"http://kubernetesio.blogspot.com/2015/04/kubernetes-and-mesosphere-dcos.html\">http://kubernetesio.blogspot.com/2015/04/kubernetes-and-mesosphere-dcos.html</a></li>\n</ul>\n\n<p>Use <a href=\"https://mesosphere.github.io/marathon/\">Marathon</a> if:</p>\n\n<ul>\n<li>You want to launch Docker or non-Docker long-running apps/services.</li>\n<li>You want to use Mesos attributes for constraint-based scheduling.</li>\n<li>You want to use Application Groups and Dependencies to launch, scale, or upgrade related services.</li>\n<li>You want to use health checks to automatically restart unhealthy services or rollback unhealthy deployments/upgrades.</li>\n<li>You want to integrate HAProxy or Consul for service discovery.</li>\n<li>You want to launch and monitor apps through a web UI or REST API.</li>\n<li>You want to use a framework built from the start with Mesos in mind.</li>\n</ul>\n\n<p>Use <a href=\"https://github.com/mesos/chronos\">Chronos</a> if:</p>\n\n<ul>\n<li>You want to launch Docker or non-Docker tasks that are expected to exit.</li>\n<li>You want to schedule a task to run at a specific time/schedule (a la <code>cron</code>).</li>\n<li>You want to schedule a DAG workflow of dependent tasks.</li>\n<li>You want to launch and monitor jobs through a web UI or REST API.</li>\n<li>You want to use a framework built from the start with Mesos in mind.</li>\n</ul>\n", "answer_id": 29815033, "last_activity_date": 1429769183, "creation_date": 1429769183, "score": 142, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 29198840}], "score": 75, "link": "https://stackoverflow.com/questions/29198840/marathon-vs-kubernetes-vs-docker-swarm-on-dc-os-with-docker-containers", "answer_count": 2, "owner": {"user_id": 398441, "profile_image": "https://www.gravatar.com/avatar/a8950160c2b3d7d0bf948d8c1f937e7f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 8502, "link": "https://stackoverflow.com/users/398441/johan", "accept_rate": 86, "display_name": "Johan"}, "creation_date": 1427052398, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 29198840}{"closed_date": 1467137103, "is_answered": true, "closed_reason": "off-topic", "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "How to use a load balancer to choose a docker?", "body": "<p>I am running a docker which runs a tomcat server. This container has a web application which is linked with a mysql server. I am using mesos-marathon for the whole setup and a single node master-slave configuration. Now I want to scale the number of tomcat server and use a load balancer to choose which server to call. Scaling is easy with marathon but how do I use the load balancer? Does docker or marathon have anything to support this?</p>\n", "view_count": 473, "answers": [{"body": "<p>Yes, Marathon supports this. You would want to use <a href=\"https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html\" rel=\"nofollow\">HAProxy for load balancing</a>. For more advanced use cases you also can check out the <a href=\"https://github.com/mesosphere/marathon/blob/master/bin/servicerouter.py\" rel=\"nofollow\">servicerouter</a>, part of Marathon.</p>\n\n<p>To get up and running with this topic, you might first want to watch the following video: <a href=\"https://www.youtube.com/watch?v=hZNGST2vIds\" rel=\"nofollow\">Docker Clustering on Mesos with Marathon</a>.</p>\n\n<p>Another, recent solution in this space is <a href=\"http://traefik.github.io/\" rel=\"nofollow\">Traefik</a> which has a Marathon backend as well.</p>\n", "answer_id": 30694256, "last_activity_date": 1443168508, "creation_date": 1433684857, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "last_edit_date": 1443168508, "question_id": 30659541}], "last_activity_date": 1467136506, "score": -1, "link": "https://stackoverflow.com/questions/30659541/how-to-use-a-load-balancer-to-choose-a-docker", "answer_count": 1, "owner": {"user_id": 3690397, "profile_image": "https://i.stack.imgur.com/Pe9bM.jpg?s=128&g=1", "user_type": "registered", "reputation": 69, "link": "https://stackoverflow.com/users/3690397/208rishabh", "accept_rate": 17, "display_name": "208rishabh"}, "accepted_answer_id": 30694256, "creation_date": 1433484920, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 30659541}{"body": "<p>I want mesos to start <strong>my</strong> services on a different interface.</p>\n\n<p>Right now, it can only bind to <code>0.0.0.0</code>, and my host is accessible to the outside.</p>\n\n<p>I have tried to play with <code>LIBPROCESS_IP</code> as recommended in the doc, but I couldn't make it work.</p>\n\n<p>Edit : </p>\n\n<p>Mesos is already starting it's <strong>own</strong> services on a private interface, I am writing about the services I want start on marathon, they all get binded to <strong>0.0.0.0</strong></p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1447177417, "title": "How to bind Mesos services to 127.0.0.1?", "last_activity_date": 1447177417, "answer_count": 1, "creation_date": 1447115834, "score": 0, "link": "https://stackoverflow.com/questions/33620951/how-to-bind-mesos-services-to-127-0-0-1", "answers": [{"body": "<p>You could start mesos with <code>--ip</code> to bind it to <code>127.0.0.1</code>. For example, bind <code>mesos-master</code> to <code>127.0.0.1</code>:</p>\n\n<pre><code>mesos-master.sh --ip=127.0.0.1 --work_dir=/tmp/mesos\n</code></pre>\n\n<p>Or bind <code>mesos-slave</code> to <code>127.0.0.1</code>:</p>\n\n<pre><code>mesos-slave.sh --ip=127.0.0.1 --master=127.0.0.1:5050 --work_dir=/tmp/emsos\n</code></pre>\n", "answer_id": 33631392, "last_activity_date": 1447162890, "creation_date": 1447162890, "score": 3, "owner": {"user_id": 891145, "profile_image": "https://www.gravatar.com/avatar/221cfd6267f65ba83aaa3d5ee6271291?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 548, "link": "https://stackoverflow.com/users/891145/haosdent", "accept_rate": 80, "display_name": "haosdent"}, "is_accepted": false, "question_id": 33620951}], "owner": {"user_id": 2127277, "profile_image": "https://www.gravatar.com/avatar/e4222dda177339b2ade17d1a36cbac90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1232, "link": "https://stackoverflow.com/users/2127277/bigdong", "accept_rate": 59, "display_name": "BigDong"}, "view_count": 197, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33620951}{"body": "<p>I got a cluster of 1 master node and 2 slaves and I'm trying to compile my application with mesos.</p>\n\n<p>Basically, here is the command that I use:</p>\n\n<pre><code>mesos-execute --name=alc1 --command=\"ccmake -j myapp\" --master=10.11.12.13:5050\n</code></pre>\n\n<p>Offers are made from the slave but this compilation task keeps failing.</p>\n\n<pre><code>[root@master-node ~]# mesos-execute --name=alc1 --command=\"ccmake -j myapp\" --master=10.11.12.13:5050\nI0511 22:26:11.623016 11560 sched.cpp:222] Version: 0.28.0\nI0511 22:26:11.625602 11564 sched.cpp:326] New master detected at master@10.11.12.13:5050\nI0511 22:26:11.625952 11564 sched.cpp:336] No credentials provided. Attempting to register without authentication\nI0511 22:26:11.627279 11564 sched.cpp:703] Framework registered with 70582e35-5d6e-4915-a919-cae61c904fd9-0139\nFramework registered with 70582e35-5d6e-4915-a919-cae61c904fd9-0139\ntask alc1 submitted to slave 70582e35-5d6e-4915-a919-cae61c904fd9-S2\nReceived status update TASK_RUNNING for task alc1\nReceived status update TASK_FAILED for task alc1\nI0511 22:26:11.759610 11567 sched.cpp:1903] Asked to stop the driver\nI0511 22:26:11.759639 11567 sched.cpp:1143] Stopping framework '70582e35-5d6e-4915-a919-cae61c904fd9-0139'\n</code></pre>\n\n<p>On the sandbox slave node, here is the stderr logs:</p>\n\n<pre><code>I0511 22:26:13.781070  5037 exec.cpp:143] Version: 0.28.0\nI0511 22:26:13.785001  5040 exec.cpp:217] Executor registered on slave 70582e35-5d6e-4915-a919-cae61c904fd9-S2\nsh: ccmake: command not found\nI0511 22:26:13.892653  5042 exec.cpp:390] Executor asked to shutdown\n</code></pre>\n\n<p>Just to mentionned that commands like this work fine and get me the expected results:</p>\n\n<pre><code>[root@master-node ~]# mesos-execute --name=alc1 --command=\"find / -name a\" --master=10.11.12.13:5050\nI0511 22:26:03.733172 11550 sched.cpp:222] Version: 0.28.0\nI0511 22:26:03.736112 11554 sched.cpp:326] New master detected at master@10.11.12.13:5050\nI0511 22:26:03.736383 11554 sched.cpp:336] No credentials provided. Attempting to register without authentication\nI0511 22:26:03.737730 11554 sched.cpp:703] Framework registered with 70582e35-5d6e-4915-a919-cae61c904fd9-0138\nFramework registered with 70582e35-5d6e-4915-a919-cae61c904fd9-0138\ntask alc1 submitted to slave 70582e35-5d6e-4915-a919-cae61c904fd9-S2\nReceived status update TASK_RUNNING for task alc1\nReceived status update TASK_FINISHED for task alc1\nI0511 22:26:04.184813 11553 sched.cpp:1903] Asked to stop the driver\nI0511 22:26:04.184844 11553 sched.cpp:1143] Stopping framework '70582e35-5d6e-4915-a919-cae61c904fd9-0138'\n</code></pre>\n\n<p>I don't really get what is needed for even troubleshot this issue.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1463024406, "title": "How can I compile my C++ code with Mesos?", "last_activity_date": 1463024406, "answer_count": 0, "creation_date": 1463020391, "score": 1, "link": "https://stackoverflow.com/questions/37176282/how-can-i-compile-my-c-code-with-mesos", "owner": {"user_id": 3301370, "profile_image": "https://www.gravatar.com/avatar/ebda08cee8ee58e0f98c5d850e9ce15a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 117, "link": "https://stackoverflow.com/users/3301370/djidiouf", "accept_rate": 75, "display_name": "Djidiouf"}, "view_count": 152, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37176282}{"body": "<p>I'm moving a bare metal java application (jar jdk8) to docker containers and DC/OS. I am noticing an odd pattern on the dockers, we set -XMX to 32 gig and allocate a 36 gig docker container. Every few hours or so the application will spike in old gen mem allocation and the GC will get stuck in a loop ( maxing CPU) while it tries to do the heap dump. </p>\n\n<p>Are there any optimizations or things I can use to see why in that 1-5 second interval we are spiking so fast? Are there any gotchas I might need to be aware of with Docker and JVM?</p>\n\n<p>We are using default GC</p>\n", "is_answered": true, "title": "JVM Optimizations for Docker and DC/OS", "tags": ["java", "docker", "dcos"], "last_activity_date": 1504726795, "accepted_answer_id": 46083119, "creation_date": 1504366939, "answers": [{"body": "<p>Just for future reference:</p>\n\n<p>We are using JDK 8 and it seems as if Oracle has just recently added some experimental flags for using Docker. I believe the case could have been when GC was allocating threads it wasn't respecting the docker thread count from cgroup. The experimental flags seemed to have fixed our \"off the rails issue\"</p>\n\n<p><a href=\"https://blogs.oracle.com/java-platform-group/java-se-support-for-docker-cpu-and-memory-limits\" rel=\"nofollow noreferrer\">https://blogs.oracle.com/java-platform-group/java-se-support-for-docker-cpu-and-memory-limits</a></p>\n", "answer_id": 46083119, "last_activity_date": 1504726745, "creation_date": 1504726745, "score": 1, "owner": {"user_id": 8552275, "profile_image": "https://lh3.googleusercontent.com/-na45jJyBGIE/AAAAAAAAAAI/AAAAAAAAACw/PvYyqgNggnE/photo.jpg?sz=128", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/8552275/matthew-essenburg", "display_name": "Matthew Essenburg"}, "is_accepted": true, "question_id": 46015451}, {"body": "<p>Usually you would like to avoid this gigantic applications with > 30GB of memory and split your application into smaller parts with less memory requirements if you have the possibility to use a container platform like DC/OS.</p>\n\n<p>In general about GC and heap size: If you have big heap sizes, full GC can take a long time. Personally I experienced full GC freezes up to a minute or more with a quite similar heap size to your mentioned 30GB.</p>\n\n<p>About Java in containers: The JVM actually needs more memory than you configure with <code>-Xmx</code>. So, if you specify a memory limit of 2GB within your DC/OS (Marathon) application, you can not set <code>-Xmx2G</code>, because this memory restriction is a hard limitation. If your process inside the container will exceed these memory limit, the container will be killed. By the fact that the JVM will reserve temporary more memory than in <code>-Xmx</code> configured, this is really likely to happen. In general I would suggest to use around 75% of your configured memory as value for <code>-Xmx</code>.</p>\n\n<p>You could have a look at newer JRE versions, which support <code>-XX:+UseCGroupMemoryLimits</code>. This is a JRE flag to use cgroup container limitations for memory consumption, see <a href=\"https://developers.redhat.com/blog/2017/04/04/openjdk-and-containers/\" rel=\"nofollow noreferrer\">https://developers.redhat.com/blog/2017/04/04/openjdk-and-containers/</a> for more informations.</p>\n", "answer_id": 46083125, "last_activity_date": 1504726795, "creation_date": 1504726795, "score": 1, "owner": {"user_id": 3058534, "profile_image": "https://i.stack.imgur.com/UZ79s.jpg?s=128&g=1", "user_type": "registered", "reputation": 34, "link": "https://stackoverflow.com/users/3058534/unterstein", "display_name": "unterstein"}, "is_accepted": false, "question_id": 46015451}], "score": 3, "link": "https://stackoverflow.com/questions/46015451/jvm-optimizations-for-docker-and-dc-os", "answer_count": 2, "owner": {"user_id": 8552275, "profile_image": "https://lh3.googleusercontent.com/-na45jJyBGIE/AAAAAAAAAAI/AAAAAAAAACw/PvYyqgNggnE/photo.jpg?sz=128", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/8552275/matthew-essenburg", "display_name": "Matthew Essenburg"}, "view_count": 43, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 46015451}{"body": "<p>I am running a Mesos/Deimos cluster using the Python bindings, and I'm getting the following error:</p>\n\n<p><code>F0719 03:26:17.994248     7 os.hpp:131] Expecting 'MESOS_SLAVE_PID' in environment variables</code></p>\n\n<p>This error shows up in the pailer for the executor in Mesos's web interface. The line above the error indicates that the executor script has started running (my own log message).</p>\n\n<p>The error occurrs when the executor is run from the executor Python script, i.e. with this</p>\n\n<pre><code>driver.run()\n</code></pre>\n\n<p>And the error has to do with Mesos expecting the <code>MESOS_SLAVE_PID</code> environment variable to be set (see <a href=\"https://github.com/apache/mesos/blob/master/src/exec/exec.cpp#L648\" rel=\"nofollow\">https://github.com/apache/mesos/blob/master/src/exec/exec.cpp#L648</a>). However, Deimos does not seem to set this variable by default (at least in this case) within the Docker container (which it should, I think).</p>\n\n<p>EDIT: this seems to be a bug in Deimos itself. Here is the relevant bug report by me: <a href=\"https://github.com/mesosphere/deimos/issues/43\" rel=\"nofollow\">https://github.com/mesosphere/deimos/issues/43</a></p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere"], "last_edit_date": 1407368299, "title": "Deimos Expecting 'MESOS_SLAVE_PID' in environment variables", "last_activity_date": 1407368299, "answer_count": 1, "creation_date": 1405973959, "score": 1, "link": "https://stackoverflow.com/questions/24873949/deimos-expecting-mesos-slave-pid-in-environment-variables", "answers": [{"body": "<p>Did you run the demos binary directly? Or did you provide the executor_uri to some framework.\nBecause normally, the executor is not expected to be launched directly. We specify the executor by providing the executor_uri to the framework. So each time the framework starts a task:</p>\n\n<p>1, Framework will send the executor_uri among other infos to the slave.\n2, Slave will use the infos to fetch the executor and then tell the containerizer to set up environments and launch the executor.</p>\n\n<p>FYI:\n<a href=\"https://github.com/apache/mesos/blob/0ba6b89b7421d426709af5bf89fac138cf0ca63e/src/slave/containerizer/containerizer.cpp#L262\" rel=\"nofollow\">https://github.com/apache/mesos/blob/0ba6b89b7421d426709af5bf89fac138cf0ca63e/src/slave/containerizer/containerizer.cpp#L262</a></p>\n", "answer_id": 25147607, "last_activity_date": 1407270029, "creation_date": 1407270029, "score": 0, "owner": {"user_id": 3911917, "profile_image": "https://www.gravatar.com/avatar/6486b0fd5f453a392d3c48bd9abdd70c?s=128&d=identicon&r=PG", "user_type": "unregistered", "reputation": 1, "link": "https://stackoverflow.com/users/3911917/yifan", "display_name": "yifan"}, "is_accepted": false, "question_id": 24873949}], "owner": {"user_id": 755934, "profile_image": "https://www.gravatar.com/avatar/78206ae90608eeec3892338bc3f1d1b4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 948, "link": "https://stackoverflow.com/users/755934/blacksheep", "accept_rate": 76, "display_name": "BlackSheep"}, "view_count": 683, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 24873949}{"is_answered": false, "tags": ["apache-spark", "pyspark", "mesosphere"], "last_edit_date": 1442667004, "title": "How to run PySpark (possibly in client mode) on Mesosphere cluster?", "last_activity_date": 1444958954, "answer_count": 1, "creation_date": 1442391208, "score": 3, "link": "https://stackoverflow.com/questions/32603102/how-to-run-pyspark-possibly-in-client-mode-on-mesosphere-cluster", "owner": {"user_id": 5341245, "profile_image": "https://www.gravatar.com/avatar/3f8f792d6dfdcc7ac17dd79c71ef7dca?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/5341245/jeff", "display_name": "Jeff"}, "view_count": 245, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 32603102}{"body": "<p>I have set up Mesos Cluster including Marathon &amp; Chronos using Docker image for each service.</p>\n\n<p>Docker images I am using are as follows;</p>\n\n<ul>\n<li>ZooKeeper: <a href=\"https://registry.hub.docker.com/u/jplock/zookeeper/\" rel=\"nofollow noreferrer\">jplock/zookeeper:3.4.5</a></li>\n<li>Mesos Master: <a href=\"https://registry.hub.docker.com/u/redjack/mesos-master/\" rel=\"nofollow noreferrer\">redjack/mesos-master:0.21.0</a></li>\n<li>Mesos Slave: <a href=\"https://registry.hub.docker.com/u/redjack/mesos-slave/\" rel=\"nofollow noreferrer\">redjack/mesos-slave:0.21.0</a></li>\n<li>Marathon: <a href=\"https://registry.hub.docker.com/u/mesosphere/marathon/\" rel=\"nofollow noreferrer\">mesosphere/marathon:v0.8.2-RC3</a></li>\n<li><strong>Chronos</strong>: <a href=\"https://registry.hub.docker.com/u/tomaskral/chronos/\" rel=\"nofollow noreferrer\">tomaskral/chronos:2.3.0-mesos0.21.0</a></li>\n</ul>\n\n<p>ZooKeeper is running on port 2181, Mesos Master on 5050, Mesos Slave on 5051, marathon on 8088, and Chronos on 8080.</p>\n\n<p><strong>What I want to do is; Run Docker container on Marathon &amp; Chronos.</strong></p>\n\n<p>Marathon successfully runs Docker containers as its Apps.</p>\n\n<p>But <strong>Chronos doesn't runs any Jobs.</strong> Even if the Job is not with Docker.</p>\n\n<p>Config for Chronos Job I tried to launch is;</p>\n\n<pre><code>{\n    \"schedule\": \"R/2015-05-28T10:16:30Z/PT2M\",\n    \"name\": \"simplejob\",\n    \"cpus\": \"0.5\",\n    \"mem\": \"512\",\n    \"command\": \"while sleep 10; do date -u %T; done\"\n}\n</code></pre>\n\n<p>Jobs are registered on Chronos but never be launched.\n<img src=\"https://i.stack.imgur.com/GvHpt.png\" alt=\"enter image description here\"></p>\n\n<p>My command for running Chronos container is as follows;</p>\n\n<pre><code>docker run -p 8080:8080 -e LIBPROCESS_PORT=5050 tomaskral/chronos:2.3.0-mesos0.21.0 --http_port 8080 --master zk://&lt;master-hostname&gt;:2181/mesos --zk_hosts zk://&lt;master-hostname&gt;:2181/mesos\n</code></pre>\n", "is_answered": true, "title": "Chronos does not run job", "tags": ["docker", "mesos", "mesosphere"], "last_activity_date": 1435654471, "accepted_answer_id": 31133752, "creation_date": 1432808868, "answers": [{"body": "<p>Change <code>--zk_hosts zk://&lt;master-hostname&gt;:2181/mesos</code> in your Chronos command-line to <code>--zk_hosts &lt;master-hostname&gt;:2181</code>, since this is supposed to be a list of zk node:port pairs, so that Chronos can store its own state in a <code>/chronos</code> znode (as opposed to the <code>/mesos</code> znode, where Mesos stores its leading master info).</p>\n", "answer_id": 31133752, "last_activity_date": 1435654471, "creation_date": 1435654471, "score": 3, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 30503907}], "score": 1, "link": "https://stackoverflow.com/questions/30503907/chronos-does-not-run-job", "answer_count": 1, "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 1377, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30503907}{"body": "<p>I have a three node chronos cluster. When request reach node 1 I see in the log that chronos proxying request to node2_hostname:4400 which is expected.</p>\n\n<p>When I check the chronos logs on node 2, I see entries saying Proxying request to node2_hostanme:4400 (the same node) and job is never scheduled. I don't understand why th log says the request is proxying to the same node. Any leads on this will be much appreciated.</p>\n\n<p>Regards</p>\n", "is_answered": true, "title": "Chronos Proxying Request to same Node", "tags": ["cron", "mesos", "mesosphere", "apache-zookeeper"], "last_activity_date": 1478087348, "accepted_answer_id": 40379232, "creation_date": 1469194808, "answers": [{"body": "<p>It is an open issue in chronos. Please refer to the below pull request for more information.</p>\n\n<p><a href=\"https://github.com/mesos/chronos/pull/497\" rel=\"nofollow noreferrer\">https://github.com/mesos/chronos/pull/497</a></p>\n", "answer_id": 40379232, "last_activity_date": 1478087348, "creation_date": 1478087348, "score": -1, "owner": {"user_id": 2621477, "profile_image": "https://www.gravatar.com/avatar/28f83b19d3586c0cbb02e08ff5f39d34?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 75, "link": "https://stackoverflow.com/users/2621477/chandu", "accept_rate": 70, "display_name": "chandu"}, "is_accepted": true, "question_id": 38527972}], "score": 0, "link": "https://stackoverflow.com/questions/38527972/chronos-proxying-request-to-same-node", "answer_count": 1, "owner": {"user_id": 2621477, "profile_image": "https://www.gravatar.com/avatar/28f83b19d3586c0cbb02e08ff5f39d34?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 75, "link": "https://stackoverflow.com/users/2621477/chandu", "accept_rate": 70, "display_name": "chandu"}, "view_count": 21, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 38527972}{"body": "<p>Trying to deploy a teamcity build agent on the Mesosphere Marathon platform and having problems with the port mappings.</p>\n\n<p>By default the teamcity server will try to talk to the teamcity agent on port 9090</p>\n\n<p>Therefor I set the container port like so :</p>\n\n<p>\"containerPort\": 9090</p>\n\n<p>However when I deploy the teamcity agent container, Marathon maps port 9090 to a port in the 30000 range.</p>\n\n<p>When teamcity server talks back to the container on port 9090 it fails because the port is mapped to 30000.</p>\n\n<p>I've figured out how to get this dynamic port into the teamcity config file by running the following sed command in the marathon args :</p>\n\n<pre><code>\"args\": [\"sh\", \"-c\", \"sed -i -- \\\"s/ownPort=9090/ownPort=$PORT0/g\\\" buildAgent.properties; bin/agent.sh run\"],\n</code></pre>\n\n<p>When the container is spun up it will swap out ownPort=9090 for ownPort=$PORT0 in buildAgent.properties and then start the agent.</p>\n\n<p>However now that the agent is on port 30000 the \"containerPort\": 9090 is now invalid, it should be \"containerPort\": $PORT0 however this is invalid json as containerPort should be an integer.</p>\n\n<p>I have tried setting \"containerPort\": 0 which should dynamically assign a port, but using this value I cannot get the container to start it just disappears straight away and keeps trying to deploy it.</p>\n\n<p>I log onto the mesos slave host and run docker ps -a I can see the containers ports are blank :</p>\n\n<pre><code>CONTAINER ID        IMAGE                    COMMAND                CREATED             STATUS                       PORTS                     NAMES\n28*********0        teamcityagent            \"\\\"sh -c 'sed -i --    7 minutes ago       Exited (137) 2 minutes ago                             mes************18a8\n</code></pre>\n\n<p>This is the Marathon json file I'm using and Marathon version is Version 0.8.2 :</p>\n\n<pre><code>{\n    \"id\": \"teamcityagent\",\n    \"args\": [\"sh\", \"-c\", \"sed -i -- \\\"s/ownPort=9090/ownPort=$PORT0/g\\\" buildAgent.properties; bin/agent.sh run\"],\n    \"cpus\": 0.05,\n    \"mem\": 4000.0,\n    \"instances\": 1,\n    \"container\": \n    {\n        \"type\": \"DOCKER\",\n        \"docker\": \n        {\n            \"image\": \"teamcityagent\",\n            \"forcePullImage\": true,\n            \"network\": \"BRIDGE\",\n            \"portMappings\": \n            [\n                {\n                    \"containerPort\": 0,\n                    \"hostPort\": 0,\n                    \"servicePort\": 0,\n                    \"protocol\": \"tcp\"\n                }\n            ]\n        }\n    }\n\n}\n</code></pre>\n\n<p>Any help would be greatly appreciated!</p>\n", "is_answered": true, "title": "Setting Team City Build Agent Port Number in Marathon", "last_edit_date": 1437032955, "tags": ["docker", "teamcity", "mesos", "mesosphere", "marathon"], "view_count": 226, "accepted_answer_id": 31466018, "last_activity_date": 1437087953, "answers": [{"body": "<p>Upgrading from Marathon Version 0.8.2 to Marathon Version 0.9.0 fixed the issue, using settings \"containerPort\": 0, now dynamically sets a port properly and the container starts up and the teamcity server can now communicate with it.</p>\n", "answer_id": 31466018, "last_activity_date": 1437087953, "creation_date": 1437087953, "score": 0, "owner": {"user_id": 2129923, "profile_image": "https://i.stack.imgur.com/tw5WQ.jpg?s=128&g=1", "user_type": "registered", "reputation": 140, "link": "https://stackoverflow.com/users/2129923/alex-laverty", "accept_rate": 67, "display_name": "Alex Laverty"}, "is_accepted": true, "question_id": 31448054}], "score": 0, "link": "https://stackoverflow.com/questions/31448054/setting-team-city-build-agent-port-number-in-marathon", "answer_count": 1, "owner": {"user_id": 2129923, "profile_image": "https://i.stack.imgur.com/tw5WQ.jpg?s=128&g=1", "user_type": "registered", "reputation": 140, "link": "https://stackoverflow.com/users/2129923/alex-laverty", "accept_rate": 67, "display_name": "Alex Laverty"}, "creation_date": 1437032083, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31448054}{"body": "<p>When mesos or marathon service restart due to some reasons and leader of mesos and marathon is not on the same machine, deployments stuck in marathon and nothing happens in mesos, that leads to terrible results when marathon can not restart failed services and do nothing with deployments until leaders will not match again.</p>\n\n<p>Our cluster has 3 masters (installed through mesosphere website) and this situation happens quite often, is there any way to fix that?</p>\n\n<p>Marathon v.0.9.0\nMesos v0.22.1</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1444299820, "title": "Marathon loses control over Mesos when Marathon and Mesos leaders mismatch", "last_activity_date": 1445263801, "answer_count": 1, "creation_date": 1444298991, "score": 0, "link": "https://stackoverflow.com/questions/33012728/marathon-loses-control-over-mesos-when-marathon-and-mesos-leaders-mismatch", "answers": [{"body": "<p>It sounds like either Mesos or Marathon use a private ip (localhost/127.0.0.1), thus they weren't able to <em>talk</em> to each other.<br>\nYou should be able to solve your issue by setting a public ip using the respective <code>--ip</code> command line flag or <code>LIBPROCESS_IP</code> environment var.</p>\n\n<blockquote>\n  <p>One particularly useful setting is LIBPROCESS_IP, which tells the master and slave binaries which IP address to bind to; in some installations, the default interface that the hostname resolves to is not the machine\u2019s external IP address, so you can set the right IP through this variable.</p>\n</blockquote>\n\n<p>/source <a href=\"http://mesos.apache.org/documentation/latest/deploy-scripts/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/deploy-scripts/</a></p>\n", "answer_id": 33216643, "last_activity_date": 1445263801, "creation_date": 1445263801, "score": 2, "owner": {"user_id": 2248027, "profile_image": "https://www.gravatar.com/avatar/16cd33c129d8d541920eb1178a359c5c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 46, "link": "https://stackoverflow.com/users/2248027/orlando-hohmeier", "display_name": "Orlando Hohmeier"}, "is_accepted": false, "question_id": 33012728}], "owner": {"user_id": 2170491, "profile_image": "https://i.stack.imgur.com/mhDM9.jpg?s=128&g=1", "user_type": "registered", "reputation": 504, "link": "https://stackoverflow.com/users/2170491/ihar-krasnik", "accept_rate": 31, "display_name": "Ihar Krasnik"}, "view_count": 93, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33012728}{"body": "<p>I am wondering how <code>Apache Mesos</code> implements the front-end web ui (<code>localhost:port</code>) in which users can track the system's current status and the submitted jobs. Is there any library for this? How does <code>Mesos</code> do this (in C++)?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Front-end web UI implementation of Apache Mesos", "last_activity_date": 1472148082, "answer_count": 1, "creation_date": 1472079251, "score": -2, "link": "https://stackoverflow.com/questions/39134204/front-end-web-ui-implementation-of-apache-mesos", "answers": [{"body": "<p>Well, having a look at the source code reveals what it's using:</p>\n\n<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\" ng-app=\"mesos\"&gt;\n  &lt;head&gt;\n    ...\n    &lt;link href=\"/static/css/bootstrap-3.3.6.min.css\" rel=\"stylesheet\"&gt;\n    ...\n  &lt;/head&gt;\n  &lt;body&gt;\n    ...\n    &lt;script src=\"/static/js/jquery-1.7.1.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"/static/js/underscore-1.4.3.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"/static/js/zeroclipboard-1.1.7.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"/static/js/angular-1.2.3.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"/static/js/angular-route-1.2.3.min.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"/static/js/ui-bootstrap-tpls-0.9.0.min.js\"&gt;&lt;/script&gt;\n    ...\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n\n<p>So, it's using </p>\n\n<ul>\n<li>Angular</li>\n<li>jQuery</li>\n<li>Bootstrap</li>\n</ul>\n", "answer_id": 39151967, "last_activity_date": 1472148082, "creation_date": 1472148082, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 39134204}], "owner": {"user_id": 2828925, "profile_image": "https://www.gravatar.com/avatar/18abe23c6b1123371f171f55be659ef5?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 721, "link": "https://stackoverflow.com/users/2828925/jes", "accept_rate": 50, "display_name": "Jes"}, "view_count": 60, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39134204}{"body": "<p>I have assigned slave resources to the particular role (<em>\"app-role\"</em>) by set <code>--default_role=\"app-role\"</code> parameter to <code>ExecStart</code> for slave service ( <code>/etc/systemd/system/dcos-mesos-slave.service</code>). Next I have restarted slave agent:</p>\n\n<pre><code>sudo systemctl daemon-reload\nsudo systemctl stop dcos-mesos-slave.service\nsudo rm -f /var/lib/mesos/slave/meta/slaves/latest\nsudo systemctl start dcos-mesos-slave.service \n</code></pre>\n\n<p>and verified by: <code>curl master.mesos/mesos/slaves</code>.</p>\n\n<p>After that I expect marathon app with acceptedResourceRoles attribute  will receive only these particular resource offers, but it does not happen (the app is still in waiting state). </p>\n\n<p>Why does marathon didn't receive it? How should this be done to make it work?</p>\n\n<pre><code>{\n  \"id\": \"/basic-4\",\n  \"cmd\": \"python3 -m http.server 8080\",\n  \"cpus\": 0.5,\n  \"mem\": 32,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"acceptedResourceRoles\": [\n    \"app-role\"\n  ],\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"python:3\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8080,\n          \"hostPort\": 0,\n          \"servicePort\": 10000,\n          \"protocol\": \"tcp\",\n          \"name\": \"my-vip\",\n          \"labels\": {\n            \"VIP_0\": \"/my-service:5555\"\n          }\n        }\n      ],\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10000,\n      \"protocol\": \"tcp\",\n      \"name\": \"default\",\n      \"labels\": {}\n    }\n  ]\n}\n</code></pre>\n", "is_answered": true, "title": "Mesos/Marathon - reserved resources for role are not offered for Marathon app", "last_edit_date": 1496842078, "tags": ["mesos", "marathon", "dcos"], "view_count": 29, "accepted_answer_id": 44452397, "last_activity_date": 1496997283, "answers": [{"body": "<p>This works only if marathon is started with <code>--mesos_role</code> set.\nIn the context of the question this should be: <code>--mesos_role 'app-role'</code>.</p>\n\n<blockquote>\n  <ol>\n  <li>If you set\u00a0--mesos_role other, Marathon will register with Mesos for this role \u2013 it will receive offers for resources that are reserved\n  for this role, in addition to unreserved resources.</li>\n  <li>If you set\u00a0default_accepted_resource_roles *, Marathon will apply this default to all AppDefinitions that do not explicitly\n  define\u00a0acceptedResourceRoles. Since your AppDefinition defines that\n  option, the default will not be applied (both are equal anyways).</li>\n  <li>If you set\u00a0\"acceptedResourceRoles\": [\"<em>\"]\u00a0in an AppDefinition (or the AppDefinition\u00a0inherits\u00a0a default of\u00a0\"</em>\"), Marathon will only\n  consider unreserved resources for launching of this app.</li>\n  </ol>\n</blockquote>\n\n<p>More: <a href=\"https://mesosphere.github.io/marathon/docs/recipes.html\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/recipes.html</a></p>\n", "answer_id": 44452397, "last_activity_date": 1496997283, "creation_date": 1496995123, "score": 0, "owner": {"user_id": 5672927, "profile_image": "https://www.gravatar.com/avatar/7ce7daa2121de3654ad9d3265662670c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 314, "link": "https://stackoverflow.com/users/5672927/milso", "accept_rate": 89, "display_name": "Milso"}, "is_accepted": true, "last_edit_date": 1496997283, "question_id": 44413951}], "score": 0, "link": "https://stackoverflow.com/questions/44413951/mesos-marathon-reserved-resources-for-role-are-not-offered-for-marathon-app", "answer_count": 1, "owner": {"user_id": 5672927, "profile_image": "https://www.gravatar.com/avatar/7ce7daa2121de3654ad9d3265662670c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 314, "link": "https://stackoverflow.com/users/5672927/milso", "accept_rate": 89, "display_name": "Milso"}, "creation_date": 1496841809, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44413951}{"body": "<p>Currently I have a mesos cluster with docker container enabled. I use mesos docker support to run spark framework on my cluster. I want to schedule a spark-submit job from chronos. Could you please let me know the steps or the best way to do it. I am pretty new to mesos and I dont know how chronos will find the spark-submit command to submit the application.</p>\n", "is_answered": true, "tags": ["apache-spark", "pyspark", "mesos", "mesosphere"], "title": "Running spark-submit in chronos", "last_activity_date": 1460615883, "answer_count": 1, "creation_date": 1460535945, "score": 0, "link": "https://stackoverflow.com/questions/36592640/running-spark-submit-in-chronos", "answers": [{"body": "<p>You could package your application together with a Spark distribution into a Docker container, and create a Docker job in Chronos:</p>\n\n<ul>\n<li><a href=\"http://mesos.github.io/chronos/docs/api.html#adding-a-docker-job\" rel=\"nofollow\">http://mesos.github.io/chronos/docs/api.html#adding-a-docker-job</a></li>\n</ul>\n\n<p>For example, send a POST request to the Chronos REST API like this:</p>\n\n<pre><code>curl -L -H 'Content-Type: application/json' -X POST chronos-node:8080/scheduler/iso8601 -d '\n{\n  \"schedule\": \"R/2016-04-15T12:00:00Z/PT2M\",\n  \"name\": \"spark-submit-job\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"image\": \"my/sparksubmitapp\",\n    \"network\": \"BRIDGE\",\n    \"forcePullImage\": true\n  },\n  \"cpus\": \"0.5\",\n  \"mem\": \"1024\",\n  \"uris\": [],\n  \"command\": \"/path/to/spark/bin/spark-submit --class com.my.app.Main myApp.jar\"\n}'\n</code></pre>\n", "answer_id": 36615493, "last_activity_date": 1460615883, "creation_date": 1460615883, "score": 2, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 36592640}], "owner": {"user_id": 4481208, "profile_image": "https://lh6.googleusercontent.com/-hXni_F6hxMs/AAAAAAAAAAI/AAAAAAAAAEY/QavUudeabis/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/4481208/ramakanta-samal", "display_name": "Ramakanta Samal"}, "view_count": 478, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36592640}{"body": "<p>Does Mesos Master and Mesos agent require root access? what is the default permission level for Mesos master and Mesos agent? can they run with non-root access?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "Does Mesos Master and Mesos agent require root access?", "last_activity_date": 1486374047, "answer_count": 1, "creation_date": 1484780927, "score": 2, "link": "https://stackoverflow.com/questions/41731079/does-mesos-master-and-mesos-agent-require-root-access", "answers": [{"body": "<p>No,\nMesos Master and Mesos agent doesn't need root access.Yes they can run with non-root acess</p>\n", "answer_id": 42064564, "last_activity_date": 1486374047, "creation_date": 1486374047, "score": 0, "owner": {"user_id": 7522378, "profile_image": "https://www.gravatar.com/avatar/98279c97b44e0993148547946339212e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7522378/kool", "display_name": "Kool"}, "is_accepted": false, "question_id": 41731079}], "owner": {"user_id": 1870400, "profile_image": "https://www.gravatar.com/avatar/86a511ab70d0d94c77746a4d27c66fdf?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 772, "link": "https://stackoverflow.com/users/1870400/user1870400", "accept_rate": 39, "display_name": "user1870400"}, "view_count": 131, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41731079}{"body": "<p>I'm using Apache Mesos + Marathon + Zookeeper to deploy my rails app.\nI need share data between rails app and other container. I found some reference here to do it with marathon as follow:</p>\n\n<p><a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">marathon/docs/native-docker.html</a></p>\n\n<pre><code>{\n\"id\": \"privileged-job\",\n\"container\": {\n    \"docker\": {\n        \"image\": \"mesosphere/inky\"\n        \"privileged\": true,\n        \"parameters\": [\n            { \"key\": \"hostname\", \"value\": \"a.corp.org\" },\n            { \"key\": \"volumes-from\", \"value\": \"another-container\" },\n            { \"key\": \"lxc-conf\", \"value\": \"...\" }\n        ]\n    },\n    \"type\": \"DOCKER\",\n    \"volumes\": []\n},\n\"args\": [\"hello\"],\n\"cpus\": 0.2,\n\"mem\": 32.0,\n\"instances\": 1\n}\n</code></pre>\n\n<p>But I can't found a way to discover a name of my rails app container because marathon assign names with format: \"mesos-uuid\". Any idea to solve it? or another way to share volume from containers with marathon?</p>\n", "is_answered": true, "title": "how know container name with marathon rest API", "last_edit_date": 1424728080, "tags": ["docker", "mesos", "mesosphere", "marathon"], "view_count": 2853, "accepted_answer_id": 28683947, "last_activity_date": 1502272841, "answers": [{"body": "<p>You can add <a href=\"https://mesosphere.github.io/marathon/docs/constraints.html\" rel=\"nofollow\">constraints</a> to your app to force them onto specific hosts.</p>\n\n<p>In a simple case, you could do something like this to force an app onto a specific host:</p>\n\n<pre><code>{\n \"instances\": 1,\n \"constraints\": [[\"hostname\", \"LIKE\", \"worker-1\"]]\n}\n</code></pre>\n\n<p>The next option brings in attributes.\nYou can tag a known number of hosts (let's say 3) with some custom tag.</p>\n\n<p>Then your app definition could look like this:</p>\n\n<pre><code>{\n \"instances\": 3,\n \"constraints\": [\n   [\"hostname\", \"UNIQUE\"],\n   [\"your-custom-tag\", \"GROUP_BY\"]\n ]\n}\n</code></pre>\n\n<p>You'd add this to the app definition for both of your apps, resulting in one instance of each running on all three slaves you tagged.</p>\n\n<p>See the a <a href=\"http://mesosphere.com/docs/reference/mesos-slave\" rel=\"nofollow\">reference doc</a> on setting attributes.</p>\n", "answer_id": 28683947, "last_activity_date": 1424727419, "creation_date": 1424727419, "score": 2, "owner": {"user_id": 854825, "profile_image": "https://www.gravatar.com/avatar/4880df3637aecd0e4bdaad5a6aabd56b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1362, "link": "https://stackoverflow.com/users/854825/connor-doyle", "accept_rate": 83, "display_name": "Connor Doyle"}, "is_accepted": true, "question_id": 28681235}, {"body": "<p>The answer might help others who are looking for it.</p>\n\n<p>Use <code>docker inspect</code> and search for the environment setting in the JSON with key value \"<strong>MESOS_TASK_ID</strong>\". </p>\n\n<p>Now you have a matching <code>CONTAINER_ID</code> and <code>MESOS_TASK_ID</code> pair.</p>\n\n<p>Hope this helps.</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>For determining that in an automated way, first make sure that you docker daemon can be accessed remotely. <em>Note: This may raise security concerns</em></p>\n\n<p>Edit <code>/etc/default/docker</code> and add <code>DOCKER_OPTS=\"-H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375\"</code> and restart docker - on all your mesos slaves.</p>\n\n<p>Use the following code, to get the <code>MESOS_SLAVE CONTAINER_ID    MESOS_TASK_ID</code> mappings</p>\n\n<pre><code>#!/bin/bash\nHOSTS=($(curl -s -X GET -H \"Accept: text/plain\" http://mesosmaster:8080/v2/tasks | tail -n1 | cut -f3-))\nhosts=()\nfor i in \"${HOSTS[@]}\"\ndo\nhosts+=($(echo $i | awk -F\":\" '{print $1}'))\ndone\nhost=($(printf \"%s\\n\" \"${hosts[@]}\" | sort -u))\nfor host in \"${host[@]}\"\ndo\nINSTANCES=($(docker -H $host:2375 ps -q))\nfor container_id in \"${INSTANCES[@]}\"\ndo\nmesos_id=$(docker -H $host:2375 inspect $container_id | grep MESOS_TASK_ID | awk -F '[=\"]' '{print $3}')\nprintf \"$host\\t$container_id\\t$mesos_id\\n\"\ndone\ndone\n</code></pre>\n\n<p>Hope this will help you.</p>\n", "answer_id": 29383504, "last_activity_date": 1428414031, "creation_date": 1427866386, "score": 2, "owner": {"user_id": 4614568, "profile_image": "https://www.gravatar.com/avatar/3e01713d9d283c4a285be2d911880e97?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 497, "link": "https://stackoverflow.com/users/4614568/shan", "accept_rate": 43, "display_name": "Shan"}, "is_accepted": false, "last_edit_date": 1428414031, "question_id": 28681235}, {"body": "<p>My script based on Shan's script.\nTakes hostname as first argument and a list of marathon deployment ids as others arguments.</p>\n\n<p>I wish this will be helpfull to someone ;) </p>\n\n<p>I am using marathon 0.11.1 and with this version the mesos container name is the value required for the volumes-from parameter.</p>\n\n<pre><code>#!/bin/bash\n\nfind_mesos_id () {\n  # Parameters\n  HOST=\"$1\"\n\n  # All running containers\n  CONTAINERS=`docker -H $HOST:2375 ps | sed 1d | awk '{print $1}'`\n  CONTAINERS_ARRAY=($CONTAINERS)\n\n  # for each get MARATHON_ID &amp; MESOS_ID\n  for i in \"${CONTAINERS_ARRAY[@]}\"\n  do  \n     MARATHON_APP_ID=$(docker -H $HOST:2375 inspect $i | grep MARATHON_APP_ID | awk -F '[=\"]' '{print $3}' | awk -F '\\/' '{print $2}')\n     MESOS_CONTAINER_NAME=$(docker -H $HOST:2375 inspect $i | grep MESOS_CONTAINER_NAME | awk -F '[=\"]' '{print $3}')\n\n     # Print MESOS_ID only for desired container\n     if [[ $MARATHON_APP_ID = $2 ]]; then\n        printf \"{ \\\"key\\\": \\\"volumes-from\\\", \\\"value\\\": \\\"%s\\\" }\" $MESOS_CONTAINER_NAME\n     fi   \n  done\n}   \n\nif [ \"$#\" -lt 2 ]; then\n  echo \"USAGE: bash gen-data-volumes.sh &lt;host&gt; [&lt;marathon-id&gt;]\"\n  printf \"This script takes at least two arguments (%d given).\\n\" $#\n  echo \"exit 1.\"\n  exit 1;\nfi  \n\nif [ \"$#\" -gt 1 ]; then\n  for ((i=2;i&lt;$#+1;i++)) \n    do  \n      printf \"%s\" $(find_mesos_id $1 ${!i})\n      if [[ $i -ne $# ]]; then\n        printf \",\u00a0\"\n      else \n        echo\n      fi  \n    done\nfi\n</code></pre>\n", "answer_id": 34316626, "last_activity_date": 1450281682, "creation_date": 1450281682, "score": 0, "owner": {"user_id": 2318925, "profile_image": "https://www.gravatar.com/avatar/bfd4dc1f78bd14c010a2c4d8e934262b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/2318925/benoit-brayer", "display_name": "Benoit Brayer"}, "is_accepted": false, "question_id": 28681235}, {"body": "<p>You can run something like to get the Container Id</p>\n\n<p><code>docker ps --filter label=MESOS_TASK_ID=&lt;mesos-task-id&gt; -q</code></p>\n", "answer_id": 43620084, "last_activity_date": 1493151024, "creation_date": 1493151024, "score": 0, "owner": {"user_id": 7921657, "profile_image": "https://lh5.googleusercontent.com/-FAVpZw4y_jY/AAAAAAAAAAI/AAAAAAAAAOg/5alj4LPbeIM/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7921657/pedro-martucci", "display_name": "Pedro Martucci"}, "is_accepted": false, "question_id": 28681235}, {"body": "<p>Get back your real requirement, I don't think it's better using container_id to comunicate with other container(s) than ipaddress. Though you are using zookeeper, you may use it as name service server\u2014\u2014when \"rails app container\" is up, it could register itself in zk at specific node and then other app in other container(s) could find what they want there.</p>\n", "answer_id": 45587464, "last_activity_date": 1502272841, "creation_date": 1502272841, "score": 0, "owner": {"user_id": 8438999, "profile_image": "https://www.gravatar.com/avatar/32caaa7e6d0d135f484ff35bca15c90e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/8438999/light", "display_name": "Light"}, "is_accepted": false, "question_id": 28681235}], "score": 3, "link": "https://stackoverflow.com/questions/28681235/how-know-container-name-with-marathon-rest-api", "answer_count": 5, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "creation_date": 1424717741, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 28681235}{"body": "<ul>\n<li>Test environment: multi-node mesos 0.27.2 cluster on AWS (3 x masters, 2 x slaves, quorum=2).</li>\n<li>Tested persistence with zkCli.sh and it works fine.</li>\n<li>If i start the masters with <code>--registry=in_memory</code>, it works fine, master is elected, i can start tasks via Marathon.</li>\n<li>If i use the default (<code>--registry=replicated_log</code>) the cluster fails to elect a master:</li>\n</ul>\n\n<p><a href=\"https://gist.github.com/mitel/67acd44408f4d51af192\" rel=\"nofollow\">https://gist.github.com/mitel/67acd44408f4d51af192</a></p>\n\n<p><code>EDIT</code>: apparently the problem was the firewall. Applied an allow-all type of rule to all my security groups and now i have a stable master. Once i figure out what was blocking the communication i'll post it here.</p>\n", "is_answered": true, "title": "Mesos cluster fails to elect master when using replicated_log", "last_edit_date": 1457945149, "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon"], "view_count": 377, "accepted_answer_id": 36067679, "last_activity_date": 1459837033, "answers": [{"body": "<p>First off, let me briefly clarify the flags meaning for posterity. <code>--registry</code> does not influence leader election, it specifies the persistence strategy for the registry (where Mesos tracks data that should be carried over failover). The <code>in_memory</code> value should not be used in production, it may even be removed in the future.</p>\n\n<p>Leader election is performed by zookeeper. According to your log, you use the following zookeeper cluster: <code>zk://10.1.69.172:2181,10.1.9.139:2181,10.1.79.211:2181/mesos</code>.</p>\n\n<p>Now, from your log, the cluster did not fail to elect the master, it actually did it twice:</p>\n\n<pre><code>\nI0313 18:35:28.257139  3253 master.cpp:1710] The newly elected leader is master@10.1.69.172:5050 with id edd3e4a7-ede8-44fe-b24c-67a8790e2b79\n...\nI0313 18:35:36.074087  3257 master.cpp:1710] The newly elected leader is master@10.1.9.139:5050 with id c4fd7c4d-e3ce-4ac3-9d8a-28c841dca7f5\n</code></pre>\n\n<p>I can't say why exactly the leader was elected twice, for that I would need logs from 2 other masters as well. According to your log, the last elected master is on <code>10.1.9.139:5050</code>, which is most probably not the one you provided the log from.</p>\n\n<p>One suspicious thing I see in the log is that master IDs differ for the same IP:port. Do you have an idea why?</p>\n\n<pre><code>I0313 18:35:28.237251  3244 master.cpp:374] Master 24ecdfff-2c97-4de8-8b9c-dcea91115809 (10.1.69.172) started on 10.1.69.172:5050\n...\nI0313 18:35:28.257139  3253 master.cpp:1710] The newly elected leader is master@10.1.69.172:5050 with id edd3e4a7-ede8-44fe-b24c-67a8790e2b79\n</code></pre>\n", "answer_id": 35975870, "last_activity_date": 1457903106, "creation_date": 1457903106, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 35975001}, {"body": "<p>Discovered that mesos masters also initiate connections to other masters on 5050. After adding the egress rule to the master's security group, the cluster is stable, master election happens as expected. <a href=\"https://gist.github.com/mitel/783df5a7b1a33a2693b8\" rel=\"nofollow\">firewall rules</a> </p>\n\n<p>UPDATE: for those who try to build an internal firewall between the various components of mesos/zk/.. - don't do it. better to design the security as in Mesosphere's <a href=\"https://docs.mesosphere.com/administration/dcosarchitecture/security\" rel=\"nofollow\">DCOS</a></p>\n", "answer_id": 36067679, "last_activity_date": 1459837033, "creation_date": 1458235592, "score": 1, "owner": {"user_id": 3834939, "profile_image": "https://www.gravatar.com/avatar/3ce63bf036556cd8f6d1ce25b24fbc70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 96, "link": "https://stackoverflow.com/users/3834939/mitelone", "display_name": "mitelone"}, "is_accepted": true, "last_edit_date": 1459837033, "question_id": 35975001}], "score": 3, "link": "https://stackoverflow.com/questions/35975001/mesos-cluster-fails-to-elect-master-when-using-replicated-log", "answer_count": 2, "owner": {"user_id": 3834939, "profile_image": "https://www.gravatar.com/avatar/3ce63bf036556cd8f6d1ce25b24fbc70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 96, "link": "https://stackoverflow.com/users/3834939/mitelone", "display_name": "mitelone"}, "creation_date": 1457898751, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 35975001}{"body": "<p>I refer <a href=\"https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/getting-started-guides/mesos.md\" rel=\"nofollow\">Getting started with Kubernetes on Mesos</a> and try to deploy <code>k8s</code> and <code>Mesos</code> on the same local <code>Ubuntu</code>. Executing the following command:  </p>\n\n<pre><code>$ km controller-manager \\\n  --master=${KUBERNETES_MASTER_IP}:8888 \\\n  --cloud-provider=mesos \\\n  --cloud-config=./mesos-cloud.conf  \\\n  --v=8 &gt;controller.log 2&gt;&amp;1 &amp;\n</code></pre>\n\n<p>From the <code>controller.log</code>:  </p>\n\n<pre><code>$ more controller.log\nI1210 05:33:13.570789   12082 controllermanager.go:217] Creating hostIP:hostPort endpoint controller\nI1210 05:33:13.571253   12082 mesos.go:75] new mesos cloud, master='16.187.250.141:5050'\nI1210 05:33:13.571294   12082 standalone.go:46] creating new standalone detector for &amp;MasterInfo{Id:*master,Ip:*0,Port:*5050,Pid:*master@16\n.187.250.141:5050,Hostname:*16.187.250.141,Version:nil,Address:nil,XXX_unrecognized:[],}\nI1210 05:33:13.571469   12082 standalone.go:67] Detect()\nI1210 05:33:13.571485   12082 standalone.go:69] spinning up asyc master detector poller\nI1210 05:33:13.571501   12082 standalone.go:78] spawning asyc master detector listener\nI1210 05:33:13.571608   12082 nodecontroller.go:132] Sending events to api server.\nI1210 05:33:13.571706   12082 standalone.go:140] polling for master leadership at '16.187.250.141:5050'\nI1210 05:33:13.571729   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/services\nI1210 05:33:13.571757   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.571772   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.571831   12082 standalone.go:80] waiting for polled to send updates\nI1210 05:33:13.571986   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/replicationcontrollers\nI1210 05:33:13.572010   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572026   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nE1210 05:33:13.571994   12082 controllermanager.go:152] Failed to start service controller: the cloud provider does not support TCP load ba\nlancers.\nI1210 05:33:13.572124   12082 round_trippers.go:222] GET http://16.187.250.141:8888/apis/extensions/v1beta1/daemonsets\nI1210 05:33:13.572151   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572167   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572208   12082 persistentvolume_claim_binder_controller.go:346] Starting PersistentVolumeClaimBinder\nI1210 05:33:13.572262   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/nodes\nI1210 05:33:13.572268   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/pods\nI1210 05:33:13.572300   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572314   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572305   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/pods\nI1210 05:33:13.572331   12082 plugins.go:265] Loaded volume plugin \"kubernetes.io/host-path\"\nI1210 05:33:13.572371   12082 plugins.go:265] Loaded volume plugin \"kubernetes.io/nfs\"\nI1210 05:33:13.572393   12082 persistentvolume_recycler_controller.go:211] Starting PersistentVolumeRecycler\nI1210 05:33:13.572452   12082 resource_quota_controller.go:133] Resource quota controller queued all resource quota for full calculation of\n usage\nI1210 05:33:13.572479   12082 client.go:77] Reloading cached Mesos state\nI1210 05:33:13.572283   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572499   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/pods\nI1210 05:33:13.572346   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572508   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572531   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572535   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/nodes\nI1210 05:33:13.572547   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/nodes\nI1210 05:33:13.572571   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572584   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572521   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572612   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572632   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/namespaces\nI1210 05:33:13.572662   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572676   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572684   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/resourcequotas\nI1210 05:33:13.572702   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572714   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572756   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/persistentvolumeclaims\nI1210 05:33:13.572551   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572791   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572815   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/persistentvolumes\nI1210 05:33:13.572329   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/nodes\nI1210 05:33:13.572846   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572858   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572864   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/serviceaccounts?fieldSelector=metadata.name%3Dde\nfault\nI1210 05:33:13.572869   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/persistentvolumes\nI1210 05:33:13.572885   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572892   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572777   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.572948   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572167   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/pods\nI1210 05:33:13.573010   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.573019   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572834   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.573072   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572876   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.573120   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.572641   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/namespaces\nI1210 05:33:13.573193   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.573202   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.573286   12082 round_trippers.go:222] GET http://16.187.250.141:8888/api/v1/pods\nI1210 05:33:13.573304   12082 round_trippers.go:229] Request Headers:\nI1210 05:33:13.573313   12082 round_trippers.go:232]     User-Agent: km/v1.2.0 (linux/amd64) kubernetes/c2cfcd5\nI1210 05:33:13.576806   12082 standalone.go:214] Got mesos state, content length 1795\nI1210 05:33:13.577013   12082 standalone.go:147] detected leadership change from '&lt;nil&gt;' to 'master@16.187.250.141:5050'\nI1210 05:33:13.577098   12082 standalone.go:185] master leader poller sleeping for 29.994633799s\nI1210 05:33:13.577118   12082 standalone.go:88] detected master change: &amp;MasterInfo{Id:*master,Ip:*0,Port:*5050,Pid:*master@16.187.250.141:\n5050,Hostname:*16.187.250.141,Version:nil,Address:nil,XXX_unrecognized:[],}\nI1210 05:33:13.577218   12082 client.go:155] cloud master changed to '16.187.250.141:5050'\nI1210 05:33:14.192579   12082 round_trippers.go:247] Response Status: 403 Forbidden in 619 milliseconds\nI1210 05:33:14.192610   12082 round_trippers.go:250] Response Headers:\nI1210 05:33:14.192621   12082 round_trippers.go:253]     Proxy-Connection: Keep-Alive\nE1210 05:33:14.192639   12082 statusupdater.go:68] Error listing slaves without kubelet: HTTP request failed with code 403: 403 Forbidden\nI1210 05:33:14.192667   12082 round_trippers.go:253]     Connection: Keep-Alive\nI1210 05:33:14.192692   12082 round_trippers.go:253]     Content-Length: 606\nI1210 05:33:14.192703   12082 round_trippers.go:253]     Cache-Control: no-cache\nI1210 05:33:14.192712   12082 round_trippers.go:253]     Pragma: no-cache\nI1210 05:33:14.192722   12082 round_trippers.go:253]     Content-Type: text/html; charset=utf-8\nI1210 05:33:14.192765   12082 round_trippers.go:247] Response Status: 403 Forbidden in 620 milliseconds\nI1210 05:33:14.192800   12082 round_trippers.go:250] Response Headers:\nI1210 05:33:14.192812   12082 round_trippers.go:253]     Pragma: no-cache\nI1210 05:33:14.192823   12082 round_trippers.go:253]     Content-Type: text/html; charset=utf-8\nI1210 05:33:14.192833   12082 round_trippers.go:253]     Proxy-Connection: Keep-Alive\nI1210 05:33:14.192842   12082 round_trippers.go:253]     Connection: Keep-Alive\nI1210 05:33:14.192851   12082 round_trippers.go:253]     Content-Length: 606\nI1210 05:33:14.192861   12082 round_trippers.go:253]     Cache-Control: no-cache\nI1210 05:33:14.192905   12082 request.go:804] Response Body: &lt;HTML&gt;&lt;HEAD&gt;\n&lt;TITLE&gt;Access Denied&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;blockquote&gt;\n&lt;TABLE border=0 cellPadding=1 width=\"80%\"&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;Access Denied (policy_denied)&lt;/big&gt;\n&lt;BR&gt;\n&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\nYour system policy has denied access to the requested URL.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\" SIZE=2&gt;\n&lt;BR&gt;\nFor assistance, contact your network support team.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;/TABLE&gt;\n&lt;/blockquote&gt;\n&lt;/FONT&gt;\n&lt;/BODY&gt;&lt;/HTML&gt;\nI1210 05:33:14.192935   12082 request.go:861] Response Body: &lt;HTML&gt;&lt;HEAD&gt;\n&lt;TITLE&gt;Access Denied&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;blockquote&gt;\n&lt;TABLE border=0 cellPadding=1 width=\"80%\"&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;Access Denied (policy_denied)&lt;/big&gt;\n&lt;BR&gt;\n&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\nYour system policy has denied access to the requested URL.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\" SIZE=2&gt;\n&lt;BR&gt;\nFor assistance, contact your network support team.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;/TABLE&gt;\n&lt;/blockquote&gt;\n&lt;/FONT&gt;\n&lt;/BODY&gt;&lt;/HTML&gt;\nI1210 05:33:14.192785   12082 request.go:804] Response Body: &lt;HTML&gt;&lt;HEAD&gt;\n&lt;TITLE&gt;Access Denied&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;blockquote&gt;\n&lt;TABLE border=0 cellPadding=1 width=\"80%\"&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;Access Denied (policy_denied)&lt;/big&gt;\n&lt;BR&gt;\n&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\nYour system policy has denied access to the requested URL.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\" SIZE=2&gt;\n&lt;BR&gt;\nFor assistance, contact your network support team.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;/TABLE&gt;\n&lt;/blockquote&gt;\n&lt;/FONT&gt;\n&lt;/BODY&gt;&lt;/HTML&gt;\nI1210 05:33:14.193025   12082 round_trippers.go:247] Response Status: 403 Forbidden in 620 milliseconds\nI1210 05:33:14.193034   12082 request.go:861] Response Body: &lt;HTML&gt;&lt;HEAD&gt;\n</code></pre>\n\n<p>I can see there are some \"<code>403</code>\" http response error. But how can I find which http request cause this response error?</p>\n", "is_answered": true, "title": "How can I find matched http request through a response error while running k8s on Mesos?", "tags": ["http", "kubernetes", "mesos", "mesosphere"], "last_activity_date": 1449825863, "accepted_answer_id": 34220023, "creation_date": 1449798806, "answers": [{"body": "<p>After investigating, there are two steps:  </p>\n\n<p>(1) use <code>lsof</code> to find the <code>http</code> connection:  </p>\n\n<pre><code>lsof -p pid -P -n\n</code></pre>\n\n<p>(2) Use <code>tcpdump</code> to capture the network package:  </p>\n\n<pre><code>sudo tcpdump -vv -A -s 0 'tcp port xxxx' -i em1 -w capture.pcap\n</code></pre>\n\n<p>Then analyze the package. </p>\n", "answer_id": 34220023, "last_activity_date": 1449825863, "creation_date": 1449825863, "score": 0, "owner": {"user_id": 2106207, "profile_image": "https://www.gravatar.com/avatar/960430ab7aba908bb9aa62d530618a75?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4686, "link": "https://stackoverflow.com/users/2106207/nan-xiao", "accept_rate": 78, "display_name": "Nan Xiao"}, "is_accepted": true, "question_id": 34214936}], "score": 0, "link": "https://stackoverflow.com/questions/34214936/how-can-i-find-matched-http-request-through-a-response-error-while-running-k8s-o", "answer_count": 1, "owner": {"user_id": 2106207, "profile_image": "https://www.gravatar.com/avatar/960430ab7aba908bb9aa62d530618a75?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4686, "link": "https://stackoverflow.com/users/2106207/nan-xiao", "accept_rate": 78, "display_name": "Nan Xiao"}, "view_count": 74, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34214936}{"body": "<p>We are doing spark job submission using the rest api to spark master/cluster manager in dcos cluster</p>\n\n<p>The below job works perfect</p>\n\n<p>rest end point => service/spark/v1/submissions/create</p>\n\n<pre><code>{\n\"action\" : \"CreateSubmissionRequest\",\n\"appArgs\" : [ \"100\" ],\n\"appResource\" : \"https://&lt;s3 location&gt;/spark-examples-1.5.1-hadoop2.4.0.jar\",\n\"clientSparkVersion\" : \"1.6.1\",\n\"environmentVariables\" : {\n\"SPARK_ENV_LOADED\" : \"1\",\n\"SPARK_JAVA_OPTS\" : \"-Dspark.mesos.coarse=true -Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.0-1.6.1-2\"\n},\n\"mainClass\" : \"org.apache.spark.examples.SparkPi\",\n\"sparkProperties\" : {\n\"spark.jars\" : \"https://&lt;s3 location&gt;/spark-examples-1.5.1-hadoop2.4.0.jar\",\n\"spark.app.name\" : \"SparkPi\",\n\"spark.submit.deployMode\" : \"cluster\",\n\"spark.master\" : \"mesos://&lt;dcos mesos master&gt;/service/spark/\",\n\"spark.executor.cores\" : \"1\",\n\"spark.executor.memory\" : \"2048m\",\n\"spark.cores.max\" : \"2\",\n\"spark.mesos.executor.docker.image\" : \"mesosphere/spark:1.0.0-1.6.1-2\"\n}\n}\n</code></pre>\n\n<p>with Authorization header Authorization token=${token}</p>\n\n<p>When i submit it to chronos\nrest endpoint - /service/chronos/scheduler/iso8601 </p>\n\n<pre><code>{\n  \"schedule\": \"R10/2016-06-16T08:28:00Z/PT2H\",\n  \"name\": \"sparkjavachronos\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"image\": \"mesosphere/spark:1.0.0-1.6.1-2\"\n  },\n  \"cpus\": \"0.5\",\n  \"mem\": \"1024\",\n  \"command\": \"/opt/spark/dist/bin/spark-submit --class org.apache.spark.examples.SparkPi --master mesos://&lt;dcos mesos-master&gt;/service/spark/ --deploy-mode cluster --supervise --executor-memory 2g --total-executor-cores 1 https://&lt;s3 location&gt;/spark-examples-1.5.1-hadoop2.4.0.jar 100\"\n}\n</code></pre>\n\n<p>chronos job submission is ok with Authorization header Authorization token=${token}, </p>\n\n<p><strong>but when chronos executes the command it ends up with response indicating the request is unauthorized . is there a way for token forwarding to the command</strong> .</p>\n\n<p>or how chronos command which talks to the cluster manager provides token ,in dcos which has the authorization token setup.</p>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere", "dcos"], "title": "dcos chronos spark-submit command to mesos master fails as unauthorized", "last_activity_date": 1466134247, "answer_count": 0, "creation_date": 1466134247, "score": 3, "link": "https://stackoverflow.com/questions/37872669/dcos-chronos-spark-submit-command-to-mesos-master-fails-as-unauthorized", "owner": {"user_id": 6314636, "profile_image": "https://www.gravatar.com/avatar/7f0fb2aeaf6db6d14de97e39708e34c3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/6314636/venkatesh", "display_name": "Venkatesh"}, "view_count": 276, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37872669}{"body": "<p>I'm running container services using Marathon on a DC/OS cluster running on AWS. After ~3 weeks some of the slave nodes ran out of free space. I've checked inside the nodes and saw that the folder /var/lib/docker/tmp was filled up with ~24gb of data that was not automatically elimintaed by the Docker agent.</p>\n\n<p>According to <a href=\"https://stackoverflow.com/questions/31489802/can-i-clean-var-lib-docker-tmp\">Can I clean /var/lib/docker/tmp?</a> the issue was fixed in Docker 1.8, but my nodes all have Docker 1.7 installed on them.</p>\n\n<p>My question is - is there any way to automatically upgrade Docker on all nodes at once, or should I ssh into each and every one of them to do the upgrade?</p>\n", "is_answered": false, "tags": ["amazon-web-services", "mesosphere", "marathon", "dcos"], "last_edit_date": 1495541408, "title": "Upgrading Docker on DC/OS cluster", "last_activity_date": 1463568118, "answer_count": 0, "creation_date": 1463568118, "score": 1, "link": "https://stackoverflow.com/questions/37297191/upgrading-docker-on-dc-os-cluster", "owner": {"user_id": 3833773, "profile_image": "https://graph.facebook.com/554650175/picture?type=large", "user_type": "registered", "reputation": 2116, "link": "https://stackoverflow.com/users/3833773/yaron-idan", "accept_rate": 95, "display_name": "Yaron Idan"}, "view_count": 41, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37297191}{"body": "<p>I have been able to procure 4 physical machines to set up a spark test cluster. The data will be stored in cassandra, computation will be done with spark (sql and data frames). I am planning on using mesos, because, as a developer, I want to do as little infrastructure work as possible.</p>\n\n<p>However, almost all tutorials I have found are from mesophere, using their <em>commercial</em> dcos infrastructure. I was able to configure the dcos cli to use marathon, but one of the mesophere support people told me that it may not work very well. </p>\n\n<p>I was able to get cassandra installed, but marathon tells me that it's status is 'unhealthy.' Spark doesn't even get that far, Marathon tells me that the deployment task is failing, but there are no longs, no error messages, nothing.</p>\n\n<p>Is it just a bad idea to use mesos? Is there an alternative? Any other resources on how to get cassandra and spark running? I don't mind purchasing books.</p>\n\n<p>update: I am running CentOS 7 on all four machines. These machines have over 20 gigs of ram, 12 cpus and about a terrabyte of disk. One of them is setup as the master node (running zookeeper and mesos masters), the remaining machines are slaves/clients.</p>\n", "is_answered": false, "tags": ["cassandra", "apache-spark", "mesos", "mesosphere", "spark-cassandra-connector"], "last_edit_date": 1445612626, "title": "Any resources on how to setup a physical (test) cluster of mesos, cassandra and spark", "last_activity_date": 1445612626, "answer_count": 1, "creation_date": 1445542495, "score": 0, "link": "https://stackoverflow.com/questions/33289257/any-resources-on-how-to-setup-a-physical-test-cluster-of-mesos-cassandra-and", "answers": [{"body": "<p>Well, there are a few good articles on how to install a cluster, like</p>\n\n<ul>\n<li><a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04\" rel=\"nofollow\">https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04</a></li>\n<li><a href=\"https://open.mesosphere.com/advanced-course/\" rel=\"nofollow\">https://open.mesosphere.com/advanced-course/</a></li>\n</ul>\n\n<p>Unfortunately, you don't give much details on your environment, such as the OS you're using.</p>\n\n<p>Personally, I run Mesos on a CoreOS cluster in a completely dockerized manner, meaning that the Mesos Master and Slaves also run in an container. If you're intrested, have a look at </p>\n\n<ul>\n<li><a href=\"https://github.com/tobilg/coreos-setup\" rel=\"nofollow\">https://github.com/tobilg/coreos-setup</a> </li>\n</ul>\n\n<p>to see my <code>systemd</code> setup to run Mesos on CoreOS.</p>\n\n<p>Concerning Spark, there are several way to get it running on Mesos. Have a look at the Spark docs at </p>\n\n<ul>\n<li><a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html\" rel=\"nofollow\">http://spark.apache.org/docs/latest/running-on-mesos.html</a> </li>\n</ul>\n\n<p>to get an idea. Furthermore, you can run <a href=\"https://github.com/spark-jobserver/spark-jobserver\" rel=\"nofollow\">Spark-Jobserver</a> in a Docker container, which will then act as client application for your Spark jobs (with REST API etc.). The Dockerfile/the image are available under</p>\n\n<ul>\n<li><a href=\"https://github.com/tobilg/docker-spark-jobserver\" rel=\"nofollow\">https://github.com/tobilg/docker-spark-jobserver</a></li>\n<li><a href=\"https://hub.docker.com/r/tobilg/spark-jobserver/\" rel=\"nofollow\">https://hub.docker.com/r/tobilg/spark-jobserver/</a></li>\n</ul>\n\n<p>To run Cassandra as a framework on Mesos, have a look at</p>\n\n<ul>\n<li><a href=\"https://github.com/mesosphere/cassandra-mesos\" rel=\"nofollow\">https://github.com/mesosphere/cassandra-mesos</a></li>\n</ul>\n", "answer_id": 33297401, "last_activity_date": 1445587410, "creation_date": 1445586921, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "last_edit_date": 1445587410, "question_id": 33289257}], "owner": {"user_id": 46799, "profile_image": "https://www.gravatar.com/avatar/347a316c4264c392d83d0195a0b5b01c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3891, "link": "https://stackoverflow.com/users/46799/shahbaz", "accept_rate": 71, "display_name": "Shahbaz"}, "view_count": 309, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33289257}{"body": "<p>Is mesos provide support for docker 1.9.0 custom network creation facility?\nUsing docker 1.9.0 I can create my own network which binds with a custom linux bridge instead of legacy docker0 bridge, once container is launched in customed network.</p>\n\n<pre><code>sudo docker network create --subnet=172.23.0.0/16 bridge1\n</code></pre>\n\n<p>Create a bridged network bridge1. but previous docker version has only three networks (bridge,host,none).</p>\n\n<p>So, does latest versions of marathon and mesos support this changes?</p>\n\n<p>Thanking in advance.</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "docker 1.9.0 network support in mesos", "last_activity_date": 1453333008, "answer_count": 1, "creation_date": 1453179407, "score": 0, "link": "https://stackoverflow.com/questions/34868743/docker-1-9-0-network-support-in-mesos", "answers": [{"body": "<p>As of this writing, Mesos does not support networks created via the <code>docker network create</code> command. For single-host networks, there is a ticket tracking the addition of this functionality <a href=\"https://issues.apache.org/jira/browse/MESOS-4354\" rel=\"nofollow\">here</a>.</p>\n\n<p>The community has not reached consensus on whether or not Mesos will attempt to integrate Docker's multi-host networking feature; you can find a discussion on this subject in <a href=\"https://issues.apache.org/jira/browse/MESOS-3828\" rel=\"nofollow\">this ticket</a>.</p>\n", "answer_id": 34912754, "last_activity_date": 1453333008, "creation_date": 1453333008, "score": 0, "owner": {"user_id": 3461847, "profile_image": "https://www.gravatar.com/avatar/82b8cb6f44d1503bb2613525023ff73b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/3461847/greggomann", "display_name": "greggomann"}, "is_accepted": false, "question_id": 34868743}], "owner": {"user_id": 5462392, "profile_image": "https://www.gravatar.com/avatar/44559cb6e57899e133669bdf6eb62384?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 4, "link": "https://stackoverflow.com/users/5462392/kuldeepsinh", "display_name": "Kuldeepsinh"}, "view_count": 305, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34868743}{"body": "<p>I am setting up Mesos Cluster(ZooKeeper+Mesos) using docker, with 3 nodes(A,B,C) running zookeeper&amp;master&amp;slave containers for each.</p>\n\n<p><strong>node B &amp; C redirects each other (quorum=2)</strong></p>\n\n<p>As I run Mesos-Master container and open Mesos Web UI,</p>\n\n<ul>\n<li>node A seems like a master node</li>\n<li>node B redirects to node C</li>\n<li>node C redirects to node B</li>\n</ul>\n\n<p>It seems strange that node A is isolated and node B and C redirects each other forever.</p>\n\n<p><strong>What is happening here?</strong></p>\n\n<p><code>docker run</code> command for Mesos-Master is as following.\n(Same for 3 nodes except <code>MESOS_IP</code>)</p>\n\n<pre><code>docker run \n--net=host \n-e MESOS_LOG_DIR=/var/log/mesos \n-e MESOS_ZK=zk://&lt;hostname-nodeA&gt;:2181,&lt;hostname-nodeB&gt;:2181,&lt;hostname-nodeC&gt;:2181/mesos \n-e MESOS_CLUSTER=cheeter \n-e MESOS_HOSTNAME=&lt;hostname-nodeA&gt; \n-e MESOS_WORK_DIR=/var/lib/mesos \n-e MESOS_QUORUM=2 \n-e MESOS_ISOLATOR=cgroups/cpu,cgroups/mem,cgroups/devices \n-e MESOS_CONTAINERIZERS=docker,mesos \n-e MESOS_IP=&lt;ip-nodeA&gt; \n-p 5050:5050 \n-v /run/docker.sock:/var/run/docker.sock \n-v /var/log:/var/log \n-v /cgroup:/cgroup \n-v /sys:/sys \n-v /proc:/proc \n-t mesosphere/mesos-master:0.20.1\n</code></pre>\n\n<p><code>docker run</code> command for ZooKeeper is as following.\n(Same for 3 nodes except <code>ZOOKEEPER_ID</code>)</p>\n\n<pre><code>docker run \n-e ZOOKEEPER_ID=1 \n-e ZOOKEEPER_SERVER_1=&lt;hostname-nodeA&gt;:2888:3888 \n-e ZOOKEEPER_SERVER_2=&lt;hostname-nodeB&gt;:2888:3888 \n-e ZOOKEEPER_SERVER_3=&lt;hostname-nodeC&gt;:2888:3888 \n-e ZOOKEEPER_DATADIR=/var/zookeeper \n-p 2181:2181 \n-p 2888:2888 \n-p 3888:3888 \n-v /var:/var \n-v /sys:/sys \n-v /proc:/proc \n-v /cgroup:/cgroup \n-t jplock/zookeeper:3.4.6\n</code></pre>\n\n<p>I have tried to change quorum number 1-3, and the results were;</p>\n\n<p><strong>3 nodes redirects in roop (quorum=1)</strong></p>\n\n<p>As I run Mesos-Master with <code>quorum=1</code>, nodes redirects in roop like A->B->C->A->....</p>\n\n<p><strong>Each node shows \"No master is currently leading...\" (quorum=3)</strong></p>\n\n<p>As I run Mesos-Master with <code>quorum=1</code>, no redirection happened and each node shows \"No master is currently leading...\"</p>\n", "is_answered": false, "tags": ["docker", "apache-zookeeper", "mesos", "mesosphere"], "title": "Leader election in Mesos cluster seems not working", "last_activity_date": 1432646826, "answer_count": 1, "creation_date": 1432543589, "score": 0, "link": "https://stackoverflow.com/questions/30434348/leader-election-in-mesos-cluster-seems-not-working", "answers": [{"body": "<p>For 3 master nodes quorum should be at least 2 (see <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/configuration/</a>). Could you please share master logs? They may help to understand what went wrong.</p>\n", "answer_id": 30459948, "last_activity_date": 1432646826, "creation_date": 1432646826, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 30434348}], "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 1681, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30434348}{"is_answered": false, "tags": ["docker", "mesos", "mesosphere", "dcos"], "last_edit_date": 1495013706, "title": "Private registry authentication while creating pod in Mesosphere", "last_activity_date": 1495013706, "answer_count": 0, "creation_date": 1494691720, "score": 0, "link": "https://stackoverflow.com/questions/43955249/private-registry-authentication-while-creating-pod-in-mesosphere", "owner": {"user_id": 2342287, "profile_image": "https://www.gravatar.com/avatar/d27331309193685631c8eafe2348d961?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3, "link": "https://stackoverflow.com/users/2342287/vivek-kumar", "display_name": "Vivek Kumar"}, "view_count": 56, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43955249}{"body": "<p>The instructions for <a href=\"https://dcos.io/docs/1.7/administration/installing/cloud/aws/\" rel=\"nofollow noreferrer\">installing Mesosphere DC/OS on AWS</a> use a CloudFormation template where the minimum configuration indicates:</p>\n\n<blockquote>\n  <p>You have the option of 1 or 3 Mesos master nodes. \n  5 private Mesos agent nodes is the default. \n  1 public Mesos agent node is the default.</p>\n</blockquote>\n\n<p>For our POC, as not to incur too much up-front cost, is it possible to do this all with two nodes?  One for DC/OS and the other containterized with ElasticSearch and Kafka?</p>\n\n<p>If not, what would be a good configuration for this type of architecture?</p>\n", "is_answered": true, "tags": ["elasticsearch", "apache-kafka", "kubernetes", "docker-swarm", "dcos"], "last_edit_date": 1485433812, "title": "How to set up a POC environment with DC/OS, Kafka and ElasticSearch on two nodes with Docker Swarm or Kubernetes containers?", "last_activity_date": 1485482755, "answer_count": 1, "creation_date": 1485430021, "score": 0, "link": "https://stackoverflow.com/questions/41872439/how-to-set-up-a-poc-environment-with-dc-os-kafka-and-elasticsearch-on-two-nodes", "answers": [{"body": "<p>DC/OS does not run on Docker Swarm or Kubernetes. But you can run a development docker-in-docker local deployment on linux (or in a VM on mac/windows): <a href=\"https://github.com/dcos/dcos-docker\" rel=\"nofollow noreferrer\">dcos-docker</a></p>\n\n<p>You could then install ElasticSearch and Kafka on top of DC/OS.</p>\n\n<p>You could also use <a href=\"https://github.com/dcos/dcos-vagrant\" rel=\"nofollow noreferrer\">dcos-vagrant</a> to run a multiple VM DC/OS local dev cluster.</p>\n\n<p>Warning: the current vagrant v1.9.1 has a <a href=\"https://github.com/mitchellh/vagrant/issues/8096\" rel=\"nofollow noreferrer\">crippling centos network bug</a>, if you need a VM. dcos-vagrant has a monkey patch workaround included, dcos-docker does not.</p>\n", "answer_id": 41886072, "last_activity_date": 1485482755, "creation_date": 1485482755, "score": 2, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 41872439}], "owner": {"user_id": 172359, "profile_image": "https://www.gravatar.com/avatar/5e175feb0a9092abd02950f4973d376a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6610, "link": "https://stackoverflow.com/users/172359/elhaix", "accept_rate": 93, "display_name": "ElHaix"}, "view_count": 141, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41872439}{"body": "<p>I've setup a Mesos cluster using the CloudFormation templates from Mesosphere. Things worked fine after cluster launch.</p>\n\n<p>I recently noticed that none of the slave nodes are listed in the Mesos dashboard. EC2 console shows the slaves are running &amp; pass health checks. I restarted nodes on cluster but that didn't help.\nI ssh'ed into one of the slaves and noticed mesos-slave services are not running. Executed <code>sudo systemctl status dcos-mesos-slave.service</code> but that couldn't start the service.</p>\n\n<p>Looked in <code>/var/log/mesos/</code> and <code>tail -f mesos-slave.xxx.invalid-user.log.ERROR.20151127-051324.31267</code> and saw the following...</p>\n\n<p><code>F1127 05:13:24.242182 31270 slave.cpp:4079] CHECK_SOME(state::checkpoint(path, bootId.get())): Failed to create temporary file: No space left on device\n</code></p>\n\n<p>But the output of <code>df -h</code> and <code>free</code> show there is plenty of disk space left.</p>\n\n<p>Which leads me to wonder, why is it complaining about no disk space?</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Mesos slave node unable to restart", "last_activity_date": 1448606142, "answer_count": 1, "creation_date": 1448602141, "score": 0, "link": "https://stackoverflow.com/questions/33950777/mesos-slave-node-unable-to-restart", "answers": [{"body": "<p>Ok I figured it out. </p>\n\n<p>When running Mesos for a long time or under frequent load, the <code>/tmp</code> folder won't have any disk space left since Mesos uses the <code>/tmp/mesos/</code> as the work_dir. You see, the filesystem can only hold a certain number of file references(inodes). In my case, slaves were collecting large number of file chuncks from image pulls in <code>/var/lib/docker/tmp</code>.</p>\n\n<p>To resolve this issue:</p>\n\n<p>1) Remove files under <code>/tmp</code></p>\n\n<p>2) Set a different work_dir location</p>\n", "answer_id": 33951524, "last_activity_date": 1448606142, "creation_date": 1448606142, "score": 1, "owner": {"user_id": 410112, "profile_image": "https://www.gravatar.com/avatar/8ef38669379fb8a1e221386b9c1d217b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 339, "link": "https://stackoverflow.com/users/410112/babalu", "accept_rate": 0, "display_name": "babalu"}, "is_accepted": false, "question_id": 33950777}], "owner": {"user_id": 410112, "profile_image": "https://www.gravatar.com/avatar/8ef38669379fb8a1e221386b9c1d217b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 339, "link": "https://stackoverflow.com/users/410112/babalu", "accept_rate": 0, "display_name": "babalu"}, "view_count": 766, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33950777}{"body": "<p>I'm trying to implement a lizardfs cluster using mesos/marathon. I created some docker images for that purpose.</p>\n\n<p>I need to get a docker container of a certain type (lizardfs-master) NOT run on the same node that is already running another type of container (lizardfs-shadow or lizardfs-metalogger). That is, I need to run an instance of each of these three types of containers but they must not run on the same node simultaneously. They are mutually exclusive. </p>\n\n<p>I don't want to restrict the nodes that can run each container. I just want to make them exclusive. </p>\n\n<p>Is there any way to accomplish this in marathon, ie, using constraints? How would it be?</p>\n\n<p>Thanks.</p>\n", "is_answered": false, "tags": ["docker", "mesosphere", "marathon"], "last_edit_date": 1444916588, "title": "Marathon constraints for mutually exclusive docker containers", "last_activity_date": 1444918601, "answer_count": 1, "creation_date": 1444915485, "score": 0, "link": "https://stackoverflow.com/questions/33149791/marathon-constraints-for-mutually-exclusive-docker-containers", "answers": [{"body": "<p>I could imagine that there are several approaches to this. :)</p>\n\n<p>I would do the following..</p>\n\n<p>Set up 3 applications, each for your specific docker image (master, shadow, metalogger).\nThen you could create a constraint on the app that ties the application to specific nodes:</p>\n\n<pre><code>\"constraints\": [[\"hostname\", \"CLUSTER\", \"a.specific.node.com\"]]\n</code></pre>\n\n<p><a href=\"https://github.com/mesosphere/marathon/blob/master/docs/docs/constraints.md#cluster-operator\" rel=\"nofollow\">https://github.com/mesosphere/marathon/blob/master/docs/docs/constraints.md#cluster-operator</a></p>\n\n<p>I think you can also define multiple nodes.</p>\n\n<p>I didn't test this, but it looks reasonable to me. ;)</p>\n", "answer_id": 33150916, "last_activity_date": 1444918601, "creation_date": 1444918601, "score": 0, "owner": {"user_id": 1581246, "profile_image": "https://www.gravatar.com/avatar/0302c3e82f92d5379f477bd1a96106e2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 147, "link": "https://stackoverflow.com/users/1581246/felix-gertz", "display_name": "Felix Gertz"}, "is_accepted": false, "question_id": 33149791}], "owner": {"user_id": 5449590, "profile_image": "https://www.gravatar.com/avatar/d9e11b8444d29d884c65d746360100ec?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5449590/marcelo-aguero", "display_name": "Marcelo Aguero"}, "view_count": 764, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 33149791}{"body": "<p>For example:</p>\n\n<p>If Marathon is running a task named <code>/cassandra</code>, Mesos-DNS assigns it a DNS name - <code>cassandra.marathon.mesos</code>. </p>\n\n<p>Now I have a task named <code>/monit/promdash</code>. <strong>How can I find its DNS name?</strong></p>\n\n<p>Already tried: </p>\n\n<ul>\n<li><p><code>monit_promdash.marathon.mesos</code>, <code>promdash_monit.marathon.mesos</code> <del>(and with <code>-</code> instead of <code>_</code>)</del>, <code>monit.marathon.mesos</code>, <code>promdash.marathon.mesos</code>, ...)</p></li>\n<li><p>There's a <a href=\"https://mesosphere.github.io/mesos-dns/docs/http.html\" rel=\"nofollow\">HTTP interface</a>. Couldn't find how to list all DNS names either...</p></li>\n</ul>\n\n<p>Thanks,</p>\n", "is_answered": true, "title": "How does Mesos-DNS name tasks with slash (\"nested\")?", "last_edit_date": 1445180772, "tags": ["dns", "mesos", "mesosphere"], "view_count": 95, "accepted_answer_id": 33199233, "last_activity_date": 1445180772, "answers": [{"body": "<p>Marathon reverses the hierarchical names, concatenates them with <code>-</code> and this is the app name then, so in your case it would be <code>promdash-monit.marathon.mesos</code>. Try it out.</p>\n\n<p>At the bottom of the <a href=\"http://mesosphere.github.io/mesos-dns/docs/naming.html\" rel=\"nofollow\">Mesos-DNS naming</a> documentation we provide some more details about how these FQHN are constructed and you can also check out a <a href=\"https://mesosphere.com/blog/2015/06/21/web-application-analytics-using-docker-and-marathon/\" rel=\"nofollow\">complete end-to-end example</a> I've put together, using two levels of hierarchies.</p>\n", "answer_id": 33199233, "last_activity_date": 1445179168, "creation_date": 1445179168, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 33199166}], "score": 1, "link": "https://stackoverflow.com/questions/33199166/how-does-mesos-dns-name-tasks-with-slash-nested", "answer_count": 1, "owner": {"user_id": 1563935, "profile_image": "https://www.gravatar.com/avatar/74933a08f0ca658cc1352fe98b740b03?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1855, "link": "https://stackoverflow.com/users/1563935/alonl", "accept_rate": 73, "display_name": "AlonL"}, "creation_date": 1445178796, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 33199166}{"body": "<p>Running DCOS 1.8 on Centos.\nI installed the CLI as below:\n<a href=\"https://docs.mesosphere.com/1.8/usage/cli/install/\" rel=\"nofollow\">https://docs.mesosphere.com/1.8/usage/cli/install/</a></p>\n\n<p>When I try to do a spark install I get the below error. Any ideas?</p>\n\n<pre><code>./dcos package install spark\nip-172-16-6-6.localdomain's username: admin\nadmin@ip-172-16-6-6.localdomain's password:\nTraceback (most recent call last):\n File \"cli/dcoscli/subcommand.py\", line 99, in run_and_capture\n File \"cli/dcoscli/package/main.py\", line 21, in main\n File \"cli/dcoscli/util.py\", line 21, in wrapper\n File \"cli/dcoscli/package/main.py\", line 35, in _main\n File \"dcos/cmds.py\", line 43, in execute\n File \"cli/dcoscli/package/main.py\", line 356, in _install\n File \"dcos/cosmospackage.py\", line 191, in get_package_version\n File \"dcos/cosmospackage.py\", line 366, in __init__\n File \"cli/env/lib/python3.4/site-packages/requests/models.py\", line 826, in       json\n File \"json/__init__.py\", line 318, in loads\n File \"json/decoder.py\", line 343, in decode\n File \"json/decoder.py\", line 361, in raw_decode\n ValueError: Expecting value: line 1 column 1 (char 0)\n</code></pre>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "title": "DCOS CLI install not working", "last_activity_date": 1485988472, "answer_count": 1, "creation_date": 1476092726, "score": 2, "link": "https://stackoverflow.com/questions/39955522/dcos-cli-install-not-working", "answers": [{"body": "<p>I just had this issue to.  For me it was because I forgot to install virtualenv.  <code>pip install virtualenv</code>.</p>\n", "answer_id": 41991094, "last_activity_date": 1485988472, "creation_date": 1485988472, "score": 0, "owner": {"user_id": 462070, "profile_image": "https://www.gravatar.com/avatar/50dce9eba9fe9d0908104734f653bc9c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 477, "link": "https://stackoverflow.com/users/462070/greg-schnie-neiheisel", "accept_rate": 60, "display_name": "Greg Schnie Neiheisel"}, "is_accepted": false, "question_id": 39955522}], "owner": {"user_id": 3773719, "profile_image": "https://graph.facebook.com/725764480/picture?type=large", "user_type": "registered", "reputation": 186, "link": "https://stackoverflow.com/users/3773719/colman", "accept_rate": 0, "display_name": "Colman"}, "view_count": 236, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39955522}{"body": "<p>both have very complementary features and it would be great to be able to have the schedule flexibility of Quartz, with the distributed computing of Apache Mesos.\nI couldn't find anything on google.<br>\nHas anybody tried this?</p>\n", "is_answered": false, "tags": ["quartz-scheduler", "mesos", "mesosphere"], "title": "is it possible to run Quartz Scheduler on Apache Mesos", "last_activity_date": 1464916069, "answer_count": 0, "creation_date": 1464916069, "score": 1, "link": "https://stackoverflow.com/questions/37604422/is-it-possible-to-run-quartz-scheduler-on-apache-mesos", "owner": {"user_id": 482711, "profile_image": "https://www.gravatar.com/avatar/654c42ba9749282615644c55ad3ccdbe?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 5083, "link": "https://stackoverflow.com/users/482711/rockscience", "accept_rate": 78, "display_name": "RockScience"}, "view_count": 71, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37604422}{"body": "<pre><code>\"container\": {\n    \"type\": \"MESOS\",\n    \"docker\": {\n      \"image\": \"redis\",\n      \"forcePullImage\": false\n    }\n  }\n</code></pre>\n\n<ol>\n<li>The above example has the container type as Mesos..but again specifying \"docker\" image... for using universal container or mesos container, do we need to install docker?</li>\n<li>because, when i try to run a sample in mesos with type \"mesos\" container, i am getting error like this:</li>\n</ol>\n\n<blockquote>\n  <p>unsupported container image:DOCKER.</p>\n</blockquote>\n\n<p>I have not installed docker.</p>\n\n<ol start=\"3\">\n<li>I am using Mesos1.1 version</li>\n</ol>\n", "is_answered": false, "tags": ["docker", "containers", "mesos", "marathon", "mesosphere"], "last_edit_date": 1484147675, "title": "Getting error while running the Mesos container in mesos cluster using marathon", "last_activity_date": 1484147675, "answer_count": 1, "creation_date": 1484134471, "score": -1, "link": "https://stackoverflow.com/questions/41589835/getting-error-while-running-the-mesos-container-in-mesos-cluster-using-marathon", "answers": [{"body": "<p>See <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html#mesos-containerizer-and-universal-container-runtime\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/native-docker.html#mesos-containerizer-and-universal-container-runtime</a> for a valid example on how to run a Docker image with the Mesos UCR.</p>\n\n<pre><code>{\n    \"id\": \"mesos-docker\",\n    \"container\": {\n        \"docker\": {\n            \"image\": \"mesosphere/inky\"\n        },\n        \"type\": \"MESOS\"\n    },\n    \"args\": [\"hello\"],\n    \"cpus\": 0.2,\n    \"mem\": 16.0,\n    \"instances\": 1\n}\n</code></pre>\n\n<p>You'll need Marathon >= 1.3.0 and Mesos >= 1.0 for that.</p>\n", "answer_id": 41590848, "last_activity_date": 1484137283, "creation_date": 1484137283, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 41589835}], "owner": {"user_id": 2478392, "profile_image": "https://www.gravatar.com/avatar/7bc222cf329c571d38e6facb898ff892?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 129, "link": "https://stackoverflow.com/users/2478392/user12345", "accept_rate": 59, "display_name": "User12345"}, "view_count": 98, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41589835}{"is_answered": true, "tags": ["vagrant", "dcos"], "title": "WARNING: bridge-nf-call-iptables is disabled while starting dcos-vagrant", "last_activity_date": 1475267582, "answer_count": 1, "creation_date": 1475259160, "score": 0, "link": "https://stackoverflow.com/questions/39797602/warning-bridge-nf-call-iptables-is-disabled-while-starting-dcos-vagrant", "owner": {"user_id": 6494157, "profile_image": "https://www.gravatar.com/avatar/a37e884c6ea7935aab85eac13afb0825?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 17, "link": "https://stackoverflow.com/users/6494157/plahm21", "accept_rate": 50, "display_name": "PLahm21"}, "view_count": 773, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 39797602}{"body": "<p>I've installed DC/OS to a new cluster and am learning it. Bootstrapping and installing was a relatively okay process; I chose the advanced method and found it to be the easiest to get working with our system.</p>\n\n<p>Once deployed, I'm confused about how I am to go about updating the cluster configuration (the values I'd provided with bootstrap). Does DC/OS do anything to help here, or is configuration relatively static?</p>\n\n<p>Specifically, I'd like to modify the configuration of Spartan to:</p>\n\n<ul>\n<li>Only listen on the dummy device (it's listening on all of them at the moment)</li>\n<li>Configure a zone specific resolver (I was told it's possible <a href=\"https://github.com/mesosphere/mesos-dns/pull/441\" rel=\"nofollow\">https://github.com/mesosphere/mesos-dns/pull/441</a>)</li>\n</ul>\n", "is_answered": false, "tags": ["mesosphere", "dcos"], "title": "Best way to update Spartan Config", "last_activity_date": 1490370479, "answer_count": 1, "creation_date": 1466753277, "score": 1, "link": "https://stackoverflow.com/questions/38007886/best-way-to-update-spartan-config", "answers": [{"body": "<p>According to <a href=\"https://docs.mesosphere.com/1.9/administration/installing/custom/configuration-parameters/\" rel=\"nofollow noreferrer\">DCOS docs</a> for 1.9 (see \"resolvers\" option), upstream DNS servers cannot be changed once provided during bootstrap. </p>\n\n<blockquote>\n  <p>\"Upstream DNS Servers [...] Caution: If you set this parameter\n  incorrectly you will have to reinstall DC/OS.\"</p>\n</blockquote>\n", "answer_id": 43003853, "last_activity_date": 1490370479, "creation_date": 1490370479, "score": 0, "owner": {"user_id": 1661204, "profile_image": "https://www.gravatar.com/avatar/b6d8debae0c2654a22d93ac1df3a7609?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/1661204/pawe%c5%82-rein", "display_name": "Pawe\u0142 Rein"}, "is_accepted": false, "question_id": 38007886}], "owner": {"user_id": 183863, "profile_image": "https://www.gravatar.com/avatar/63f259ca39670e260cd50dd71013663c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2091, "link": "https://stackoverflow.com/users/183863/tim-harper", "accept_rate": 67, "display_name": "Tim Harper"}, "view_count": 269, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 38007886}{"body": "<p>Apache Mesos and Rocks Cluster Distribution can both be used to run tasks and manage cluster resources.</p>\n\n<p>What is the difference between them and in what scenarios is it better to choose one instead of the other. </p>\n\n<p>From what I understand the similarities are:</p>\n\n<ul>\n<li>Both are used to manage resources in a cluster</li>\n<li>Both can be installed on RHEL/CentOS</li>\n<li>List item</li>\n</ul>\n\n<p>And likewise the differences are:</p>\n\n<ul>\n<li>Apache Mesos also supports Ubuntu installations</li>\n<li>Apache Mesos requires for managed tasks to be run in containers</li>\n<li>Apache Mesos allows (although not encourages) to run tasks outside of the framework whilst the framework is installed</li>\n<li>Rocks Cluster Distribution treats the cluster as one machine (it is not obvious to the user that tasks are being run on the cluster).</li>\n</ul>\n\n<p>Why would someone use Apache Mesos over Rocks Cluster Distribution?</p>\n", "is_answered": true, "title": "What are the advantages of using Apache Mesos (or DC/OS) over Rocks Cluster Distribution?", "tags": ["cluster-computing", "mesos", "hpc", "mesosphere", "rocks"], "last_activity_date": 1479420212, "accepted_answer_id": 40665861, "creation_date": 1474135080, "answers": [{"body": "<p>I'm not a Rocks user or expert and work at <a href=\"https://mesosphere.com/\" rel=\"nofollow noreferrer\">Mesosphere</a>. These comments are based on research, but not deep experience with Rocks. So take this with at a heaping pile of salt... If someone knows better, I'm happy to take updates.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Rocks_Cluster_Distribution\" rel=\"nofollow noreferrer\">Rocks Cluster Distribution</a> seems like a traditional <a href=\"https://en.wikipedia.org/wiki/Distributed_operating_system\" rel=\"nofollow noreferrer\">distributed operating system</a> designed for use on supercomputers, with the exception that it runs on an existing operating system rather than using its own microkernel. This has several evolutional advantages over older distributed operating system, like Plan 9, but isn't designed to take advantage of more modern advancements in scheduling and hyperscale computing.</p>\n\n<h2>Maturity</h2>\n\n<p>Rocks is definitely more mature than Mesos. This is both a pro and a con.</p>\n\n<p>I think the best way to look at it is that Rocks solves problems academics and governments had around ~2000, before VMware brought virtualization to the masses, before Chef, Puppet, and Ansible made cluster provisioning common place, before Google and AWS had planet-sized hyperscale computers spanning datacenters on every continent, before Hadoop popularized map/reduce and distributed computing, before agile invaded enterprise companies, before the iPhone put a supercomputer in everyone's pocket, before microservices made monoliths pass\u00e9, before Docker popularized containerization, and before IoT put microchips in your shoes and thermostats. All these advancements in the last 15 years mean that people's problems have shifted significantly.</p>\n\n<p>Mesos is only 5 years old. So it's more mature than Docker and Kubernetes, still supports non-containerized native processes (they get wrapped in a configurably isolated container transparently), yet has been used in production for years at massive scale by dozens of companies like Twitter and Apple.</p>\n\n<p>Being new isn't always better, but the landscape moves really fast and it gets harder and harder to incorporate new ideas into old designs. </p>\n\n<h2>Scheduling</h2>\n\n<p>Modern cluster task schedulers (Hadoop YARN, Mesos, Kubernetes, etc). Allow for scheduling, monitoring, restarting, and re-scheduling tasks at runtime. Rocks however requires re-installing from RPM on every node. Often a <a href=\"https://en.wikipedia.org/wiki/Grid_computing\" rel=\"nofollow noreferrer\">GRID computing system</a> must be layered on top, in order to actually use the resources efficiently.</p>\n\n<p>Mesos, on the other hand, makes it easier to write customer schedulers for handling runtime task and application lifecycle management. Several very generic Mesos schedulers also already exist to handle common application lifecycles (Marathon, Aurora, etc). Other distributed applications like Cassandra, Kafka, and Spark have their own custom schedulers to handle business-logic-specific lifecycle management, especially related to persistent data, drain cleanup, and auto-scaling.</p>\n\n<h2>Hyperscale</h2>\n\n<p>Rocks was designed to support the premise of a <a href=\"https://en.wikipedia.org/wiki/Single_system_image\" rel=\"nofollow noreferrer\">single system image</a> and has done so by making the cluster invisible to applications running on the cluster. This sounds like an amazing feat, but in practice it's hugely inefficient, causes unpredictable performance, and doesn't provide enough API to handle all the complexities of cluster operations. </p>\n\n<p>In the mean time, Google, Amazon, and others are investing in <a href=\"https://en.wikipedia.org/wiki/Hyperscale\" rel=\"nofollow noreferrer\">hyperscale computing</a> which allows for tolerating massive growth at moderate costs, without having to re-architect their infrastructure, platforms, or software.</p>\n\n<p>Mesos provides a new layer of abstraction, rather than trying to emulate the lower levels of abstraction (like POSIX and single-machine OSs). So it is better equipped to handle cluster and node lifecycle events. </p>\n\n<h2>Sockets vs TCP/IP</h2>\n\n<p>Rocks applications use POSIX sockets to communicate. While this enables a lot of low level flexibility, sockets were not designed to tolerate failure the same way network protocols are. Unlike legacy monoliths, modern microservices use network communication as their primary form of communication. This new architecture paradigm of extreme decoupling makes it so that applications don't need to be run together but instead use service discovery to find each other over the network. So modern clusters don't need to accommodate multi-node socket traffic, which frees them up to be significantly more reliable and fault tolerant.</p>\n\n<h2>State Storage</h2>\n\n<p>Mesos uses Zookeeper. Rocks uses MySQL. </p>\n\n<h2>Containers</h2>\n\n<p>Mesos allows but does not require workloads to use container images. You can easily just tarball up your process and Mesos will download it to the nodes that need it. Mesos optionally supports Docker containers, but the default is the Mesos container runtime, which has configurable and pluggable levels of isolation.</p>\n\n<h2>DC/OS</h2>\n\n<p>Mesos isn't an operating system. It's really more like a distributed kernel with master and agent configurations. If you really want to compare against another distributed operating system, take a look at <a href=\"https://dcos.io/\" rel=\"nofollow noreferrer\">DC/OS</a>, which fills out a lot of the functionality around Mesos to make it into an operating system for your datacenter.</p>\n", "answer_id": 40665861, "last_activity_date": 1479420212, "creation_date": 1479420212, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "question_id": 39550032}], "score": 1, "link": "https://stackoverflow.com/questions/39550032/what-are-the-advantages-of-using-apache-mesos-or-dc-os-over-rocks-cluster-dist", "answer_count": 1, "owner": {"user_id": 4605629, "profile_image": "https://www.gravatar.com/avatar/741edb45b2f1d3e3c3d9555085004ad1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 792, "link": "https://stackoverflow.com/users/4605629/dave", "accept_rate": 92, "display_name": "Dave"}, "view_count": 291, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39550032}{"body": "<p>Since you can enable autoscaling of containers through DC/OS, when running this on an EC2 cluster, is it still necessary to, or redundant to run your cluster in an AutoScaling cluster?</p>\n", "is_answered": true, "title": "If you are running your applications on DC/OS in AWS, is creating an AutoScaling group redundant?", "last_edit_date": 1485755487, "tags": ["amazon-web-services", "autoscaling", "dcos"], "view_count": 32, "accepted_answer_id": 41929695, "last_activity_date": 1485755487, "answers": [{"body": "<p>There are two (orthogonal) concepts here at play and unfortunately the term 'auto-scale' is ambiguous here:</p>\n\n<ul>\n<li>Certain IaaS platforms (incl. AWS) support dynamically adding VMs to a cluster. </li>\n<li>The other is the capability of a container orchestrator to scale the number of copies of a service\u2014in case of Marathon this is called instances or replicas in the context of Kubernetes\u2014as long as there are sufficient resources (CPU, RAM, etc.) available in the cluster,</li>\n</ul>\n\n<p>In the simplest case you'd auto-scale the services up to the point where the overall cluster utilization is high (>60%? >70%? >80%?) and the use the IaaS-level auto-scaling functionality to add further nodes. Turns out scaling back is the trickier thing.</p>\n\n<p>So, complementary rather than redundant. </p>\n", "answer_id": 41929695, "last_activity_date": 1485755283, "creation_date": 1485755283, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 41927762}], "score": 0, "link": "https://stackoverflow.com/questions/41927762/if-you-are-running-your-applications-on-dc-os-in-aws-is-creating-an-autoscaling", "answer_count": 1, "owner": {"user_id": 172359, "profile_image": "https://www.gravatar.com/avatar/5e175feb0a9092abd02950f4973d376a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6610, "link": "https://stackoverflow.com/users/172359/elhaix", "accept_rate": 93, "display_name": "ElHaix"}, "creation_date": 1485738559, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41927762}{"body": "<p>I was trying to install Cassandra package on my DC/OS cluster but i have problems through its communication.</p>\n\n<p>All requisites are satisfied like min number of nodes, memory and cpus. All nodes also can reach internet.</p>\n\n<pre><code># dcos --log-level=ERROR package install cassandra\n\nDC/OS Cassandra Service default configuration requires 3 nodes each with 1.5 CPU shares, 5376MB of memory and 11264MB of disk for running Cassandra Nodes. And, 1 node with 0.5 CPU shares, 2048MB of memory for running the service scheduler.\nContinue installing? [yes/no] YES\nInstalling Marathon app for package [cassandra] version [1.0.25-3.0.10]\nInstalling CLI subcommand for package [cassandra] version [1.0.25-3.0.10]\n\nMainThread: 2017-03-17 08:57:55,255 dcos/subcommand.py:_install_with_binary:500 - HTTPSConnectionPool(host='downloads.mesosphere.com', port=443): Max retries exceeded with url: /cassandra/assets/1.0.25-3.0.10/dcos-cassandra-linux (Caused by NewConnectionError('&lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7feaec682080&gt;: Failed to establish a new connection: [Errno 110] Connection timed out',))\nTraceback (most recent call last):\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connection.py\", line 138, in _new_conn\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/util/connection.py\", line 98, in create_connection\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\nTimeoutError: [Errno 110] Connection timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\", line 594, in urlopen\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\", line 350, in _make_request\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\", line 835, in _validate_conn\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connection.py\", line 281, in connect\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connection.py\", line 147, in _new_conn\nrequests.packages.urllib3.exceptions.NewConnectionError: &lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7feaec682080&gt;: Failed to establish a new connection: [Errno 110] Connection timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"cli/env/lib/python3.4/site-packages/requests/adapters.py\", line 423, in send\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\", line 643, in urlopen\n  File \"cli/env/lib/python3.4/site-packages/requests/packages/urllib3/util/retry.py\", line 363, in increment\nrequests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='downloads.mesosphere.com', port=443): Max retries exceeded with url: /cassandra/assets/1.0.25-3.0.10/dcos-cassandra-linux (Caused by NewConnectionError('&lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7feaec682080&gt;: Failed to establish a new connection: [Errno 110] Connection timed out',))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"dcos/subcommand.py\", line 460, in _install_with_binary\n  File \"dcos/subcommand.py\", line 432, in _download_and_store\n  File \"cli/env/lib/python3.4/site-packages/requests/api.py\", line 70, in get\n  File \"cli/env/lib/python3.4/site-packages/requests/api.py\", line 56, in request\n  File \"cli/env/lib/python3.4/site-packages/requests/sessions.py\", line 488, in request\n  File \"cli/env/lib/python3.4/site-packages/requests/sessions.py\", line 609, in send\n  File \"cli/env/lib/python3.4/site-packages/requests/adapters.py\", line 487, in send\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='downloads.mesosphere.com', port=443): Max retries exceeded with url: /cassandra/assets/1.0.25-3.0.10/dcos-cassandra-linux (Caused by NewConnectionError('&lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7feaec682080&gt;: Failed to establish a new connection: [Errno 110] Connection timed out',))\nError installing 'cassandra' package.\n</code></pre>\n\n<p>Can anyone help? Thank you</p>\n", "is_answered": false, "tags": ["cassandra", "mesosphere", "dcos"], "title": "Installing Cassandra on DC/OS community - NewConnectionError - TimeoutError", "last_activity_date": 1489753648, "answer_count": 0, "creation_date": 1489753648, "score": 0, "link": "https://stackoverflow.com/questions/42857560/installing-cassandra-on-dc-os-community-newconnectionerror-timeouterror", "owner": {"user_id": 7727062, "profile_image": "https://lh6.googleusercontent.com/--Hm-fEI9spA/AAAAAAAAAAI/AAAAAAAABKQ/zYcShhduUQU/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7727062/humberto-j%c3%banior", "display_name": "Humberto J\u00fanior"}, "view_count": 46, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42857560}{"body": "<p>I am using the chef cookbook for DCOS on-premise setup. Here are the 2 issues I faced, the second one being the one that I am still stuck on....</p>\n\n<p><strong>1. Package dcos-el-repo was not found:</strong></p>\n\n<blockquote>\n  <p>*10.40.1.2     * Package dcos-el-repo not found: <a href=\"http://repos.mesosphere.io/dcos/el/7/noarch/RPMS/dcos-el-repo-7-0.el7.centos.noarch.rpm\" rel=\"nofollow\">http://repos.mesosphere.io/dcos/el/7/noarch/RPMS/dcos-el-repo-7-0.el7.centos.noarch.rpm</a>*</p>\n</blockquote>\n\n<p>Note: I was able to bypass this by manually installing the RPM on each node and just commenting out the _repo.rb recipe from running. Not sure why it wouldn't work via recipe though.</p>\n\n<p><strong>2. execute[wait for leader] action run</strong></p>\n\n<blockquote>\n  <p>10.40.1.9 Error executing action <code>run</code> on resource 'execute[wait for leader]'\n  10.40.1.9 ================================================================================\n  10.40.1.9 \n  10.40.1.9 \n  10.40.1.9 Mixlib::ShellOut::ShellCommandFailed\n  10.40.1.9 ------------------------------------\n  10.40.1.9 Expected process to exit with [0], but received '2'\n  10.40.1.9 ---- Begin output of ping -c 1 leader.mesos ----\n  10.40.1.9 STDOUT: \n  10.40.1.9 STDERR: ping: unknown host leader.mesos\n  10.40.1.9 ---- End output of ping -c 1 leader.mesos ----\n  10.40.1.9 Ran ping -c 1 leader.mesos returned 2</p>\n</blockquote>\n", "is_answered": false, "tags": ["chef", "mesos", "mesosphere"], "last_edit_date": 1435607563, "title": "Error executing action `run` on resource 'execute[wait for leader]'", "last_activity_date": 1435607563, "answer_count": 0, "creation_date": 1435594093, "score": 0, "link": "https://stackoverflow.com/questions/31120484/error-executing-action-run-on-resource-executewait-for-leader", "owner": {"user_id": 2708638, "profile_image": "https://www.gravatar.com/avatar/bf6e6cc88f78d823aba1982ad1dd0f9f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/2708638/user2708638", "display_name": "user2708638"}, "view_count": 134, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31120484}{"is_answered": false, "tags": ["tachyon", "dcos", "spark-notebook"], "title": "Instructions on installing Tachyon in DCOS (Mesosphere)?", "last_activity_date": 1463704361, "answer_count": 0, "creation_date": 1463704361, "score": 1, "link": "https://stackoverflow.com/questions/37336166/instructions-on-installing-tachyon-in-dcos-mesosphere", "owner": {"user_id": 1059610, "profile_image": "https://www.gravatar.com/avatar/6a04ed8e4d6e027f3f6ae67c8e470275?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 167, "link": "https://stackoverflow.com/users/1059610/1001b", "accept_rate": 83, "display_name": "1001b"}, "view_count": 50, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37336166}{"is_answered": true, "tags": ["dcos"], "title": "DCOS: not able to start any service is always shows deploying", "last_activity_date": 1477589124, "answer_count": 2, "creation_date": 1469132850, "score": 0, "link": "https://stackoverflow.com/questions/38513768/dcos-not-able-to-start-any-service-is-always-shows-deploying", "owner": {"user_id": 1830314, "profile_image": "https://www.gravatar.com/avatar/47816f4b0279f143614334a7cfbb849b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 338, "link": "https://stackoverflow.com/users/1830314/rahul-shukla", "accept_rate": 7, "display_name": "Rahul Shukla"}, "view_count": 67, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 38513768}{"body": "<p>How do master and slave communicate is Mesos. Does the master run a webserver? Is it using HTTP or TCP/IP requests ?</p>\n\n<p>Thanks for your reply</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Mesos master slave communication", "last_activity_date": 1431022973, "answer_count": 1, "creation_date": 1430896240, "score": 1, "link": "https://stackoverflow.com/questions/30069866/mesos-master-slave-communication", "answers": [{"body": "<p>Master and worker (aka slave) exchange protobuf messages packed in HTTP/1.1. Master has a tiny built-in webserver that processes messages from workers and requests coming via HTTP endpoints. If you want to learn more, you can start with looking at <code>mesos/3rdparty/libprocess/src/encoder.hpp:107</code></p>\n", "answer_id": 30108860, "last_activity_date": 1431022973, "creation_date": 1431022973, "score": 3, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 30069866}], "owner": {"user_id": 1423561, "profile_image": "https://www.gravatar.com/avatar/4b5d6f86665e4ff9285da5ca1a49d835?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 114, "link": "https://stackoverflow.com/users/1423561/user1423561", "accept_rate": 50, "display_name": "user1423561"}, "view_count": 393, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30069866}{"body": "<p>i have a setup where i am using 3 mesos masters and 3 mesos slasves. after making all the required configurations i can see 3 mesos masters are part of a cluster which is maintained by zookeepers. </p>\n\n<p>now i have setup 3 mesos slaves and when i am starting mesos-slave service, i am expecting that mesos slaves will be available to the mesos masters web UI page. But i can not see any of them in the slaves tab.</p>\n\n<p>selinux, firewall, iptalbes all are disabled. able to perform ssh between node.</p>\n\n<pre><code>[cloud-user@slave1 ~]$ sudo systemctl status mesos-slave -l\n   mesos-slave.service - Mesos Slave\n   Loaded: loaded (/usr/lib/systemd/system/mesos-slave.service; enabled)\n   Active: active (running) since Sat 2016-01-16 16:11:55 UTC; 3s ago\n   Main PID: 2483 (mesos-slave)\n   CGroup: /system.slice/mesos-slave.service\n           \u251c\u25002483 /usr/sbin/mesos-slave --master=zk://10.0.0.2:2181,10.0.0.6:2181,10.0.0.7:2181/mesos --log_dir=/var/log/mesos --containerizers=docker,mesos --executor_registration_timeout=5mins\n           \u251c\u25002493 logger -p user.info -t mesos-slave[2483]\n           \u2514\u25002494 logger -p user.err -t mesos-slave[2483]\n\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.628670  2497 detector.cpp:482] A new leading master (UPID=master@127.0.0.1:5050) is detected\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.628732  2497 slave.cpp:729] New master detected at master@127.0.0.1:5050\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.628825  2497 slave.cpp:754] No credentials provided. Attempting to register without authentication\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.628844  2497 slave.cpp:765] Detecting new master\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.628872  2497 status_update_manager.cpp:176] Pausing sending status updates\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: E0116 16:11:55.628922  2503 process.cpp:1911] Failed to shutdown socket with fd 11: Transport endpoint is not connected\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.629093  2502 slave.cpp:3215] master@127.0.0.1:5050 exited\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: W0116 16:11:55.629107  2502 slave.cpp:3218] Master disconnected! Waiting for a new master to be elected\nJan 16 16:11:55 slave1.novalocal mesos-slave[2494]: E0116 16:11:55.983531  2503 process.cpp:1911] Failed to shutdown socket with fd 11: Transport endpoint is not connected\nJan 16 16:11:57 slave1.novalocal mesos-slave[2494]: E0116 16:11:57.465049  2503 process.cpp:1911] Failed to shutdown socket with fd 11: Transport endpoint is not connected\n</code></pre>\n", "is_answered": true, "title": "mesos slaves are not connecting with mesos masters cluster", "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_activity_date": 1453081265, "accepted_answer_id": 34846029, "creation_date": 1452962507, "answers": [{"body": "<p>So the problematic line is:</p>\n\n<pre><code>Jan 16 16:11:55 slave1.novalocal mesos-slave[2494]: I0116 16:11:55.629093  2502 slave.cpp:3215] master@127.0.0.1:5050 exited\n</code></pre>\n\n<p>Specifically, note it's detecting the master as having the IP address 127.0.0.1. The Mesos Agent[1] sees that IP address, and tries to connect which fails (The master isn't running on the same machine as the agent).</p>\n\n<p>This happens because the master announces what it thinks it's IP address is into Zookeeper. In your case, the master is thinking it's IP is 127.0.0.1 and then storing that into zk. Mesos has several configuration flags to control this behavior, mainly <code>--hostname</code>, <code>--no-hostname_lookup</code>, <code>--ip</code>, <code>--ip_discovery_command</code>, and via setting the environment variable LIBPROCESS_IP. See <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/configuration/</a> for details about them and what they do.</p>\n\n<p>The best thing you can do to make sure things work out of the box is to make sure the machines have resolvable hostnames. Mesos does a reverse-DNS lookup of the boxes hostname in order to figure out what IP people will contact it from.</p>\n\n<p>If you can't get the hostnames setup properly, I would recommend setting <code>--hostname</code> and <code>--ip</code> manually which should cause mesos to announce exactly what you want.</p>\n\n<p>[1]The mesos slave has been renamed to agent, see: <a href=\"https://issues.apache.org/jira/browse/MESOS-1478\" rel=\"nofollow\">https://issues.apache.org/jira/browse/MESOS-1478</a></p>\n", "answer_id": 34846029, "last_activity_date": 1453081265, "creation_date": 1453081265, "score": 3, "owner": {"user_id": 2803594, "profile_image": "https://www.gravatar.com/avatar/b63e00c0b20b57650d77a1b6beb43ead?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/2803594/firebird347", "display_name": "Firebird347"}, "is_accepted": true, "question_id": 34829419}], "score": 0, "link": "https://stackoverflow.com/questions/34829419/mesos-slaves-are-not-connecting-with-mesos-masters-cluster", "answer_count": 1, "owner": {"user_id": 5751125, "profile_image": "https://www.gravatar.com/avatar/8abda5a76cb0e8734dcc4f5d6441cd9b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/5751125/sunil", "display_name": "Sunil"}, "view_count": 1280, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34829419}{"body": "<p>After changing two of three master nodes in an DC/OS 1.8 cluster to a newer CoreOS version (one with a kernel that is patched against the DirtyCOW vulnerability) the masters stopped working. The dashboard showed an empty data center.</p>\n\n<p>We synchronized /var/lib/dcos from the old master to the two new master nodes. Then the dashboard started working again. The DC/OS dashboard still shows flapping metrics.\nWe have a mesos.leader and a zookeeper leader.</p>\n\n<p>How can we stabilize the cluster?</p>\n", "is_answered": true, "title": "Flapping metrics in DC/OS dashboard after changing master nodes", "last_edit_date": 1490014455, "tags": ["apache-zookeeper", "coreos", "mesosphere", "dcos"], "view_count": 65, "accepted_answer_id": 42876952, "last_activity_date": 1490014455, "answers": [{"body": "<p>Last time this happened to us we had to reinstall the cluster. I just finished stopping our master nodes one at a time to increase the disk size. We are now back in the flapping state. I think a reinstall is in our future. I'm searching for answers now to help avoid that.</p>\n", "answer_id": 42876952, "last_activity_date": 1489854761, "creation_date": 1489854761, "score": 1, "owner": {"user_id": 6047444, "profile_image": "https://lh5.googleusercontent.com/-HAv7OcjzSOo/AAAAAAAAAAI/AAAAAAAAB7k/ieys4h9f-nU/photo.jpg?sz=128", "user_type": "registered", "reputation": 33, "link": "https://stackoverflow.com/users/6047444/steve-mitchell", "display_name": "Steve Mitchell"}, "is_accepted": true, "question_id": 40551535}], "score": 1, "link": "https://stackoverflow.com/questions/40551535/flapping-metrics-in-dc-os-dashboard-after-changing-master-nodes", "answer_count": 1, "owner": {"user_id": 6375384, "profile_image": "https://i.stack.imgur.com/X09tt.jpg?s=128&g=1", "user_type": "registered", "reputation": 109, "link": "https://stackoverflow.com/users/6375384/andr%c3%a9-veelken", "display_name": "Andr\u00e9 Veelken"}, "creation_date": 1478879430, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 40551535}{"body": "<p>Im following steps on <a href=\"https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html\" rel=\"nofollow\">here</a></p>\n\n<p>I've created a json file as such:</p>\n\n<pre><code>{\n  \"id\": \"/myjavabuild-2\",\n  \"cmd\": null,\n  \"cpus\": 1,\n  \"mem\": 1024,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"hub.docker.com/eugenepark3/myjavabuild\",\n      \"network\": \"HOST\",\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10001,\n      \"protocol\": \"tcp\",\n      \"labels\": {}\n    }\n  ],\n  \"uris\": [\n    \"file:///etc/docker.tar.gz\"\n  ],\n  \"fetch\": [\n    {\n      \"uri\": \"file:///etc/docker.tar.gz\",\n      \"extract\": true,\n      \"executable\": false,\n      \"cache\": false\n    }\n  ]\n}\n</code></pre>\n\n<p>it keeps erroring out on Marathon.</p>\n\n<p>Is this the correct way to pull docker image from hub.docker.com?</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon", "dockerhub"], "last_edit_date": 1472022992, "title": "apache marathon: my docker image keeps failing", "last_activity_date": 1472024747, "answer_count": 0, "creation_date": 1472022682, "score": 2, "link": "https://stackoverflow.com/questions/39116648/apache-marathon-my-docker-image-keeps-failing", "owner": {"user_id": 1686628, "profile_image": "https://www.gravatar.com/avatar/a03a6bd4b5f83b04ff39aec4b44e17ed?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 3671, "link": "https://stackoverflow.com/users/1686628/ealeon", "accept_rate": 79, "display_name": "ealeon"}, "view_count": 64, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39116648}{"body": "<p>I have an error with the DC/OS cloudformation template.</p>\n\n<blockquote>\n  <p>Your requested instance type (m3.medium) is not supported in your requested Availability Zone (us-east-1d)</p>\n</blockquote>\n\n<p>I also read that m3 are being deprecated by aws.</p>\n\n<p>How can I change the instance of the machines in the cloudformation script?</p>\n", "is_answered": false, "tags": ["amazon-web-services", "amazon-ec2", "amazon-cloudformation", "mesosphere", "dcos"], "title": "Can't create DCOS cluster with m3.medium", "last_activity_date": 1498746041, "answer_count": 0, "creation_date": 1498746041, "score": 0, "link": "https://stackoverflow.com/questions/44827772/cant-create-dcos-cluster-with-m3-medium", "owner": {"user_id": 3434397, "profile_image": "https://www.gravatar.com/avatar/f76cdcd4fbc55698f5f6a85bb5d77b90?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/3434397/ignaciopl", "accept_rate": 50, "display_name": "IgnacioPL"}, "view_count": 38, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44827772}{"is_answered": true, "tags": ["dcos"], "title": "DCOS with IPv6 only", "last_activity_date": 1480596835, "answer_count": 1, "creation_date": 1480587393, "score": 3, "link": "https://stackoverflow.com/questions/40907902/dcos-with-ipv6-only", "owner": {"user_id": 5550658, "profile_image": "https://www.gravatar.com/avatar/233e5d3fdcabdabb2cdfead84db3240e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5550658/ista-ranjan-samanta", "accept_rate": 0, "display_name": "Ista Ranjan Samanta"}, "view_count": 103, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 40907902}{"body": "<p>I have 2 cores on my vagrant development machine, and want to run 2 streaming applications.</p>\n\n<p>If:</p>\n\n<ul>\n<li><p>both of them take both available cores ( I didn't specify \"spark.cores.max\")</p></li>\n<li><p>they have streaming interval of 15 seconds</p></li>\n<li><p>5 seconds is enough to perform computation</p></li>\n</ul>\n\n<p>Is expected behaviour of Mesos to shift these 2 available cores between 2 applications? I would expect that behaviour, because \"Mesos locks the resources until job is executed\", and in Spark Streaming one job is what is executed within batch interval.</p>\n\n<p>Otherwise, If resources are locked for the life of application (in spark streaming it is forever), what is the benefit of using Mesos instead of Standalone cluster manager? </p>\n", "is_answered": true, "tags": ["apache-spark", "spark-streaming", "mesos", "mesosphere"], "title": "Spark streaming on Mesos - course grained", "last_activity_date": 1462469874, "answer_count": 1, "creation_date": 1462465677, "score": 1, "link": "https://stackoverflow.com/questions/37055616/spark-streaming-on-mesos-course-grained", "answers": [{"body": "<p>Spark Streaming locks each stream <code>Reader</code> to a core, plus you'll need at least one other core for the rest of the processing. So you can't run two jobs simultaneously on a 2-core machine.</p>\n\n<p>Mesos gives you much better resource utilization in a cluster. Standalone is more static. It might fine, though, for a fixed number of long-running streams, as long as you have enough resources and you use the recommendations for capping the allowed resources each job can grab (default is to grab everything).</p>\n\n<p>If you're really just running on a single machine, use <code>local[*]</code> to avoid the overhead of master and slave daemons, etc.</p>\n", "answer_id": 37056896, "last_activity_date": 1462469874, "creation_date": 1462469874, "score": 2, "owner": {"user_id": 385104, "profile_image": "https://www.gravatar.com/avatar/f2e417d5a4b0be046bec25a2c44be606?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1971, "link": "https://stackoverflow.com/users/385104/dean-wampler", "display_name": "Dean Wampler"}, "is_accepted": false, "question_id": 37055616}], "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "view_count": 85, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37055616}{"body": "<p>On Chronos WebUI, I can \"Force Run\" jobs and immediately get results.</p>\n\n<p>Is it possible to perform \"Force Run\" via Chronos REST API?</p>\n\n<p>Thank you.</p>\n", "is_answered": true, "title": "Chronos \"Force Run\" via API", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1429935358, "accepted_answer_id": 29860934, "creation_date": 1429236179, "answers": [{"body": "<p>Jobs can be manually triggered with a PUT to /scheduler/job/$JOB_NAME. For example:</p>\n\n<pre><code>curl -L -X PUT chronos-node:8080/scheduler/job/$JOB_NAME\n</code></pre>\n\n<p>See <a href=\"https://github.com/mesos/chronos#manually-starting-a-job\" rel=\"nofollow\">https://github.com/mesos/chronos#manually-starting-a-job</a>.</p>\n", "answer_id": 29860934, "last_activity_date": 1429935358, "creation_date": 1429935358, "score": 3, "owner": {"user_id": 2371859, "profile_image": "https://www.gravatar.com/avatar/0f06d00fca1684d0e9cbdc840aa1aada?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 71, "link": "https://stackoverflow.com/users/2371859/bookest", "display_name": "bookest"}, "is_accepted": true, "question_id": 29688963}], "score": 2, "link": "https://stackoverflow.com/questions/29688963/chronos-force-run-via-api", "answer_count": 1, "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 576, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29688963}{"body": "<p>I am using mesos in a distribtued testing system. While I can specify slave/host resources very easily (on a per slave basis), is there a way I can specify a central resource (saucelab connections) in mesos? I am trying to ensure that at any given time, I don't have more than X amount of that central resource used.</p>\n", "is_answered": true, "title": "Can mesos handle central resource?", "tags": ["distributed-computing", "mesos", "mesosphere"], "last_activity_date": 1491817181, "accepted_answer_id": 29816870, "creation_date": 1429559000, "answers": [{"body": "<p>Short answer: Not yet.</p>\n\n<p>We've discussed the idea of cluster-wide resources before, for NAS/SAN I/O, software licenses, or even a pool of IPs, but we don't have a JIRA for it yet. Like any resource, there are a few aspects to consider:</p>\n\n<ol>\n<li>Registering the resource(s). I could imagine some ResourceProvider other than a Mesos-slave that registers with the master and provides resources that are accessible from some/all slaves and can be consumed by some/any task.</li>\n<li>Allocation: Once the resources are available to Mesos, it should be easy to modify the allocator to allocate, offer, and track the usage of these cluster-wide resources.</li>\n<li>Resource isolation: Once a task launches, we need each slave to be able to enforce the resource limits allocated to a task, or to enforce that a task was not allocated any of that resource. This can be done with custom isolator modules, perhaps packaged (and distributed?) by the resource provider.</li>\n</ol>\n", "answer_id": 29816870, "last_activity_date": 1429775044, "creation_date": 1429775044, "score": 3, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 29756950}, {"body": "<p>As mentioned by Adam, there is no such way in Mesos by which you can achieve this requirement directly. However, you can achieve this by writing you own module on top of ZooKeeper.</p>\n\n<ol>\n<li><p>Keep your central resources metadata on zookeeper.       </p></li>\n<li><p>Your framework scheduler can access this metadata to know available\ncentral resources and can take a decision depending on availability of resources.</p></li>\n<li>Your framework executor can also read this information to get an\nidea of existing count of central resources.</li>\n</ol>\n", "answer_id": 43319754, "last_activity_date": 1491817181, "creation_date": 1491817181, "score": 0, "owner": {"user_id": 1266150, "profile_image": "https://www.gravatar.com/avatar/7732616c0735b113af792c141346dafc?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 63, "link": "https://stackoverflow.com/users/1266150/amar-gajbhiye", "accept_rate": 75, "display_name": "Amar Gajbhiye"}, "is_accepted": false, "question_id": 29756950}], "score": 2, "link": "https://stackoverflow.com/questions/29756950/can-mesos-handle-central-resource", "answer_count": 2, "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 77, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 29756950}{"is_answered": false, "tags": ["meteor", "meteorite"], "last_edit_date": 1377376288, "title": "How to pass login callback to form error in Meteorite with Mesosphere?", "last_activity_date": 1377376288, "answer_count": 1, "creation_date": 1377334896, "score": 0, "link": "https://stackoverflow.com/questions/18416775/how-to-pass-login-callback-to-form-error-in-meteorite-with-mesosphere", "owner": {"user_id": 1191551, "profile_image": "https://www.gravatar.com/avatar/97ced8a229689b73b098a542636052e8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4303, "link": "https://stackoverflow.com/users/1191551/chet", "accept_rate": 46, "display_name": "Chet"}, "view_count": 429, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 18416775}{"body": "<p>I am new to Mesos and just finished setting up mesos and along with zookeeper on my test server. </p>\n\n<p>Unfortunately I keep getting this error message on my mesos console indicating i am unable to connect to mesos on port 5050 and can't seem to figure out why.</p>\n\n<p>I have included the error in the screen shot below </p>\n\n<p>The mesos log files doesn't point to why the error is showing either. </p>\n\n<p><a href=\"https://i.stack.imgur.com/nnuNg.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nnuNg.png\" alt=\"enter image description here\"></a></p>\n", "is_answered": true, "tags": ["apache", "apache-zookeeper", "mesos", "mesosphere"], "last_edit_date": 1479752988, "title": "Mesos Failed to connect error to IP:5050", "last_activity_date": 1491648056, "answer_count": 5, "creation_date": 1479328047, "score": 1, "link": "https://stackoverflow.com/questions/40641674/mesos-failed-to-connect-error-to-ip5050", "answers": [{"body": "<p>There can be multiple issues here.</p>\n\n<ul>\n<li>Is your mesos-master running and healthy ?</li>\n<li>Has leader election process completed, if all is good. </li>\n</ul>\n\n<p>Check if you are able to do </p>\n\n<pre><code>ping leader.mesos\n</code></pre>\n\n<p>If above ping doesn't work, that means leader has not been elected. First fix that.</p>\n", "answer_id": 40780683, "last_activity_date": 1479973860, "creation_date": 1479973860, "score": 0, "owner": {"user_id": 1229355, "profile_image": "https://graph.facebook.com/727850431/picture?type=large", "user_type": "registered", "reputation": 366, "link": "https://stackoverflow.com/users/1229355/tyagi-akhilesh", "accept_rate": 50, "display_name": "Tyagi Akhilesh"}, "is_accepted": false, "question_id": 40641674}, {"body": "<p>I had this problem also. Luckily, I have a running mesos server also. So, I can compare the different between my demo and the running mesos server. I captured the packets between client and server in my demo. I found the explorer didn`t resend fresh request, only some keepalive packets.</p>\n\n<p><img src=\"https://i.stack.imgur.com/INRtT.jpg\" alt=\"https://i.stack.imgur.com/INRtT.jpg\"></p>\n\n<p>but, when I catch the packets in the running mesos server, I found the explorer send get request frequently. like the image</p>\n\n<p><img src=\"https://i.stack.imgur.com/LnWNB.jpg\" alt=\"https://i.stack.imgur.com/LnWNB.jpg\"></p>\n\n<p>I think, if you run some task or add some agent, maybe it will activate the explore to send request frequently. Then the \"Failed to connect\" will disappeared.</p>\n", "answer_id": 41332997, "last_activity_date": 1482766255, "creation_date": 1482764583, "score": 0, "owner": {"user_id": 7342702, "profile_image": "https://www.gravatar.com/avatar/7c467f0f49acc7b7f5baf0432d99542b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/7342702/zhiyuan-jin", "display_name": "zhiyuan jin"}, "is_accepted": false, "last_edit_date": 1482766255, "question_id": 40641674}, {"body": "<p>I have resolved this problem. Open the web page in Chrome, and open the developer tool, you will see the chrome is accessing the web site with domain, in my case the domain name is \"mesosphere\", as there is no mesosphere in dns, so the accessing was failed.\n<a href=\"https://i.stack.imgur.com/2ybZD.jpg\" rel=\"nofollow noreferrer\">https://i.stack.imgur.com/2ybZD.jpg</a></p>\n\n<p>I added the mesosphere in the hosts file, C:/windows/system32/etc/hosts/</p>\n\n<p>I resolved the problem</p>\n", "answer_id": 41358258, "last_activity_date": 1482927471, "creation_date": 1482914274, "score": 1, "owner": {"user_id": 7342702, "profile_image": "https://www.gravatar.com/avatar/7c467f0f49acc7b7f5baf0432d99542b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/7342702/zhiyuan-jin", "display_name": "zhiyuan jin"}, "is_accepted": false, "last_edit_date": 1482927471, "question_id": 40641674}, {"body": "<p>I resolved the problem by this:</p>\n\n<pre><code>./bin/mesos-master.sh --ip=x.x.x.x --work_dir=/var/lib/mesos --hostname=x.x.x.x\n</code></pre>\n", "answer_id": 41408606, "last_activity_date": 1483193075, "creation_date": 1483190040, "score": 3, "owner": {"user_id": 7360654, "profile_image": "https://www.gravatar.com/avatar/1cf8b98d1a670f9d2d45e10ecbec88ce?s=128&d=identicon&r=PG", "user_type": "unregistered", "reputation": 31, "link": "https://stackoverflow.com/users/7360654/zhang", "display_name": "Zhang"}, "is_accepted": false, "last_edit_date": 1483193075, "question_id": 40641674}, {"body": "<p>I was having the same issues and what fixed it for me was the zookeeper configuration.  In my case I was using the EC2 public IP Address rather than the private one.  Once I changed the /etc/mesos/zk file to <strong><em>zk://&lt;private IP&gt;:2181/mesos</em></strong> I was able to connect without the constant error messages.  In other words, zookeeper was reporting to be running in one IP and mesos-master was trying to connect using a different IP.</p>\n", "answer_id": 43293013, "last_activity_date": 1491648056, "creation_date": 1491648056, "score": 0, "owner": {"user_id": 1110261, "profile_image": "https://www.gravatar.com/avatar/49d9bd785a170f3e5e2da208875bf723?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 7, "link": "https://stackoverflow.com/users/1110261/oeg-bizz", "display_name": "Oeg Bizz"}, "is_accepted": false, "question_id": 40641674}], "owner": {"user_id": 7089682, "profile_image": "https://www.gravatar.com/avatar/79f60c6a150ddfa56c34d402c65dfc61?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/7089682/crusadecoder", "accept_rate": 24, "display_name": "crusadecoder"}, "view_count": 1787, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 40641674}{"body": "<p>I'm using the latest jar files of cassandra-mesos framework (by using this jason file: <a href=\"https://teamcity.mesosphere.io/repository/download/Oss_Mesos_Cassandra_CassandraFramework/97399:id/marathon.json\" rel=\"nofollow\">https://teamcity.mesosphere.io/repository/download/Oss_Mesos_Cassandra_CassandraFramework/97399:id/marathon.json</a>), but getting the following errors:</p>\n\n<blockquote>\n  <p>I0310 13:19:34.699774 16389 sched.cpp:264] No credentials provided.\n  Attempting to register without authentication I0310 13:19:34.701026\n  16389 sched.cpp:819] Got error 'Completed framework attempted to\n  re-register' I0310 13:19:34.701038 16389 sched.cpp:1625] Asked to\n  abort the driver I0310 13:19:34.701364 16389 sched.cpp:861] Aborting\n  framework '20160309-183453-2497969674-5050-19271-0001' I0310\n  13:19:34.719744 16373 sched.cpp:1591] Asked to stop the driver I0310\n  13:19:34.719784 16389 sched.cpp:835] Stopping framework\n  '20160309-183453-2497969674-5050-19271-0001'</p>\n</blockquote>\n\n<p>Any idea?</p>\n", "is_answered": true, "tags": ["cassandra", "mesos", "mesosphere"], "last_edit_date": 1457616443, "title": "Deploying cassandra-mesos framework with marathon", "last_activity_date": 1457866468, "answer_count": 2, "creation_date": 1457614044, "score": 1, "link": "https://stackoverflow.com/questions/35916943/deploying-cassandra-mesos-framework-with-marathon", "answers": [{"body": "<p>The error says <code>Completed framework attempted to re-register</code> which means the framework keeps its state somewhere (probably in Zookeeper, but cannot access your URL with marathon.json to verify), and thus tries to start with the framework ID stored in this state. However, that framework ID is already deregistered, and Mesos does not allow you to start the framework with the same ID again.</p>\n\n<p>The solution to this would be either to pick a different znode for framework storage or remove the existing znode before starting the framework.</p>\n", "answer_id": 35917885, "last_activity_date": 1457616472, "creation_date": 1457616472, "score": 1, "owner": {"user_id": 1472049, "profile_image": "https://i.stack.imgur.com/1qeQt.jpg?s=128&g=1", "user_type": "registered", "reputation": 11659, "link": "https://stackoverflow.com/users/1472049/serejja", "accept_rate": 100, "display_name": "serejja"}, "is_accepted": false, "question_id": 35916943}, {"body": "<p>Thanks a lot :-). It's working now. but when I tried to check zookeeper for cassandra-mesos, I got the following error:  mesos-resolve zk://mesos-master-2:2181/cassandra-mesos/cassandra-mesos-fw\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@712: Client environment:zookeeper.version=zookeeper C client 3.4.5\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@716: Client environment:host.name=mesos-slave-1\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@723: Client environment:os.name=Linux\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@724: Client environment:os.arch=3.10.0-327.4.4.el7.x86_64\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@725: Client environment:os.version=#1 SMP Tue Jan 5 16:07:00 UTC 2016\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@733: Client environment:user.name=root\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@741: Client environment:user.home=/root\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@log_env@753: Client environment:user.dir=/ephemeral/cassandra-mesos\n2016-03-13 12:46:22,428:26613(0x7fa4fa843700):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=mesos-master-2:2181 sessionTimeout=10000 watcher=0x7fa5023200b0 sessionId=0 sessionPasswd= context=0x7fa4d8001ec0 flags=0\n2016-03-13 12:46:22,429:26613(0x7fa4f6628700):ZOO_INFO@check_events@1703: initiated connection to server [10.254.227.148:2181]\n2016-03-13 12:46:22,434:26613(0x7fa4f6628700):ZOO_INFO@check_events@1750: session establishment complete on server [10.254.227.148:2181], sessionId=0x25364fb9f3a0020, negotiated timeout=10000\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nI0313 12:46:22.434587 26616 group.cpp:313] Group process (group(1)@10.254.235.46:56890) connected to ZooKeeper\nI0313 12:46:22.434659 26616 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0313 12:46:22.434670 26616 group.cpp:385] Trying to create path '/cassandra-mesos/cassandra-mesos-fw' in ZooKeeper\nFailed to detect master from 'zk://mesos-master-2:2181/cassandra-mesos/cassandra-mesos-fw' within 5secs</p>\n", "answer_id": 35969336, "last_activity_date": 1457866468, "creation_date": 1457866468, "score": 0, "owner": {"user_id": 6044704, "profile_image": "https://www.gravatar.com/avatar/9973e5d01931b3fc40931b71e24aa9e0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6044704/abu", "display_name": "Abu"}, "is_accepted": false, "question_id": 35916943}], "owner": {"user_id": 6044704, "profile_image": "https://www.gravatar.com/avatar/9973e5d01931b3fc40931b71e24aa9e0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6044704/abu", "display_name": "Abu"}, "view_count": 120, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35916943}{"body": "<p>I am using:</p>\n\n<ul>\n<li>jenkins 1.595 </li>\n<li>mesos jenkins plugin 0.5.0 </li>\n<li>mesos 0.21.0</li>\n</ul>\n\n<p>I have configured Cloud Mesos in jenkins. Jenkins framework is already registerd with description in mesos frameworks view like this:</p>\n\n<p>Id: 5050-2830-29614</p>\n\n<p>Host: My-PC</p>\n\n<p>User: Jenkins</p>\n\n<p>Name: Jenkins Scheduler</p>\n\n<p>Active Tasks: 0</p>\n\n<p>CPU: 1.7</p>\n\n<p>Mem: 2.5 Gb</p>\n\n<p>Max Share: 37442%</p>\n\n<p>Registered: 33 minutes ago</p>\n\n<p>Re-Registered: -</p>\n\n<p>But Jenkins not show online slave and get this output\nStarting mesos slave mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd</p>\n\n<pre><code>HTTP ERROR 404\n\nProblem accessing /computer/mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd/logText/progressiveHtml. Reason:\n\n    Not Found\n</code></pre>\n\n<p>and this log</p>\n\n<pre><code>INFO: Enqueuing jenkins slave request\nJan 13, 2015 10:18:57 AM hudson.model.DownloadService$Downloadable load\nINFO: Obtained the updated data file for hudson.tools.JDKInstaller\nJan 13, 2015 10:20:12 AM org.jenkinsci.plugins.mesos.MesosRetentionStrategy check\nINFO: Disconnecting offline computer mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd\nJan 13, 2015 10:20:12 AM org.jenkinsci.plugins.mesos.MesosSlave terminate\nINFO: Terminating slave mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd\nJan 13, 2015 10:20:12 AM org.jenkinsci.plugins.mesos.JenkinsScheduler terminateJenkinsSlave\nINFO: Terminating jenkins slave mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd\nJan 13, 2015 10:20:12 AM org.jenkinsci.plugins.mesos.JenkinsScheduler terminateJenkinsSlave\nINFO: Removing enqueued mesos task mesos-jenkins-d4dd533e-bed4-44bc-b0d9-8fc5474710bd\nJan 13, 2015 10:21:24 AM hudson.model.UpdateSite updateData\nINFO: Obtained the latest update center data file for UpdateSource default\n</code></pre>\n\n<p>the log in mesos is this:</p>\n\n<pre><code>I0113 10:07:13.690115  2851 master.cpp:1434] Framework 20150105-100316-1275074476-5050-2830-29614 (Jenkins Scheduler) at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612 already registered, resending acknowledgement\nI0113 10:07:14.690235  2854 master.cpp:1383] Received registration request for framework 'Jenkins Scheduler' at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612\nI0113 10:07:14.690510  2854 master.cpp:1434] Framework 20150105-100316-1275074476-5050-2830-29614 (Jenkins Scheduler) at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612 already registered, resending acknowledgement\nI0113 10:07:15.690466  2854 master.cpp:1383] Received registration request for framework 'Jenkins Scheduler' at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612\nI0113 10:07:15.690723  2854 master.cpp:1434] Framework 20150105-100316-1275074476-5050-2830-29614 (Jenkins Scheduler) at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612 already registered, resending acknowledgement\nI0113 10:07:16.691149  2852 master.cpp:1383] Received registration request for framework 'Jenkins Scheduler' at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612\nI0113 10:07:16.691689  2852 master.cpp:1434] Framework 20150105-100316-1275074476-5050-2830-29614 (Jenkins Scheduler) at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612 already registered, resending acknowledgement\nI0113 10:07:17.691560  2853 master.cpp:1383] Received registration request for framework 'Jenkins Scheduler' at scheduler-83e56c80-e586-4564-88cb-e0fd541ad845@172.23.0.76:58612\n</code></pre>\n\n<p>and so on...</p>\n\n<p>also mesos show\n<strong>Offered   1.7     2.5 GB</strong>  (the same resources of framework registered)</p>\n", "is_answered": true, "title": "jenkins slave in mesos not start", "tags": ["jenkins", "jenkins-plugins", "mesos", "mesosphere"], "last_activity_date": 1427157450, "accepted_answer_id": 28505185, "creation_date": 1421163846, "answers": [{"body": "<p>Have a look at the environment variable LIBPROCESS_IP=\"IP of the jenkins host\". See <a href=\"https://github.com/mesos/chronos/issues/193\" rel=\"nofollow\">mesos/chronos#193</a></p>\n", "answer_id": 28505185, "last_activity_date": 1427157450, "creation_date": 1423848165, "score": 0, "owner": {"user_id": 3423239, "profile_image": "https://www.gravatar.com/avatar/aba844f9b5b63a7b30fb1eb6521244ce?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/3423239/mroth", "display_name": "mroth"}, "is_accepted": true, "last_edit_date": 1427157450, "question_id": 27925909}], "score": 0, "link": "https://stackoverflow.com/questions/27925909/jenkins-slave-in-mesos-not-start", "answer_count": 1, "owner": {"user_id": 818094, "profile_image": "https://www.gravatar.com/avatar/f93ac57e4452df30894e5db2f589cf31?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2469, "link": "https://stackoverflow.com/users/818094/montells", "accept_rate": 82, "display_name": "montells"}, "view_count": 780, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 27925909}{"is_answered": false, "tags": ["jenkins", "jenkins-plugins", "dcos"], "title": "Jenkings on DCOS - Marathon-plugin missing after install", "last_activity_date": 1487932519, "answer_count": 1, "creation_date": 1486152637, "score": 0, "link": "https://stackoverflow.com/questions/42032273/jenkings-on-dcos-marathon-plugin-missing-after-install", "owner": {"user_id": 5327086, "profile_image": "https://www.gravatar.com/avatar/7da3e0464eb2cde1eef7387ab766051e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 25, "link": "https://stackoverflow.com/users/5327086/adoyt", "accept_rate": 29, "display_name": "Adoyt"}, "view_count": 43, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42032273}{"body": "<p>I am using my local system as a slave which is behind campus firewall. Firewall allows me to access only 8082 to 8090 ports for all incoming requests. My slave system is having a private ip address. So I am using a NAT conversion at the firewall which will convert all incoming requests to ports 8080-8090 ports on the firewall to my private ip machine.</p>\n\n<p>Firewall has a public ip: 128.x.y.z  and  mesos slave has a private ip: 10.11.12.13</p>\n\n<p>Here is the NAT rule:   128.x.y.z port 8082-8090 will change into 10.11.12.13 port 8082-8090</p>\n\n<p>I am using firewalls address as  --advertise_ip= 128.x.y.z address, which is registering  128.x.y.z:8082 as a slave. Now jobs are coming to my private ip machine through that NAT conversion but containers are failing and relaunching again and again.</p>\n\n<p>Mesos Master is running on 5050\nMesos slave is running on 8082\nMesos ports as resources are (8083-8084).\nLinux ephemeral port range is changed in slave machine to (8085-8090).</p>\n\n<p>I hope this explains my setup. Problem in jobs are coming to my slave system and creating process id for the same but failing. I am not sure which part of the authentication actually failing. So from mesos framework i can see jobs are either failing or staying in stagged state.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "jobs are stuck in meos agents and staying in stagged state", "last_activity_date": 1473400379, "answer_count": 0, "creation_date": 1473400379, "score": 0, "link": "https://stackoverflow.com/questions/39404693/jobs-are-stuck-in-meos-agents-and-staying-in-stagged-state", "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 43, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39404693}{"body": "<ul>\n<li>DC/OS 1.9.0 </li>\n<li>MARATHON 1.4.2 </li>\n<li>LIQUIBASE 3.5.3</li>\n</ul>\n\n<p>I implemented a short lived docker container that runs a Liquibase migration against a mysql database. The container has been working great during development via docker-compose. However, I'm attempting to implement this container within a DCOS cluster in preparation for production.</p>\n\n<p>When Liquibase runs, it successfully acquires a lock and then just dies. Here is the output of the run:</p>\n\n<pre><code>DEBUG 4/14/17 8:06 PM: liquibase: Connected to root@10.0.1.113@jdbc:mysql://test-db.marathon.l4lb.thisdcos.directory/myapp\nDEBUG 4/14/17 8:06 PM: liquibase: Setting auto commit to false from true\nDEBUG 4/14/17 8:06 PM: liquibase: Executing QUERY database command: select count(*) from myapp.DATABASECHANGELOGLOCK\nDEBUG 4/14/17 8:06 PM: liquibase: Executing QUERY database command: select count(*) from myapp.DATABASECHANGELOGLOCK\nINFO 4/14/17 8:06 PM: liquibase: Successfully acquired change log lock\n/usr/local/bin/liquibase: line 56:   295 Killed                  java -cp \"$CP\" $JAVA_OPTS liquibase.integration.commandline.Main ${1+\"$@\"}\n</code></pre>\n\n<p>The <code>DATABASECHANGELOGLOCK</code> table is successfully created so I know it is both accessing the database and creating tables, however it just dies. </p>\n\n<p>After the run, the lock table looks like:</p>\n\n<pre><code>MySQL [myapp]&gt; select * from DATABASECHANGELOGLOCK;\n+----+--------+-------------+----------+\n| ID | LOCKED | LOCKGRANTED | LOCKEDBY |\n+----+--------+-------------+----------+\n|  1 |        | NULL        | NULL     |\n+----+--------+-------------+----------+\n</code></pre>\n\n<p>Here is the command that is being run:</p>\n\n<pre><code>liquibase --changeLogFile=base_change_log.xml --driver=com.mysql.jdbc.Driver --url=jdbc:mysql://test-db.marathon.l4lb.thisdcos.directory/myapp --contexts=production --username=root --password=****** --classpath=/opt/jdbc_drivers/mysql-connector-java-5.1.40-bin.jar --logLevel=debug update\n</code></pre>\n\n<p>This is the command the liquibase bash file runs:</p>\n\n<pre><code>java -cp .:/opt/liquibase/liquibase.jar:/opt/liquibase/lib/snakeyaml-1.17.jar liquibase.integration.commandline.Main --changeLogFile=base_change_log.xml --driver=com.mysql.jdbc.Driver --url=jdbc:mysql://test-db.marathon.l4lb.thisdcos.directory/myapp --contexts=production --username=root --password=****** --classpath=/opt/jdbc_drivers/mysql-connector-java-5.1.40-bin.jar --logLevel=debug update\n</code></pre>\n\n<p>As I said, this container works fine locally with docker-compose, it also works if I install all deps on one of the dcos slaves and run liquibase locally.</p>\n\n<p>Are there any better ways to debug this? Has anyone successfully run a liquibase migration inside a DCOS cluster?</p>\n", "is_answered": true, "title": "Why does Liquibase migration on MySQL database die after acquiring lock on DC/OS (worked fine with docker-compose)?", "last_edit_date": 1492245279, "tags": ["docker", "liquibase", "dcos"], "view_count": 61, "accepted_answer_id": 43435580, "last_activity_date": 1492333589, "answers": [{"body": "<p>Please check the Mesos master logs. I suspect you are encountering a OOM kill of the task. </p>\n", "answer_id": 43435580, "last_activity_date": 1492333589, "creation_date": 1492333589, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 43418775}], "score": 2, "link": "https://stackoverflow.com/questions/43418775/why-does-liquibase-migration-on-mysql-database-die-after-acquiring-lock-on-dc-os", "answer_count": 1, "owner": {"user_id": 1211778, "profile_image": "https://www.gravatar.com/avatar/5095839ff238d21a5d2622e8f21ce2ad?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 435, "link": "https://stackoverflow.com/users/1211778/rjbez", "accept_rate": 90, "display_name": "rjbez"}, "creation_date": 1492201698, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43418775}{"body": "<p>I use Mesosphere and I want to make a custom rule to validate equalsField:</p>\n\n<pre><code>Mesosphere.registerRule(\"equalsField\", function(fieldValue, ruleValue){\n  //var ruleValue = $('#'+ruleValue).val();\n  //var ruleValue = document.getElementById(ruleValue).value;\n  return fieldValue === ruleValue;\n});\n</code></pre>\n\n<p>But I can't use jquery $ or document because is not accesible on the server side (these works only on the client side)</p>\n", "is_answered": false, "tags": ["meteor", "mesosphere"], "title": "How can I access form elements from server function?", "last_activity_date": 1392180655, "answer_count": 1, "creation_date": 1391181971, "score": 0, "link": "https://stackoverflow.com/questions/21483640/how-can-i-access-form-elements-from-server-function", "answers": [{"body": "<p>So it looks like what you want to to is check that one field is equal to another field.</p>\n\n<p>In actuality when a rule is validated in Mesosphere, the rule is passed 5 parameters: fieldValue, ruleValue, fieldName, formFieldsObject, and fields. Since formFieldsObject is an object containing the raw unvalidated data from the form, with the name of each input as the key and the current value as the key value, This means that you can create your new rule as follows..</p>\n\n<pre><code>Mesosphere.registerRule(\"equalsField\", function(fieldValue, ruleValue, fieldName, formFieldsObject, fields){\n  return fieldValue === formFieldsObject[ruleValue];\n});\n</code></pre>\n\n<p>Then when you set up your rules, pass the name of the field that the current field should be equal to and you should be good to go.</p>\n", "answer_id": 21718953, "last_activity_date": 1392180655, "creation_date": 1392180655, "score": 0, "owner": {"user_id": 394961, "profile_image": "https://www.gravatar.com/avatar/c4c5d9c8611d1921f62999d51db005c1?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2028, "link": "https://stackoverflow.com/users/394961/kelly-copley", "display_name": "Kelly Copley"}, "is_accepted": false, "question_id": 21483640}], "owner": {"user_id": 799853, "profile_image": "https://www.gravatar.com/avatar/4087fa40d402c6418774c115347c1dd8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 25, "link": "https://stackoverflow.com/users/799853/ciocan", "accept_rate": 50, "display_name": "ciocan"}, "view_count": 105, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 21483640}{"body": "<p>I tried to run pyspark with mesos, and my spark package is uploaded to local accessable hdfs.</p>\n\n<p>However, whenever I tried to launch the shell, always got following error</p>\n\n<pre><code>16/04/18 22:21:33 INFO CoarseMesosSchedulerBackend: Blacklisting Mesos slave a8509a2e-fad8-485d-850e-8243fd2ee449-S0 due to too many failures; is Spark installed on it?\n</code></pre>\n\n<p>I have added the following to spark-env.sh</p>\n\n<pre><code>export MESOS_NATIVE_JAVA_LIBRAR=/usr/local/lib/libmesos.so\nexport SPARK_EXECUTOR_URI=hdfs://ipaddress:9000/spark/spark-1.6.1-bin-hadoop2.6\n</code></pre>\n\n<p>But seems slave still cannot find spark package to execute. How can I resolve this issue?</p>\n", "is_answered": false, "tags": ["hadoop", "apache-spark", "hdfs", "mesos", "mesosphere"], "last_edit_date": 1461147150, "title": "Running spark with mesos and spark package on hdfs", "last_activity_date": 1461147150, "answer_count": 0, "creation_date": 1461018622, "score": 1, "link": "https://stackoverflow.com/questions/36705434/running-spark-with-mesos-and-spark-package-on-hdfs", "owner": {"user_id": 4577893, "profile_image": "https://www.gravatar.com/avatar/56e0e1b038365b9df641d758739179ad?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 20, "link": "https://stackoverflow.com/users/4577893/gujason", "display_name": "gujason"}, "view_count": 103, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36705434}{"is_answered": true, "tags": ["docker", "marathon", "mesosphere"], "title": "Is &quot;args&quot; in Mesosphere equivalent with environment variables in docker run command?", "last_activity_date": 1497570828, "answer_count": 1, "creation_date": 1497565428, "score": 0, "link": "https://stackoverflow.com/questions/44577952/is-args-in-mesosphere-equivalent-with-environment-variables-in-docker-run-comm", "accepted_answer_id": 44578625, "owner": {"user_id": 1986597, "profile_image": "https://www.gravatar.com/avatar/59acb1f9dda0d6e2d7a60cc06d7c4b87?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 626, "link": "https://stackoverflow.com/users/1986597/casper", "accept_rate": 88, "display_name": "Casper"}, "view_count": 20, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44577952}{"body": "<p>Please this is not asked anywhere I have checked. Here is what I have done. I am able to deploy single instance of mesos, marathon and docker. Moving next step ahead I want to have 2 mesos slave(docker containers) linked to each other. Just using docker the same can be achieved by using the docker link feature. But while using the orchestration(mesos) and scheduler(marathon)it seems u need to use service discovery. </p>\n\n<p>My setup up is simple and runnning on a single host. So I will have 2 docker containers one running a simple pub/sub and one running rabbitmq. How can I use HA PRoxy in this setup. I have seen some documents provided by mesosphere\n<a href=\"http://mesosphere.com/docs/getting-started/service-discovery/\" rel=\"nofollow\">http://mesosphere.com/docs/getting-started/service-discovery/</a> but it is not clear how to go about it.</p>\n", "is_answered": true, "title": "HaProxy for service discovery on a marathon mesos docker linked containers", "tags": ["docker", "haproxy", "mesos", "mesosphere", "marathon"], "last_activity_date": 1464590617, "accepted_answer_id": 28687864, "creation_date": 1424426160, "answers": [{"body": "<p>The canonical approach for service discovery with Mesos + Marathon + Docker is currently what is described in the document you linked. </p>\n\n<p>I'm assuming you're able to get the two applications running in Marathon already.</p>\n\n<p>Typically what happens is:</p>\n\n<p>1) Configure your application definition to include the ports that your application requires.</p>\n\n<p>2) You set up the provided <code>haproxy-marathon-bridge</code> script to run periodically using a utility like cron. This script scrapes Marathon's API to figure out what host and port the application instances are running on and what the known \"friendly\" port is. </p>\n\n<p>In the example in the service discovery article, the first application has friendly ports of <code>80</code> and <code>443</code>, whilst the second has a friendly port of <code>8081</code>. </p>\n\n<p>The script then generates a <code>haproxy.cfg</code> configuration that has rules mapping <code>localhost:friendly_port</code> to <code>actual_host:actual_port</code>.</p>\n\n<p>3) Configure your applications to look for each other on <code>localhost:friendly_port</code>. HAProxy will route connections appropriately.</p>\n\n<p>Hope this helps your understanding!</p>\n", "answer_id": 28687864, "last_activity_date": 1424749972, "creation_date": 1424749972, "score": 5, "owner": {"user_id": 948993, "profile_image": "https://www.gravatar.com/avatar/7ee6e3e1d1c7831d01acd349ff9ae9db?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 173, "link": "https://stackoverflow.com/users/948993/ssk2", "display_name": "ssk2"}, "is_accepted": true, "question_id": 28626083}, {"body": "<p>I created a haproxy service discovery docker container that you can run in mesos. It's not production ready but I am using it in my development environment doing exactly what you're trying to do. The reason I prefer this over what comes with marathon is I haven't found a good way to do complicated haproxy configurations with <code>haproxy-marathon-bridge</code>. With <code>spiderweb</code> you can create a template for the haproxy configuration which enables you to do things such as acl routing etc. It doesn't support health checks yet which is something that will need to be done before its production ready. You can see the project here <a href=\"https://github.com/SBRDevelopment/spiderweb\" rel=\"nofollow\">https://github.com/SBRDevelopment/spiderweb</a>.</p>\n", "answer_id": 28745868, "last_activity_date": 1424963185, "creation_date": 1424963185, "score": 0, "owner": {"user_id": 1046468, "profile_image": "https://www.gravatar.com/avatar/993b49a16d7f203a11cf147ff224e24b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2994, "link": "https://stackoverflow.com/users/1046468/bwight", "display_name": "bwight"}, "is_accepted": false, "question_id": 28626083}, {"body": "<p>We have combined Mesos and Marathon with consul and registartor,\nso in the end you have haproxy configuration auto-generated with consul-template.</p>\n\n<p>try <a href=\"https://github.com/eBayClassifiedsGroup/PanteraS\" rel=\"nofollow\">https://github.com/eBayClassifiedsGroup/PanteraS</a>\nAll in one container.</p>\n", "answer_id": 29549069, "last_activity_date": 1428613737, "creation_date": 1428613737, "score": 0, "owner": {"user_id": 3796643, "profile_image": "https://i.stack.imgur.com/jyQ0K.png?s=128&g=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/3796643/sielaq", "display_name": "SielaQ"}, "is_accepted": false, "question_id": 28626083}, {"body": "<p>With Mesos-DNS you can also do the following:</p>\n\n<ol>\n<li>Setup mesos-dns as in this guide: <a href=\"http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/\" rel=\"nofollow\">http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/</a> (you can skip HAProxy steps they are not required)</li>\n<li>When you start your docker containers make sure that they have \"namespace %slave_ip_with_mesos_dns%\" (replace string with IP address) in their /etc/resolv.conf files.</li>\n<li>if lets say name of an app is \"peek\" it should be reachable from other applications at peek.marathon.mesos</li>\n</ol>\n", "answer_id": 37519188, "last_activity_date": 1464590617, "creation_date": 1464590617, "score": 0, "owner": {"user_id": 574951, "profile_image": "https://www.gravatar.com/avatar/f622e884403fcf9cad23db9b7c3d1c1e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 543, "link": "https://stackoverflow.com/users/574951/ivan-a", "display_name": "ivan_a"}, "is_accepted": false, "question_id": 28626083}], "score": 4, "link": "https://stackoverflow.com/questions/28626083/haproxy-for-service-discovery-on-a-marathon-mesos-docker-linked-containers", "answer_count": 4, "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 3947, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 28626083}{"body": "<p>In a microservice stack that uses docker for container orchestration, consul for service discovery and mesos for container scheduling, there are two services that user facing (with GUI) requiring to be configured with HAProxy for load balancing.</p>\n\n<p>The question is, at which level should they be load-balanced. There are some implementations of LB that support each use case. dockercloud-haproxy, fabio with consul and marathon-lb if DC/OS is in place.</p>\n\n<p>What would be a selection criteria ?</p>\n", "is_answered": false, "tags": ["docker", "load-balancing", "mesosphere", "consul", "dcos"], "last_edit_date": 1467989234, "title": "HAProxy with docker, consul and mesos, which one to choose?", "last_activity_date": 1467989234, "answer_count": 1, "creation_date": 1467957764, "score": 0, "link": "https://stackoverflow.com/questions/38259876/haproxy-with-docker-consul-and-mesos-which-one-to-choose", "answers": [{"body": "<p>If your need is not that pressing you might want to wait until docker 1.12 is stabilised and use the included LB feature, which is pretty slick:\n<a href=\"https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/\" rel=\"nofollow\">https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/</a></p>\n", "answer_id": 38261034, "last_activity_date": 1467962555, "creation_date": 1467962555, "score": 0, "owner": {"user_id": 6561431, "profile_image": "https://i.stack.imgur.com/QNn4A.png?s=128&g=1", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/6561431/kniepbert", "display_name": "kniepbert"}, "is_accepted": false, "question_id": 38259876}], "owner": {"user_id": 1844510, "profile_image": "https://www.gravatar.com/avatar/4f4a07fc489174de50f7a659b26f0b54?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 69, "link": "https://stackoverflow.com/users/1844510/mihir-pandya", "display_name": "Mihir Pandya"}, "view_count": 249, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38259876}{"body": "<p>This is going to be a generic question.</p>\n\n<p>We are a young startup faced with the inevitable problem of scaling and during our research, Apache Mesos seemed like a good fit for our architecture, which is \u2013</p>\n\n<ul>\n<li>Core Scala based microservices, each responsible for dealing with a\npart of our database, which is mainly MySQL</li>\n<li>Middleware microservices,\nto deal with some other persistent data-storage systems like MongoDB,\nElasticsearch etc.</li>\n</ul>\n\n<p>Which basically means that we can containerise all of our services and ship them to a single datacenter which can then deploy these containers in a topographically agnostic way.</p>\n\n<p>What we are currently stumped by is \u2013</p>\n\n<ul>\n<li>Mesos doesn't seem to have any native support for MySQL </li>\n<li>Container based persistence seems awfully tricky and hard to manage/maintain.</li>\n</ul>\n\n<p>We'd like to continue using MySQL/MongoDB/ElasticSearch because migrating to Cassandra etc. at this stage (we are a small team) is too much of an overhead and hence not an option.\nWhat are the best strategies for this problem?</p>\n", "is_answered": true, "tags": ["mysql", "persistence", "mesos", "mesosphere"], "title": "Mesos & persistent storage using MySQL", "last_activity_date": 1455300734, "answer_count": 2, "creation_date": 1441011315, "score": 0, "link": "https://stackoverflow.com/questions/32307398/mesos-persistent-storage-using-mysql", "answers": [{"body": "<p>Mesos provide <a href=\"https://issues.apache.org/jira/browse/MESOS-1554\" rel=\"nofollow\">Persistent resources support for storage-like services</a>.</p>\n\n<p>If you want to use MySQL on mesos, please consider try <a href=\"https://github.com/apache/incubator-cotton\" rel=\"nofollow\">https://github.com/apache/incubator-cotton</a> </p>\n", "answer_id": 32327250, "last_activity_date": 1441097166, "creation_date": 1441097166, "score": 1, "owner": {"user_id": 891145, "profile_image": "https://www.gravatar.com/avatar/221cfd6267f65ba83aaa3d5ee6271291?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 548, "link": "https://stackoverflow.com/users/891145/haosdent", "accept_rate": 80, "display_name": "haosdent"}, "is_accepted": false, "question_id": 32307398}, {"body": "<p>After some research we decided not to try <a href=\"http://incubator.apache.org/projects/cotton.html\" rel=\"nofollow\">Cotton</a> but we're still sticking to deploying our services across a Mesos cluster. </p>\n\n<p>Instead of hosting our own MySQL database, we decided to outsource it to Amazon RDS. But we're now faced with problems like doing something for our other databases like MongoDB.</p>\n", "answer_id": 32327398, "last_activity_date": 1441097647, "creation_date": 1441097647, "score": 0, "owner": {"user_id": 1360368, "profile_image": "https://www.gravatar.com/avatar/7997d33ca6f47d0e48080d6f58a72443?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1926, "link": "https://stackoverflow.com/users/1360368/ashesh", "accept_rate": 64, "display_name": "Ashesh"}, "is_accepted": false, "question_id": 32307398}], "owner": {"user_id": 1360368, "profile_image": "https://www.gravatar.com/avatar/7997d33ca6f47d0e48080d6f58a72443?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1926, "link": "https://stackoverflow.com/users/1360368/ashesh", "accept_rate": 64, "display_name": "Ashesh"}, "view_count": 279, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 32307398}{"body": "<p>Which <strong>HTTP endpoint</strong> will help me to find all the active frameworks current resource utilization?</p>\n\n<p>We want this information because we want to dynamically scale Mesos cluster and our algorithm needs information regarding what resources each active framework is using.</p>\n", "is_answered": true, "title": "finding active framework current resource usage in mesos", "last_edit_date": 1456998862, "tags": ["mesos", "mesosphere"], "view_count": 249, "accepted_answer_id": 35766575, "last_activity_date": 1456998862, "answers": [{"body": "<p>I think to focus on the frameworks is not really what you would want to to. What you're after is probably the Mesos Slave utilization, which can be requested via calling</p>\n\n<pre><code>http://{mesos-master}:5050/master/state-summary\n</code></pre>\n\n<p>In the JSON answer, you'll find a <code>slaves</code> property which contains an array of slave objects:</p>\n\n<pre><code>{\n    \"hostname\": \"192.168.0.3\",\n    \"cluster\": \"mesos-hw-cluster\",\n    \"slaves\": [{\n        \"id\": \"bd9c29d7-8530-4c5b-8c50-5d2f60dffbf6-S2\",\n        \"pid\": \"slave(1)@192.168.0.1:5051\",\n        \"hostname\": \"192.168.0.1\",\n        \"registered_time\": 1456826950.99075,\n        \"resources\": {\n            \"cpus\": 12.0,\n            \"disk\": 1840852.0,\n            \"mem\": 63304.0,\n            \"ports\": \"[31000-32000]\"\n        },\n        \"used_resources\": {\n            \"cpus\": 5.75,\n            \"disk\": 0.0,\n            \"mem\": 14376.0,\n            \"ports\": \"[31000-31000, 31109-31109, 31267-31267, 31699-31699, 31717-31717, 31907-31907, 31979-31980]\"\n        },\n        \"offered_resources\": {\n            \"cpus\": 0.0,\n            \"disk\": 0.0,\n            \"mem\": 0.0\n        },\n        \"reserved_resources\": {},\n        \"unreserved_resources\": {\n            \"cpus\": 12.0,\n            \"disk\": 1840852.0,\n            \"mem\": 63304.0,\n            \"ports\": \"[31000-32000]\"\n        },\n        \"attributes\": {},\n        \"active\": true,\n        \"version\": \"0.27.1\",\n        \"TASK_STAGING\": 0,\n        \"TASK_STARTING\": 0,\n        \"TASK_RUNNING\": 7,\n        \"TASK_FINISHED\": 18,\n        \"TASK_KILLED\": 27,\n        \"TASK_FAILED\": 3,\n        \"TASK_LOST\": 0,\n        \"TASK_ERROR\": 0,\n        \"framework_ids\": [\"bd9c29d7-8530-4c5b-8c50-5d2f60dffbf6-0000\", \"bd9c29d7-8530-4c5b-8c50-5d2f60dffbf6-0002\"]\n    },\n    ...\n}\n</code></pre>\n\n<p>You could iterate over all the slave objects and calculate the overall ressource usage by summarizing the <code>resources</code> and then subtract the summary of the <code>used_resources</code>. </p>\n\n<p>See</p>\n\n<ul>\n<li><a href=\"http://mesos.apache.org/documentation/latest/endpoints/master/state-summary/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/endpoints/master/state-summary/</a></li>\n<li><a href=\"http://mesos.apache.org/documentation/latest/endpoints/\" rel=\"nofollow\">http://mesos.apache.org/documentation/latest/endpoints/</a></li>\n</ul>\n", "answer_id": 35766575, "last_activity_date": 1456992789, "creation_date": 1456992789, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 35765417}], "score": 0, "link": "https://stackoverflow.com/questions/35765417/finding-active-framework-current-resource-usage-in-mesos", "answer_count": 1, "owner": {"user_id": 5556904, "profile_image": "https://www.gravatar.com/avatar/40c9055e408af4149b47a63bfec2e19d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 43, "link": "https://stackoverflow.com/users/5556904/kovit-nisar", "display_name": "kovit nisar"}, "creation_date": 1456989076, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35765417}{"body": "<p>I am unable to run the jar fetched remotely via http in a chronos job.</p>\n\n<pre><code>{ \"schedule\": \"R/2017-07-08T09:12:00Z/PT1H\", \n\"name\": \"payment-history\", \n\"epsilon\": \"PT15M\", \n\"shell\": true,\n\"fetch\": [{\n \"uri\": \"http://&lt;remote host IP&gt;:80/payment-history.jar\",\n \"extract\": false,\n \"executable\": true,\n \"cache\": false\n}],\n\n \"command\": \"java -jar payment-history.jar all\",\n \"owner\": \"bob@airbnb.com\", \n \"async\": false\n}\n</code></pre>\n\n<p>I am able to post the json file via curl , the job schedules but on the mesos logs I see the below</p>\n\n<pre><code>Error: Unable to access jarfile payment-history.jar\n</code></pre>\n\n<p>I also tried using\n       the \"uris\" but it is deprecated and tried below</p>\n\n<pre><code>\"shell\" : false\n</code></pre>\n\n<p>but doesnt work\n, I referred <a href=\"https://mesos.github.io/chronos/docs/api.html#adding-a-scheduled-job\" rel=\"nofollow noreferrer\">this</a> documentation</p>\n\n<p>please suggest</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "mesos-chronos"], "last_edit_date": 1499584030, "title": "chronos not fetching remote file", "last_activity_date": 1499584030, "answer_count": 0, "creation_date": 1499512248, "score": 0, "link": "https://stackoverflow.com/questions/44985544/chronos-not-fetching-remote-file", "owner": {"user_id": 4478261, "profile_image": "https://i.stack.imgur.com/SppMh.png?s=128&g=1", "user_type": "registered", "reputation": 115, "link": "https://stackoverflow.com/users/4478261/anudeep", "accept_rate": 40, "display_name": "anudeep"}, "view_count": 32, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44985544}{"body": "<p>I have three machines M1, M2 &amp; M3. I deployed mesos-master, zookeeper and marathon on M1 And mesos-slave on M2 &amp; M3. However, on Mesos Gui, there are ZERO slaves being shown. Then I ran the command <strong>mesos-resolve <code>cat /etc/mesos/zk</code></strong> to check if slave is discovering the correct master. But no, it is incorrectly discovering 127.0.0.1:5050 as the master. Below are the logs for the above command :</p>\n\n<pre><code>2015-07-31 15:38:02,522:17271(0x7f538b7cf700):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=M1_IP:2181 sessionTimeout=10000 watcher=0x7f5392b130b0 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f5378003960 flags=0\n2015-07-31 15:38:02,525:17271(0x7f5386dba700):ZOO_INFO@check_events@1703: initiated connection to server [M1_IP:2181]\n2015-07-31 15:38:02,541:17271(0x7f5386dba700):ZOO_INFO@check_events@1750: session establishment complete on server [M1_IP:2181], sessionId=0x14ee590e0ec0008, negotiated timeout=10000\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nI0731 15:38:02.541931 17273 group.cpp:313] Group process (group(1)@127.0.0.1:53978) connected to ZooKeeper\nI0731 15:38:02.542022 17273 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0731 15:38:02.542045 17273 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0731 15:38:02.545756 17273 detector.cpp:138] Detected a new leader: (id='1')\nI0731 15:38:02.545891 17273 group.cpp:656] Trying to get '/mesos/info_0000000001' in ZooKeeper\nW0731 15:38:02.547034 17273 detector.cpp:444] Leading master master@127.0.0.1:5050 is using a Protobuf binary format when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0731 15:38:02.547114 17273 detector.cpp:481] A new leading master (UPID=master@127.0.0.1:5050) is detected\n</code></pre>\n\n<p>As the log indicates, I looked up the node value of /mesos/info_0000000001 in M1/zookeeper. It turned out to be something like this :</p>\n\n<pre><code>!20150801-152910-16777343-5050-765???'\"master@127.0.0.1:5050*\nmarathon-120.23.0\n</code></pre>\n\n<p>Mesos master setting : <strong>cat /etc/mesos/zk</strong></p>\n\n<pre><code>zk://M1_IP:2181/mesos\n</code></pre>\n\n<p>So as it looks like, mesos master at M1 some how not storing its absolute ip in zookeeper node. Can any one explain the strange behaviour.</p>\n", "is_answered": true, "tags": ["java", "apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_edit_date": 1484994451, "title": "Mesos cluster deployment with Marathon", "last_activity_date": 1484994451, "answer_count": 4, "creation_date": 1438459341, "score": 1, "link": "https://stackoverflow.com/questions/31765682/mesos-cluster-deployment-with-marathon", "answers": [{"body": "<p>You may want explicitly tell the Master what IP to bind to, see <code>--ip</code> flag.</p>\n", "answer_id": 31785814, "last_activity_date": 1438680634, "creation_date": 1438600553, "score": 3, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "last_edit_date": 1438680634, "question_id": 31765682}, {"body": "<p>In </p>\n\n<p><code>/etc/mess/zk</code> file, please mention your machine IP address.</p>\n\n<p>Ex:</p>\n\n<pre><code>zk://192.168.0.1:2181/mesos\n</code></pre>\n\n<p>Please reflect the same changes in  mesos slave.</p>\n", "answer_id": 32345247, "last_activity_date": 1441171779, "creation_date": 1441171779, "score": 1, "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "is_accepted": false, "question_id": 31765682}, {"body": "<p>It's a good practice to add the external interface IP to <code>/etc/mesos-master/ip</code>. Which will then get published correctly to zookeeper as opposed to the localhost ip. You should do the same for slaves as well.</p>\n", "answer_id": 35676637, "last_activity_date": 1456614642, "creation_date": 1456614642, "score": 0, "owner": {"user_id": 701260, "profile_image": "https://www.gravatar.com/avatar/660bb878ae25be5b78c87508f64e68f5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1419, "link": "https://stackoverflow.com/users/701260/eren-g%c3%bcven", "accept_rate": 80, "display_name": "Eren G\u00fcven"}, "is_accepted": false, "question_id": 31765682}, {"body": "<p>In my case, the problem was solved by replacing the loopback address (127.0.1.1) in /etc/hosts with the correct IP for eth0 (so that <code>hostname -i</code> returns the correct IP address). Then I restarted all the services and everything started working.  Of course this will break if the IP address changes.</p>\n\n<p>I didn't see anything about this in the Mesos install instructions (maybe I overlooked it) but I've had to do this same thing for Hadoop installs to work correctly.</p>\n", "answer_id": 36653454, "last_activity_date": 1460741510, "creation_date": 1460741510, "score": 0, "owner": {"user_id": 78656, "profile_image": "https://www.gravatar.com/avatar/d4aa26cf5db7a8fbf21d74228f16ca73?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 88, "link": "https://stackoverflow.com/users/78656/clark-updike", "accept_rate": 25, "display_name": "Clark Updike"}, "is_accepted": false, "question_id": 31765682}], "owner": {"user_id": 3901604, "profile_image": "https://www.gravatar.com/avatar/1802c2f1cdaff7ca69ad90b10550a7e1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 80, "link": "https://stackoverflow.com/users/3901604/nitin", "accept_rate": 33, "display_name": "Nitin"}, "view_count": 296, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 31765682}{"is_answered": true, "tags": ["mesos", "dcos"], "last_edit_date": 1496751675, "title": "DCOS/Mesos doesn&#39;t unreserve resources on framework delete", "last_activity_date": 1496751675, "answer_count": 1, "creation_date": 1496666176, "score": 1, "link": "https://stackoverflow.com/questions/44369075/dcos-mesos-doesnt-unreserve-resources-on-framework-delete", "accepted_answer_id": 44381831, "owner": {"user_id": 5672927, "profile_image": "https://www.gravatar.com/avatar/7ce7daa2121de3654ad9d3265662670c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 314, "link": "https://stackoverflow.com/users/5672927/milso", "accept_rate": 89, "display_name": "Milso"}, "view_count": 36, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44369075}{"body": "<p>I\u2019m now stumbling with manually deployment from Azure Container Registry to Azure Container Service DC/OS. </p>\n\n<p><strong>Problem 1</strong>: I followed the how-to articles from Microsoft.  <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-dcos-acr\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-dcos-acr</a>, the stdout in marathon application says the below error, (I pushed a asp.net core application)</p>\n\n<pre><code>System.ArgumentException: Http request Host is not specified\n   at Microsoft.ApplicationInsights.AspNetCore.Extensions.HttpRequestExtensions.GetUri(HttpRequest request)\n   at Microsoft.ApplicationInsights.AspNetCore.DiagnosticListeners.HostingDiagnosticListener.EndRequest(HttpContext httpContext, Int64 timestamp)\n   at Proxy_Method_From_&lt;&gt;f__AnonymousType0`2_To_Void OnEndRequest(Microsoft.AspNetCore.Http.HttpContext, Int64)(Object , Object , IProxyFactory )\n   at Microsoft.Extensions.DiagnosticAdapter.DiagnosticSourceAdapter.Write(String diagnosticName, Object parameters)\n   at Microsoft.Extensions.DiagnosticAdapter.DiagnosticSourceAdapter.System.IObserver&lt;System.Collections.Generic.KeyValuePair&lt;System.String,System.Object&gt;&gt;.OnNext(KeyValuePair`2 value)\n   at System.Diagnostics.DiagnosticListener.Write(String name, Object value)\n   at Microsoft.AspNetCore.Hosting.Internal.HostingApplication.DisposeContext(Context context, Exception exception)\n   at Microsoft.AspNetCore.Server.Kestrel.Internal.Http.Frame`1.&lt;RequestProcessingAsync&gt;d__2.MoveNext()\n</code></pre>\n\n<p>Who do you know I can approach for getting error clear out?</p>\n\n<p><strong>Problem 2:</strong>\nWhen I somehow pushed another image per VSTS build with agent \"Hosted VS2017\", and created another marathon app, now the error is new,</p>\n\n<pre><code>Failed to launch container: Failed to run 'docker -H unix:///var/run/docker.sock pull *****.azurecr.io/travel.*****.*****.web:latest': exited with status 1; stderr='unknown blob '\n</code></pre>\n\n<p>Where's error come from?</p>\n\n<p><strong>To answer Problem 2</strong>: it's caused by container built per \"Hosted VS2017\" is windows container, to clear this error, it's has to be built per \"Hosted Linux Preview\"</p>\n", "is_answered": false, "tags": ["c#", "azure", "acs", "dcos"], "last_edit_date": 1497927085, "title": "Problems got from deploy from ACR to ACS DC/OS", "last_activity_date": 1497927085, "answer_count": 0, "creation_date": 1497427808, "score": 0, "link": "https://stackoverflow.com/questions/44539062/problems-got-from-deploy-from-acr-to-acs-dc-os", "owner": {"user_id": 343117, "profile_image": "https://www.gravatar.com/avatar/45499efdf89d65313db4820d84ea7a01?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 615, "link": "https://stackoverflow.com/users/343117/elaine", "accept_rate": 75, "display_name": "Elaine"}, "view_count": 37, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44539062}{"body": "<p>I have Marathon/Mesos master set up on a single AWS EC2 instance. I also have a Mesos agent running on a non-AWS external machine <strike>with strict firewall rules</strike> (all ports are open between the two).</p>\n\n<p>The agent registers itself with the master correctly. When I start a Marathon app it creates a Docker task. The Docker image specified is successfully pulled from Docker Hub on the agent machine, <strong>but it never runs</strong> for some reason... I don't see any relevant information in the Mesos master logs; only that the 'task failed'. When I run the Docker image on the Mesos agent machine manually (with the parameters I specified in my Marathon configuration) it runs perfectly fine. I have the same configuration running on different machines in a local network and Marathon deploys apps without any issues. I'm not sure what to try next.</p>\n\n<p>Does the Mesos agent need to connect directly to Marathon for some reason? I assumed that communication with the Mesos master was all that was needed.</p>\n\n<p>Mesos task stderr (updated 3/24/2017):</p>\n\n<pre><code>I0324 16:17:22.286581  7304 fetcher.cpp:498] Fetcher Info: {\"cache_directory\":\"\\/tmp\\/mesos\\/fetch\\/slaves\\/5086ccee-b936-4c32-884e-479a75e6a13e-S0\",\"items\":[{\"action\":\"BYPASS_CACHE\",\"uri\":{\"cache\":false,\"executable\":false,\"extract\":true,\"value\":\"file:\\/\\/\\/etc\\/mesos\\/auth\\/docker.tar.gz\"}}],\"sandbox_directory\":\"\\/var\\/lib\\/mesos\\/slaves\\/5086ccee-b936-4c32-884e-479a75e6a13e-S0\\/frameworks\\/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\\/executors\\/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122\\/runs\\/49ac20eb-8d9a-4605-903c-ffe700475308\"}\nI0324 16:17:22.290792  7304 fetcher.cpp:409] Fetching URI 'file:///etc/mesos/auth/docker.tar.gz'\nI0324 16:17:22.290828  7304 fetcher.cpp:250] Fetching directly into the sandbox directory\nI0324 16:17:22.290864  7304 fetcher.cpp:187] Fetching URI 'file:///etc/mesos/auth/docker.tar.gz'\nI0324 16:17:22.290887  7304 fetcher.cpp:167] Copying resource with command:cp '/etc/mesos/auth/docker.tar.gz' '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308/docker.tar.gz'\nI0324 16:17:22.295295  7304 fetcher.cpp:84] Extracting with command: tar -C '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308' -xf '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308/docker.tar.gz'\nI0324 16:17:22.302006  7304 fetcher.cpp:92] Extracted '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308/docker.tar.gz' into '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308'\nI0324 16:17:22.302070  7304 fetcher.cpp:547] Fetched 'file:///etc/mesos/auth/docker.tar.gz' to '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_eureka-discovery-service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308/docker.tar.gz'\nI0324 16:17:23.632253  7328 openssl.cpp:416] CA file path is unspecified! NOTE: Set CA file path with LIBPROCESS_SSL_CA_FILE=&lt;filepath&gt;\nI0324 16:17:23.632388  7328 openssl.cpp:421] CA directory path unspecified! NOTE: Set CA directory path with LIBPROCESS_SSL_CA_DIR=&lt;dirpath&gt;\nI0324 16:17:23.632400  7328 openssl.cpp:426] Will not verify peer certificate!\nNOTE: Set LIBPROCESS_SSL_VERIFY_CERT=1 to enable peer certificate verification\nI0324 16:17:23.632407  7328 openssl.cpp:432] Will only verify peer certificate if presented!\nNOTE: Set LIBPROCESS_SSL_REQUIRE_CERT=1 to require peer certificate verification\nI0324 16:17:23.636519  7328 exec.cpp:162] Version: 1.1.0\nI0324 16:19:30.956297  7332 exec.cpp:496] Agent exited ... shutting down\nE0324 16:19:30.956517  7337 process.cpp:2154] Failed to shutdown socket with fd 7: Transport endpoint is not connected\n</code></pre>\n\n<p>Mesos agent log (updated 3/24/2017):</p>\n\n<pre><code>I0324 16:16:04.465209  7244 linux_launcher.cpp:150] Using /sys/fs/cgroup/freezer as the freezer hierarchy for the Linux launcher\nI0324 16:16:04.469977  7277 slave.cpp:208] Mesos agent started on (1)@external.public.ip.addr:5051\nI0324 16:16:04.470039  7277 slave.cpp:209] Flags at startup: --advertise_ip=\"external.public.ip.addr\" --appc_simple_discovery_uri_prefix=\"http://\" --appc_store_dir=\"/tmp/mesos/store/appc\" --attributes=\"node:external-hostname\" --authenticate_http_readonly=\"false\" --authenticate_http_readwrite=\"false\" --authenticatee=\"crammd5\" --authentication_backoff_factor=\"1secs\" --authorizer=\"local\" --cgroups_cpu_enable_pids_and_tids_count=\"false\" --cgroups_enable_cfs=\"false\" --cgroups_hierarchy=\"/sys/fs/cgroup\" --cgroups_limit_swap=\"false\" --cgroups_root=\"mesos\" --container_disk_watch_interval=\"15secs\" --containerizers=\"docker,mesos\" --credential=\"/etc/mesos/auth/credential\" --default_role=\"*\" --disk_watch_interval=\"1mins\" --docker=\"docker\" --docker_kill_orphans=\"true\" --docker_registry=\"https://registry-1.docker.io\" --docker_remove_delay=\"6hrs\" --docker_socket=\"/var/run/docker.sock\" --docker_stop_timeout=\"0ns\" --docker_store_dir=\"/tmp/mesos/store/docker\" --docker_volume_checkpoint_dir=\"/var/run/mesos/isolators/docker/volume\" --enforce_container_disk_quota=\"false\" --executor_environment_variables=\"{\"SSL_CERT_FILE\":\"\\/etc\\/mesos\\/ssl\\/mesos.pem\",\"SSL_ENABLED\":\"true\",\"SSL_KEY_FILE\":\"\\/etc\\/mesos\\/ssl\\/mesos.key\"}\" --executor_registration_timeout=\"5mins\" --executor_shutdown_grace_period=\"5secs\" --fetcher_cache_dir=\"/tmp/mesos/fetch\" --fetcher_cache_size=\"2GB\" --frameworks_home=\"\" --gc_delay=\"1weeks\" --gc_disk_headroom=\"0.1\" --hadoop_home=\"\" --help=\"false\" --hostname_lookup=\"true\" --http_authenticators=\"basic\" --http_command_executor=\"false\" --image_provisioner_backend=\"copy\" --initialize_driver_logging=\"true\" --isolation=\"posix/cpu,posix/mem\" --launcher=\"linux\" --launcher_dir=\"/usr/libexec/mesos\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --master=\"zk://aws.public.ip.addr:2181/mesos\" --max_completed_executors_per_framework=\"150\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --port=\"5051\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registration_backoff_factor=\"1secs\" --resources=\"ports:[45000-45300]\" --revocable_cpu_low_priority=\"true\" --runtime_dir=\"/var/run/mesos\" --sandbox_directory=\"/mnt/mesos/sandbox\" --strict=\"true\" --switch_user=\"true\" --systemd_enable_support=\"true\" --systemd_runtime_directory=\"/run/systemd/system\" --version=\"false\" --work_dir=\"/var/lib/mesos\"\nI0324 16:16:04.470541  7277 credentials.hpp:86] Loading credential for authentication from '/etc/mesos/auth/credential'\nI0324 16:16:04.475219  7277 slave.cpp:346] Agent using credential for: user\nI0324 16:16:04.476274  7277 slave.cpp:533] Agent resources: ports(*):[45000-45300]; cpus(*):2; mem(*):1000; disk(*):17933\nI0324 16:16:04.476395  7277 slave.cpp:541] Agent attributes: [ node=external-hostname ]\nI0324 16:16:04.476418  7277 slave.cpp:546] Agent hostname: external-hostname.com\nI0324 16:16:04.478091  7273 state.cpp:57] Recovering state from '/var/lib/mesos/meta'\nI0324 16:16:04.478227  7273 state.cpp:698] No committed checkpointed resources found at '/var/lib/mesos/meta/resources/resources.info'\nI0324 16:16:04.478538  7273 state.cpp:100] Failed to find the latest agent from '/var/lib/mesos/meta'\nI0324 16:16:04.478847  7273 status_update_manager.cpp:203] Recovering status update manager\nI0324 16:16:04.479176  7274 docker.cpp:764] Recovering Docker containers\nI0324 16:16:04.479267  7273 containerizer.cpp:555] Recovering containerizer\nI0324 16:16:04.483211  7273 provisioner.cpp:253] Provisioner recovery complete\nI0324 16:16:04.556633  7273 slave.cpp:5281] Finished recovery\nI0324 16:16:04.557209  7273 slave.cpp:5314] Garbage collecting old agent 58f98804-d979-414c-99f0-b9453a64d133-S0\nI0324 16:16:04.557435  7273 slave.cpp:5314] Garbage collecting old agent 58f98804-d979-414c-99f0-b9453a64d133-S1\nI0324 16:16:04.557416  7271 gc.cpp:55] Scheduling '/var/lib/mesos/slaves/58f98804-d979-414c-99f0-b9453a64d133-S0' for gc 6.99999354992days in the future\nI0324 16:16:04.557569  7271 gc.cpp:55] Scheduling '/var/lib/mesos/meta/slaves/58f98804-d979-414c-99f0-b9453a64d133-S0' for gc 6.99999354837926days in the future\nI0324 16:16:04.557613  7271 gc.cpp:55] Scheduling '/var/lib/mesos/slaves/58f98804-d979-414c-99f0-b9453a64d133-S1' for gc 6.99999354770963days in the future\nI0324 16:16:04.557642  7271 gc.cpp:55] Scheduling '/var/lib/mesos/meta/slaves/58f98804-d979-414c-99f0-b9453a64d133-S1' for gc 6.99999354741926days in the future\nI0324 16:16:04.567785  7273 group.cpp:340] Group process (zookeeper-group(1)@external.public.ip.addr:5051) connected to ZooKeeper\nI0324 16:16:04.567862  7273 group.cpp:828] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0324 16:16:04.567885  7273 group.cpp:418] Trying to create path '/mesos' in ZooKeeper\nI0324 16:16:04.651988  7272 detector.cpp:152] Detected a new leader: (id='17')\nI0324 16:16:04.652292  7272 group.cpp:697] Trying to get '/mesos/json.info_0000000017' in ZooKeeper\nI0324 16:16:04.694649  7272 zookeeper.cpp:259] A new leading master (UPID=master@aws.public.ip.addr:5050) is detected\nI0324 16:16:04.694806  7272 slave.cpp:915] New master detected at master@aws.public.ip.addr:5050\nI0324 16:16:04.694839  7272 slave.cpp:974] Authenticating with master master@aws.public.ip.addr:5050\nI0324 16:16:04.694878  7275 status_update_manager.cpp:177] Pausing sending status updates\nI0324 16:16:04.695226  7272 slave.cpp:985] Using default CRAM-MD5 authenticatee\nI0324 16:16:04.695358  7272 slave.cpp:947] Detecting new master\nI0324 16:16:04.695709  7272 authenticatee.cpp:97] Initializing client SASL\nI0324 16:16:04.697775  7272 authenticatee.cpp:121] Creating new client SASL connection\nI0324 16:16:04.994292  7275 authenticatee.cpp:213] Received SASL authentication mechanisms: CRAM-MD5\nI0324 16:16:04.994408  7275 authenticatee.cpp:239] Attempting to authenticate with mechanism 'CRAM-MD5'\nI0324 16:16:05.073065  7270 authenticatee.cpp:259] Received SASL authentication step\nI0324 16:16:05.119057  7274 authenticatee.cpp:299] Authentication success\nI0324 16:16:05.119209  7274 slave.cpp:1069] Successfully authenticated with master master@aws.public.ip.addr:5050\nI0324 16:16:05.167603  7270 slave.cpp:1115] Registered with master master@aws.public.ip.addr:5050; given agent ID 5086ccee-b936-4c32-884e-479a75e6a13e-S0\nI0324 16:16:05.167878  7277 status_update_manager.cpp:184] Resuming sending status updates\nI0324 16:16:05.168328  7270 slave.cpp:1175] Forwarding total oversubscribed resources {}\nI0324 16:17:04.477218  7276 slave.cpp:5044] Current disk usage 13.80%. Max allowed age: 5.334189423043843days\nI0324 16:17:22.210543  7277 slave.cpp:1539] Got assigned task 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' for framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:17:22.212566  7277 slave.cpp:1701] Launching task 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' for framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:17:22.214239  7277 paths.cpp:536] Trying to chown '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308' to user 'root'\nI0324 16:17:22.222681  7277 slave.cpp:6179] Launching executor 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000 with resources cpus(*):0.1; mem(*):32 in work directory '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308'\nI0324 16:17:22.224074  7277 slave.cpp:1987] Queued task 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' for executor 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:17:22.230206  7277 docker.cpp:1022] Starting container '49ac20eb-8d9a-4605-903c-ffe700475308' for task 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' (and executor 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122') of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:17:23.576908  7271 docker.cpp:670] Checkpointing pid 7328 to '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308/pids/forked.pid'\nI0324 16:18:04.478448  7270 slave.cpp:5044] Current disk usage 13.80%. Max allowed age: 5.334151467743322days\nI0324 16:19:04.479935  7273 slave.cpp:5044] Current disk usage 13.80%. Max allowed age: 5.334151467743322days\nI0324 16:19:30.984578  7271 docker.cpp:2164] Executor for container 49ac20eb-8d9a-4605-903c-ffe700475308 has exited\nI0324 16:19:30.984671  7271 docker.cpp:1887] Destroying container 49ac20eb-8d9a-4605-903c-ffe700475308\nI0324 16:19:30.984764  7271 docker.cpp:2014] Running docker stop on container 49ac20eb-8d9a-4605-903c-ffe700475308\nI0324 16:19:30.985744  7273 slave.cpp:4542] Executor 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000 exited with status 0\nI0324 16:19:30.987206  7273 slave.cpp:3634] Handling status update TASK_FAILED (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000 from @0.0.0.0:0\nW0324 16:19:30.987942  7270 docker.cpp:1411] Ignoring updating unknown container 49ac20eb-8d9a-4605-903c-ffe700475308\nI0324 16:19:30.988471  7271 status_update_manager.cpp:323] Received status update TASK_FAILED (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:30.988976  7271 status_update_manager.cpp:832] Checkpointing UPDATE for status update TASK_FAILED (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:30.989449  7275 slave.cpp:4051] Forwarding the update TASK_FAILED (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000 to master@aws.public.ip.addr:5050\nI0324 16:19:31.067975  7272 status_update_manager.cpp:395] Received status update acknowledgement (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:31.068097  7272 status_update_manager.cpp:832] Checkpointing ACK for status update TASK_FAILED (UUID: a4edf8e3-33db-4d76-95c4-12e1ad154b84) for task external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122 of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:31.068485  7272 slave.cpp:4646] Cleaning up executor 'external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:31.068881  7275 gc.cpp:55] Scheduling '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308' for gc 6.99999920398222days in the future\nI0324 16:19:31.068966  7272 slave.cpp:4734] Cleaning up framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:31.068994  7275 gc.cpp:55] Scheduling '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' for gc 6.99999920297481days in the future\nI0324 16:19:31.069028  7275 gc.cpp:55] Scheduling '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122/runs/49ac20eb-8d9a-4605-903c-ffe700475308' for gc 6.99999920246518days in the future\nI0324 16:19:31.069054  7275 gc.cpp:55] Scheduling '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.94f42881-10df-11e7-97c5-be1a04dcc122' for gc 6.99999920205926days in the future\nI0324 16:19:31.069083  7275 gc.cpp:55] Scheduling '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000' for gc 6.99999920099556days in the future\nI0324 16:19:31.069087  7272 status_update_manager.cpp:285] Closing status update streams for framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:31.069116  7275 gc.cpp:55] Scheduling '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000' for gc 6.99999920064889days in the future\nI0324 16:19:32.085212  7275 slave.cpp:1539] Got assigned task 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' for framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:32.086843  7275 gc.cpp:83] Unscheduling '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000' from gc\nI0324 16:19:32.086974  7275 gc.cpp:83] Unscheduling '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000' from gc\nI0324 16:19:32.087297  7274 slave.cpp:1701] Launching task 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' for framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:32.089426  7274 paths.cpp:536] Trying to chown '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122/runs/4de6d12d-a313-4921-b40b-245b57b2a886' to user 'root'\nI0324 16:19:32.098151  7274 slave.cpp:6179] Launching executor 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000 with resources cpus(*):0.1; mem(*):32 in work directory '/var/lib/mesos/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122/runs/4de6d12d-a313-4921-b40b-245b57b2a886'\nI0324 16:19:32.100893  7274 slave.cpp:1987] Queued task 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' for executor 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:32.106264  7277 docker.cpp:1022] Starting container '4de6d12d-a313-4921-b40b-245b57b2a886' for task 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122' (and executor 'external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122') of framework 3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000\nI0324 16:19:33.403033  7273 docker.cpp:670] Checkpointing pid 7367 to '/var/lib/mesos/meta/slaves/5086ccee-b936-4c32-884e-479a75e6a13e-S0/frameworks/3b9e3459-97f0-4f98-8510-50bdf55d4d7b-0000/executors/external-hostname_service.e2757782-10df-11e7-97c5-be1a04dcc122/runs/4de6d12d-a313-4921-b40b-245b57b2a886/pids/forked.pid'\nI0324 16:20:04.481197  7271 slave.cpp:5044] Current disk usage 13.80%. Max allowed age: 5.334241611582060days\n</code></pre>\n\n<p>For marathon logs, see <strong><a href=\"https://groups.google.com/forum/#!topic/marathon-framework/AXnu2QzW5E8\" rel=\"nofollow noreferrer\">HERE</a></strong> (I reached the character limit for this post)</p>\n\n<p>Versions: Marathon 1.3.6 and Mesos 1.1.0</p>\n\n<p>3/24/2017 Update notes: This problem is exclusive to having Marathon and the Mesos master on an AWS EC2 instance. If I move them to some other external machine I don't have any issues. I'm <em>guessing</em> that at some point in the process Mesos is using the EC2's private ip address even though I specify its public ip address with the flag <em>advertise_ip</em>.</p>\n", "is_answered": false, "tags": ["amazon-web-services", "amazon-ec2", "mesos", "marathon", "mesosphere"], "last_edit_date": 1490401356, "title": "AWS EC2 Marathon-Mesos Failing to Run Docker Container", "last_activity_date": 1490401356, "answer_count": 0, "creation_date": 1486583740, "score": 0, "link": "https://stackoverflow.com/questions/42122423/aws-ec2-marathon-mesos-failing-to-run-docker-container", "owner": {"user_id": 3671374, "profile_image": "https://i.stack.imgur.com/R0wts.jpg?s=128&g=1", "user_type": "registered", "reputation": 46, "link": "https://stackoverflow.com/users/3671374/sean-nelson", "accept_rate": 83, "display_name": "Sean Nelson"}, "view_count": 113, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42122423}{"is_answered": false, "tags": ["haproxy", "grpc", "marathon", "mesosphere", "grpc-java"], "last_edit_date": 1501677900, "title": "Experiencing &quot;Connection reset by peer&quot; while using grpc on Mesosphere Marathon", "last_activity_date": 1501688828, "answer_count": 0, "creation_date": 1501606502, "score": 0, "link": "https://stackoverflow.com/questions/45443630/experiencing-connection-reset-by-peer-while-using-grpc-on-mesosphere-marathon", "owner": {"user_id": 497398, "profile_image": "https://www.gravatar.com/avatar/1dac2c810e7a6d0787aadc020caa4d71?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2260, "link": "https://stackoverflow.com/users/497398/mfirry", "accept_rate": 41, "display_name": "mfirry"}, "view_count": 61, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45443630}{"body": "<p>I am trying to write a framework on top of Mesos and so far I was able to download Mesos for Ubuntu and start a master and slave on a single machine.</p>\n\n<p>I want to build a Mesos framework using Python, should I use the HTTP API or the native API? What is the difference between them?</p>\n\n<p>I was able to find no documentation on the Python native API, except for some examples.</p>\n\n<p>The HTTP API has documentation but no examples on how to use it. Should I be building a web service if I choose to use the HTTP API? </p>\n", "is_answered": true, "title": "Mesos HTTP API vs Native API", "tags": ["mesos", "mesosphere"], "last_activity_date": 1470056874, "accepted_answer_id": 38699760, "creation_date": 1469746438, "answers": [{"body": "<p><strong>You should use HTTP API</strong></p>\n\n<p>Native API is easiest way to build Mesos Framework. Just include lib in your project and implement interfaces. Although it comes with some limitations:</p>\n\n<ul>\n<li>Native API is no logger extended, new features goes only to HTTP API e.g., Maintenance Mode <a href=\"https://issues.apache.org/jira/browse/MESOS-2063\" rel=\"nofollow\">MESOS-2063</a></li>\n<li>Native API require mesoslib to be available on system. This makes hard coupling between framework and platform it runs on. With HTTP API you can run your framework on any system no needed to load mesoslib.</li>\n</ul>\n\n<p>Documetnation for HTTP API exists <a href=\"http://mesos.apache.org/documentation/latest/scheduler-http-api/\" rel=\"nofollow\">here</a>. It's language agnostic. So there are no examples in python, rather raw HTTP requests. But there are some tutorials how to use it. I can recomend one givien by Marco Massenzi at MesosCon EU 2015\n<a href=\"https://youtu.be/G7xfEs0lX5U?list=PLGeM09tlguZS6MhlSZDbf-gANWdKgje0I\" rel=\"nofollow\">Video</a>\n<a href=\"https://github.com/massenz/zk-mesos/blob/develop/notebooks/Demo-API.ipynb\" rel=\"nofollow\">Code</a>\n<a href=\"https://events.linuxfoundation.org/sites/events/files/slides/MesosCon%20EU%20-%20HTTP%20API%20Framework.pdf\" rel=\"nofollow\">Slides</a></p>\n", "answer_id": 38699760, "last_activity_date": 1470056874, "creation_date": 1470056874, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 38648010}], "score": 0, "link": "https://stackoverflow.com/questions/38648010/mesos-http-api-vs-native-api", "answer_count": 1, "owner": {"user_id": 812461, "profile_image": "https://www.gravatar.com/avatar/819a82c94b061b6a30dd2a24203b3a78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1086, "link": "https://stackoverflow.com/users/812461/yeshwanth-venkatesh", "accept_rate": 97, "display_name": "Yeshwanth Venkatesh"}, "view_count": 104, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38648010}{"is_answered": true, "tags": ["dcos"], "title": "Unable to install dcos-cli on Mac OSX", "last_activity_date": 1474367835, "answer_count": 1, "creation_date": 1474323316, "score": 2, "link": "https://stackoverflow.com/questions/39582915/unable-to-install-dcos-cli-on-mac-osx", "owner": {"user_id": 918133, "profile_image": "https://i.stack.imgur.com/DeoyK.jpg?s=128&g=1", "user_type": "registered", "reputation": 2924, "link": "https://stackoverflow.com/users/918133/pkout", "accept_rate": 62, "display_name": "pkout"}, "view_count": 276, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 39582915}{"body": "<p>I have been trying to learn spark on mesos, but the spark-shell just keeps on ignoring the offers. Here is my setup:</p>\n\n<p>All the components are in the same subnet</p>\n\n<ul>\n<li><p>1 mesos master  on EC2 instance (t2.micro)</p>\n\n<p>command: <code>mesos-master  --work_dir=/tmp/abc --hostname=&lt;public IP&gt;</code></p></li>\n<li><p>2 mesos agents (each with 4 cores, 16 GB ram and 30 GB disk space)</p>\n\n<p>command: <code>mesos-slave --master=\"&lt;private IP of master&gt;:5050\" --hostname=\"&lt;private IP of slave&gt;\" --work_dir=/tmp/abc</code></p></li>\n<li><p>1 spark-shell (client) on ec2 instance (t2.micro)\nI have set the following environment variables on this instance before launching the spark-shell</p>\n\n<pre><code>export MESOS_NATIVE_JAVA_LIBRARY=/usr/lib/libmesos.so\nexport SPARK_EXECUTOR_URI=local://home/ubuntu/spark-2.1.1-bin-hadoop2.7.tgz\n</code></pre>\n\n<p>and then I launch the the spark-shell as follows</p>\n\n<pre><code>./bin/spark-shell --master mesos://172.31.1.93:5050 \n</code></pre>\n\n<p>(private IP of the master)</p>\n\n<p>I have ensured that <code>spark-2.1.1-bin-hadoop2.7.tgz</code> is placed in\n<code>/home/ubuntu</code> on both the agents, before starting the spark shell.</p></li>\n</ul>\n\n<p>Once the spark-shell is up, I run the simplest program possible</p>\n\n<pre><code>val f = sc.textFile (\"/tmp/ok.txt\");\nf.count()\n</code></pre>\n\n<p>.. and I keep getting the following logs on spark-shell</p>\n\n<pre><code> (0 + 0) / 2]17/05/21 15:13:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n17/05/21 15:13:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n17/05/21 15:14:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n</code></pre>\n\n<p>Master side logs: (these logs I see even before doing anything inside spark-shell and they keep coming even after I have run the above code in the spark shell)</p>\n\n<pre><code>I0521 15:14:12.949108 10166 master.cpp:6992] Sending 2 offers to framework 64c1ef67-9e4f-4236-bb86-80d7aaab540f-0000 (Spark shell) at scheduler-7a375e65-7a0d-4267-befa-e69937404d5f@172.31.1.203:45596\nI0521 15:14:12.955731 10164 master.cpp:4731] Processing DECLINE call for offers: [ 64c1ef67-9e4f-4236-bb86-80d7aaab540f-O34 ] for framework 64c1ef67-9e4f-4236-bb86-80d7aaab540f-0000 (Spark shell) at scheduler-7a375e65-7a0d-4267-befa-e69937404d5f@172.31.1.203:45596\nI0521 15:14:12.956130 10167 master.cpp:4731] Processing DECLINE call for offers: [ 64c1ef67-9e4f-4236-bb86-80d7aaab540f-O35 ] for framework 64c1ef67-9e4f-4236-bb86-80d7aaab540f-0000 (Spark shell) at scheduler-7a375e65-7a0d-4267-befa-e69937404d5f@172.31.1.203:45596\n</code></pre>\n\n<p>I am using Mesos 1.2.0 and spark 2.1.1 on Ubuntu 16.04. I have verified by writing a small node.js based http client and the offers from the master seem fine. What possibly is going wrong here?</p>\n", "is_answered": true, "title": "spark-shell declining offers from mesos master", "last_edit_date": 1495443990, "tags": ["apache-spark", "mesos", "mesosphere"], "view_count": 77, "accepted_answer_id": 44127289, "last_activity_date": 1495531925, "answers": [{"body": "<p>OK, There were two problems here. </p>\n\n<ol>\n<li><p>The <code>SPARK_EXECUTOR_URI</code> was <code>local</code>, so changed it to <code>http</code>. <code>local</code> I guess is for hadoop (correct me here incase). </p></li>\n<li><p>After changing the URI to <code>local</code> , the netty blockmanager service that runs as a part of spark executor launched by mesos-executor (as a task, coarse mode) which is launched by Mesos Containerizer which is launched by mesos-agent, used to fail trying to bind to the public IP because I had passed the hostname as the public IP to the mesos-agent, which is bound to fail in EC2.  In fact, I was passing private IP  at first  but don't remember why I changed the hostname to public IP. Probably, to check for the sandbox logs I guess. The Mesos master was redirecting it to the mesos-agent's private IP preventing me to see the stderr logs. (I am located outside the EC2 VPC).  Note, the question above has private IP being passed to the agent, which is correct. Originally, The question above was posted  for the first problem.</p></li>\n</ol>\n", "answer_id": 44127289, "last_activity_date": 1495531925, "creation_date": 1495520860, "score": 0, "owner": {"user_id": 2686821, "profile_image": "https://www.gravatar.com/avatar/5dd46afe4f5a75f2667569582b20ac9b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 457, "link": "https://stackoverflow.com/users/2686821/soupybionics", "accept_rate": 54, "display_name": "soupybionics"}, "is_accepted": true, "last_edit_date": 1495531925, "question_id": 44100808}], "score": 0, "link": "https://stackoverflow.com/questions/44100808/spark-shell-declining-offers-from-mesos-master", "answer_count": 1, "owner": {"user_id": 2686821, "profile_image": "https://www.gravatar.com/avatar/5dd46afe4f5a75f2667569582b20ac9b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 457, "link": "https://stackoverflow.com/users/2686821/soupybionics", "accept_rate": 54, "display_name": "soupybionics"}, "creation_date": 1495394049, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44100808}{"is_answered": true, "tags": ["ubuntu-14.04", "apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_edit_date": 1453380463, "title": "Mesosphere - High Availability Cluster failing to elect leader, but logs show no errors and cannot seem to force a leader election", "last_activity_date": 1453380463, "answer_count": 1, "creation_date": 1443799314, "score": 3, "link": "https://stackoverflow.com/questions/32910539/mesosphere-high-availability-cluster-failing-to-elect-leader-but-logs-show-no", "owner": {"user_id": 2997644, "profile_image": "https://graph.facebook.com/1419960053/picture?type=large", "user_type": "registered", "reputation": 474, "link": "https://stackoverflow.com/users/2997644/yburyug", "accept_rate": 38, "display_name": "yburyug"}, "view_count": 487, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 32910539}{"body": "<p>I\u2019m building an Ansible recipe to deploy a mesos/marathon cluster (<a href=\"https://github.com/gridpocket/ansible-mesos-cluster\" rel=\"nofollow\">https://github.com/gridpocket/ansible-mesos-cluster</a>).  </p>\n\n<p>Once everything is setup, the mesos and marathon ui are up but I have 2 problems:<br>\n  - from the mesos ui I cannot see any slave registered<br>\n  - the same ui also indicates \"No master is currently leading...\"</p>\n\n<p>The setup is the following one:<br>\n- 3 mesos master (192.168.1.191, 192, 193): each running mesos-master, zookeeper, marathon<br>\n- 3 mesos slaves (192.168.1.194, 195, 196): each running mesos-slave, docker</p>\n\n<h1>Slaves configuration</h1>\n\n<p>In each slave:</p>\n\n<pre><code>/etc/mesos/zk:    \nzk://192.168.1.191:2181,192.168.1.192:2181,192.168.1.193:2181/mesos\n</code></pre>\n\n<h1>Masters configuration</h1>\n\n<p>On Each master:  </p>\n\n<pre><code>/etc/mesos/zk: \nzk://192.168.1.191:2181,192.168.1.192:2181,192.168.1.193:2181/mesos\n\n/etc/mesos-master/quorum:      \n2\n\n/etc/mesos-master/hostname and /etc/mesos-master/ip\nIP_OF_THE_MASTER\n</code></pre>\n\n<p>Am I missing something in the configuration ?</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>I rebuilt the whole cluster and corrected a zookeeper configuration (dataDir). Now,<br>\n  - mesos master interface is working and indicates the master node<br>\n  - marathon ui is working  </p>\n\n<p>On a slave machine, the mesos-slave process stops as soon as I start it.</p>\n\n<p>The mesos-slave log is not very verbose about this problem:   </p>\n\n<pre><code>Log file created at: 2015/07/09 15:51:15\nRunning on machine: vagrant-ubuntu-trusty-64\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nI0709 15:51:15.487542  8133 logging.cpp:172] INFO level logging started!\nI0709 15:51:15.488011  8133 main.cpp:156] Build: 2015-05-05 06:15:50 by root\nI0709 15:51:15.488081  8133 main.cpp:158] Version: 0.22.1\nI0709 15:51:15.488137  8133 main.cpp:161] Git tag: 0.22.1\nI0709 15:51:15.488190  8133 main.cpp:165] Git SHA: d6309f92a7f9af3ab61a878403e3d9c284ea87e0\n</code></pre>\n\n<p><strong>EDIT 2</strong></p>\n\n<p>When I start a slave manually, indicating the zk string, the slave starts correctly:</p>\n\n<pre><code>sudo /usr/sbin/mesos-slave --master=zk://192.168.1.191:2181,192.168.1.192:2181,192.168.1.193:2181/mesos\n</code></pre>\n\n<p>But the \"sudo service mesos-slave start\" does not enable to start the slave. </p>\n\n<p><strong>EDIT 3</strong></p>\n\n<p>I've changed the state from \"latest\" to \"present\" in the ansible playbook:</p>\n\n<pre><code>- name: install mesos + zookeeper\n  apt: name=mesos state=present\n\n- name: install marathon\n  apt: name=marathon state=present\n</code></pre>\n\n<p>It is fine now, the slaves appears in the activated state in the mesos UI.  </p>\n\n<p>Was it due to a version problem ?  </p>\n", "is_answered": true, "title": "Mesos slave not seen from web ui", "last_edit_date": 1436625567, "tags": ["ansible", "ansible-playbook", "mesos", "mesosphere"], "view_count": 1350, "accepted_answer_id": 31358304, "last_activity_date": 1436625657, "answers": [{"body": "<p>Any of the Mesos command-line parameters can be set as files like <code>/etc/mesos-slave/master</code> (for <code>mesos-slave --master</code>). This is how the service startup finds Mesos parameters.</p>\n\n<p>You can also use <code>/etc/default/mesos-slave/</code> (or <code>-master/</code>) for environment variables, or <code>/etc/mesos/</code> for general parameters.</p>\n", "answer_id": 31325992, "last_activity_date": 1436468259, "creation_date": 1436468259, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 31302860}, {"body": "<p>The slaves can be seen as activated within the mesos UI when I used the \"present\" state instead of the \"latest\" state in the Ansible playbook while installing mesos.</p>\n\n<pre><code>- name: install mesos + zookeeper\n  apt: name=mesos state=present\n\n- name: install marathon\n  apt: name=marathon state=present\n</code></pre>\n", "answer_id": 31358304, "last_activity_date": 1436625657, "creation_date": 1436625657, "score": -1, "owner": {"user_id": 231957, "profile_image": "https://www.gravatar.com/avatar/67db701d6a4e067c6aeeca5dec7a82ef?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6319, "link": "https://stackoverflow.com/users/231957/luc", "accept_rate": 80, "display_name": "Luc"}, "is_accepted": true, "question_id": 31302860}], "score": 0, "link": "https://stackoverflow.com/questions/31302860/mesos-slave-not-seen-from-web-ui", "answer_count": 2, "owner": {"user_id": 231957, "profile_image": "https://www.gravatar.com/avatar/67db701d6a4e067c6aeeca5dec7a82ef?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6319, "link": "https://stackoverflow.com/users/231957/luc", "accept_rate": 80, "display_name": "Luc"}, "creation_date": 1436386625, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31302860}{"body": "<p>I want to submit a docker container which contains 'fat jar' to a Spark cluster running on DC/OS. Here's what I have done.</p>\n\n<ol>\n<li><code>mvn clean install</code>, so the jar resides here /target/application.jar</li>\n<li><code>docker build -t &lt;repo/image&gt; . &amp;&amp; docker push &lt;repo/image&gt;</code></li>\n<li>Now my DC/OS is able to pull the image from my private repository</li>\n</ol>\n\n<p>My Dockerfile looks like this:</p>\n\n<pre><code>FROM docker-release.com/spark:0.1.1-2.1.0-2.8.0  # I extended from this image to get all necessary components\n\nADD target/application.jar /application.jar # just put fat jar under root dir of Docker image\n\nCOPY bootstrap.sh /etc/bootstrap.sh\nENTRYPOINT [\"/etc/bootstrap.sh\"]\n</code></pre>\n\n<p>Here's what bootstrap.sh looks like:</p>\n\n<pre><code>#!/bin/bash -e\n\n/usr/local/spark/bin/spark-submit --class com.spark.sample.MainClass --master spark://&lt;host&gt;:&lt;port&gt; --deploy-mode cluster --executor-memory 20G --total-executor-cores 100 /application.jar\n</code></pre>\n\n<p>I deployed this image as a service to DC/OS, where Spark cluster also runs, and the service successfully submit to Spark cluster. However, Spark cluster is not able to locate the jar because it sits in the service docker. </p>\n\n<blockquote>\n  <p>I0621 06:06:25.985144  8760 fetcher.cpp:167] Copying resource with\n  command:cp '/application.jar'\n  '/var/lib/mesos/slave/slaves/e8a89a81-1da6-46a2-8caa-40a37a3f7016-S4/frameworks/e8a89a81-1da6-46a2-8caa-40a37a3f7016-0003/executors/driver-20170621060625-18190/runs/c8e710a6-14e3-4da5-902d-e554a0941d27/application.jar'</p>\n  \n  <p>cp: cannot stat '/application.jar': No such file or directory </p>\n  \n  <p>Failed  to fetch '/application.jar': </p>\n  \n  <p>Failed to copy with command 'cp '/application.jar'\n  '/var/lib/mesos/slave/slaves/e8a89a81-1da6-46a2-8caa-40a37a3f7016-S4/frameworks/e8a89a81-1da6-46a2-8caa-40a37a3f7016-0003/executors/driver-20170621060625-18190/runs/c8e710a6-14e3-4da5-902d-e554a0941d27/application.jar'',</p>\n  \n  <p>exit status: 256 Failed to synchronize with agent (it's probably\n  exited)</p>\n</blockquote>\n\n<p>My question is:</p>\n\n<p>Does the jar need to be placed somewhere other than inside the Docker container? It doesn't make any sense to me, but if not, how can Spark correctly find the jar file?</p>\n", "is_answered": false, "tags": ["apache-spark", "docker", "apache-spark-sql", "dcos"], "last_edit_date": 1498025953, "title": "Submit docker which contains fat jar to Spark cluster", "last_activity_date": 1498025953, "answer_count": 0, "creation_date": 1498025602, "score": 1, "link": "https://stackoverflow.com/questions/44668109/submit-docker-which-contains-fat-jar-to-spark-cluster", "owner": {"user_id": 3416953, "profile_image": "https://www.gravatar.com/avatar/0c4f1d6ab1019fba4cc4c3575719a850?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 67, "link": "https://stackoverflow.com/users/3416953/m%e8%80%81%e7%ab%8b", "accept_rate": 30, "display_name": "M\u8001\u7acb"}, "view_count": 31, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44668109}{"body": "<p>I went through the <a href=\"https://youtu.be/0I6qG9RQUnY\" rel=\"nofollow\">video on introduction of DCOS</a>. It was good but got me somewhat confused in terms of classification of component definitions in Mesosphere. </p>\n\n<ol>\n<li><p>I get that DCOS is an ecosystem and Mesos is like a kernel. Please correct me if I am wrong. For eg. It's like Ubuntu and Linux kernel I presume.</p></li>\n<li><p>What is marathon? Is it a service or framework or is it something else that falls in neither category? I am bit confused in terms of service vs framework vs application vs Task definition in Mesosphere's context.</p></li>\n<li><p>Are the services(Cassandra, HDFS, Kubernetes, etc..)  that he launches in the video can safely be also called as frameworks?</p></li>\n<li><p>From 3, are these \"services\" running as executors in the slaves?</p></li>\n<li><p>What should rails-app's type be here? Is it a task? So will it also have an executor?</p></li>\n<li><p>Who makes the decision of autoscaling the rails-app to more nodes, when he increases the traffic using marathon.</p></li>\n</ol>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon", "dcos"], "last_edit_date": 1460969046, "title": "Confused on Mesos Terminologies", "last_activity_date": 1462307098, "answer_count": 1, "creation_date": 1460823368, "score": 2, "link": "https://stackoverflow.com/questions/36666575/confused-on-mesos-terminologies", "answers": [{"body": "<blockquote>\n  <p>1) I get that DCOS is an ecosystem and Mesos is like a kernel. Please\n  correct me if I am wrong. For eg. It's like Ubuntu and Linux kernel I\n  presume.</p>\n</blockquote>\n\n<p>Correct!</p>\n\n<blockquote>\n  <p>2) What is marathon? Is it a service or framework or is it something\n  else that falls in neither category? I am bit confused in terms of\n  service vs framework vs application vs Task definition in Mesosphere's\n  context.</p>\n</blockquote>\n\n<p>In Apache Mesos terminology, Marathon is a framework. Every framework consists of a framework scheduler and an executor. Many frameworks reuse the standard executor rather than providing their own. An app is a Marathon specific term, meaning the long-running task you launch through it. A task is the unit of execution, running on a Mesos agent (in an executor). In DC/OS (the product, Mesosphere is our company) we call frameworks in general services. Also, in the context of DC/OS, Marathon plays a special role: it acts as a sort of distributed initd, launching other services such as Spark or Kafka.</p>\n\n<blockquote>\n  <p>3) Are the services(Cassandra, HDFS, Kubernetes, etc..) that he\n  launches in the video can safely be also called as frameworks?</p>\n</blockquote>\n\n<p>See above.</p>\n\n<blockquote>\n  <p>4) From 3), are these \"services\" running as executors in the slaves?</p>\n</blockquote>\n\n<p>No. See above.</p>\n\n<blockquote>\n  <p>5) What should rails-app's type be here? Is it a task? So will it also\n  have an executor?</p>\n</blockquote>\n\n<p>The Rails app may have one or more (Mesos) tasks running in executors on one or more agents.</p>\n\n<blockquote>\n  <p>6) Who makes the decision of autoscaling the rails-app to more nodes,\n  when he increases the traffic using marathon.</p>\n</blockquote>\n\n<p>Not nodes but instances of the app. Also as @air suggested, with <a href=\"https://dcos.io/docs/1.7/usage/tutorials/autoscaling/\" rel=\"nofollow\">Marathon autoscaling</a> is simple, see also this <a href=\"https://github.com/mhausenblas/elsa\" rel=\"nofollow\">autoscaling example</a>.</p>\n", "answer_id": 36670800, "last_activity_date": 1462307098, "creation_date": 1460847856, "score": 6, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "last_edit_date": 1462307098, "question_id": 36666575}], "owner": {"user_id": 2686821, "profile_image": "https://www.gravatar.com/avatar/5dd46afe4f5a75f2667569582b20ac9b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 457, "link": "https://stackoverflow.com/users/2686821/soupybionics", "accept_rate": 54, "display_name": "soupybionics"}, "view_count": 558, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36666575}{"closed_date": 1477372505, "is_answered": false, "closed_reason": "duplicate", "tags": ["mesos", "marathon", "dcos"], "last_edit_date": 1477328895, "title": "DC/OS cli auth login is not working", "body": "<p>I have a setup of mesos masters and slaves which is working fine and I wan't to install DCOS-cli for my cluster. I have a external windows machine which can communicate to my cluster and this is where I want to install DCOS-cli.\nI did this as following in the external machine:\n<code>./dcos config set core.dcos_url http://leader_mesos_master_ip:5050</code> and then \n<code>./dcos auth login</code> but on auth login I get the error <em><code>Error while fetching [http://10.198.161.41:5050/exhibitor/]: HTTP 404: Not Found\n</code></em></p>\n", "view_count": 30, "answer_count": 0, "last_activity_date": 1477328895, "score": 0, "link": "https://stackoverflow.com/questions/40217809/dc-os-cli-auth-login-is-not-working", "owner": {"user_id": 4511560, "profile_image": "https://i.stack.imgur.com/jhc6e.jpg?s=128&g=1", "user_type": "registered", "reputation": 148, "link": "https://stackoverflow.com/users/4511560/tinkal-gogoi", "accept_rate": 50, "display_name": "Tinkal Gogoi"}, "creation_date": 1477310286, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40217809}{"body": "<p>I have a running Mesos master node with a public IP on a KVM based Virtual machine on the Cloud, to which I can connect other agents across the network. I have one machine in my lab which I have public ip and I can connect it to the Mesos master. I have used below commands to start master and slaves into the cluster. </p>\n\n<blockquote>\n  <p>sudo ./bin/mesos-master.sh --work_dir=/var/lib/mesos --advertise_ip=129.xxx.110.yy </p>\n  \n  <p>sudo ./bin/mesos-slave.sh --master=129.xxx.110.yy:5050 --advertise_ip=129.xxx.111.zz</p>\n</blockquote>\n\n<p>Now the problem is I have many other machines in my lab, which does not have public ip addresses. </p>\n\n<p>How can I connect them to the Mesos master?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "creating a mesos cluster with many nodes without public ips", "last_activity_date": 1468262072, "answer_count": 0, "creation_date": 1468262072, "score": 0, "link": "https://stackoverflow.com/questions/38313849/creating-a-mesos-cluster-with-many-nodes-without-public-ips", "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 100, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38313849}{"is_answered": true, "tags": ["cluster-computing", "mesos", "dcos", "np-hard"], "title": "DCOS cluster resource allocation is np-hard", "last_activity_date": 1492506666, "answer_count": 1, "creation_date": 1490724332, "score": 1, "link": "https://stackoverflow.com/questions/43076831/dcos-cluster-resource-allocation-is-np-hard", "accepted_answer_id": 43448790, "owner": {"user_id": 654457, "profile_image": "https://www.gravatar.com/avatar/8806c26cc5687109c0669221ab54ecb7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1730, "link": "https://stackoverflow.com/users/654457/noname", "accept_rate": 82, "display_name": "noname"}, "view_count": 46, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 43076831}{"body": "<p>I am in the process of creating DC/OS cluster on AWS for running Kafka->Spark->Cassandra workloads.</p>\n\n<p>I am interested what is the minimum specification for master node in DC/OS environment. I see that DC/OS suggests m3.xlarge instances, but I do not know why do I need 4 processors and 15GB of RAM, when master is only runnning processes described on: <a href=\"https://docs.mesosphere.com/overview/architecture/\" rel=\"nofollow\">https://docs.mesosphere.com/overview/architecture/</a> \n-> There is no actual data processing performed by the master.</p>\n\n<p>I would maybe go with m3.large or r3.large instances.</p>\n\n<p>Kindest regards,</p>\n\n<p>Srdjan</p>\n", "is_answered": true, "title": "Mesos master configuration on DC/OS", "tags": ["mesos", "mesosphere", "dcos"], "last_activity_date": 1463561920, "accepted_answer_id": 37294778, "creation_date": 1463484546, "answers": [{"body": "<p>DC/OS masters are not used to run any high computation loads, but their memory usage tends to be pretty exhaustive, and so a large instance is recommended. </p>\n\n<p>There might be a way to use smaller instances and compensate for the missing memory using swap files, but straying from the supplier's recommendations should only be done after careful consideration of the potential consequences.</p>\n", "answer_id": 37294778, "last_activity_date": 1463561920, "creation_date": 1463561920, "score": 2, "owner": {"user_id": 3833773, "profile_image": "https://graph.facebook.com/554650175/picture?type=large", "user_type": "registered", "reputation": 2116, "link": "https://stackoverflow.com/users/3833773/yaron-idan", "accept_rate": 95, "display_name": "Yaron Idan"}, "is_accepted": true, "question_id": 37274849}], "score": 2, "link": "https://stackoverflow.com/questions/37274849/mesos-master-configuration-on-dc-os", "answer_count": 1, "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "view_count": 182, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37274849}{"body": "<p>I added two repository in DC/OS repositories.</p>\n\n<ol>\n<li><a href=\"https://github.com/mesosphere/multiverse/archive/version-1.x.zip\" rel=\"nofollow\">https://github.com/mesosphere/multiverse/archive/version-1.x.zip</a></li>\n<li><a href=\"https://universe.mesosphere.com/repo\" rel=\"nofollow\">https://universe.mesosphere.com/repo</a></li>\n</ol>\n\n<p>But nothing showed in my <strong>Universe Packages</strong> page! and I get the following error:</p>\n\n<blockquote>\n  <p>undefined You can go to the Repositories Settings page to change installed repositories.</p>\n</blockquote>\n\n<p>where i can see more related error messages (except in journalctl)</p>\n\n<p>My DCOS version is 1.8.4 and I have also a VPN connection.</p>\n", "is_answered": false, "tags": ["docker", "mesosphere", "dcos"], "last_edit_date": 1474456995, "title": "DC/OS packages not exist", "last_activity_date": 1474456995, "answer_count": 1, "creation_date": 1474292710, "score": 1, "link": "https://stackoverflow.com/questions/39574755/dc-os-packages-not-exist", "answers": [{"body": "<p>Remove <code>https://github.com/mesosphere/multiverse/archive/version-1.x.zip</code> from the repositories.</p>\n", "answer_id": 39575501, "last_activity_date": 1474294886, "creation_date": 1474294886, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 39574755}], "owner": {"user_id": 2527458, "profile_image": "https://i.stack.imgur.com/fYtXY.jpg?s=128&g=1", "user_type": "registered", "reputation": 237, "link": "https://stackoverflow.com/users/2527458/majid-hajibaba", "accept_rate": 40, "display_name": "majid hajibaba"}, "view_count": 120, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39574755}{"is_answered": true, "tags": ["performance", "restart", "mesos", "marathon"], "title": "Mesosphere marathon restart task on all instances", "last_activity_date": 1456860612, "answer_count": 1, "creation_date": 1456845267, "score": 1, "link": "https://stackoverflow.com/questions/35726566/mesosphere-marathon-restart-task-on-all-instances", "accepted_answer_id": 35731747, "owner": {"user_id": 1597656, "profile_image": "https://www.gravatar.com/avatar/22f0d3352b38fd97b8d86992c5dde179?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1600, "link": "https://stackoverflow.com/users/1597656/yerken", "accept_rate": 80, "display_name": "Yerken"}, "view_count": 419, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 35726566}{"body": "<p>I've got some mesos-slave nodes that I would like to expose to the internet. As such, I would like mesos-slave to offer port 80 and 443 in addition to its default slew of ports/resources.</p>\n\n<p>From <a href=\"http://mesos.apache.org/documentation/attributes-resources/\">what I have gathered</a>, I need to adjust the <code>--resources</code> parameter and include both 80 and 443 in the port resource offerings. However, from my tests, in doing this, I must also hard-code the machine's CPU/Mem/Disk offerings as well (as opposed to allowing mesos-slave to determine these at runtime).</p>\n\n<p>Because the size of nodes I want to run <code>mesos-slave</code> on may change in the future, I want to avoid hardcoding the CPU/Mem/Disk offerings and let them be determined at runtime. <strong>How do I change mesos-slave's port <code>--resource</code> offerings without hardcoding the CPU/Mem/Disk offerings?</strong> Ideally such a system would be additive: \"offer port 80/443 in <em>addition</em> to the default ports\".</p>\n\n<p>Best!</p>\n\n<p>Advait</p>\n", "is_answered": true, "title": "Mesos: mesos-slave offer additional ports", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1448411339, "accepted_answer_id": 30022432, "creation_date": 1430697933, "answers": [{"body": "<p>Even after specifying the ports resource Disk, CPU, Mem should be added automatically (see log excerpt) below. </p>\n\n<pre><code>mesos-slave.sh --master=xxxx:5050 --resources=ports:80\nI0503 20:48:04.999114 2057073408 main.cpp:200] Starting Mesos slave\nI0503 20:48:05.000370 243535872 slave.cpp:316] Slave resources: ports(*):80; cpus(*):8; mem(*):15360; disk(*):470848\n</code></pre>\n\n<p>Unfortunately the ports are not additive anymore... Maybe one idea could be to specify an new resource for those ports (you should be sure nothing else outside mesos uses these ports). I.e. you could be to specify --resources=port80:1;port443:1.</p>\n\n<pre><code>build joergschad$ bin/mesos-slave.sh --master=xxxx:5050 --resources=port80:1\nI0503 20:58:52.742509 119599104 slave.cpp:316] Slave resources: port80(*):1; cpus(*):8; mem(*):15360; disk(*):470848; ports(*):[31000-32000]\n</code></pre>\n", "answer_id": 30022432, "last_activity_date": 1430712092, "creation_date": 1430712092, "score": 3, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "question_id": 30020839}], "score": 5, "link": "https://stackoverflow.com/questions/30020839/mesos-mesos-slave-offer-additional-ports", "answer_count": 1, "owner": {"user_id": 379482, "profile_image": "https://www.gravatar.com/avatar/d890d7f1ddeb893a8f810bdaf086e13f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4003, "link": "https://stackoverflow.com/users/379482/advait", "accept_rate": 73, "display_name": "advait"}, "view_count": 819, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 30020839}{"body": "<p>so there is a set of applications that position itself as a distributed cluster O/S called <strong>DCOS</strong>.</p>\n\n<p>It has an <strong><code>MPI</code></strong> and <code>spark</code> running on top of it.</p>\n\n<p>I am a developer and I have a set of distributed services running connected via <code>socket</code> or <strong><code>ZeroMQ</code></strong> communication system.</p>\n\n<p><strong>How can I port my existing services to DCOS?</strong></p>\n\n<p>Meaning use it's communication facilities instead of <code>sockets</code>/<code>zmq</code>.</p>\n\n<p><strong>Is there any API \\ Docs on how not to run it but develop for it?</strong></p>\n", "is_answered": true, "title": "How to port existing distributed service application to DCOS?", "last_edit_date": 1431741700, "tags": ["c++", "linux", "mesos", "mesosphere"], "view_count": 131, "accepted_answer_id": 30271626, "last_activity_date": 1431748107, "answers": [{"body": "<p>There are a number of ways to get your application to run on DCOS (and/or Mesos).</p>\n\n<p>First for legacy applications you can use the <a href=\"https://github.com/mesosphere/marathon\" rel=\"nofollow\">marathon framework </a> which you can view as kind of the init system of DCOS/Mesos.\nIf you need more elaborate applications and want to really program against the apis you would write a mesos framework: see the <a href=\"http://mesos.apache.org/documentation/latest/app-framework-development-guide/\" rel=\"nofollow\">framework development guide</a> for more details.\nFor deeper integration of your framework into DCOS as for example using the package repository/ command line install option check out/contact <a href=\"https://mesosphere.com/\" rel=\"nofollow\">mesosphere</a> for more details.</p>\n\n<p>Hope this helps!\nJoerg</p>\n", "answer_id": 30271626, "last_activity_date": 1431748107, "creation_date": 1431748107, "score": 3, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "question_id": 30270696}], "score": 0, "link": "https://stackoverflow.com/questions/30270696/how-to-port-existing-distributed-service-application-to-dcos", "answer_count": 1, "owner": {"user_id": 1973207, "profile_image": "https://www.gravatar.com/avatar/557d7fa74d7ec23c6726f1c16986b032?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 653, "link": "https://stackoverflow.com/users/1973207/duckqueen", "accept_rate": 43, "display_name": "DuckQueen"}, "creation_date": 1431737368, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30270696}{"is_answered": true, "tags": ["mesos", "amazon-cloudwatch", "mesosphere", "prometheus"], "last_edit_date": 1439548527, "title": "Setting up cloud watch exporter for prometheus on mesosphere DCOS cluster", "last_activity_date": 1440140099, "answer_count": 2, "creation_date": 1439269809, "score": 0, "link": "https://stackoverflow.com/questions/31933673/setting-up-cloud-watch-exporter-for-prometheus-on-mesosphere-dcos-cluster", "accepted_answer_id": 31959486, "owner": {"user_id": 5188802, "profile_image": "https://www.gravatar.com/avatar/96fdffb493ccaef2a9b3bb57a332ffe1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5188802/rajasi-kulkarni", "accept_rate": 100, "display_name": "Rajasi Kulkarni"}, "view_count": 619, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 31933673}{"is_answered": false, "tags": ["dcos"], "title": "DCOS/mesos increase log retention", "last_activity_date": 1498481797, "answer_count": 0, "creation_date": 1498481797, "score": 0, "link": "https://stackoverflow.com/questions/44760301/dcos-mesos-increase-log-retention", "owner": {"user_id": 8215628, "profile_image": "https://lh4.googleusercontent.com/-2AN2DQB77p8/AAAAAAAAAAI/AAAAAAAAAPM/IcthpHBYR4I/photo.jpg?sz=128", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/8215628/shithindas-mk", "display_name": "shithindas mk"}, "view_count": 8, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44760301}{"body": "<p>According to the <a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html#uploading-spark-package\">Spark on Mesos docs</a> one needs to set the <code>spark.executor.uri</code> pointing to a Spark distribution:</p>\n\n<pre><code>val conf = new SparkConf()\n  .setMaster(\"mesos://HOST:5050\")\n  .setAppName(\"My app\")\n  .set(\"spark.executor.uri\", \"&lt;path to spark-1.4.1.tar.gz uploaded above&gt;\")\n</code></pre>\n\n<p>The docs also note that one can build a custom version of the Spark distribution. </p>\n\n<p>My question now is whether it is possible/desirable to pre-package external libraries such as </p>\n\n<ul>\n<li>spark-streaming-kafka</li>\n<li>elasticsearch-spark</li>\n<li>spark-csv</li>\n</ul>\n\n<p>which will be used in mostly all of the job-jars I'll submit via <code>spark-submit</code> to</p>\n\n<ul>\n<li>reduce the time <code>sbt assembly</code> need to package the fat jars</li>\n<li>reduce the size of the fat jars which need to be submitted</li>\n</ul>\n\n<p>If so, how can this be achieved? Generally speaking, are there some hints on how the fat jar generation on job submitting process can be speed up? </p>\n\n<p>Background is that I want to run some code-generation for Spark jobs, and submit these right away and show the results in a browser frontend asynchronously. The frontend part shouldn't be too complicated, but I wonder how the backend part can be achieved.</p>\n", "is_answered": true, "title": "How to pre-package external libraries when using Spark on a Mesos cluster", "last_edit_date": 1440748455, "tags": ["scala", "apache-spark", "mesos", "mesosphere"], "view_count": 1494, "accepted_answer_id": 32963781, "last_activity_date": 1444115256, "answers": [{"body": "<p>When you say pre-package do you really mean distribute to all the slaves and set up the jobs to use those packages so that you don't need to download those every time? That might be an option, however it sounds a bit cumbersome because distributing everything to the slaves and keeping all the packages up to date is not an easy task.</p>\n\n<p>How about breaking your .tar.gz into smaller pieces, so that instead of a single fat file your jobs fetch several smaller files? In this case it should be possible to leverage the <a href=\"http://mesos.apache.org/documentation/latest/fetcher/\" rel=\"nofollow\">Mesos Fetcher Cache</a>. So you'll see <em>bad</em> performance when the agent cache is cold, but once it warms up (i.e. once one job runs and downloads the common files locally) consecutive jobs will complete faster. </p>\n", "answer_id": 32327467, "last_activity_date": 1441097910, "creation_date": 1441097910, "score": 2, "owner": {"user_id": 43668, "profile_image": "https://www.gravatar.com/avatar/2fb130a1a2f63e782fe2345cd48452c2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 361, "link": "https://stackoverflow.com/users/43668/hartem", "display_name": "hartem"}, "is_accepted": false, "question_id": 32265456}, {"body": "<p>Yeah, you can copy the dependencies out to the workers and put them in the system-wide jvm lib directory in order to get them on the classpath.  </p>\n\n<p>Then you can mark those dependencies as provided in your sbt build, and they won't be included in the assembly. This does speed up assembly and transfer time.</p>\n\n<p>I haven't tried this on mesos specifically, but have used it on spark standalone for things that are in every job and rarely change.</p>\n", "answer_id": 32363939, "last_activity_date": 1441231610, "creation_date": 1441231610, "score": 2, "owner": {"user_id": 5212105, "profile_image": "https://lh6.googleusercontent.com/-42xdNT44lLY/AAAAAAAAAAI/AAAAAAAAAHA/AYbdg5r1o8Q/photo.jpg?sz=128", "user_type": "registered", "reputation": 385, "link": "https://stackoverflow.com/users/5212105/cody-koeninger", "display_name": "Cody Koeninger"}, "is_accepted": false, "question_id": 32265456}, {"body": "<p>Create sample maven project with your all dependencies and then use maven plugin <code>maven-shade-plugin</code>. It will create one shade jar in your target folder.</p>\n\n<p>Here is sample pom</p>\n\n<pre><code>&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;groupId&gt;com&lt;/groupId&gt;\n    &lt;artifactId&gt;test&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n    &lt;properties&gt;\n        &lt;java.version&gt;1.7&lt;/java.version&gt;\n        &lt;hadoop.version&gt;2.4.1&lt;/hadoop.version&gt;\n        &lt;spark.version&gt;1.4.0&lt;/spark.version&gt;\n        &lt;version.spark-csv_2.10&gt;1.1.0&lt;/version.spark-csv_2.10&gt;\n        &lt;version.spark-avro_2.10&gt;1.0.0&lt;/version.spark-avro_2.10&gt;\n    &lt;/properties&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;version&gt;3.1&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;${java.version}&lt;/source&gt;\n                    &lt;target&gt;${java.version}&lt;/target&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.3&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;phase&gt;package&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;shade&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n                &lt;configuration&gt;\n                    &lt;!-- &lt;minimizeJar&gt;true&lt;/minimizeJar&gt; --&gt;\n                    &lt;filters&gt;\n                        &lt;filter&gt;\n                            &lt;artifact&gt;*:*&lt;/artifact&gt;\n                            &lt;excludes&gt;\n                                &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;\n                                &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;\n                                &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;\n                                &lt;exclude&gt;org/bdbizviz/**&lt;/exclude&gt;\n                            &lt;/excludes&gt;\n                        &lt;/filter&gt;\n                    &lt;/filters&gt;\n                    &lt;finalName&gt;spark-${project.version}&lt;/finalName&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n    &lt;dependencies&gt;\n        &lt;dependency&gt; &lt;!-- Hadoop dependency --&gt;\n            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;\n            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;\n            &lt;version&gt;${hadoop.version}&lt;/version&gt;\n            &lt;exclusions&gt;\n                &lt;exclusion&gt;\n                    &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;\n                    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;\n                &lt;/exclusion&gt;\n                &lt;exclusion&gt;\n                    &lt;artifactId&gt;guava&lt;/artifactId&gt;\n                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;\n                &lt;/exclusion&gt;\n            &lt;/exclusions&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;joda-time&lt;/groupId&gt;\n            &lt;artifactId&gt;joda-time&lt;/artifactId&gt;\n            &lt;version&gt;2.4&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt; &lt;!-- Spark Core --&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt; &lt;!-- Spark SQL --&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-sql_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt; &lt;!-- Spark CSV --&gt;\n            &lt;groupId&gt;com.databricks&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-csv_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${version.spark-csv_2.10}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt; &lt;!-- Spark Avro --&gt;\n            &lt;groupId&gt;com.databricks&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-avro_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${version.spark-avro_2.10}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt; &lt;!-- Spark Hive --&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-hive_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt; &lt;!-- Spark Hive thriftserver --&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-hive-thriftserver_2.10&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n&lt;/project&gt;\n</code></pre>\n", "answer_id": 32403191, "last_activity_date": 1441386199, "creation_date": 1441386199, "score": 3, "owner": {"user_id": 1362926, "profile_image": "https://i.stack.imgur.com/C7pSe.jpg?s=128&g=1", "user_type": "registered", "reputation": 1078, "link": "https://stackoverflow.com/users/1362926/kaushal", "accept_rate": 69, "display_name": "Kaushal"}, "is_accepted": false, "question_id": 32265456}, {"body": "<p>After I discovered the <strong><a href=\"https://github.com/spark-jobserver/spark-jobserver\" rel=\"nofollow\">Spark JobServer</a></strong> project, I decided that this is the most suitable one for my use case. </p>\n\n<p>It supports dynamic context creation via a REST API, as well as adding JARs to the newly created context manually/programmatically. It also is capable of runnign low-latency synchronous jobs, which is exactly what I need.</p>\n\n<p>I created a Dockerfile so you can try it out with the most recent (supported) versions of Spark (1.4.1), Spark JobServer (0.6.0) and buit-in Mesos support (0.24.1):</p>\n\n<ul>\n<li><a href=\"https://github.com/tobilg/docker-spark-jobserver\" rel=\"nofollow\">https://github.com/tobilg/docker-spark-jobserver</a></li>\n<li><a href=\"https://hub.docker.com/r/tobilg/spark-jobserver/\" rel=\"nofollow\">https://hub.docker.com/r/tobilg/spark-jobserver/</a></li>\n</ul>\n\n<p>References:</p>\n\n<ul>\n<li><a href=\"https://github.com/spark-jobserver/spark-jobserver#features\" rel=\"nofollow\">https://github.com/spark-jobserver/spark-jobserver#features</a></li>\n<li><a href=\"https://github.com/spark-jobserver/spark-jobserver#context-configuration\" rel=\"nofollow\">https://github.com/spark-jobserver/spark-jobserver#context-configuration</a></li>\n</ul>\n", "answer_id": 32963781, "last_activity_date": 1444115256, "creation_date": 1444115256, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 32265456}], "score": 9, "link": "https://stackoverflow.com/questions/32265456/how-to-pre-package-external-libraries-when-using-spark-on-a-mesos-cluster", "answer_count": 4, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "creation_date": 1440746543, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32265456}{"body": "<pre><code>I0909 22:47:01.240753 21904 sched.cpp:635] Scheduler::statusUpdate took    23007ns\nI0909 22:47:01.240617 21904 master.cpp:3600] Sending 1 offers to framework 20140909-224659-16842879-44263-21883-0000\n</code></pre>\n\n<p>What is I0909? What is the date/timestamp format used? What pattern does it use ? </p>\n", "is_answered": true, "title": "How do I read mesos logs ? I mean can somebody please explain whats the meaning of each argument?", "tags": ["logging", "logstash", "mesos", "mesosphere"], "last_activity_date": 1446870791, "accepted_answer_id": 33525679, "creation_date": 1446637428, "answers": [{"body": "<p>This is a default format of glog libraray</p>\n\n<pre><code> [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line]\n</code></pre>\n\n<p>For example </p>\n\n<pre><code>I0909 22:47:01.240753 21904 sched.cpp:635] Scheduler::statusUpdate took    23007ns\n</code></pre>\n\n<ul>\n<li>I  -- Level</li>\n<li>09 -- month</li>\n<li>09 -- date</li>\n<li>22 -- hour</li>\n<li>47 -- minute</li>\n<li>01 -- second</li>\n<li>240753 -- micro second</li>\n<li>21904  -- thread id</li>\n<li>sched.cpp -- source file</li>\n<li>635       -- source file line</li>\n<li>Scheduler::statusUpdate took    23007ns -- message</li>\n</ul>\n", "answer_id": 33525679, "last_activity_date": 1446650888, "creation_date": 1446650888, "score": 4, "owner": {"user_id": 891145, "profile_image": "https://www.gravatar.com/avatar/221cfd6267f65ba83aaa3d5ee6271291?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 548, "link": "https://stackoverflow.com/users/891145/haosdent", "accept_rate": 80, "display_name": "haosdent"}, "is_accepted": true, "question_id": 33520990}, {"body": "<p>Now, @haosdent has already provided the concrete answer. Just for the sake of completeness, we're using <a href=\"https://github.com/google/glog\" rel=\"nofollow\">glog</a> in Apache Mesos for logging.</p>\n", "answer_id": 33579161, "last_activity_date": 1446870791, "creation_date": 1446870791, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 33520990}], "score": 2, "link": "https://stackoverflow.com/questions/33520990/how-do-i-read-mesos-logs-i-mean-can-somebody-please-explain-whats-the-meaning", "answer_count": 2, "owner": {"user_id": 2585874, "profile_image": "https://i.stack.imgur.com/9MWHF.jpg?s=128&g=1", "user_type": "registered", "reputation": 176, "link": "https://stackoverflow.com/users/2585874/tanmay-deshpande", "display_name": "Tanmay Deshpande"}, "view_count": 156, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33520990}{"body": "<p>We are using Haproxy on top of Mesos cluster, We are doing  dynamic reloads for Haproxy based on marathon events (50-100 times in a day). We have nearly 300 applications that are running on Mesos (300 virtual hosts in Haproxy). When we do dynamic reloads, Haproxy is taking long time to reload Haproxy, we observed that for 50 applications takes 30-40secs to reload Haproxy. We have a single config file for Haproxy, when we do reload all the applications are getting reloaded (Front-ends), this causing downtime of all applications. Is there anyway to reduce the downtime and impact on end-users.</p>\n\n<p>We tried this scenario,<br>\n<a href=\"http://engineeringblog.yelp.com/2015/04/true-zero-downtime-haproxy-reloads.html\" rel=\"nofollow\" title=\"true-zero-downtime-haproxy-reloads\">\"http://engineeringblog.yelp.com/2015/04/true-zero-downtime-haproxy-reloads.html\"</a></p>\n\n<p>By this if user requests while reload, the requests are queued and serving after reload.</p>\n\n<p>But if we do multiple reloads one after another, HaProxy's old processes persist even after reloading the HaProxy service, this is causing serious issues.</p>\n\n<pre><code>root      7816  0.1  0.0  20024  3028 ?        Ss   03:52   0:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /var/run/haproxy.pid -D -sf 6778\nroot      7817  0.0  0.0  20024  3148 ?        Ss   03:52   0:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /var/run/haproxy.pid -D -sf 6778\n</code></pre>\n\n<p><strong>Is there any solution stop the previous process once after it serving the request.</strong></p>\n\n<p><strong>Can we separate the configurations based on front-ends like in Nginx, so that only those apps will effect if there is any changes in backend.</strong></p>\n\n<p>Thank you.</p>\n", "is_answered": true, "tags": ["haproxy", "mesos", "mesosphere", "marathon"], "last_edit_date": 1442318311, "title": "Issue with Haproxy Reload", "last_activity_date": 1444909814, "answer_count": 1, "creation_date": 1441891095, "score": 2, "link": "https://stackoverflow.com/questions/32503029/issue-with-haproxy-reload", "answers": [{"body": "<p>We found the issue, it's because of DNS, Haproxy is taking much time for resolving the URLS, we added the /etc/hosts file for local cache DNS..</p>\n\n<p>Now it's taking 30ms for a reload.</p>\n\n<p>Thank you.</p>\n", "answer_id": 33147785, "last_activity_date": 1444909814, "creation_date": 1444909814, "score": 2, "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "is_accepted": false, "question_id": 32503029}], "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "view_count": 436, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32503029}{"body": "<p>How to restart a service in dc/os as an example marathon or admin router?\ni tried the command:- /etc/systemd/system/dcos-marathon.service but no luck.</p>\n\n<p>This question may seem simple but i tried searching in google didn't find answer hence m here in stackoverflow.</p>\n", "is_answered": true, "tags": ["dcos"], "title": "How to restart Marathon or any DC/OS services in dc/os Cluster", "last_activity_date": 1484292996, "answer_count": 1, "creation_date": 1484290295, "score": 1, "link": "https://stackoverflow.com/questions/41628927/how-to-restart-marathon-or-any-dc-os-services-in-dc-os-cluster", "answers": [{"body": "<p>systemctl restart dcos-marathon</p>\n", "answer_id": 41629534, "last_activity_date": 1484292996, "creation_date": 1484292996, "score": 4, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 41628927}], "owner": {"user_id": 5783271, "profile_image": "https://graph.facebook.com/1008526032559430/picture?type=large", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/5783271/sandhya-km", "accept_rate": 25, "display_name": "Sandhya Km"}, "view_count": 703, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41628927}{"body": "<p>I installed mesos on mac using brew . After the installation i went to mesos/0.22.1/sbin folder and tried to execute mesos-start-master.sh . \nbut it failed with </p>\n\n<pre><code>error : Failed to find /usr/local/Cellar/mesos/0.22.1/etc/mesos/masters\n</code></pre>\n\n<p>My question is how is this etc folder generated. After installation . I can type mesos on cmd and work .But i need to execute above mentioned  sh file.</p>\n\n<p>Thanks</p>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere"], "last_edit_date": 1436528338, "title": "Failed to find /usr/local/Cellar/mesos/0.22.1/etc/mesos/masters", "last_activity_date": 1450368666, "answer_count": 1, "creation_date": 1436528143, "score": 0, "link": "https://stackoverflow.com/questions/31339777/failed-to-find-usr-local-cellar-mesos-0-22-1-etc-mesos-masters", "answers": [{"body": "<p>The etc folder should be created when you install mesos via brew. Just create a text file with each mesos master per line.</p>\n\n<p><code>echo $(hostname) &gt;&gt; /usr/local/Cellar/mesos/0.22.1/etc/mesos/master</code></p>\n", "answer_id": 34339214, "last_activity_date": 1450368666, "creation_date": 1450368666, "score": 0, "owner": {"user_id": 4529074, "profile_image": "https://www.gravatar.com/avatar/1ccf46ee1d79858a5ec994401c30cd41?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 113, "link": "https://stackoverflow.com/users/4529074/joeyreid", "display_name": "joeyreid"}, "is_accepted": false, "question_id": 31339777}], "owner": {"user_id": 3417179, "profile_image": "https://www.gravatar.com/avatar/3112f5097cc8c1c9dc4ece37ac79d0de?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 291, "link": "https://stackoverflow.com/users/3417179/alok", "accept_rate": 21, "display_name": "Alok"}, "view_count": 174, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 31339777}{"body": "<p>My mesos version was recently upgraded from 0.28 to 1.2.1.</p>\n\n<p>Jobs are being scheduled using Chronos. My docker job is being invoked properly, but still getting TASK_FAILED error event it completes with exit status ZERO.</p>\n\n<p>This is reproducible always. I tried with multiple mesos versions, but still no luck. Wondering if I am missing anything.</p>\n\n<p><strong>OS details :-</strong></p>\n\n<pre><code>Kernel  - 3.8.13-98.7.1.el7uek\nOS - OL 7.3\nSanpshot - 7-2017.6.4\n</code></pre>\n\n<p>Since, it is not the latest Kernal, I have added the following in my Chronos Job environment variable as i am not able to install the latest docker version.</p>\n\n<pre><code>{\n          \"name\":\"DOCKER_API_VERSION\",\n          \"value\":\"1.22\"\n      }\n</code></pre>\n\n<p><strong>Launching 'mesos-docker-executor' with flags</strong> </p>\n\n<pre><code>'--container=\"mesos-81cb9c2a-d18b-4127-872b-2a5676dfb314-S0.97dc2c67-5d69-4a8c-b4e1-ba15807697cf\" \n--docker=\"docker\" \n--docker_socket=\"/var/run/docker.sock\" \n--help=\"false\" \n--initialize_driver_logging=\"true\" \n--launcher_dir=\"/usr/libexec/mesos\" --logbufsecs=\"0\" \n--logging_level=\"INFO\" \n--mapped_directory=\"/mnt/mesos/sandbox\" \n--quiet=\"false\" \n--sandbox_directory=\"/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/docker/links/97dc2c67-5d69-4a8c-b4e1-ba15807697cf\" \n--stop_timeout=\"0ns\"'\n</code></pre>\n\n<p><strong>Mesos slave logs :-</strong></p>\n\n<pre><code>    I0906 14:05:00.958442     9 slave.cpp:1625] Got assigned task 'ct:1504706700007:0:Job_Task_Test:' for framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:00.958544     9 slave.cpp:6386] Checkpointing FrameworkInfo to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/framework.info'\nI0906 14:05:00.958868     9 slave.cpp:6397] Checkpointing framework pid 'scheduler-766fa517-8ca6-430e-b044-7fa7e9b339b8@20.426.45.305:43144' to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/framework.pid'\nI0906 14:05:00.959430     9 slave.cpp:1785] Launching task 'ct:1504706700007:0:Job_Task_Test:' for framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:00.966035     9 paths.cpp:547] Trying to chown '/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf' to user 'root'\nI0906 14:05:00.966223     9 slave.cpp:6903] Checkpointing ExecutorInfo to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/executor.info'\nI0906 14:05:00.966648     9 slave.cpp:6479] Launching executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 with resources cpus(*)(allocated: *):0.1; mem(*)(allocated: *):32 in work directory '/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf'\nI0906 14:05:00.967015     9 slave.cpp:6926] Checkpointing TaskInfo to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf/tasks/ct:1504706700007:0:Job_Task_Test:/task.info'\nI0906 14:05:00.967300     9 slave.cpp:2118] Queued task 'ct:1504706700007:0:Job_Task_Test:' for executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:00.967337     9 slave.cpp:884] Successfully attached file '/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf'\nI0906 14:05:00.967501    12 docker.cpp:1165] Starting container '97dc2c67-5d69-4a8c-b4e1-ba15807697cf' for task 'ct:1504706700007:0:Job_Task_Test:' (and executor 'ct:1504706700007:0:Job_Task_Test:') of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:00.968152     9 fetcher.cpp:353] Starting to fetch URIs for container: 97dc2c67-5d69-4a8c-b4e1-ba15807697cf, directory: /mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/docker/links/97dc2c67-5d69-4a8c-b4e1-ba15807697cf\nI0906 14:05:00.969274    16 docker.cpp:1348] Running docker -H unix:///var/run/docker.sock pull docker.xyz.com/test/job-action:latest\nI0906 14:05:01.165390     9 docker.cpp:1274] Running docker -H unix:///var/run/docker.sock inspect docker.xyz.com/test/job-action:latest\nI0906 14:05:01.267083    13 docker.cpp:465] Docker pull docker.xyz.com/test/job-action:latest completed\nI0906 14:05:01.267663    13 docker.cpp:1514] Launching 'mesos-docker-executor' with flags '--container=\"mesos-81cb9c2a-d18b-4127-872b-2a5676dfb314-S0.97dc2c67-5d69-4a8c-b4e1-ba15807697cf\" --docker=\"docker\" --docker_socket=\"/var/run/docker.sock\" --help=\"false\" --initialize_driver_logging=\"true\" --launcher_dir=\"/usr/libexec/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --mapped_directory=\"/mnt/mesos/sandbox\" --quiet=\"false\" --sandbox_directory=\"/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/docker/links/97dc2c67-5d69-4a8c-b4e1-ba15807697cf\" --stop_timeout=\"0ns\"'\nI0906 14:05:01.269182    13 docker.cpp:803] Checkpointing pid 147 to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf/pids/forked.pid'\nI0906 14:05:01.308346    15 slave.cpp:3385] Got registration for executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 from executor(1)@20.426.45.305:48379\nI0906 14:05:01.308658    15 slave.cpp:3471] Checkpointing executor pid 'executor(1)@20.426.45.305:48379' to '/mesos-data/slave-1/meta/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf/pids/libprocess.pid'\nI0906 14:05:01.309453    15 docker.cpp:1608] Ignoring updating container 97dc2c67-5d69-4a8c-b4e1-ba15807697cf because resources passed to update are identical to existing resources\nI0906 14:05:01.309587    15 slave.cpp:2331] Sending queued task 'ct:1504706700007:0:Job_Task_Test:' to executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 at executor(1)@20.426.45.305:48379\nI0906 14:05:02.914752    11 slave.cpp:3816] Handling status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 from executor(1)@20.426.45.305:48379\nI0906 14:05:02.915037    11 status_update_manager.cpp:323] Received status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:02.915063    11 status_update_manager.cpp:500] Creating StatusUpdate stream for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:02.915396    11 status_update_manager.cpp:832] Checkpointing UPDATE for status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:02.915513    11 status_update_manager.cpp:377] Forwarding update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to the agent\nI0906 14:05:02.915587    11 slave.cpp:4256] Forwarding the update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to master@20.426.45.305:5050\nI0906 14:05:02.915688    11 slave.cpp:4150] Status update manager successfully handled status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:02.915700    11 slave.cpp:4166] Sending acknowledgement for status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to executor(1)@20.426.45.305:48379\nI0906 14:05:03.628334    10 status_update_manager.cpp:395] Received status update acknowledgement (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:03.628398    10 status_update_manager.cpp:832] Checkpointing ACK for status update TASK_RUNNING (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:03.628463    10 slave.cpp:3105] Status update manager successfully handled status update acknowledgement (UUID: 72a301e2-f3d3-4e24-8e43-fc5ee44b3730) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:04.256636    14 slave.cpp:5731] Querying resource estimator for oversubscribable resources\nI0906 14:05:04.256691    14 slave.cpp:5745] Received oversubscribable resources {} from the resource estimator\nI0906 14:05:04.944047    10 slave.cpp:4346] Received ping from slave-observer(1)@20.426.45.305:5050\nI0906 14:05:11.049429    12 slave.cpp:3816] Handling status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 from executor(1)@20.426.45.305:48379\nI0906 14:05:11.049636    12 docker.cpp:987] Running docker -H unix:///var/run/docker.sock inspect mesos-81cb9c2a-d18b-4127-872b-2a5676dfb314-S0.97dc2c67-5d69-4a8c-b4e1-ba15807697cf\nI0906 14:05:11.136464    13 status_update_manager.cpp:323] Received status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.136502    13 status_update_manager.cpp:832] Checkpointing UPDATE for status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.136572    13 status_update_manager.cpp:377] Forwarding update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to the agent\nI0906 14:05:11.136642    12 slave.cpp:4256] Forwarding the update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to master@20.426.45.305:5050\nI0906 14:05:11.136739    12 slave.cpp:4150] Status update manager successfully handled status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.136752    12 slave.cpp:4166] Sending acknowledgement for status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 to executor(1)@20.426.45.305:48379\nI0906 14:05:11.152230    13 status_update_manager.cpp:395] Received status update acknowledgement (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.152271    13 status_update_manager.cpp:832] Checkpointing ACK for status update TASK_FAILED (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.152307    13 status_update_manager.cpp:531] Cleaning up status update stream for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.152454    13 slave.cpp:3105] Status update manager successfully handled status update acknowledgement (UUID: 83eceb05-6a94-4660-bdb5-3cbc2b166b1b) for task ct:1504706700007:0:Job_Task_Test: of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:11.152475    13 slave.cpp:6882] Completing task ct:1504706700007:0:Job_Task_Test:\nI0906 14:05:12.059929    13 slave.cpp:4388] Got exited event for executor(1)@20.426.45.305:48379\nI0906 14:05:12.140215    14 docker.cpp:2397] Executor for container 97dc2c67-5d69-4a8c-b4e1-ba15807697cf has exited\nI0906 14:05:12.140244    14 docker.cpp:2091] Destroying container 97dc2c67-5d69-4a8c-b4e1-ba15807697cf\nI0906 14:05:12.140283    14 docker.cpp:2218] Running docker stop on container 97dc2c67-5d69-4a8c-b4e1-ba15807697cf\nI0906 14:05:12.140717    11 slave.cpp:4768] Executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 exited with status 0\nI0906 14:05:12.140748    11 slave.cpp:4868] Cleaning up executor 'ct:1504706700007:0:Job_Task_Test:' of framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000 at executor(1)@20.426.45.305:48379\nI0906 14:05:12.141062    11 slave.cpp:4956] Cleaning up framework 5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000\nI0906 14:05:12.141129    11 gc.cpp:55] Scheduling '/mesos-data/slave-1/slaves/81cb9c2a-d18b-4127-872b-2a5676dfb314-S0/frameworks/5175f6c9-0617-4145-ab46-3b7e64dc67ea-0000/executors/ct:1504706700007:0:Job_Task_Test:/runs/97dc2c67-5d69-4a8c-b4e1-ba15807697cf' for gc 6.99999836858667days in the future\n</code></pre>\n\n<p><strong>Executor stderr :-</strong></p>\n\n<pre><code>I0906 13:25:02.165338  3399 exec.cpp:162] Version: 1.2.1\nI0906 13:25:02.169983  3405 exec.cpp:237] Executor registered on agent f20ab78e-acd3-407a-b1b6-47d67a947eff-S1\n</code></pre>\n\n<p><strong>Mesos version 1.3.1 :-</strong></p>\n\n<pre><code>I0906 16:15:02.975457   580 exec.cpp:162] Version: 1.3.1\nI0906 16:15:02.979501   586 exec.cpp:237] Executor registered on agent 920fa575-b534-48a8-8305-61f6097f2f49-S1\nE0906 16:15:13.523074   589 process.cpp:956] Failed to accept socket: future discarded\n</code></pre>\n\n<p>I am scheduling a docker job thru Chronos. The docker job runs fine and I can see the following in the Mesos stdout logs.\nPartial logs :-</p>\n\n<p><strong>Executor stdout :-</strong></p>\n\n<pre><code>Registered docker executor on &lt;hostname&gt;\nStarting task ct:1504704300002:0:Job_Task_Test:\n.....\n.....\n.....\n: success: true\n: Stopping HTTP executor\n: Started Application in 6.734 seconds (JVM running for 7.642)\ns.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@bebdb06: startup date [Wed Sep 06 17:25:07 UTC 2017]; root of context hierarchy\n2017-09-06 17:25:14.050 INFO 1 \u2014 [ Thread-1] o.s.c.support.DefaultLifecycleProcessor : Stopping beans in phase 0\n2017-09-06 17:25:14.051 INFO 1 \u2014 [ Thread-1] o.s.j.e.a.AnnotationMBeanExporter : Unregistering JMX-exposed beans on shutdown\n2017-09-06 17:25:14.051 DEBUG 1 \u2014 [ Thread-1] h.i.c.PoolingHttpClientConnectionManager : Connection manager is shutting down\n2017-09-06 17:25:14.051 DEBUG 1 \u2014 [ Thread-1] h.i.c.DefaultManagedHttpClientConnection : http-outgoing-0: Close connection\n2017-09-06 17:25:14.052 DEBUG 1 \u2014 [ Thread-1] h.i.c.PoolingHttpClientConnectionManager : Connection manager shut down\n</code></pre>\n\n<p>The docker job is a java process which invokes the remote service and finally exits by calling System.exit(0);\nWe print the following in the docker Job.</p>\n\n<pre><code>Expected status: 200, Actual status: 200, success: true\n</code></pre>\n\n<p>We see no issues with the task execution.</p>\n\n<p>The status code as \"Exited (0) 2 minutes ago\"  by executing the following command.</p>\n\n<p>docker ps -a</p>\n\n<pre><code>CONTAINER ID        IMAGE                  COMMAND    CREATED      \n                                                                                       STATUS                         PORTS               NAMES\n789ec59e32442        docker-test:latest   \"/bin/sh -c 'java -ja\"   2 minutes ago       Exited (0) 2 minutes ago                           mesos-05fb536b-asdff-3d634c4ed860-S1.be003d0e-7701-4020-84be-234643565244\n</code></pre>\n\n<p>Thanks,</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "mesos-chronos"], "bounty_closes_date": 1505487062, "last_edit_date": 1504757677, "title": "Mesos 1.2.1 & 1.3.1 slave - docker job exits normally but reporting as failure", "view_count": 62, "answer_count": 0, "last_activity_date": 1504882262, "score": 2, "link": "https://stackoverflow.com/questions/46066948/mesos-1-2-1-1-3-1-slave-docker-job-exits-normally-but-reporting-as-failure", "bounty_amount": 50, "owner": {"user_id": 1578872, "profile_image": "https://www.gravatar.com/avatar/80b9c8f75d350cccb189ca77db412590?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 628, "link": "https://stackoverflow.com/users/1578872/user1578872", "accept_rate": 62, "display_name": "user1578872"}, "creation_date": 1504673146, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 46066948}{"is_answered": true, "tags": ["marathon", "dcos"], "last_edit_date": 1466612784, "title": "Installing a marathon group as a DCOS package", "last_activity_date": 1479128348, "answer_count": 1, "creation_date": 1466611762, "score": 3, "link": "https://stackoverflow.com/questions/37973259/installing-a-marathon-group-as-a-dcos-package", "owner": {"user_id": 6500124, "profile_image": "https://www.gravatar.com/avatar/125b837383a4967e54b83ec7e6dd321b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6500124/acalderon", "display_name": "acalderon"}, "view_count": 192, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 37973259}{"body": "<p>Iam trying to run elasticsearch-mesos on mesos.My machine is running ubuntu 14.04. I have running mesos cluster installed with mesosphere packages by following these <a href=\"https://mesosphere.com/docs/tutorials/install_ubuntu_debian/\" rel=\"nofollow\">instructions</a>. When I run test frameworks it gets lister under frameworks of mesosUI but for elasticsearch-mesos its not getting listed under mesos webUI. I want to run elasticsearch-mesos on top of mesos. I followed instructions given <a href=\"https://github.com/mesosphere/elasticsearch-mesos\" rel=\"nofollow\">here</a>. When I run <code>./elasticsearch-mesos</code> I am getting a message in terminal</p>\n\n<pre><code>I0108 17:24:01.898540 23861 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\n</code></pre>\n\n<p>I tried running ./elasticsearch-mesos on both mesos masters and slaves. </p>\n\n<p>The last few lines of terminal output is given below</p>\n\n<pre><code>2015-01-08 17:24:01,881:23844(0x7f175bfff700):ZOO_INFO@zookeeper_init@786: Initiating       \nclient connection, host=localhost:2181 sessionTimeout=10000 watcher=0x7f1762a3e6a0 \nsessionId=0 sessionPasswd=&lt;null&gt; context=0x7f1710002530 flags=0\nI0108 17:24:01.881392 23858 sched.cpp:137] Version: 0.21.1\n2015-01-08 17:24:01,881:23844(0x7f172b7fe700):ZOO_INFO@check_events@1703: initiated  \nconnection to server [127.0.0.1:2181]\n2015-01-08 17:24:01,897:23844(0x7f172b7fe700):ZOO_INFO@check_events@1750: session \nestablishment complete on server [127.0.0.1:2181], sessionId=0x14ac7c469270006,    \nnegotiated timeout=10000\nI0108 17:24:01.898455 23861 group.cpp:313] Group process (group(1)@127.0.1.1:38668) \nconnected to ZooKeeper\nI0108 17:24:01.898509 23861 group.cpp:790] Syncing group operations: queue size (joins, \ncancels, datas) = (0, 0, 0)\nI0108 17:24:01.898540 23861 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\n</code></pre>\n", "is_answered": true, "title": "elasticsearch-mesos not getting listed under frameworks of mesosUI", "tags": ["apache", "elasticsearch", "apache-zookeeper", "mesos", "mesosphere"], "last_activity_date": 1421089609, "accepted_answer_id": 27909009, "creation_date": 1420805193, "answers": [{"body": "<p>According to the README at <a href=\"https://github.com/mesosphere/elasticsearch-mesos\" rel=\"nofollow\">https://github.com/mesosphere/elasticsearch-mesos</a>,\nyou may need to modify <code>mesos.master.url</code> to point to the same ZK url that the Mesos master is using (maybe not localhost). If you're using a single-master Mesos cluster, you can skip the ZK url and point this parameter directly to the Mesos master.</p>\n\n<p>Please also note that the elasticsearch framework is a bit outdated, so use with caution</p>\n", "answer_id": 27909009, "last_activity_date": 1421089609, "creation_date": 1421089609, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 27860208}], "score": 2, "link": "https://stackoverflow.com/questions/27860208/elasticsearch-mesos-not-getting-listed-under-frameworks-of-mesosui", "answer_count": 1, "owner": {"user_id": 4242049, "profile_image": "https://www.gravatar.com/avatar/ec74ffb2ffb37ac642193757941cb2a7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 87, "link": "https://stackoverflow.com/users/4242049/piero-simoni-urbino", "accept_rate": 80, "display_name": "Piero Simoni Urbino"}, "view_count": 456, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 27860208}{"body": "<p>I have built a DCOS local universe and installed it into a cluster behind a firewall - there is no internet access to the cluster.  One of the packages installed in the universe is Flink.  I have installed DCOS using the <code>cluster_docker_registry_url</code> variable pointing at a local Docker registry which has a very small number of packages on it; it is not a mirror of the main Docker Hub.</p>\n\n<p>When I try to install the Flink package into DCOS, I get 404 errors in the Mesos logs relating to missing docker images that I assume the package tries to download from the local Docker registry.  The Flink cluster fails to start.</p>\n\n<p>What Docker images does the Flink package try to download?  I thought the build process of a local universe pulled all dependencies down when it is built, so there should be no external dependencies once it's built?  What do I need to do to be able to install DCOS when there is no internet access?</p>\n", "is_answered": true, "tags": ["mesos", "apache-flink", "mesosphere", "dcos"], "title": "What docker images does DCOS Flink package require?", "last_activity_date": 1500691887, "answer_count": 1, "creation_date": 1493851329, "score": 1, "link": "https://stackoverflow.com/questions/43771151/what-docker-images-does-dcos-flink-package-require", "answers": [{"body": "<p>That depends on the scala version you are using:</p>\n\n<ul>\n<li>scala 2.10: <code>mesosphere/dcos-flink:1.2.0-1.4</code></li>\n<li>scala 2.11: <code>mesosphere/dcos-flink-2-11:1.2.0-1.4</code></li>\n</ul>\n\n<p>See <a href=\"https://github.com/mesosphere/universe/blob/4157d261a8bcb1ff745a861afd1818721a175b2b/repo/packages/F/flink/1/resource.json#L6-L7\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p>Furthermore, it requires </p>\n\n<ul>\n<li>openjdk:8-jre ,see <a href=\"https://github.com/mesosphere/dcos-flink-service/blob/master/container/appmaster/conf/flink-conf.yaml#L31\" rel=\"nofollow noreferrer\">here</a></li>\n</ul>\n\n<p>For more details feel free to refer to the universe specification for the Apache Flink service (or ping me directly):\n<a href=\"https://github.com/mesosphere/universe/blob/version-3.x/repo/packages/F/flink/1/\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/universe/blob/version-3.x/repo/packages/F/flink/1/</a></p>\n", "answer_id": 43782142, "last_activity_date": 1500691887, "creation_date": 1493898697, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "last_edit_date": 1500691887, "question_id": 43771151}], "owner": {"user_id": 272023, "profile_image": "https://www.gravatar.com/avatar/25dbc4a263833e5a5b36f5394cfc1d01?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1708, "link": "https://stackoverflow.com/users/272023/john", "accept_rate": 66, "display_name": "John"}, "view_count": 36, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43771151}{"body": "<p>I am setting up a Mesos cluster. Our setup is:</p>\n\n<p>3 Primary boxes (8gb RAM, 4 cpu)\n3 Worker boxes (1gb RAM, 1 cpu)</p>\n\n<p>The configuration files I have are all matching and proper from what I can see. In <code>/etc/mesos/zk</code> I have:</p>\n\n<p><code>\nzk://106.133.117.128:2181,zk://153.213.95.171:2181,zk://106.121.34.29:2181/mesos\n</code></p>\n\n<p>(I changed the IP addresses from the actual ones, but will use them with these same numbers when referenced throughout)</p>\n\n<p>I am not quite sure where to go from here. I have stepped through each piece of configuration.</p>\n\n<p>The ID's are located at <code>/etc/zookeeper/conf/myid</code> on each machine and properly set up. In the config on each machine for zookeeper conf they are set to the matching IP and id as well.</p>\n\n<p>My Quorum size is 2.</p>\n\n<p>IP and hostname are set to the IP of each machine respectively.</p>\n\n<p>The configuration for marathon in <code>/etc/marathon/conf/master</code> reads:</p>\n\n<p><code>\nzk://106.133.117.128:2181,zk://153.213.95.171:2181,zk://106.121.34.29:2181/marathon\n</code></p>\n\n<p>The exact error from the logs is:</p>\n\n<pre><code>Log file created at: 2015/10/01 13:56:32\nRunning on machine: mesos-primary-1\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nI1001 13:56:32.595760  6618 logging.cpp:172] INFO level logging started!\nI1001 13:56:32.596060  6618 main.cpp:229] Build: 2015-09-25 19:13:24 by root\nI1001 13:56:32.596082  6618 main.cpp:231] Version: 0.24.1\nI1001 13:56:32.596094  6618 main.cpp:234] Git tag: 0.24.1\nI1001 13:56:32.596106  6618 main.cpp:238] Git SHA: 44873806c2bb55da37e9adbece938274d8cd7c48\nI1001 13:56:32.596161  6618 main.cpp:252] Using 'HierarchicalDRF' allocator\nI1001 13:56:32.602738  6618 leveldb.cpp:176] Opened db in 6.456045ms\nI1001 13:56:32.611217  6618 leveldb.cpp:183] Compacted db in 8.423531ms\nI1001 13:56:32.611312  6618 leveldb.cpp:198] Created db iterator in 22068ns\nI1001 13:56:32.611348  6618 leveldb.cpp:204] Seeked to beginning of db in 1287ns\nI1001 13:56:32.611372  6618 leveldb.cpp:273] Iterated through 0 keys in the db in 376ns\nI1001 13:56:32.611448  6618 replica.cpp:744] Replica recovered with log positions 0 -&gt; 0 with 1 holes and 0 unlearned\nI1001 13:56:32.647243  6648 log.cpp:238] Attempting to join replica to ZooKeeper group\nI1001 13:56:32.689388  6651 recover.cpp:449] Starting replica recovery\nI1001 13:56:32.690028  6651 recover.cpp:475] Replica is in EMPTY status\nW1001 13:56:32.690147  6649 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\nW1001 13:56:32.690726  6644 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\nW1001 13:56:32.690768  6647 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\nW1001 13:56:32.690821  6645 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\nI1001 13:56:32.690891  6618 main.cpp:465] Starting Mesos master\nI1001 13:56:32.691463  6618 master.cpp:378] Master 20151001-135632-2088076136-5050-6618 (104.131.117.124) started on 106.133.117.128:5050\nI1001 13:56:32.691494  6618 master.cpp:380] Flags at startup: --allocation_interval=\"1secs\" --allocator=\"HierarchicalDRF\" --authenticate=\"false\" --authenticate_slaves=\"false\" --authenticators=\"crammd5\" --authorizers=\"local\" --framework_sorter=\"drf\" --help=\"false\" --hostname=\"106.133.117.128\" --initialize_driver_logging=\"true\" --ip=\"106.133.117.128\" --log_auto_initialize=\"true\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --max_slave_ping_timeouts=\"5\" --port=\"5050\" --quiet=\"false\" --quorum=\"2\" --recovery_slave_removal_limit=\"100%\" --registry=\"replicated_log\" --registry_fetch_timeout=\"1mins\" --registry_store_timeout=\"5secs\" --registry_strict=\"false\" --root_submissions=\"true\" --slave_ping_timeout=\"15secs\" --slave_reregister_timeout=\"10mins\" --user_sorter=\"drf\" --version=\"false\" --webui_dir=\"/usr/share/mesos/webui\" --work_dir=\"/var/lib/mesos\" --zk=\"zk://106.133.117.128:2181,zk://153.213.95.171:2181,zk://106.121.34.29:2181/mesoss\" --zk_session_timeout=\"10secs\"\nI1001 13:56:32.691671  6618 master.cpp:427] Master allowing unauthenticated frameworks to register\nI1001 13:56:32.691700  6618 master.cpp:432] Master allowing unauthenticated slaves to register\nI1001 13:56:32.691725  6618 master.cpp:469] Using default 'crammd5' authenticator\nW1001 13:56:32.691756  6618 authenticator.cpp:505] No credentials provided, authentication requests will be refused.\nI1001 13:56:32.691790  6618 authenticator.cpp:512] Initializing server SASL\nI1001 13:56:32.695333  6646 master.cpp:1464] Successfully attached file '/var/log/mesos/mesos-master.INFO'\nI1001 13:56:32.695377  6646 contender.cpp:149] Joining the ZK group\nW1001 13:56:33.690989  6649 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\nW1001 13:56:33.691220  6644 zookeeper.cpp:101] zookeeper_init failed: Invalid argument ; retrying in 1 second\n</code></pre>\n\n<p>Any input is much appreciated.</p>\n", "is_answered": true, "title": "Apache Mesos - Zookeeper failing on load, cannot access marathon/attach slaves.", "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon"], "last_activity_date": 1443726458, "accepted_answer_id": 32895032, "creation_date": 1443723292, "answers": [{"body": "<p>You mesos zookeeper string is malformatted. It should be of the form</p>\n\n<pre><code>zk://host1:port1,host2:port2,host3:port3/path\n</code></pre>\n\n<p>That should fix your issue (barring any other configuration problems).</p>\n\n<p>Answered on #mesos on freenode as well.</p>\n", "answer_id": 32895032, "last_activity_date": 1443726458, "creation_date": 1443726458, "score": 2, "owner": {"user_id": 5398914, "profile_image": "https://lh5.googleusercontent.com/-wYyWAU2qiWE/AAAAAAAAAAI/AAAAAAAAAJM/XbyHdV4xF5w/photo.jpg?sz=128", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/5398914/matt-coffin", "display_name": "Matt Coffin"}, "is_accepted": true, "question_id": 32894228}], "score": 1, "link": "https://stackoverflow.com/questions/32894228/apache-mesos-zookeeper-failing-on-load-cannot-access-marathon-attach-slaves", "answer_count": 1, "owner": {"user_id": 2997644, "profile_image": "https://graph.facebook.com/1419960053/picture?type=large", "user_type": "registered", "reputation": 474, "link": "https://stackoverflow.com/users/2997644/yburyug", "accept_rate": 38, "display_name": "yburyug"}, "view_count": 704, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32894228}{"body": "<p>I'm developing a new mesos-slurm framework where jobs from outside mesos can also be pushed to slurm queues.</p>\n\n<p><strong>UPDATE to explain better the problem</strong>: The mesos agent has a slurm workload manager installed in the same computer that orchestrates jobs in a HPC. This Slurm receive jobs either from the mesos executor as from other methods (for example third-party users sending jobs directly to slurm through ssh). </p>\n\n<p>Therefore I'd like the agent could know, before sending offers to mesos, the state of the slurm queues (number of jobs running and waiting to run), and offer resources accordingly. This can not be achieved only by knowing the tasks accepted by the executor, as other resources of the HPC could have been taken by third-party users using slurm directly.</p>\n\n<p>In other words what I'd like to do is customize the way the agent know the resources available to offer, to take into account the current state of Slurm queues.</p>\n\n<p><strong>UPDATE 2</strong> Diagram to explain the situation:\n<a href=\"https://i.stack.imgur.com/DUoDs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/DUoDs.png\" alt=\"enter image description here\"></a></p>\n\n<p>As you can see in the diagram, the way the agent creates offers (in red) is what I'd like to customise so the agent would take into account the state of Slurm (this can be read by the executor or the agent) before generate them.</p>\n\n<p>Is this possible? If positive, how could be achieved?</p>\n\n<p>Thanks in advance.</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "last_edit_date": 1486722527, "title": "Modify mesos agent to add custom resources that change dynamically", "last_activity_date": 1486722527, "answer_count": 1, "creation_date": 1485954030, "score": 2, "link": "https://stackoverflow.com/questions/41980462/modify-mesos-agent-to-add-custom-resources-that-change-dynamically", "answers": [{"body": "<p>I think this design is broken. If you allow jobs to be started without Mesos control you lost control of resources. </p>\n\n<ul>\n<li><p><strong>If you can prepare simple framework that will proxy users request to Mesos:</strong> you can use custom resources and get current status in offers. </p></li>\n<li><p><strong>If you can't change your design and you need to start some jobs outside of Mesos:</strong> you can use oversubscription mechanism with combination with custom resources. Then your QoS will update resources according to current usage and you get usage in offer. </p></li>\n</ul>\n", "answer_id": 42143583, "last_activity_date": 1486662649, "creation_date": 1486662649, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": false, "question_id": 41980462}], "owner": {"user_id": 1568781, "profile_image": "https://www.gravatar.com/avatar/2d9505f198a215f8ee2118292c5f9bb9?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 103, "link": "https://stackoverflow.com/users/1568781/javi-carnero", "accept_rate": 67, "display_name": "Javi Carnero"}, "view_count": 108, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 41980462}{"body": "<p>Is it possible to specify resource requirements (cpu, mem, ...) when scheduling a job in <a href=\"https://github.com/airbnb/chronos\" rel=\"nofollow\">chronos</a> via the REST API? I <a href=\"https://github.com/airbnb/chronos/blob/master/docs/CONFIG.md\" rel=\"nofollow\">found</a> there are configuration options that allow specifying general resource requirements for each task but I wonder whether it is possible to do this per job.</p>\n", "is_answered": true, "title": "Specifying resource requirements for chronos jobs", "tags": ["mesos", "mesosphere"], "last_activity_date": 1389653651, "accepted_answer_id": 21103023, "creation_date": 1389634571, "answers": [{"body": "<p>Generally it's possible to restrict resources per task, but you have to use <code>cgroups</code> isolation on mesos slaves. However it seems that Chronos API <a href=\"https://github.com/airbnb/chronos/issues/111\" rel=\"nofollow\">doesn't support it yet (see github issue for more details)</a>. Mesos is being developed quite rapidly, be sure to check that it is supported in your version.</p>\n", "answer_id": 21103023, "last_activity_date": 1389653651, "creation_date": 1389653651, "score": 1, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": true, "question_id": 21097751}], "score": 2, "link": "https://stackoverflow.com/questions/21097751/specifying-resource-requirements-for-chronos-jobs", "answer_count": 1, "owner": {"user_id": 1228765, "profile_image": "https://www.gravatar.com/avatar/f5c43126e7b66e31cd2e21190c5f7fce?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1196, "link": "https://stackoverflow.com/users/1228765/martin-studer", "accept_rate": 50, "display_name": "Martin Studer"}, "view_count": 471, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 21097751}{"is_answered": false, "tags": ["docker", "vagrant", "mesosphere"], "title": "Trying Mesosphere with docker on local machine", "last_activity_date": 1444935510, "answer_count": 0, "creation_date": 1444935510, "score": 0, "link": "https://stackoverflow.com/questions/33156384/trying-mesosphere-with-docker-on-local-machine", "owner": {"user_id": 2587904, "profile_image": "https://i.stack.imgur.com/31ZTY.jpg?s=128&g=1", "user_type": "registered", "reputation": 2400, "link": "https://stackoverflow.com/users/2587904/georg-heiler", "accept_rate": 95, "display_name": "Georg Heiler"}, "view_count": 74, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 33156384}{"body": "<p>I'm quite new to Mesos, and I'm still trying to wrap my head around its concepts and ideas. So far I think I have understood that basically Mesos tries to abstract away your data center and present it as one big computer.</p>\n\n<p>Using the <a href=\"https://github.com/mesosphere/mesos-docker\">Mesos + Docker integration</a> it is basically possible to run <em>any</em> application on Mesos, as long as your application can be run from inside a Docker container.</p>\n\n<p>This makes me expect that I can use Mesos to run Node.js applications. This shouldn't be too hard to set up.</p>\n\n<p>I get that I need to create a new application, set its instances &amp; co., and then go for it. Mesos then deploys my application and takes care of distributing it over the data center. When asking Mesos for endpoints I can find out the IP addresses / host names and ports that were created.</p>\n\n<p>But, of course, I want a web application to be available at a specific domain or subdomain, ideally port 80 or 443, also using load-balancing and high-availability. Is there <em>anything</em> built into Mesos that I can use for that?</p>\n", "is_answered": true, "title": "How to access a web application running on Mesos?", "tags": ["node.js", "docker", "mesos", "mesosphere"], "last_activity_date": 1394208429, "accepted_answer_id": 22254977, "creation_date": 1394097820, "answers": [{"body": "<p>Have a look at <a href=\"http://haproxy.1wt.eu/\" rel=\"nofollow\">HAProxy</a> (load balancer), the application might run on any node and in case of failure it will be migrated to another node (and we need to update IP address of our app). From Marathon framework (sort of init.d for Mesos) we can get current IP address and port and update HAProxy config.</p>\n\n<p>Here is a sample project: <a href=\"https://github.com/riywo/sample-fluentd-on-mesos-docker\" rel=\"nofollow\">https://github.com/riywo/sample-fluentd-on-mesos-docker</a></p>\n", "answer_id": 22254977, "last_activity_date": 1394208429, "creation_date": 1394208429, "score": 4, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": true, "question_id": 22220066}], "score": 5, "link": "https://stackoverflow.com/questions/22220066/how-to-access-a-web-application-running-on-mesos", "answer_count": 1, "owner": {"user_id": 1333873, "profile_image": "https://www.gravatar.com/avatar/7ae9b432531de46073888f1a49c2391c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 43389, "link": "https://stackoverflow.com/users/1333873/golo-roden", "accept_rate": 84, "display_name": "Golo Roden"}, "view_count": 1776, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 22220066}{"body": "<p>I installed dc-os vagrant on my VMware Workstation, everything seems fine after setup with command \"vagrant up\" (see tail log below). </p>\n\n<pre><code>############################# \"vagrant up\" log\n...\n\n==&gt; p1:       Created symlink from /etc/systemd/system/multi-user.target.wants/dcos-setup.service to /etc/systemd/system/dcos-setup.service.\n==&gt; a1:       Created symlink from /etc/systemd/system/multi-user.target.wants/dcos-setup.service to /etc/systemd/system/dcos-setup.service.\n==&gt; p1: DC/OS Postflight\n==&gt; p1: [sudo]$ dcos-postflight\n==&gt; a1: DC/OS Postflight\n==&gt; m1: DC/OS Postflight\n==&gt; a1: [sudo]$ dcos-postflight\n==&gt; m1: [sudo]$ dcos-postflight\n==&gt; p1: Setting Mesos Memory: 1024 (role=slave_public)\n==&gt; p1: [sudo]$ mesos-memory 1024 slave_public\n    p1:       Updating /var/lib/dcos/mesos-resources\n==&gt; p1: Restarting Mesos Agent\n==&gt; p1: [sudo]$ bash -ceu \"systemctl stop dcos-mesos-slave-public.service &amp;&amp; rm -f /var/lib/mesos/slave/meta/slaves/latest &amp;&amp; systemctl start dcos-mesos-slave-public.service --no-block\"\n==&gt; a1: Setting Mesos Memory: 5632 (role=*)\n==&gt; a1: [sudo]$ mesos-memory 5632\n    a1:       Updating /var/lib/dcos/mesos-resources\n==&gt; a1: Restarting Mesos Agent\n==&gt; a1: [sudo]$ bash -ceu \"systemctl stop dcos-mesos-slave.service &amp;&amp; rm -f /var/lib/mesos/slave/meta/slaves/latest &amp;&amp; systemctl start dcos-mesos-slave.service --no-block\"\n==&gt; boot: DC/OS Installation Complete\n==&gt; boot: Web Interface: http://m1.dcos/\n############################# \"vagrant up\" log\n</code></pre>\n\n<p>But when I try to access m1.dcos or 192.168.65.90 thru web browser, the website is not availble.\nWhen I do curl command \"curl <a href=\"http://192.168.65.90\" rel=\"nofollow noreferrer\">http://192.168.65.90</a>\", below log also shows it's not available.</p>\n\n<pre><code>############################# curl http://192.168.65.90\n[root@localhost dcos-vagrant]# curl http://192.168.65.90\n\n&lt;HTML&gt;&lt;HEAD&gt;\n&lt;TITLE&gt;Network Error&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;blockquote&gt;\n&lt;TABLE border=0 cellPadding=1 width=\"80%\"&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\n&lt;big&gt;Network Error (tcp_error)&lt;/big&gt;\n&lt;BR&gt;\n&lt;BR&gt;\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\nA communication error occurred: \"Operation timed out\"\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\"&gt;\nThe Web Server may be down, too busy, or experiencing other problems preventing it from responding to requests. You may wish to try again at a later time.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;TR&gt;&lt;TD&gt;\n&lt;FONT face=\"Helvetica\" SIZE=2&gt;\n&lt;BR&gt;\nFor assistance, contact your network support team.\n&lt;/FONT&gt;\n&lt;/TD&gt;&lt;/TR&gt;\n&lt;/TABLE&gt;\n&lt;/blockquote&gt;\n&lt;/FONT&gt;\n&lt;/BODY&gt;&lt;/HTML&gt;\n############################# curl http://192.168.65.90\n</code></pre>\n\n<p>When I ping the m1.dcos it's fine.</p>\n\n<pre><code>############################# ping\n[root@localhost dcos-vagrant]# ping 192.168.65.90\nPING 192.168.65.90 (192.168.65.90) 56(84) bytes of data.\n64 bytes from 192.168.65.90: icmp_seq=1 ttl=64 time=0.518 ms\n64 bytes from 192.168.65.90: icmp_seq=2 ttl=64 time=0.721 ms\n^C\n--- 192.168.65.90 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 0.518/0.619/0.721/0.104 ms\n[root@localhost dcos-vagrant]# \n[root@localhost dcos-vagrant]# \n[root@localhost dcos-vagrant]# ping m1.dcos\nPING m1.dcos (192.168.65.90) 56(84) bytes of data.\n64 bytes from m1.dcos (192.168.65.90): icmp_seq=1 ttl=64 time=0.821 ms\n^C\n--- m1.dcos ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.821/0.821/0.821/0.000 ms\n############################# ping\n</code></pre>\n\n<p>I can also ssh to node m1 as vagrant.\nI am wondering which part I am missing or which service is having issue?</p>\n", "is_answered": false, "tags": ["web-services", "vagrant", "vmware", "dcos"], "last_edit_date": 1499338734, "title": "DC-OS vagrant web GUI not available", "last_activity_date": 1499338734, "answer_count": 0, "creation_date": 1499319608, "score": 1, "link": "https://stackoverflow.com/questions/44940586/dc-os-vagrant-web-gui-not-available", "owner": {"user_id": 8262820, "profile_image": "https://www.gravatar.com/avatar/4a217f6ead96631cc99b3b87e2f2637d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/8262820/webss", "display_name": "webss"}, "view_count": 41, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44940586}{"body": "<p>In slide 25 of <a href=\"http://www.slideshare.net/caniszczyk/apache-mesos-at-twitter-texas-linuxfest-2014\">this talk</a> by Twitter's Head of Open Source office, the presenter says that Mesos allows one to track and manage even GPU (I assume he meant GPGPU) resources. But I cant find any information on this anywhere else. Can someone please help? Besides Mesos, are there other cluster managers that support GPGPU?</p>\n", "is_answered": true, "title": "Does Apache Mesos recognize GPU cores?", "tags": ["twitter", "cluster-computing", "gpgpu", "mesos", "mesosphere"], "last_activity_date": 1421088990, "accepted_answer_id": 27908870, "creation_date": 1420860246, "answers": [{"body": "<p>Mesos does not yet provide direct support for (GP)GPUs, but does support custom resource types. If you specify <code>--resources=\"gpu(*):8\"</code> when starting the mesos-slave, then this will become part of the resource offer to frameworks, which can launch tasks that claim to use these resources. Once some of the gpu resources are in use by a task, only the remaining resources will be offered again, until that task completes and the gpu resources become available again. In this way, the Mesos resource allocator can actually schedule the gpu resources you declared, and ensure that only the amount declared are offered/allocated to frameworks.</p>\n\n<p>Mesos does not yet have support for gpu isolation, but with \"pluggable isolator modules\", you could build your own gpu isolator to enforce gpu resource limits.</p>\n\n<p>Alternately, if you don't want to allocate individual gpu resources, but only want to declare some nodes as having gpus while others do not, you can just use <code>--attributes=\"hasGpu:true\"</code> or something similar to differentiate the nodes that do/do not have gpus. This information is also passed onto the frameworks in resource offers, but these attributes cannot be \"consumed\" by a running task, so they will always be offered for that node.</p>\n\n<p>For more information, see <a href=\"https://mesos.apache.org/documentation/attributes-resources/\" rel=\"noreferrer\">https://mesos.apache.org/documentation/attributes-resources/</a></p>\n", "answer_id": 27908870, "last_activity_date": 1421088990, "creation_date": 1421088990, "score": 5, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 27872558}], "score": 5, "link": "https://stackoverflow.com/questions/27872558/does-apache-mesos-recognize-gpu-cores", "answer_count": 1, "owner": {"user_id": 3716293, "profile_image": "https://www.gravatar.com/avatar/7a8cd5bb41e926b0973deb7c882e5782?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 332, "link": "https://stackoverflow.com/users/3716293/crackjack", "accept_rate": 73, "display_name": "crackjack"}, "view_count": 1884, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 27872558}{"body": "<p>What exactly is the difference between Apache's Mesos and Google's Kubernetes?\nI understand both are server cluster management software. Can anyone elaborate where the main differences are - when would which framework be preferred?</p>\n\n<p>Why would you want to use <a href=\"http://googlecloudplatform.blogspot.ch/2014/08/mesosphere-collaborates-with-kubernetes-and-google-cloud-platform.html\">Kubernetes on top of Mesosphere</a>?</p>\n", "is_answered": true, "title": "What's the difference between Apache's Mesos and Google's Kubernetes", "last_edit_date": 1415387454, "tags": ["cloud", "cluster-computing", "mesosphere", "kubernetes"], "view_count": 92892, "accepted_answer_id": 26789308, "last_activity_date": 1497321942, "answers": [{"body": "<p>Kubernetes is an open source project that brings 'Google style' cluster management capabilities  to the world of virtual machines, or 'on the metal' scenarios.  It works very well with modern operating system environments (like CoreOS or Red Hat Atomic) that offer up lightweight computing 'nodes' that are managed for you.  It is written in Golang and is lightweight, modular, portable and extensible.  We (the Kubernetes team) are working with a number of different technology companies (including Mesosphere who curate the Mesos open source project) to establish Kubernetes as the standard way to interact with computing clusters.  The idea is to reproduce the patterns that we see people needing to build cluster applications based on our experience at Google. Some of these concepts include:</p>\n\n<ul>\n<li><em>pods</em> \u2014 a way to group containers together</li>\n<li><em>replication controllers</em> \u2014 a way to handle the lifecycle of containers</li>\n<li><em>labels</em> \u2014 a way to find and query containers, and</li>\n<li><em>services</em> \u2014 a set of containers performing a common function.  </li>\n</ul>\n\n<p>So with Kubernetes alone you will have something that is simple, easy to get up-and-running, portable and extensible that adds 'cluster' as a noun to the things that you manage in the lightest weight manner possible.  Run an application on a cluster, and stop worrying about an individual machine.  In this case, cluster is a flexible resource just like a VM.  It is a logical computing unit.  Turn it up, use it, resize it, turn it down quickly and easily. </p>\n\n<p>With Mesos, there is a fair amount of overlap in terms of the basic vision, but the products are at quite different points in their lifecycle and have different sweet spots.  Mesos is a distributed systems kernel that stitches together a lot of different machines into a logical computer. It was born for a world where you own a lot of physical resources to create a big static computing cluster.  The great thing about it is that lots of modern scalable data processing application run well on Mesos (Hadoop, Kafka, Spark) and it is nice because you can run them all on the same basic resource pool, along with your new age container packaged apps.  It is somewhat more heavy weight than the Kubernetes project, but is getting easier and easier to manage thanks to the work of folks like Mesosphere. </p>\n\n<p>Now what gets really interesting is that Mesos is currently being adapted to add a lot of the Kubernetes concepts and to support the Kubernetes API.  So it will be a gateway to getting more capabilities for your Kubernetes app (high availability master, more advanced scheduling semantics, ability to scale to a very large number of nodes) if you need them, and is well suited to run production workloads (Kubernetes is still in an alpha state).</p>\n\n<p>When asked, I tend to say:</p>\n\n<ol>\n<li><p>Kubernetes is a great place to start if you are new to the clustering world;  it is the quickest, easiest and lightest way to kick the tires and start experimenting with cluster oriented development.  It offers a very high level of portability since it is being supported by a lot of different providers (Microsoft, IBM, Red Hat, CoreOs, MesoSphere, VMWare, etc).</p></li>\n<li><p>If you have existing workloads (Hadoop, Spark, Kafka, etc), Mesos gives you a framework that let's you interleave those workloads with each other, and mix in a some of the new stuff including Kubernetes apps.</p></li>\n<li><p>Mesos gives you an escape valve if you need capabilities that are not yet implemented by the community in the Kubernetes framework.  </p></li>\n</ol>\n", "answer_id": 26789308, "last_activity_date": 1430518141, "creation_date": 1415307734, "score": 357, "owner": {"user_id": 4150795, "profile_image": "https://lh6.googleusercontent.com/-K3q7yHjYQPI/AAAAAAAAAAI/AAAAAAAAAug/GwoPvCiQ7-c/photo.jpg?sz=128", "user_type": "registered", "reputation": 3664, "link": "https://stackoverflow.com/users/4150795/craig-mcluckie", "display_name": "Craig Mcluckie"}, "is_accepted": true, "last_edit_date": 1430518141, "question_id": 26705201}, {"body": "<blockquote>\n  <p>Kubernetes and Mesos are a match made in heaven. Kubernetes enables the Pod (group of co-located containers) abstraction, along with Pod labels for service discovery, load-balancing, and replication control. Mesos provides the fine-grained resource allocations for pods across nodes in a cluster, and can make Kubernetes play nicely with other frameworks running on the same cluster resources.</p>\n</blockquote>\n\n<p>from <a href=\"https://github.com/mesosphere/kubernetes-mesos/blob/master/README.md\">readme of kubernetes-mesos</a></p>\n", "answer_id": 28062232, "last_activity_date": 1421827312, "creation_date": 1421827312, "score": 24, "owner": {"user_id": 667254, "profile_image": "https://i.stack.imgur.com/Y6CGj.jpg?s=128&g=1", "user_type": "registered", "reputation": 1249, "link": "https://stackoverflow.com/users/667254/herodot", "display_name": "herodot"}, "is_accepted": false, "question_id": 26705201}, {"body": "<p>Mesos and Kubernetes can both be used to manage a cluster of machines and abstract away the hardware.</p>\n\n<p>Mesos, by design, doesn't provide you with a scheduler (to decide where and when to run processes and what to do if the process fails), you can use something like Marathon or Chronos, or write your own.</p>\n\n<p>Kubernetes will do scheduling for you out of the box, and can be used as a scheduler for Mesos (please correct me if I'm wrong here!) which is where you can use them together. Mesos can have multiple schedulers sharing the same cluster, so in theory you could run kubernetes and chronos together on the same hardware.</p>\n\n<p>Super simplistically: if you want control over how your containers are scheduled, go for Mesos, otherwise Kubernetes rocks.</p>\n", "answer_id": 28719621, "last_activity_date": 1425293373, "creation_date": 1424868983, "score": 10, "owner": {"user_id": 2851943, "profile_image": "https://www.gravatar.com/avatar/7356c8ed45eb90f9ecc92912ceccbef5?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 527, "link": "https://stackoverflow.com/users/2851943/user2851943", "accept_rate": 80, "display_name": "user2851943"}, "is_accepted": false, "last_edit_date": 1425293373, "question_id": 26705201}, {"body": "<p>Both projects aim to make it easier to deploy &amp; manage applications inside containers in your datacenter or cloud.</p>\n\n<p>In order to deploy applications on top of Mesos, one can use Marathon or Kubernetes for Mesos.</p>\n\n<p>Marathon is a cluster-wide init and control system for running Linux services in cgroups and Docker containers.  Marathon has a number of different canary deploy features and is a very mature project.</p>\n\n<p>Marathon runs on top of Mesos, which is a highly scalable, battle tested and flexible resource manager. Marathon is proven to scale and runs many in many production environments. </p>\n\n<p>The Mesos and Mesosphere technology stack provides a cloud-like environment for running existing Linux workloads, but it also provides a native environment for building new distributed systems.</p>\n\n<p>Mesos is a distributed systems kernel, with a full API for programming directly against the datacenter. It abstracts underlying hardware (e.g. bare metal or VMs) away and just exposes the resources. It contains primitives for writing distributed applications (e.g. Spark was originally a Mesos App, Chronos, etc.) such as Message Passing, Task Execution, etc. Thus, entirely new applications are made possible. Apache Spark is one example for a new (in Mesos jargon called) framework that was built originally for Mesos. This enabled really fast development - the developers of Spark didn't have to worry about networking to distribute tasks amongst nodes as this is a core primitive in Mesos.</p>\n\n<p>To my knowledge, Kubernetes is not used inside Google in production deployments today. For production, Google uses Omega/Borg, which is much more similar to the Mesos/Marathon model. However the great thing about using Mesos as the foundation is that both Kubernetes and Marathon can run on top of it.</p>\n\n<p>More resources about Marathon:</p>\n\n<p><a href=\"https://mesosphere.github.io/marathon/\">https://mesosphere.github.io/marathon/</a></p>\n\n<p>Video:\n<a href=\"https://www.youtube.com/watch?v=hZNGST2vIds\">https://www.youtube.com/watch?v=hZNGST2vIds</a></p>\n", "answer_id": 28725899, "last_activity_date": 1424886288, "creation_date": 1424885961, "score": 45, "owner": {"user_id": 3114359, "profile_image": "https://www.gravatar.com/avatar/b68f37dafa798778fafbf9f805c71402?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 451, "link": "https://stackoverflow.com/users/3114359/mesospherian", "display_name": "mesospherian"}, "is_accepted": false, "last_edit_date": 1424886288, "question_id": 26705201}, {"body": "<p>I like this short video here <a href=\"https://mesosphere.com/learn/\" rel=\"nofollow\">mesos learning material</a></p>\n\n<p>with bare metal clusters, you would need to spawn stacks like HDFS, SPARK, MR etc... so if you launch tasks related to these using only bare metal cluster management, there will be a lot cold starting time.</p>\n\n<p>with mesos, you can install these services on top of the bare metals and you can avoid the bring up time of those base services. This is something mesos does well. and can be utilised by kubernetes building on top of it. </p>\n", "answer_id": 35681529, "last_activity_date": 1456656658, "creation_date": 1456656658, "score": 2, "owner": {"user_id": 161289, "profile_image": "https://i.stack.imgur.com/KUaQL.jpg?s=128&g=1", "user_type": "registered", "reputation": 2611, "link": "https://stackoverflow.com/users/161289/zinking", "accept_rate": 86, "display_name": "zinking"}, "is_accepted": false, "question_id": 26705201}], "score": 253, "link": "https://stackoverflow.com/questions/26705201/whats-the-difference-between-apaches-mesos-and-googles-kubernetes", "answer_count": 5, "owner": {"user_id": 2041240, "profile_image": "https://www.gravatar.com/avatar/8c4d875614b7554c7b21f9d7409c96b6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1425, "link": "https://stackoverflow.com/users/2041240/binaryanomaly", "accept_rate": 60, "display_name": "binaryanomaly"}, "creation_date": 1414967335, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 26705201}{"body": "<p>We use Terraform to create and destroy Mesos DC/OS cluster on AWS EC2. Number of agent nodes is defined in a <code>variable.tf</code> file:</p>\n\n<pre><code>variable \"instance_counts\" {\n  type = \"map\"\n  default = {   \n    master       = 1\n    public_agent = 2 \n    agent        = 5 \n  }\n}\n</code></pre>\n\n<p>Once the cluster is up, you can add or remove agent nodes by changing the number of agent in that file and apply again. Terraform is smart enough to recognize the difference and act accordingly. When it destroy nodes, it tends to go for the highest numbered nodes. For example, if I have a 8-node dcos cluster and want to terminate 2 of the agents, Terraform would take down <code>dcos_agent_node-6</code> and <code>dcos_agent_node-7</code>. </p>\n\n<p>What if I want to destroy an agent with a particular IP? Terraform must be aware of the IPs because it knows the order of the instances. How do I hack Terraform to remove agents by providing the IPs?</p>\n", "is_answered": true, "title": "Is it possible to ask Terraform to destroy AWS nodes with known IPs", "tags": ["amazon-ec2", "mesos", "terraform", "dcos"], "last_activity_date": 1486463085, "accepted_answer_id": 42087358, "creation_date": 1486400901, "answers": [{"body": "<p>I think you're misunderstanding how Terraform works.</p>\n\n<p>Terraform takes your configuration and builds out a dependency graph of how to create the resources described in the configuration. If it has a state file it then overlays information from the provider (such as AWS) to see what is already created and managed by Terraform and removes that from the plan and potentially creates destroy plans for resources that exist in the provider and state file.</p>\n\n<p>So if you have a configuration with a 6 node cluster and a fresh field (no state file, nothing built by Terraform in AWS) then Terraform will create 6 nodes. If you then set it to have 8 nodes then Terraform will attempt to build a plan containing 8 nodes, realises it already has 6 and then creates a plan to add the 2 missing nodes. When you then change your configuration back to 6 nodes Terraform will build a plan with 6 nodes, realise you have 8 nodes and create a destroy plan for nodes 7 and 8.</p>\n\n<p>To try and get it to do anything different to that would involve some horrible hacking of the state file so that it thinks that nodes 7 and 8 are different to the ones most recently added by Terraform.</p>\n\n<p>As an example your state file might look something like this:</p>\n\n<pre><code>{\n    \"version\": 3,\n    \"terraform_version\": \"0.8.1\",\n    \"serial\": 1,\n    \"lineage\": \"7b565ca6-689a-4aab-a3ec-a1ed77e83678\",\n    \"modules\": [\n        {\n            \"path\": [\n                \"root\"\n            ],\n            \"outputs\": {},\n            \"resources\": {\n                \"aws_instance.test.0\": {\n                    \"type\": \"aws_instance\",\n                    \"depends_on\": [],\n                    \"primary\": {\n                        \"id\": \"i-01ee444f57aa32b8e\",\n                        \"attributes\": {\n                            ...\n                        },\n                        \"meta\": {\n                            \"schema_version\": \"1\"\n                        },\n                        \"tainted\": false\n                    },\n                    \"deposed\": [],\n                    \"provider\": \"\"\n                },\n                \"aws_instance.test.1\": {\n                    \"type\": \"aws_instance\",\n                    \"depends_on\": [],\n                    \"primary\": {\n                        \"id\": \"i-07c1999f1109a9ce2\",\n                        \"attributes\": {\n                            ...\n                        },\n                        \"meta\": {\n                            \"schema_version\": \"1\"\n                        },\n                        \"tainted\": false\n                    },\n                    \"deposed\": [],\n                    \"provider\": \"\"\n                }\n            },\n            \"depends_on\": []\n        }\n    ]\n}\n</code></pre>\n\n<p>If I wanted to go back to a single instance instead of 2 then Terraform would attempt to remove the <code>i-07c1999f1109a9ce2</code> instance as the configuration is telling it that <code>aws_instance.test.0</code> should exist but not <code>aws_instance.test.1</code>. To get it to remove <code>i-01ee444f57aa32b8e</code> instead then I could edit my state file to flip the two around and then Terraform would think that that instance should be removed instead.</p>\n\n<p>However, you're getting into very difficult territory as soon as you start doing things like that and hacking the state file. While it's something you <em>can</em> do (and occasionally may need to) you should seriously consider how you are working if this is anything other than a one off case for a special reason (such as moving raw resources into modules - now made easier with <a href=\"https://www.terraform.io/docs/commands/state/mv.html\" rel=\"nofollow noreferrer\">Terraform's <code>state mv</code> command</a>).</p>\n\n<p>In your case I'd question why you need to remove two specific nodes in a Mesos cluster rather than just specifying the size of the Mesos cluster. If it's a case of a specific node being bad then I'd always terminate it and allow Terraform to build me a fresh, healthy one anyway.</p>\n", "answer_id": 42087358, "last_activity_date": 1486463085, "creation_date": 1486463085, "score": 1, "owner": {"user_id": 2291321, "profile_image": "https://www.gravatar.com/avatar/24a41cddd8faf69e3fbd0a778ba6fedf?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13573, "link": "https://stackoverflow.com/users/2291321/ydaetskcor", "accept_rate": 83, "display_name": "ydaetskcoR"}, "is_accepted": true, "question_id": 42073396}], "score": 1, "link": "https://stackoverflow.com/questions/42073396/is-it-possible-to-ask-terraform-to-destroy-aws-nodes-with-known-ips", "answer_count": 1, "owner": {"user_id": 3358927, "profile_image": "https://www.gravatar.com/avatar/1d55888f9dce36510f6f0e8e2a9a0a5e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 427, "link": "https://stackoverflow.com/users/3358927/ddd", "accept_rate": 90, "display_name": "ddd"}, "view_count": 111, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42073396}{"body": "<p>Is it possible to change the DCOS template to use spot instances? I have looked around and there does not seem to be much information regarding this.</p>\n", "is_answered": true, "title": "Spot Instances Support DCOS", "tags": ["amazon-web-services", "mesosphere"], "last_activity_date": 1437066764, "accepted_answer_id": 31460552, "creation_date": 1436883951, "answers": [{"body": "<p>Okay, <a href=\"https://s3.amazonaws.com/downloads.mesosphere.io/dcos/stable/single-master.cloudformation.json\" rel=\"noreferrer\">given the DCOS template</a>, the LaunchConfiguration for the slaves looks like this: (I've shortened it somewhat)</p>\n\n<pre><code>\"MasterLaunchConfig\": {\n  \"Type\": \"AWS::AutoScaling::LaunchConfiguration\",\n  \"Properties\": {\n    \"IamInstanceProfile\": { \"Ref\": \"MasterInstanceProfile\" },\n    \"SecurityGroups\": [ ... ],\n    \"ImageId\": { ... },\n    \"InstanceType\": { ... },\n    \"KeyName\": { \"Ref\": \"KeyName\" },\n    \"UserData\": { ... }\n  }\n}\n</code></pre>\n\n<p>To get started, all you need to do is add the <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-launchconfig.html#cfn-as-launchconfig-spotprice\" rel=\"noreferrer\"><code>SpotPrice</code></a> property in there. The value of <code>SpotPrice</code> is, obviously, the maximum price you want to pay. You'll probably need to do more work around autoscaling, especially with alarms and time of day. So here's your new <code>LaunchConfiguration</code> with a spot price of $1.00 per hour:</p>\n\n<pre><code>\"MasterLaunchConfig\": {\n  \"Type\": \"AWS::AutoScaling::LaunchConfiguration\",\n  \"Properties\": {\n    \"IamInstanceProfile\": { \"Ref\": \"MasterInstanceProfile\" },\n    \"SecurityGroups\": [ ... ],\n    \"ImageId\": { ... },\n    \"InstanceType\": { ... },\n    \"KeyName\": { \"Ref\": \"KeyName\" },\n    \"UserData\": { ... },\n    \"SpotPrice\": 1.00\n  }\n}\n</code></pre>\n", "answer_id": 31460552, "last_activity_date": 1437066764, "creation_date": 1437066764, "score": 5, "owner": {"user_id": 659298, "profile_image": "https://www.gravatar.com/avatar/cad260683598a6e41608b91a9b57099b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 10867, "link": "https://stackoverflow.com/users/659298/tedder42", "accept_rate": 61, "display_name": "tedder42"}, "is_accepted": true, "question_id": 31409463}], "score": 3, "link": "https://stackoverflow.com/questions/31409463/spot-instances-support-dcos", "answer_count": 1, "owner": {"user_id": 2626221, "profile_image": "https://i.stack.imgur.com/q0Dae.jpg?s=128&g=1", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/2626221/gkumar7", "accept_rate": 88, "display_name": "gkumar7"}, "view_count": 627, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31409463}{"body": "<p>It seems <strong>DC/OS v1.9</strong> just support <code>redhat</code>, <code>centos</code>, <code>coreos</code>, but most our machines are <code>ubuntu</code>.</p>\n\n<p>Seems newest DC/OS coming soon will support ubuntu1604 as it now use systemd to replace upstart, but most of our server are ubuntu1204 &amp; can not be reinstalled as maintained by other teams with a lot of services there already.</p>\n\n<p><strong>Sum up, we may have 3 centos machines &amp; 5 ubuntu1204 machines.\nWhat's the suggestion for us to use DC/OS?</strong></p>\n\n<p>(Could we just install DC/OS on 3 centos machines?\nAnd with some hack, we could add 5 ubuntu1204 to the manage of DC/OS?)</p>\n\n<p>(Maybe just add these ubuntu1204 machines as agent to the <code>marathon</code> which managed by the DC/OS installed on centos?\nWhat's potential issue?\nAnyone could give a best practice for my situation?)</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "title": "How to add ubuntu 1204 or other old version ubuntu servers to DC/OS?", "last_activity_date": 1496223552, "answer_count": 0, "creation_date": 1496223552, "score": 0, "link": "https://stackoverflow.com/questions/44281147/how-to-add-ubuntu-1204-or-other-old-version-ubuntu-servers-to-dc-os", "owner": {"user_id": 6394722, "profile_image": "https://www.gravatar.com/avatar/117654f31d6ad5c9b2b0e00dcf4b24f3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 181, "link": "https://stackoverflow.com/users/6394722/atline", "accept_rate": 83, "display_name": "atline"}, "view_count": 15, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44281147}{"body": "<p>I have a 3 nodes setup running Marathon, mesos-master,mesos-slave and Zookeeper with HA config enabled, then tested a deployment of simple hello app using mesos-execute and it's working as expected.</p>\n\n<p>Now everything looks fine, so I connect to Marathon and deploy a simple app to test marathon: (echo \"hello\" >> /tmp/output.txt) but the application get sucked in \"waiting\" status.</p>\n\n<p>what could be the problem preventing Marathon to use mesos resources for deployment ?</p>\n\n<p>Logs from mesos-master:</p>\n\n<pre><code>I0904 11:23:27.064332 19769 master.cpp:2813] Received SUBSCRIBE call for framework 'marathon' at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324\nI0904 11:23:27.064623 19769 master.cpp:2890] Subscribing framework marathon with checkpointing enabled and capabilities [ PARTITION_AWARE ]\nI0904 11:23:27.064669 19769 master.cpp:6272] Updating info for framework cb16118a-2257-4020-a907-63aa6294e11b-0000\nI0904 11:23:27.064697 19769 master.cpp:2994] Framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324 failed over\nI0904 11:23:27.065032 19770 hierarchical.cpp:342] Activated framework cb16118a-2257-4020-a907-63aa6294e11b-0000\nI0904 11:23:27.065465 19770 master.cpp:7305] Sending 3 offers to framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324\nI0904 11:23:27.907865 19769 http.cpp:1115] HTTP GET for /files/read?_=1504517007920&amp;jsonp=jQuery17109098185077823333_1504516979864&amp;length=50000&amp;offset=352538&amp;path=%2Fmaster%2Flog from 192.168.40.1:53525 with User-Agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'\nI0904 11:23:28.916651 19768 http.cpp:1115] HTTP GET for /files/read?_=1504517008930&amp;jsonp=jQuery17109098185077823333_1504516979865&amp;length=50000&amp;offset=353797&amp;path=%2Fmaster%2Flog from 192.168.40.1:53525 with User-Agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'\nE0904 11:23:30.071293 19775 process.cpp:2450] Failed to shutdown socket with fd 39, address 192.168.40.159:58072: Transport endpoint is not connected\nI0904 11:23:30.073277 19768 master.cpp:1430] Framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324 disconnected\nI0904 11:23:30.073307 19768 master.cpp:3160] Deactivating framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324\nI0904 11:23:30.073485 19768 master.cpp:3137] Disconnecting framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324\nI0904 11:23:30.073496 19768 master.cpp:1445] Giving framework cb16118a-2257-4020-a907-63aa6294e11b-0000 (marathon) at scheduler-0340362b-0bb6-4fb8-8501-118d976e2cbd@192.168.40.156:36324 1weeks to failover\nI0904 11:23:30.073519 19768 hierarchical.cpp:374] Deactivated framework cb16118a-2257-4020-a907-63aa6294e11b-0000\n</code></pre>\n\n<p>curl -XGET '<a href=\"http://mesosphere2:8098/v2/queue?pretty\" rel=\"nofollow noreferrer\">http://mesosphere2:8098/v2/queue?pretty</a>' | jq</p>\n\n<pre><code>{\n  \"queue\": [\n    {\n      \"count\": 1,\n      \"delay\": {\n        \"timeLeftSeconds\": 0,\n        \"overdue\": true\n      },\n      \"since\": \"2017-09-04T13:12:42.024Z\",\n      \"processedOffersSummary\": {\n        \"processedOffersCount\": 12,\n        \"unusedOffersCount\": 12,\n        \"lastUnusedOfferAt\": \"2017-09-04T13:14:52.554Z\",\n        \"rejectSummaryLastOffers\": [\n          {\n            \"reason\": \"UnfulfilledRole\",\n            \"declined\": 3,\n            \"processed\": 3\n          },\n          {\n            \"reason\": \"UnfulfilledConstraint\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"NoCorrespondingReservationFound\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientCpus\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientMemory\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientDisk\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientGpus\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientPorts\",\n            \"declined\": 0,\n            \"processed\": 0\n          }\n        ],\n        \"rejectSummaryLaunchAttempt\": [\n          {\n            \"reason\": \"UnfulfilledRole\",\n            \"declined\": 12,\n            \"processed\": 12\n          },\n          {\n            \"reason\": \"UnfulfilledConstraint\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"NoCorrespondingReservationFound\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientCpus\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientMemory\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientDisk\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientGpus\",\n            \"declined\": 0,\n            \"processed\": 0\n          },\n          {\n            \"reason\": \"InsufficientPorts\",\n            \"declined\": 0,\n            \"processed\": 0\n          }\n        ]\n      },\n      \"app\": {\n        \"id\": \"/test03\",\n        \"acceptedResourceRoles\": [\n          \"slave_public\"\n        ],\n        \"backoffFactor\": 1.15,\n        \"backoffSeconds\": 1,\n        \"container\": {\n          \"type\": \"DOCKER\",\n          \"docker\": {\n            \"forcePullImage\": false,\n            \"image\": \"laghao/hello-marathon\",\n            \"network\": \"BRIDGE\",\n            \"parameters\": [],\n            \"portMappings\": [\n              {\n                \"containerPort\": 80,\n                \"hostPort\": 80,\n                \"labels\": {},\n                \"protocol\": \"tcp\",\n                \"servicePort\": 10003\n              }\n            ],\n            \"privileged\": false\n          },\n          \"volumes\": []\n        },\n        \"cpus\": 0.1,\n        \"disk\": 0,\n        \"executor\": \"\",\n        \"instances\": 1,\n        \"labels\": {},\n        \"maxLaunchDelaySeconds\": 3600,\n        \"mem\": 64,\n        \"gpus\": 0,\n        \"portDefinitions\": [\n          {\n            \"port\": 10003,\n            \"name\": \"default\",\n            \"protocol\": \"tcp\"\n          }\n        ],\n        \"requirePorts\": false,\n        \"upgradeStrategy\": {\n          \"maximumOverCapacity\": 1,\n          \"minimumHealthCapacity\": 1\n        },\n        \"version\": \"2017-09-04T13:12:41.993Z\",\n        \"versionInfo\": {\n          \"lastScalingAt\": \"2017-09-04T13:12:41.993Z\",\n          \"lastConfigChangeAt\": \"2017-09-04T13:12:41.993Z\"\n        },\n        \"killSelection\": \"YOUNGEST_FIRST\",\n        \"unreachableStrategy\": {\n          \"inactiveAfterSeconds\": 300,\n          \"expungeAfterSeconds\": 600\n        }\n      }\n    }\n  ]\n}\n</code></pre>\n", "is_answered": false, "tags": ["apache-zookeeper", "mesos", "marathon", "mesosphere"], "last_edit_date": 1504531477, "title": "Marathon application deployment get stuck on Waiting status", "last_activity_date": 1504536190, "answer_count": 1, "creation_date": 1504517780, "score": 0, "link": "https://stackoverflow.com/questions/46034239/marathon-application-deployment-get-stuck-on-waiting-status", "answers": [{"body": "<p>From <a href=\"https://mesosphere.github.io/marathon/docs/troubleshooting.html#an-app-stays-in-waiting-forever\" rel=\"nofollow noreferrer\">documentation</a></p>\n\n<blockquote>\n  <p><strong>An app stays in \u201cWaiting\u201d forever</strong>\n  This means that Marathon does not receive \u201cResource Offers\u201d from Mesos that allow it to start tasks of this application. The simplest failure is that there are not sufficient resources available in the cluster or another framework hords all these resources. You can check the Mesos UI for available resources. Note that the required resources (such as CPU, Mem, Disk) have to be all available on a single host.</p>\n  \n  <p>If you do not find the solution yourself and you create a GitHub issue, please append the output of Mesos /state endpoint to the bug report so that we can inspect available cluster resources.</p>\n</blockquote>\n\n<p>In your case there is a problem with application role requirement and agent role. You can deduce it from <code>UnfulfilledRole</code>. </p>\n\n<p>Marathon 1.4 introduced information about stuck deployments. You can query <a href=\"https://mesosphere.github.io/marathon/docs/generated/api.html#v2_queue_get\" rel=\"nofollow noreferrer\"><code>/v2/queue</code></a> and get statistics why offers were declined.</p>\n", "answer_id": 46037242, "last_activity_date": 1504536190, "creation_date": 1504528634, "score": 0, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": false, "last_edit_date": 1504536190, "question_id": 46034239}], "owner": {"user_id": 4859265, "profile_image": "https://lh3.googleusercontent.com/-i8evMS2CT5I/AAAAAAAAAAI/AAAAAAAAADU/h6HrFngsVtk/photo.jpg?sz=128", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/4859265/oussema-benlagha", "accept_rate": 0, "display_name": "Oussema Benlagha"}, "view_count": 23, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 46034239}{"body": "<p>After restarting my 3 masters in my DC/OS cluster, the DC/OS dashboard is showing 0 connected nodes. However from the DC/OS cli I see all 6 of my agent nodes:</p>\n\n<pre><code>$ dcos node\n  HOSTNAME        IP                         ID\n172.16.1.20  172.16.1.20  a7af5134-baa2-45f3-892e-5e578cc00b4d-S7\n172.16.1.21  172.16.1.21  a7af5134-baa2-45f3-892e-5e578cc00b4d-S12\n172.16.1.22  172.16.1.22  a7af5134-baa2-45f3-892e-5e578cc00b4d-S8\n172.16.1.23  172.16.1.23  a7af5134-baa2-45f3-892e-5e578cc00b4d-S6\n172.16.1.24  172.16.1.24  a7af5134-baa2-45f3-892e-5e578cc00b4d-S11\n172.16.1.25  172.16.1.25  a7af5134-baa2-45f3-892e-5e578cc00b4d-S10`\n</code></pre>\n\n<p>I am still able to schedule tasks in Marathon both from the dcos cli and from the Marathon gui, they then are properly scheduled and executed on the agents. Also, from the mesos interface on :5050 I can see all of the agents in the slaves page.</p>\n\n<p>I have restarted agent nodes and master nodes. I have also rerun the DC/OS GUI installer and run preflight check, which of course fails with an \"already installed\" error. </p>\n\n<p>Is there a way to re-register the node with DC/OS GUI short of uninstalling/reinstalling a node?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1464729303, "title": "DC/OS - Dashboard showing 0 connected nodes", "last_activity_date": 1493981444, "answer_count": 1, "creation_date": 1463693366, "score": 3, "link": "https://stackoverflow.com/questions/37334339/dc-os-dashboard-showing-0-connected-nodes", "answers": [{"body": "<p>For anyone who is running into this, my problem was related to our corporate proxy. In order to get the Universe working in my cluster I had to add proxy settings to <code>/opt/mesosphere/environment</code>.  I then restarted the <code>dcos-cosmos.service</code> and life was good. However, upon server restart, dcos-history-service.service was now running with the new environment and was unable to resolve my local names with our proxy server. To solve, I added a <code>NO_PROXY</code> to the <code>/opt/mesosphere/environment</code> and DCOS dashboard is again happy.</p>\n", "answer_id": 37555493, "last_activity_date": 1464729327, "creation_date": 1464728321, "score": 0, "owner": {"user_id": 6358305, "profile_image": "https://www.gravatar.com/avatar/a35ea4fb63318d19b1fa8e50407a98bb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6358305/ndachel", "display_name": "ndachel"}, "is_accepted": false, "last_edit_date": 1464729327, "question_id": 37334339}], "owner": {"user_id": 6358305, "profile_image": "https://www.gravatar.com/avatar/a35ea4fb63318d19b1fa8e50407a98bb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6358305/ndachel", "display_name": "ndachel"}, "view_count": 542, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 37334339}{"body": "<p>Followed <a href=\"https://www.mesosphere.com/amazon/\" rel=\"nofollow\">https://www.mesosphere.com/amazon/</a> I created a DCOS cluster on Amazon AWS.\nThen I followed <a href=\"http://kubernetes.io/v1.1/docs/getting-started-guides/dcos.html\" rel=\"nofollow\">http://kubernetes.io/v1.1/docs/getting-started-guides/dcos.html</a> and installed Kubernete on it.\nThen I followed <a href=\"http://kubernetes.io/v1.1/docs/user-guide/quick-start.html\" rel=\"nofollow\">http://kubernetes.io/v1.1/docs/user-guide/quick-start.html</a>\nI was able to launch pods successfully.\nThen I ran into problem with expose the service to public.</p>\n\n<pre><code>$ dcos kubectl expose rc my-nginx --port=80 --type=LoadBalancer\nservice \"my-nginx\" exposed\n$ dcos ssun$ dcos kubectl get svc my-nginx\nNAME       CLUSTER_IP    EXTERNAL_IP   PORT(S)   SELECTOR       AGE\nmy-nginx   10.10.10.32                 80/TCP    run=my-nginx   8s\n</code></pre>\n\n<p>The EXTERNAL_IP address does not exists. According to the tutorial, it should. So I'm thinking it has something to do with the fact that my Kubernete is inside DCOS.</p>\n\n<p>Please help. Thank you very much!</p>\n", "is_answered": true, "title": "Expose Kubernete service to public inside mesosphere's DCOS", "tags": ["amazon-web-services", "kubernetes", "mesos", "mesosphere"], "last_activity_date": 1454636224, "accepted_answer_id": 35214901, "creation_date": 1454634401, "answers": [{"body": "<p>Kubernetes on Mesos/DCOS does not support automatic LoadBalancer creation yet. </p>\n\n<p>As the <a href=\"http://kubernetes.io/v1.1/docs/user-guide/quick-start.html\" rel=\"nofollow\">quick start</a> states:</p>\n\n<blockquote>\n  <p>Through integration with some cloud providers (for example Google Compute Engine and AWS EC2), Kubernetes enables you to request that it provision a public IP address for your application.</p>\n</blockquote>\n\n<p>AFAIK, only GCE, GKE, and AWS support automatic LoadBalancer creation so far.</p>\n\n<p>Another key difference about DCOS (compared to kubernetes) is that it comes by default with two zones: public and private. So nothing scheduled on the private nodes is externally accessible without a reverse-proxy on the public nodes.</p>\n\n<p>Additionally, Kubernetes on DCOS does not yet support IP-per-container. Support for IP-per-container is under development with the <a href=\"http://www.metaswitch.com/the-switch/metaswitch-mesosphere-work-on-project-calico-mesos-and-mesosphere-dcos-integration\" rel=\"nofollow\">DCOS/Calico integration</a>. Some community members have also reportedly attempted using cluster-wide docker overlay networking.</p>\n\n<p>For now, there are a few alternative options for reaching your pod externally:</p>\n\n<ol>\n<li>Deploy your pod on all the public slaves (using <a href=\"https://github.com/kubernetes/kubernetes/blob/master/contrib/mesos/docs/scheduler.md#resource-roles\" rel=\"nofollow\">resource role annotations</a>) and <code>hostPort:80</code>. Then hit the address of the DCOS public slave AWS ELB.</li>\n<li>Create your own load balancer nginx pod (e.g. <a href=\"https://github.com/kubernetes/contrib/tree/master/service-loadbalancer\" rel=\"nofollow\">service-loadbalancer</a> and schedule it on the public slaves with <code>hostPort:80</code>. Then hit the IP of the host node it's on.</li>\n</ol>\n\n<p>It's definitely a priority of the Mesosphere Kubernetes Team to make this experience smoother on DCOS. Hopefully the solution will include automatic LoadBalancer creation.</p>\n", "answer_id": 35214901, "last_activity_date": 1454636224, "creation_date": 1454636224, "score": 2, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "question_id": 35214660}], "score": 0, "link": "https://stackoverflow.com/questions/35214660/expose-kubernete-service-to-public-inside-mesospheres-dcos", "answer_count": 1, "owner": {"user_id": 1406024, "profile_image": "https://www.gravatar.com/avatar/ee060db7e04e5f29a8a98a8ab91ed6cd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 147, "link": "https://stackoverflow.com/users/1406024/gordon-sun", "accept_rate": 18, "display_name": "Gordon Sun"}, "view_count": 200, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35214660}{"body": "<p>I'am trying to add the file /etc/marathon/conf/disable_http with no value but I have this error:</p>\n\n<pre><code>Error: Bad arguments for option 'disable_http': '' - too many arguments for flag option \n</code></pre>\n\n<p>I try, empty file, \"enabled\" value, \"disabled\" value, \"true\".\nThanks.</p>\n", "is_answered": true, "title": "How can I set \"disable_http\" which is flag parameter with file strategy in marathon", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1456154963, "accepted_answer_id": 35557572, "creation_date": 1445565125, "answers": [{"body": "<p>If your are using the package provide by mesoshepere the file must start with a ? , with this the content of the file is not add to the command line</p>\n\n<p><a href=\"https://github.com/mesosphere/marathon/blob/22a00d46fa1741e5c237f2e70e4180d53b3b127b/bin/marathon-framework#L42\" rel=\"nofollow\">https://github.com/mesosphere/marathon/blob/22a00d46fa1741e5c237f2e70e4180d53b3b127b/bin/marathon-framework#L42</a></p>\n", "answer_id": 35557572, "last_activity_date": 1456154963, "creation_date": 1456154963, "score": 1, "owner": {"user_id": 722147, "profile_image": "https://www.gravatar.com/avatar/66353ce6b5b8fd4b6c22e9fb133025be?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 58, "link": "https://stackoverflow.com/users/722147/ssalvatori", "display_name": "ssalvatori"}, "is_accepted": true, "question_id": 33293639}], "score": 1, "link": "https://stackoverflow.com/questions/33293639/how-can-i-set-disable-http-which-is-flag-parameter-with-file-strategy-in-marat", "answer_count": 1, "owner": {"user_id": 592319, "profile_image": "https://www.gravatar.com/avatar/c7696e7930a885001be95fb59a3eb8cd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/592319/christian-kakesa", "display_name": "Christian Kakesa"}, "view_count": 71, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 33293639}{"body": "<p>I got a running DC/OS cluster on Azure and i'm trying to configure it to use private registry credentials. \nI'm running Azure Private Registry with admin. I can log in and use the images. </p>\n\n<p>I followed the guide provided by DC/OS but it recommends saving it on the nodes themselves. I want to use Azure File Storage instead. </p>\n\n<p>I saved the config.json file to auth to the loginserver on a blob and provide the URI with deployment configuration. </p>\n\n<p>config.json:</p>\n\n<pre><code>auths:  \n  stageon.azurecr.io:   \n     auth   \"...\"\n</code></pre>\n\n<p>Now the configuration just keeps running without any output so I assume it's hanging on pulling the image.</p>\n\n<p>I am providing the direct link URL to the file and when I access it through webbrowser it returns the JSON.</p>\n\n<p>Did anyone do something similar before I found this <a href=\"https://stackoverflow.com/questions/31075733/how-should-a-dockercfg-file-be-hosted-in-a-mesosphere-on-aws-setup-so-that-only/31180422#31180422\">thread</a>  for amazon before but I can't seem to get it working. </p>\n", "is_answered": false, "tags": ["azure", "docker-registry", "mesosphere", "registrykey", "dcos"], "last_edit_date": 1495540498, "title": "DC/OS private registry with authentication fails", "last_activity_date": 1496253619, "answer_count": 1, "creation_date": 1495185580, "score": 0, "link": "https://stackoverflow.com/questions/44066122/dc-os-private-registry-with-authentication-fails", "answers": [{"body": "<p>I've used a customization to acs-engine a few times to push registry credentials to the agent nodes. </p>\n\n<p>This approach makes sure that the credentials will be present even when you add nodes later on.</p>\n\n<p>The code is here: <a href=\"https://github.com/xtophs/acs-engine-1/tree/xtoph-registry\" rel=\"nofollow noreferrer\">https://github.com/xtophs/acs-engine-1/tree/xtoph-registry</a>. Example cluster API model is at: <a href=\"https://github.com/xtophs/acs-engine-1/blob/xtoph-registry/examples/privateregistry/dcos1.8.4.json\" rel=\"nofollow noreferrer\">https://github.com/xtophs/acs-engine-1/blob/xtoph-registry/examples/privateregistry/dcos1.8.4.json</a>  </p>\n", "answer_id": 44291736, "last_activity_date": 1496253619, "creation_date": 1496253619, "score": 0, "owner": {"user_id": 8093654, "profile_image": "https://www.gravatar.com/avatar/6fd98124946a34a221dd7bc322b7cb7c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/8093654/xtophs", "display_name": "xtophs"}, "is_accepted": false, "question_id": 44066122}], "owner": {"user_id": 7599366, "profile_image": "https://www.gravatar.com/avatar/98dcf2cfabe3b3a9a9166ecfe1f9444b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 8, "link": "https://stackoverflow.com/users/7599366/tourna", "display_name": "Tourna"}, "view_count": 52, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44066122}{"body": "<p>I'm looking for a tool that will allow tailing of Mesos task <code>stderr</code> and <code>stdout</code> logs. </p>\n\n<p><a href=\"https://github.com/mesosphere/mesos-cli\" rel=\"nofollow\"><code>mesos-cli</code></a> seems to be such a tool, but it's been deprecated in favor of <a href=\"https://github.com/dcos/dcos-cli\" rel=\"nofollow\"><code>dcos-cli</code></a>. The <a href=\"https://dcos.io/docs/1.7/administration/logging/service-logs/\" rel=\"nofollow\">documentation</a> for <code>dcos-cli</code>, however, does not make clear whether and how it works with plain Mesos.</p>\n\n<p>In summary: should I use <code>dcos-cli</code> or <code>mesos-cli</code> if I have Mesos but not DC/OS?</p>\n", "is_answered": true, "tags": ["logging", "command-line-interface", "mesos", "mesosphere", "dcos"], "title": "Does `dcos-cli` work with plain Mesos?", "last_activity_date": 1476201013, "answer_count": 1, "creation_date": 1476156834, "score": 2, "link": "https://stackoverflow.com/questions/39970133/does-dcos-cli-work-with-plain-mesos", "answers": [{"body": "<p>You can configure <code>dcos-cli</code> to use a Mesos master instead of the DC/OS master for some operations, including task logging. Simply set the <code>core.mesos_master_url</code> configuration property, as documented on the <a href=\"https://dcos.io/docs/1.8/usage/cli/\" rel=\"nofollow\">DC/OS CLI usage page</a>:</p>\n\n<pre><code>$ dcos config set core.mesos_master_url 52.34.160.132:5050\n</code></pre>\n\n<p>You should then be able to use <code>dcos task log</code> to tail <code>stdout</code> and <code>stderr</code> for the tasks you're interested in.</p>\n", "answer_id": 39981447, "last_activity_date": 1476201013, "creation_date": 1476201013, "score": 2, "owner": {"user_id": 7002313, "profile_image": "https://lh5.googleusercontent.com/-E0AYK34fmqM/AAAAAAAAAAI/AAAAAAAAACI/jRc7_04vD_Y/photo.jpg?sz=128", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/7002313/charles-ruhland", "display_name": "Charles Ruhland"}, "is_accepted": false, "question_id": 39970133}], "owner": {"user_id": 864684, "profile_image": "https://www.gravatar.com/avatar/66cc93ffb73d855bdceeea8bdb97ea93?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1480, "link": "https://stackoverflow.com/users/864684/tianxiang-xiong", "accept_rate": 88, "display_name": "Tianxiang Xiong"}, "view_count": 107, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39970133}{"body": "<p>I'm trying to setup DC/OS on AWS with different resource roles (I don't want nodes reserved for Apache Cassandra used by other things). I know in theory how to do it in a plain Mesos that I set up manually (<a href=\"https://support.mesosphere.com/hc/en-us/articles/206474745-How-to-reserve-resources-for-certain-frameworks-in-Mesos-cluster-\" rel=\"nofollow\">https://support.mesosphere.com/hc/en-us/articles/206474745-How-to-reserve-resources-for-certain-frameworks-in-Mesos-cluster-</a>), but I don't know how to do it in a DC/OS cloud installation. Any advice is greatly appreciated.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "title": "Using custom Mesos roles in DC/OS on AWS", "last_activity_date": 1468345862, "answer_count": 1, "creation_date": 1468333751, "score": 1, "link": "https://stackoverflow.com/questions/38331740/using-custom-mesos-roles-in-dc-os-on-aws", "answers": [{"body": "<p>DC/OS neither facilitates, nor prohibits services (aka frameworks) to register with a custom role. I'm not sure how to tell Cassandra to register under special role, Jenkins for example exposes it in its configurations (see screenshot below). In short, check with your framework, how to register in a custom role, DC/OS does not restrict this.</p>\n\n<p>If you want to configure role-specific things, like weights or quota, just talk directly to Mesos, which is accessible via <code>/mesos</code>, DC/OS does not prohibit it either.</p>\n\n<p><a href=\"https://i.stack.imgur.com/eOdtT.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eOdtT.png\" alt=\"Jenkins role configurations\"></a></p>\n", "answer_id": 38335833, "last_activity_date": 1468345862, "creation_date": 1468345862, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 38331740}], "owner": {"user_id": 618407, "profile_image": "https://www.gravatar.com/avatar/84bcf78d3531c26a53a54279cb562812?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1262, "link": "https://stackoverflow.com/users/618407/ftr", "accept_rate": 80, "display_name": "ftr"}, "view_count": 99, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38331740}{"body": "<p>DC/OS doesn't run Schema-registry and Rest-Proxy components of <a href=\"http://docs.confluent.io/2.0.1/platform.html\" rel=\"nofollow\">confluent 2.0</a>. I've launched Confluent 2 that contains the <code>apache-kafka</code> package in DC/OS 1.7 via Marathon, see also the <a href=\"https://docs.google.com/document/d/1e7NseupQ7F6RhrGjw5pTPx87hDc0ZX1FYtUPAsgiA7M/edit?usp=sharing\" rel=\"nofollow\">Marathon app spec</a>. As I understand, Marathon runs <code>kafka-scheduler.jar</code> from <code>kafka-scheduler.zip</code> (cf. the Marathon app spec) via a script. I didn't find any option that can specify which component to run or alternatively the source of <code>kafka-scheduler.jar</code>.</p>\n", "is_answered": true, "title": "Can't start Confluent 2.0 (apache-kafka) Schema-Registry in DC/OS", "last_edit_date": 1463664850, "tags": ["apache-kafka", "mesos", "mesosphere", "marathon", "dcos"], "view_count": 234, "accepted_answer_id": 37325489, "last_activity_date": 1500998175, "answers": [{"body": "<p>The initial implementation of Confluent Support in DC/OS included only the Kafka Broker level.   The Confluent and Mesos teams are collaborating on a more integrated offering that will include all the Confluent Platform components ... stay tuned !</p>\n", "answer_id": 37325489, "last_activity_date": 1463666268, "creation_date": 1463666268, "score": 3, "owner": {"user_id": 6317112, "profile_image": "https://www.gravatar.com/avatar/2a443bdbe7efc4e333bb40653fbba3f3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/6317112/david-tucker", "display_name": "David Tucker"}, "is_accepted": true, "question_id": 37322078}, {"body": "<p>As of DC/OS 1.8/1.9 you should find all components of Confluent Platform 3.2.x which includes schema registry.</p>\n", "answer_id": 45308249, "last_activity_date": 1500998175, "creation_date": 1500998175, "score": 0, "owner": {"user_id": 961888, "profile_image": "https://www.gravatar.com/avatar/d98986cd7bdf62a52bb3ecfad618ec60?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/961888/coughman", "display_name": "coughman"}, "is_accepted": false, "question_id": 37322078}], "score": 3, "link": "https://stackoverflow.com/questions/37322078/cant-start-confluent-2-0-apache-kafka-schema-registry-in-dc-os", "answer_count": 2, "owner": {"user_id": 6793472, "profile_image": "https://lh6.googleusercontent.com/-20gU-OFc_BI/AAAAAAAAAAI/AAAAAAAACOM/TYB-OTsdnc8/photo.jpg?sz=128", "user_type": "registered", "reputation": 48, "link": "https://stackoverflow.com/users/6793472/hryhorii-liashenko", "display_name": "Hryhorii Liashenko"}, "creation_date": 1463657917, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37322078}{"body": "<p>When using DC/OS on Azure, and I deploy a container, how can I guarantee if I launch 2 instances that they are on different physical machines (provided I have at least 2 agents).</p>\n", "is_answered": true, "title": "High Availability clustering for mesos", "tags": ["azure", "mesosphere", "dcos"], "last_activity_date": 1467989139, "accepted_answer_id": 38269494, "creation_date": 1467985513, "answers": [{"body": "<p>This is not Azure specific, it applies to any DC/OS (and with it Marathon) setup: you use constraints for placement, in this case <code>UNIQUE</code> for <code>hostname</code>, see also the <a href=\"https://mesosphere.github.io/marathon/docs/constraints.html\" rel=\"nofollow\">Marathon docs</a> for details.</p>\n", "answer_id": 38269494, "last_activity_date": 1467989139, "creation_date": 1467989139, "score": 4, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 38268256}], "score": 1, "link": "https://stackoverflow.com/questions/38268256/high-availability-clustering-for-mesos", "answer_count": 1, "owner": {"user_id": 1394981, "profile_image": "https://www.gravatar.com/avatar/8bc6f5d86a2a8d7ed90dea48ca7c67e2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1183, "link": "https://stackoverflow.com/users/1394981/matt-westlake", "accept_rate": 60, "display_name": "Matt Westlake"}, "view_count": 30, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38268256}{"body": "<p>I have successfully installed dcos-vagrant with one master and one slave node using: <code>vagrant up m1 a1 boot</code>. However, after stoping the cluster with <code>vagrant halt m1 a1 boot</code> and restarting it with <code>vagrant up m1 a1 boot</code> I cannot access the GUI at <code>https://m1.dcos</code>.</p>\n\n<p>How to stop the cluster without having to destroy it (<code>vagrant destroy -f</code>) and create it from scratch?</p>\n", "is_answered": true, "title": "DC/OS Vagrant VMs cannot access the GUI after vagrant halt and vagrant up", "last_edit_date": 1478427843, "tags": ["dcos"], "view_count": 193, "accepted_answer_id": 40474950, "last_activity_date": 1478553966, "answers": [{"body": "<p>That functionality is not currently supported: <a href=\"https://dcosjira.atlassian.net/browse/VAGRANT-7\" rel=\"nofollow noreferrer\">https://dcosjira.atlassian.net/browse/VAGRANT-7</a></p>\n", "answer_id": 40474950, "last_activity_date": 1478553966, "creation_date": 1478553966, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "question_id": 40447329}], "score": 2, "link": "https://stackoverflow.com/questions/40447329/dc-os-vagrant-vms-cannot-access-the-gui-after-vagrant-halt-and-vagrant-up", "answer_count": 1, "owner": {"user_id": 7121590, "profile_image": "https://www.gravatar.com/avatar/1b0a6edd3c77844aead237f0eb82f18d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7121590/agolfakis", "display_name": "agolfakis"}, "creation_date": 1478420667, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40447329}{"body": "<p>I have a Setup of 4 CentOS 7.1 VM's which are deployed via OpenStack. They got a public and a private IP address. The host doesn't know the public IP so if I run</p>\n\n<pre><code>ifconfig -a\n</code></pre>\n\n<p>I only get the private IP address of the host.</p>\n\n<p>Now I want to deploy Mesos 23.0 using the mesosphere packages, at first I deploy the Master with the following options</p>\n\n<pre><code>--cluster=\"my-cluster\" --hostname=\"&lt;Public-IP&gt;\" --log_dir=\"/var/log/mesos\"  --port=\"5050\" --zk=\"zk://127.0.0.1:2181/mesos\" --quorum=\"1\"\n</code></pre>\n\n<p>the rest of the options are the default Values.</p>\n\n<p>The Slaves get deployed with the following options:</p>\n\n<pre><code>--log_dir=/var/log/mesos --containerizers=docker,mesos --executor_registration_timeout=5mins --hostname=&lt;Public IP&gt; --master=&lt;Master Public IP&gt;:5050\n</code></pre>\n\n<p>The slaves get added to the cluster but they go direct into the \"deactivated\" status so I'm not able to run any Framework on my cluster. I can do a <strong>telnet</strong> to the slaves from the master on 5051. Also I tried to add <code>--ip=&lt;public IP&gt;</code> which results in an bind to error:</p>\n\n<pre><code>Failed to initialize: Failed to bind on &lt;Public IP&gt;:5051: Cannot assign requested address: Cannot assign requested address [99]\n</code></pre>\n\n<p>because the slave doesn't know it's public IP. And the mesos-slave listens per default on 0.0.0.0</p>\n\n<pre><code>netstat -ltnp | grep ':5051'\ntcp        0      0 0.0.0.0:5051            0.0.0.0:*               LISTEN      764/mesos-slave\n</code></pre>\n\n<p>When I look into the log files from the mesos-master I can see that the slaves anounce themself with their private IP</p>\n\n<pre><code>Slave 20150805-161215-1059104960-5050-715-S1136 at slave(1)@&lt;private IP&gt;:5051 (&lt;Public IP&gt;) disconnected\nDisconnecting slave 20150805-161215-1059104960-5050-715-S1136 at slave(1)@&lt;private IP&gt;:5051 (&lt;Public IP&gt;)\nDeactivating slave 20150805-161215-1059104960-5050-715-S1136 at slave(1)@&lt;private IP&gt;:5051 (&lt;Public IP&gt;)\n</code></pre>\n\n<p>Since the VM's can't communicate in the private Network this won't work. Do I have to allow the VM's to talk via their private IP or how can I make my cluster work?</p>\n\n<p>Thanks! </p>\n", "is_answered": true, "tags": ["linux", "openstack", "mesos", "mesosphere"], "title": "Mesos on OpenStack VM's Public IP", "last_activity_date": 1487387713, "answer_count": 2, "creation_date": 1438809355, "score": 0, "link": "https://stackoverflow.com/questions/31842972/mesos-on-openstack-vms-public-ip", "answers": [{"body": "<p>I solved my problem by adding the public IP via ifconfig. Maybe there is a better solution?</p>\n\n<p>We now decided to allow communication between the VM's over the private IP's which also solves the problem.</p>\n", "answer_id": 31853560, "last_activity_date": 1438962368, "creation_date": 1438857401, "score": 1, "owner": {"user_id": 2773236, "profile_image": "https://www.gravatar.com/avatar/422d5807a237247f84e06948eaa3b7ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 441, "link": "https://stackoverflow.com/users/2773236/joh-scheuer", "accept_rate": 80, "display_name": "joh.scheuer"}, "is_accepted": false, "last_edit_date": 1438962368, "question_id": 31842972}, {"body": "<p>You can use \"--advertise_ip\" option to assign your float IP in case you cannot bind to a NIC. </p>\n", "answer_id": 42310677, "last_activity_date": 1487387713, "creation_date": 1487387713, "score": 0, "owner": {"user_id": 7583740, "profile_image": "https://www.gravatar.com/avatar/01db16b8d9704c29ee8316c4da08a7e2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/7583740/fan-jiang", "display_name": "Fan Jiang"}, "is_accepted": false, "question_id": 31842972}], "owner": {"user_id": 2773236, "profile_image": "https://www.gravatar.com/avatar/422d5807a237247f84e06948eaa3b7ba?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 441, "link": "https://stackoverflow.com/users/2773236/joh-scheuer", "accept_rate": 80, "display_name": "joh.scheuer"}, "view_count": 569, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 31842972}{"body": "<p>I have a 200 node mesos cluster that can run around 2700 executors concurrently. Around 5-10% of my executors are LOST at the very beginning. They go only until extracting the executor tar file. </p>\n\n<pre><code>WARNING: Logging before InitGoogleLogging() is written to STDERR I0617 21:35:09.947180 45885 fetcher.cpp:76] Fetching URI 'http://download_url/remote_executor.tgz' I0617 21:35:09.947273 45885 fetcher.cpp:126] Downloading 'http://download_url/remote_executor.tgz' to '/mesos_dir/remote_executor.tgz' I0617 21:35:57.551722 45885 fetcher.cpp:64] Extracted resource '/mesos_dir/remote_executor.tgz' into '/extracting_mesos_dir/'\n</code></pre>\n\n<p>Please let me know if someone else is facing this issue.</p>\n\n<p>I am using python to implement both the scheduler and executor. The executor code is a python file that extends base class 'Executor'. I have implemented the launchTasks method of Executor class that simply does what the executor is supposed to do.</p>\n\n<p>The executor info is: </p>\n\n<pre><code>    executor = mesos_pb2.ExecutorInfo()\n    executor.executor_id.value = \"executor-%s\" % (str(task_id),)\n    executor.command.value = 'python -m myexecutor'\n\n    # where to download executor from\n    tar_uri = '%s/remote_executor.tgz' % (\n        self.conf.remote_executor_cache_url)\n    executor.command.uris.add().value = tar_uri\n    executor.name = 'some_executor_name'\n    executor.source = \"executor_test\"\n</code></pre>\n", "is_answered": false, "tags": ["distributed-computing", "mesos", "mesosphere"], "last_edit_date": 1434602876, "title": "Around 5-10% executors are LOST in my mesos framework", "last_activity_date": 1434602876, "answer_count": 1, "creation_date": 1432766092, "score": 0, "link": "https://stackoverflow.com/questions/30494267/around-5-10-executors-are-lost-in-my-mesos-framework", "answers": [{"body": "<p>Can you provide more details about what your Executor is supposed to do  (at best ExecutorInfo Definition and the Executor itself)? What is the Command you use to start the executor (CommandInfo)? </p>\n\n<p>For example definition of an executor have a look at <a href=\"https://github.com/mesosphere/RENDLER\" rel=\"nofollow\">Rendler</a>.\nIt includes a <a href=\"https://github.com/mesosphere/RENDLER/blob/master/cpp/crawl_executor.cpp\" rel=\"nofollow\">sample executor</a> and the <a href=\"https://github.com/mesosphere/RENDLER/blob/master/cpp/rendler.cpp#L313\" rel=\"nofollow\">ExecutorInfo definition</a>.\nRendler are also includes samples in Java, GO, Python, Scala, and Haskell.</p>\n", "answer_id": 30497357, "last_activity_date": 1432787789, "creation_date": 1432787789, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 30494267}], "owner": {"user_id": 3084164, "profile_image": "https://graph.facebook.com/857180507/picture?type=large", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/3084164/osman-sarood", "accept_rate": 67, "display_name": "Osman Sarood"}, "view_count": 115, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30494267}{"is_answered": true, "tags": ["meteor", "meteorite"], "last_edit_date": 1380062670, "title": "How to specify multiple forms with Mesosphere in Meteorite?", "last_activity_date": 1392179433, "answer_count": 1, "creation_date": 1377336397, "score": 0, "link": "https://stackoverflow.com/questions/18416998/how-to-specify-multiple-forms-with-mesosphere-in-meteorite", "accepted_answer_id": 21718698, "owner": {"user_id": 1191551, "profile_image": "https://www.gravatar.com/avatar/97ced8a229689b73b098a542636052e8?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4303, "link": "https://stackoverflow.com/users/1191551/chet", "accept_rate": 46, "display_name": "Chet"}, "view_count": 49, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 18416998}{"body": "<p>Since <code>webui_url</code> entry in Mesos state JSON is optional, one can try the luck with <code>hostname</code> (which is also optional).</p>\n\n<p>However, if both of the above entries are missing from Mesos state, is there any other way to reliably discover where Marathon API server is listening?</p>\n\n<p><s>Furthermore, if a Marathon instance is migrated to another location, Mesos <code>webui_url</code> seems to retain the old, stale value. This looks like a bug? Is there any workaround?</s></p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1455117090, "title": "How to reliably discover Marathon URL", "last_activity_date": 1455117090, "answer_count": 1, "creation_date": 1454980070, "score": -1, "link": "https://stackoverflow.com/questions/35282284/how-to-reliably-discover-marathon-url", "answers": [{"body": "<p>As far as I know you should be able to use the Mesos UI (\"Frameworks\" -> \"Active Frameworks\") to find the <code>marathon</code> framework. </p>\n\n<p>If the hostname resolution of the host Marathon is running on works correctly, you should be able to click on the link of the \"host\" column and be redirected to the Marathon UI.</p>\n\n<p>See</p>\n\n<ul>\n<li><a href=\"https://mesosphere.github.io/marathon/docs/command-line-flags.html\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/command-line-flags.html</a></li>\n</ul>\n\n<blockquote>\n  <p><code>--hostname</code> (Optional. Default: hostname of machine): The advertised hostname that is used for the communication with the mesos master. The value is also stored in the persistent store so another standby host can redirect to the elected leader. Note: <strong>Default is determined by <code>InetAddress.getLocalHost</code></strong>.</p>\n</blockquote>\n", "answer_id": 35287938, "last_activity_date": 1455009101, "creation_date": 1455009101, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 35282284}], "owner": {"user_id": 205386, "profile_image": "https://www.gravatar.com/avatar/870668e636ef0dee2a380bfa4efccfc0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2831, "link": "https://stackoverflow.com/users/205386/alex", "accept_rate": 50, "display_name": "Alex"}, "view_count": 163, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35282284}{"body": "<p>I find myself in a situation where I have the necessity to scale down container instances based on their actual lifetime. It looks like fresh instances are removed first when scaling down through marathon's API. <strong>Is there any configuration I'm not aware of to implement this kind of strategy or policy when scaling down instances on apache marathon?</strong></p>\n\n<p>As of right now I'm using <a href=\"https://github.com/mesosphere/marathon-lb-autoscale\" rel=\"nofollow noreferrer\">marathon-lb-autoscale</a> to atumatically adjust the number of running instances. What actually happens under the hood though is that <code>marathon-lb-autoscale</code> does perform a <code>PUT</code> request updating the <code>instances</code> property of the current application when req/s increases or decreaseas.</p>\n\n<pre><code>scale_list.each do |app,instances|\n    req = Net::HTTP::Put.new('/v2/apps/' + app)\n    if !@options.marathonCredentials.empty?\n      req.basic_auth(@options.marathonCredentials[0], @options.marathonCredentials[1])\n    end\n    req.content_type = 'application/json'\n    req.body = JSON.generate({'instances'=&gt;instances})\n    Net::HTTP.new(@options.marathon.host, @options.marathon.port).start do |http|\n      http.request(req)\n    end\n  end\nend\n</code></pre>\n\n<p>I don't know if the <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html#-upgradestrategy\" rel=\"nofollow noreferrer\"><code>upgradeStrategy</code></a> configuration is taken into account when scaling down instances. With default settings i cannot get the expected behaviour to work.</p>\n\n<pre><code>{\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 1,\n    \"maximumOverCapacity\": 1\n  }\n}\n</code></pre>\n\n<h3>ACTUAL</h3>\n\n<ul>\n<li>instance 1</li>\n<li>instance 2</li>\n<li><code>PUT /v2/apps/my-app {instances: 3}</code></li>\n<li>instance 1</li>\n<li>instance 2</li>\n<li>instance 3</li>\n<li><code>PUT /v2/apps/my-app {instances: 2}</code></li>\n<li>instance 1</li>\n<li>instance 2</li>\n</ul>\n\n<h3>EXPECTED</h3>\n\n<ul>\n<li>instance 1</li>\n<li>instance 2</li>\n<li><code>PUT /v2/apps/my-app {instances: 3}</code></li>\n<li>instance 1</li>\n<li>instance 2</li>\n<li>instance 3</li>\n<li><code>PUT /v2/apps/my-app {instances: 2}</code></li>\n<li>instance 2</li>\n<li>instance 3</li>\n</ul>\n", "is_answered": true, "title": "how to scale down instances based on their uptime with apache marathon?", "tags": ["mesos", "marathon", "mesosphere", "dcos"], "last_activity_date": 1503664116, "accepted_answer_id": 45879951, "creation_date": 1503654119, "answers": [{"body": "<p>One can specify a <code>killSelection</code> directly inside the application's config and specify <code>YoungestFirst</code> which kills youngest tasks first or <code>OldestFirst</code> which kills the oldest ones first.</p>\n\n<p>Reference: <a href=\"https://mesosphere.github.io/marathon/docs/configure-task-handling.html\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/configure-task-handling.html</a></p>\n", "answer_id": 45879951, "last_activity_date": 1503664116, "creation_date": 1503659023, "score": 3, "owner": {"user_id": 1086697, "profile_image": "https://www.gravatar.com/avatar/5d34a6bf73323076e6c8ddfd10831c90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3205, "link": "https://stackoverflow.com/users/1086697/ivo", "accept_rate": 38, "display_name": "Ivo"}, "is_accepted": true, "last_edit_date": 1503664116, "question_id": 45878639}], "score": 3, "link": "https://stackoverflow.com/questions/45878639/how-to-scale-down-instances-based-on-their-uptime-with-apache-marathon", "answer_count": 1, "owner": {"user_id": 1086697, "profile_image": "https://www.gravatar.com/avatar/5d34a6bf73323076e6c8ddfd10831c90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3205, "link": "https://stackoverflow.com/users/1086697/ivo", "accept_rate": 38, "display_name": "Ivo"}, "view_count": 74, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45878639}{"is_answered": true, "tags": ["database", "graph", "arangodb"], "title": "Setting up ArangoDB cluster wihout DCOS", "last_activity_date": 1472030474, "answer_count": 2, "creation_date": 1472010476, "score": 0, "link": "https://stackoverflow.com/questions/39114099/setting-up-arangodb-cluster-wihout-dcos", "accepted_answer_id": 39119271, "owner": {"user_id": 1642790, "profile_image": "https://i.stack.imgur.com/OvpjC.jpg?s=128&g=1", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/1642790/pjesudhas", "accept_rate": 71, "display_name": "pjesudhas"}, "view_count": 250, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 39114099}{"body": "<p>I'm trying to execute Spark job on Mesos cluster that depends on <a href=\"https://github.com/datastax/spark-cassandra-connector\" rel=\"nofollow\">spark-cassandra-connector</a> library, but it keeps failing with</p>\n\n<pre><code>Exception in thread \"main\" java.lang.NoClassDefFoundError: com/datastax/spark/connector/package$\n</code></pre>\n\n<p>As I understand from <a href=\"http://spark.apache.org/docs/1.6.1/submitting-applications.html\" rel=\"nofollow\">spark documentation</a></p>\n\n<blockquote>\n  <p>JARs and files are copied to the working directory for each SparkContext on the executor nodes.\n  ...\n  Users may also include any other dependencies by supplying a comma-delimited list of maven coordinates with --packages.</p>\n</blockquote>\n\n<p>But it seems that only <code>pucker-assembly-1.0.jar</code> task jar is distributed.</p>\n\n<p>I'm running  spark 1.6.1 with scala 2.10.6.\nAnd here's <code>spark-submit</code> command I'm executing:</p>\n\n<pre><code>spark-submit --deploy-mode cluster \n             --master mesos://localhost:57811 \n             --conf spark.ssl.noCertVerification=true \n             --packages datastax:spark-cassandra-connector:1.5.1-s_2.10\n             --conf spark.cassandra.connection.host=10.0.1.83,10.0.1.86,10.0.1.85 \n             --driver-cores 3 \n             --driver-memory 4000M \n             --class SimpleApp \n             https://dripit-spark.s3.amazonaws.com/pucker-assembly-1.0.jar\n             s3n://logs/E1SR85P3DEM3LU.2016-05-05-11.ceaeb015.gz\n</code></pre>\n\n<p>So why isn't <code>spark-cassandra-connector</code> distributed to all my spark executers?</p>\n", "is_answered": false, "tags": ["apache-spark", "sbt", "mesos", "dcos"], "title": "Dependency is not distributed to Spark cluster", "last_activity_date": 1467301797, "answer_count": 1, "creation_date": 1467294162, "score": 1, "link": "https://stackoverflow.com/questions/38124920/dependency-is-not-distributed-to-spark-cluster", "answers": [{"body": "<p>You should use the correct Maven coordinate syntax:</p>\n\n<pre><code>--packages com.datastax.spark:spark-cassandra-connector_2.10:1.6.0\n</code></pre>\n\n<p>See</p>\n\n<ul>\n<li><a href=\"https://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector_2.10\" rel=\"nofollow\">https://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector_2.10</a></li>\n<li><a href=\"http://spark.apache.org/docs/latest/submitting-applications.html\" rel=\"nofollow\">http://spark.apache.org/docs/latest/submitting-applications.html</a></li>\n<li><a href=\"http://spark.apache.org/docs/latest/programming-guide.html#using-the-shell\" rel=\"nofollow\">http://spark.apache.org/docs/latest/programming-guide.html#using-the-shell</a></li>\n</ul>\n", "answer_id": 38127970, "last_activity_date": 1467301797, "creation_date": 1467301797, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 38124920}], "owner": {"user_id": 1484115, "profile_image": "https://www.gravatar.com/avatar/2cf2ec4d9d378b6b41d11d0aeafd7611?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 577, "link": "https://stackoverflow.com/users/1484115/kristaps-taube", "accept_rate": 75, "display_name": "Kristaps Taube"}, "view_count": 81, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 38124920}{"body": "<p>Is there a way to make custom resource offers from a Mesos slave? Currently, the resource offers from the slave contain \"cpus\", \"mem\", \"ports\". I want to add custom resource capabilities like upload bandwidth limit, download bandwidth limit etc. There is an option of doing this via the <code>--resources</code> parameter while starting the slave. But what I am looking for is a way to achieve this via code, may be a pluggable module to Mesos, so that the person who is launching the slaves doesn't have to bother about specifying the custom resources.</p>\n\n<p>Is this possible?\nThanks.</p>\n", "is_answered": true, "title": "How to make custom resource offers from a Mesos slave?", "tags": ["mesos", "mesosphere"], "last_activity_date": 1455566683, "accepted_answer_id": 35418065, "creation_date": 1455257747, "answers": [{"body": "<p>Resources reported by the Mesos agent (aka slave) should be specified by the <code>--resources</code> flag. If the flag is omitted, defaults are used. Note that custom resources advertised via <code>--resources</code> will not be isolated, i.e. Mesos agent will not ensure a task is using not more than allocated amount of such resource.</p>\n\n<p>Why do you think a module is a nicer solution than a flag? Loading custom modules requires setting some command line flags as well.</p>\n", "answer_id": 35418065, "last_activity_date": 1455566683, "creation_date": 1455566683, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": true, "question_id": 35356030}], "score": 0, "link": "https://stackoverflow.com/questions/35356030/how-to-make-custom-resource-offers-from-a-mesos-slave", "answer_count": 1, "owner": {"user_id": 5916957, "profile_image": "https://www.gravatar.com/avatar/810a4718878574d13c60775fe71e9d1c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 30, "link": "https://stackoverflow.com/users/5916957/sudarshan-murthy", "accept_rate": 71, "display_name": "Sudarshan Murthy"}, "view_count": 279, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35356030}{"body": "<p>I'm trying to install a containerized app using Marathon to a public slave. It's all working fine until I decide to use persistent volumes. I then get the message</p>\n\n<blockquote>\n  <p>Resident apps may not define acceptedResourceRoles other than \"*\" (unreserved resources)</p>\n</blockquote>\n\n<p>I there a work-around for this or am I simply misunderstanding the role of public slaves? I'd like to access this app at some point via <code>service.mydomain.com</code>, hence I thought I'd need a public node.</p>\n", "is_answered": true, "title": "Persistent volumes on public node", "tags": ["mesos", "mesosphere", "marathon", "dcos"], "last_activity_date": 1465882457, "accepted_answer_id": 37803687, "creation_date": 1465542306, "answers": [{"body": "<p>The message you see, <code>Resident apps may not define acceptedResourceRoles other than \"*\" (unreserved resources)</code> is admittedly not very helpful and you were on the right track. Effectively, <a href=\"https://mesosphere.github.io/marathon/docs/persistent-volumes.html\" rel=\"nofollow\">persistent volumes</a> in DC/OS are not allowed on nodes with the role <code>slave_public</code> (the public nodes) and hence you'll need to use <a href=\"https://dcos.io/docs/1.7/usage/service-discovery/marathon-lb/usage/\" rel=\"nofollow\">Marathon-lb</a> as an edge router (in <code>external</code> mode) to expose the app that uses PV (and schedule it on a private agent).</p>\n", "answer_id": 37803687, "last_activity_date": 1465882457, "creation_date": 1465882457, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 37741952}], "score": 1, "link": "https://stackoverflow.com/questions/37741952/persistent-volumes-on-public-node", "answer_count": 1, "owner": {"user_id": 1364489, "profile_image": "https://www.gravatar.com/avatar/a14de6f4e93dddde282d1edd68029f6b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 866, "link": "https://stackoverflow.com/users/1364489/apotry", "accept_rate": 82, "display_name": "apotry"}, "view_count": 208, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37741952}{"body": "<p>I installed Spark service on Mesosphere with the following json config.\nI was hoping that Spark will use role slave_public.</p>\n\n<pre><code>{\n    \"service\": {\n        \"name\": \"my-spark\",\n        \"role\": \"slave_public\"\n    }\n}\n</code></pre>\n\n<p><strong>dcos package install --options=my-spark.json spark</strong></p>\n\n<p>But I see in /var/log/message that role * is being used and offers are rejected. Marathon UI show the framework in \"waiting\" state.</p>\n\n<p>Is it possible to override default role?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "title": "Mesos DCOS Spark with different role", "last_activity_date": 1467392413, "answer_count": 0, "creation_date": 1467332011, "score": 1, "link": "https://stackoverflow.com/questions/38135170/mesos-dcos-spark-with-different-role", "owner": {"user_id": 3349257, "profile_image": "https://www.gravatar.com/avatar/f37b803a3616d628a6ec3ff4e646cf70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 287, "link": "https://stackoverflow.com/users/3349257/cheeko", "accept_rate": 78, "display_name": "Cheeko"}, "view_count": 124, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38135170}{"is_answered": false, "tags": ["dcos"], "title": "DCOS serverServer responded with an HTTP &#39;www-authenticate&#39; field of &#39;oauthjwt&#39;, DCOS only supports &#39;Basic&#39;", "last_activity_date": 1465984624, "answer_count": 0, "creation_date": 1465984624, "score": 0, "link": "https://stackoverflow.com/questions/37832069/dcos-serverserver-responded-with-an-http-www-authenticate-field-of-oauthjwt", "owner": {"user_id": 6468798, "profile_image": "https://www.gravatar.com/avatar/faee4790c9722303b49050ef6eae318c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/6468798/evgeny-vovchenko", "display_name": "Evgeny Vovchenko"}, "view_count": 47, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 37832069}{"body": "<p>I have setup the mesos and marathon on my local system. Also, I have docker engine running on my system, and when I do, <code>sudo docker images</code>, I get the following, </p>\n\n<pre><code>REPOSITORY                                                 TAG                 IMAGE ID            CREATED             SIZE\nmyrepo/hello                                               latest              b7ce0084dbaf        4 weeks ago         330.3 MB\nfluent/new                                                 latest              adc4b7b4b0eb        4 weeks ago         1.589 GB\n&lt;none&gt;                                                     &lt;none&gt;              3a87799875ed        4 weeks ago         1.589 GB\n&lt;none&gt;                                                     &lt;none&gt;              16a573cd3b85        4 weeks ago         330.3 MB\n769348183957.dkr.ecr.us-east-1.amazonaws.com/ruby          2.1.10              77bf121d484e        8 weeks ago         1.535 GB\n769348183957.dkr.ecr.us-east-1.amazonaws.com/centos-base   7                   9ab68a0dd16a        10 weeks ago        330.3 MB\nhello-world                                                latest              c54a2cc56cbb        12 weeks ago        1.848 kB\ndocker/whalesay                                            latest              6b362a9f73eb        16 months ago       247 MB\n</code></pre>\n\n<p>Now, through the Marathon UI, I am trying to make an application, and after going doing all the steps in the documentation at <code>https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html</code>, when I finally create the application, it's status varies between Deploying and Waiting intermittently and finally shows delayed. I never get it in the running stage. I try to figure out the logs on my machine but I am not able to make sense of them seeing their volume. </p>\n\n<p>My JSON config for the app was as follows: </p>\n\n<pre><code>{\n  \"id\": \"/123\",\n  \"cmd\": \"sudo docker run -itd 9ab68a0dd16a /bin/bash\",\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 200,\n  \"instances\": 1,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"769348183957.dkr.ecr.us-east-1.amazonaws.com/centos-base\",\n      \"network\": \"HOST\",\n      \"forcePullImage\": true\n    },\n    \"type\": \"DOCKER\"\n  }\n}\n</code></pre>\n\n<p>Am I missing anything? AFAIK, what should happen is the application should automatically pull this image from my local repo and finally get deployed on the machine. Should I also create a task for my application because I haven't made any task specifically? If yes, won't I have to first create an application and then add tasks to it? </p>\n\n<p>Also, I restarted the mesos slave like this: <code>sudo ./bin/mesos-slave.sh --master=127.0.0.1:5050 --work_dir=/var/lib/mesos --containerizers=docker,mesos --executor_registration_timeout=5mins</code></p>\n\n<p>Also, I tried making a tar.gz file of the docker repo on my localhost and copied it to /etc and passed the <code>URI: file///etc/docker.repo.tar.gz</code></p>\n\n<p>Where am I going wrong? In the marathon logs, I am able to see this <code>None of the enabled containerizers (mesos) could create a container for the provided TaskInfo/ExecutorInfo message</code>. Hence, I think this is where I am going wrong. </p>\n\n<p>Edit: Marathon logs for the Application suggested: </p>\n\n<pre><code>[2016-09-26 12:29:30,418] INFO Task launch for 'task [nginx.c59c7403-83b6-11e6-a834-0a0027000000]' was accepted. 0 tasksToLaunch, 0 in flight, 1 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-8)\nI0926 12:29:30.418325 90841088 master.cpp:3104] Processing ACCEPT call for offers: [ d165ac5e-93dc-4b7b-bf36-071ce75aa44d-O17 ] on slave d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0 at slave(1)@172.26.35.124:63837 (172.26.35.124) for framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 (marathon) at scheduler-c27b723e-e9d3-428a-b7d3-c8c184b1ed7c@172.26.35.124:63837\nI0926 12:29:30.419334 90841088 master.hpp:177] Adding task nginx.c59c7403-83b6-11e6-a834-0a0027000000 with resources cpus(*):0.1; mem(*):256; ports(*):[31835-31835] on slave d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0 (172.26.35.124)\nI0926 12:29:30.419400 90841088 master.cpp:3589] Launching task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 (marathon) at scheduler-c27b723e-e9d3-428a-b7d3-c8c184b1ed7c@172.26.35.124:63837 with resources cpus(*):0.1; mem(*):256; ports(*):[31835-31835] on slave d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0 at slave(1)@172.26.35.124:63837 (172.26.35.124)\nI0926 12:29:30.419661 89767936 slave.cpp:1361] Got assigned task nginx.c59c7403-83b6-11e6-a834-0a0027000000 for framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000\nI0926 12:29:30.421689 90304512 gc.cpp:83] Unscheduling '/tmp/mesos/0/slaves/d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0/frameworks/fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000' from gc\nI0926 12:29:30.422006 89767936 gc.cpp:83] Unscheduling '/tmp/mesos/0/meta/slaves/d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0/frameworks/fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000' from gc\nI0926 12:29:30.422173 88158208 slave.cpp:1480] Launching task nginx.c59c7403-83b6-11e6-a834-0a0027000000 for framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000\nI0926 12:29:30.422904 88158208 paths.cpp:528] Trying to chown '/tmp/mesos/0/slaves/d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0/frameworks/fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000/executors/nginx.c59c7403-83b6-11e6-a834-0a0027000000/runs/0548c84c-40ad-40cd-bbd8-b1330e66f348' to user 'bhjain'\nI0926 12:29:30.445124 88158208 slave.cpp:5352] Launching executor nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 with resources cpus(*):0.1; mem(*):32 in work directory '/tmp/mesos/0/slaves/d165ac5e-93dc-4b7b-bf36-071ce75aa44d-S0/frameworks/fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000/executors/nginx.c59c7403-83b6-11e6-a834-0a0027000000/runs/0548c84c-40ad-40cd-bbd8-b1330e66f348'\nI0926 12:29:30.446513 88158208 slave.cpp:1698] Queuing task 'nginx.c59c7403-83b6-11e6-a834-0a0027000000' for executor 'nginx.c59c7403-83b6-11e6-a834-0a0027000000' of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000\nE0926 12:29:30.446702 88158208 slave.cpp:3784] Container '0548c84c-40ad-40cd-bbd8-b1330e66f348' for executor 'nginx.c59c7403-83b6-11e6-a834-0a0027000000' of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 failed to start: **None of the enabled containerizers (mesos) could create a container for the provided TaskInfo/ExecutorInfo message**\nE0926 12:29:30.446846 90841088 slave.cpp:3855] Termination of executor 'nginx.c59c7403-83b6-11e6-a834-0a0027000000' of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 failed: Unknown container: 0548c84c-40ad-40cd-bbd8-b1330e66f348\nI0926 12:29:30.453965 90841088 slave.cpp:3012] Handling status update TASK_FAILED (UUID: 90717092-98c0-4eab-9967-f43e005159b5) for task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 from @0.0.0.0:0\nW0926 12:29:30.454391 91914240 containerizer.cpp:1295] Ignoring update for unknown container: 0548c84c-40ad-40cd-bbd8-b1330e66f348\nI0926 12:29:30.454927 91377664 status_update_manager.cpp:320] Received status update TASK_FAILED (UUID: 90717092-98c0-4eab-9967-f43e005159b5) for task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000\nI0926 12:29:30.455751 91377664 status_update_manager.cpp:824] Checkpointing UPDATE for status update TASK_FAILED (UUID: 90717092-98c0-4eab-9967-f43e005159b5) for task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000\nI0926 12:29:30.456254 90304512 slave.cpp:3410] Forwarding the update TASK_FAILED (UUID: 90717092-98c0-4eab-9967-f43e005159b5) for task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2-8f1c-c24057bcfb58-0000 to master@172.26.35.124:63837\nI0926 12:29:30.456456 91377664 master.cpp:4763] Status update TASK_FAILED (UUID: 90717092-98c0-4eab-9967-f43e005159b5) for task nginx.c59c7403-83b6-11e6-a834-0a0027000000 of framework fa8c0ef7-651b-41c2\n</code></pre>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1474873321, "title": "Running a docker container as a task in marathon", "last_activity_date": 1474873321, "answer_count": 1, "creation_date": 1474870177, "score": 1, "link": "https://stackoverflow.com/questions/39695750/running-a-docker-container-as-a-task-in-marathon", "answers": [{"body": "<p>The JSON seems fine from a JSON schema perspective. TBH, the <code>cmd</code> property contents doesn't really make sense if you want to test running containers on Mesos.</p>\n\n<p>I even think the command you're using will not be able to work, executing Docker within the application context...</p>\n\n<p>Please use a standard image like <a href=\"https://hub.docker.com/_/nginx/\" rel=\"nofollow\">nginx</a> like this:</p>\n\n<pre><code>{\n  \"id\": \"nginx\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"nginx\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"hostPort\": 0, \"containerPort\": 80 }\n      ],\n      \"forcePullImage\":true\n    }\n  },\n  \"instances\": 1,\n  \"cpus\": 0.1,\n  \"mem\": 256,\n  \"healthChecks\": [{\n      \"protocol\": \"HTTP\",\n      \"path\": \"/\",\n      \"portIndex\": 0,\n      \"timeoutSeconds\": 10,\n      \"gracePeriodSeconds\": 10,\n      \"intervalSeconds\": 2,\n      \"maxConsecutiveFailures\": 10\n  }]\n}\n</code></pre>\n\n<p>to check the overall functionality. If this works, tag and push the <code>nginx</code> image to your local registry, and try using it via the <code>uris</code> credential passing method and the local image name.</p>\n", "answer_id": 39696446, "last_activity_date": 1474872889, "creation_date": 1474872889, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 39695750}], "owner": {"user_id": 6862012, "profile_image": "https://www.gravatar.com/avatar/f6e2aaae0112ecfad3fed2ba18452b7f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 40, "link": "https://stackoverflow.com/users/6862012/john-dui", "accept_rate": 20, "display_name": "John Dui"}, "view_count": 389, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39695750}{"body": "<ul>\n<li>I'm new to mesos, I've configured mesos cluster setup with 3 masters\nand 2 slaves in rhel6.7 machines</li>\n<li><p>I've used available rpm packages to install mesos. I've downloaded zookeeper.tar.gz and using binary's of zookeeper and its configuration is\n<a href=\"https://i.stack.imgur.com/l5mNC.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/l5mNC.png\" alt=\"enter image description here\"></a></p></li>\n<li><p>Starting mesos-master with below arguments<br>\n<a href=\"https://i.stack.imgur.com/2PXCn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2PXCn.png\" alt=\"enter image description here\"></a></p></li>\n<li>added few of the rules to accept incoming and outgoing for ports(5050, 8080, 2181, 2888, 3888). I've used below steps to add rules.\n<a href=\"https://i.stack.imgur.com/rPLDR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/rPLDR.png\" alt=\"enter image description here\"></a></li>\n<li>Started three masters and I've seen logs, not able to communicate with each-other and three masters servers are getting crashed, then I flushed(iptales -F) all rules and started three servers and its able to communicate and working properly and I did netstat on leading mesos master to know what ports are using for communication. I'm thinking its using few more ports other than 2181, 5050, 2888, 3888  and 8080 I saw more ports are using for communication. I've attached screen shot.</li>\n<li>We have firewall in production environment, Its not possible to allow all ports in proudction environment \n<a href=\"https://i.stack.imgur.com/JXxwk.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/JXxwk.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/I3fub.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/I3fub.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/u1Cry.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/u1Cry.png\" alt=\"enter image description here\"></a></li>\n<li><strong>Will mesos and zookeepr will use random ports to communication (in<br>\nscreen shot its using 39958,38574,40097,etc..)?</strong></li>\n<li><strong>If its using random ports, can we have forceport option to avoid\nusage of random ports from zookeeper or mesos?</strong>\n<strong>- Is there any solution for this kind of problem?</strong>\n<strong>- Can some one give suggestion to solve this?</strong></li>\n</ul>\n", "is_answered": false, "tags": ["apache-zookeeper", "mesos", "mesosphere", "rhel6"], "title": "Will mesos & zookeeper uses random ports to communicate with peers", "last_activity_date": 1500278878, "answer_count": 1, "creation_date": 1463476204, "score": 1, "link": "https://stackoverflow.com/questions/37271788/will-mesos-zookeeper-uses-random-ports-to-communicate-with-peers", "answers": [{"body": "<p>Since the Zookeeper servers act as both client (trying to connect to other servers) and server (listening for connections from other ZK servers) it must choose an ephemeral port when trying to connect to another server (as a client). </p>\n\n<p>This ephemeral port is taken from the range defined by the output of the following command.</p>\n\n<blockquote>\n  <p>sysctl net.ipv4.ip_local_port_range</p>\n</blockquote>\n\n<p>Ie: for my machine the port range is </p>\n\n<blockquote>\n  <p>net.ipv4.ip_local_port_range = 32768    60999</p>\n</blockquote>\n\n<p>We can reduce the ephemeral port by changing the port range using below command.</p>\n\n<blockquote>\n  <p>sudo sysctl -w net.ipv4.ip_local_port_range=\"1024 1050\"</p>\n</blockquote>\n", "answer_id": 45138980, "last_activity_date": 1500278878, "creation_date": 1500278878, "score": 0, "owner": {"user_id": 3828125, "profile_image": "https://www.gravatar.com/avatar/9d5c0a2197f3af50217fffcb443dd07e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/3828125/balamurugan", "display_name": "Balamurugan"}, "is_accepted": false, "question_id": 37271788}], "owner": {"user_id": 1392999, "profile_image": "https://www.gravatar.com/avatar/185668d3c5790042a9ad55413541b63e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/1392999/narendra", "accept_rate": 0, "display_name": "Narendra"}, "view_count": 110, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37271788}{"body": "<p><strong>Background</strong><br />\nOur current infrastructure consists of a Jenkins master and a number of slave VM's. We are running into a lot of scalability and inherently stability issues with our tests as the VM's are being overworked.</p>\n\n<p><strong>Mesosphere and Jenkins</strong> <br />\nThat being said, I'm looking to explore more solutions, particularly with mesosphere because its ability to dynamically generate slaves as needed.</p>\n\n<p>My only issue with that is that we have all these dependencies installed on the slave VM's. In order to make Jenkins work on mesos, I would have to \"dirty\" the mesos slaves by installing the dependencies on them. This would kind of render these mesos slaves useless as they would only be suited for running Jenkins.</p>\n\n<p><strong>Question</strong> <br />\nWhat is the proper method of implementing a Jenkins environment in Mesos alongside other applications?</p>\n", "is_answered": true, "title": "Jenkins, Mesos and slave dependencies", "tags": ["mesos", "build-dependencies", "mesosphere"], "last_activity_date": 1421225689, "accepted_answer_id": 27938966, "creation_date": 1421187670, "answers": [{"body": "<p>Check out eBay's video and blogs about their Mesos+Marathon+Jenkins setup:</p>\n\n<ul>\n<li><a href=\"http://blog.docker.com/2014/06/dockercon-video-delivering-ebays-ci-solution-with-apache-mesos-docker/\" rel=\"nofollow\">http://blog.docker.com/2014/06/dockercon-video-delivering-ebays-ci-solution-with-apache-mesos-docker/</a></li>\n<li><a href=\"http://www.ebaytechblog.com/2014/04/04/delivering-ebays-ci-solution-with-apache-mesos-part-i/\" rel=\"nofollow\">http://www.ebaytechblog.com/2014/04/04/delivering-ebays-ci-solution-with-apache-mesos-part-i/</a></li>\n<li><a href=\"http://www.ebaytechblog.com/2014/05/12/delivering-ebays-ci-solution-with-apache-mesos-part-ii/\" rel=\"nofollow\">http://www.ebaytechblog.com/2014/05/12/delivering-ebays-ci-solution-with-apache-mesos-part-ii/</a></li>\n</ul>\n\n<p>Part II of the blog talks about running Jenkins builds in Docker containers, which could alleviate the problem of \"dirtying\" the slaves with dependencies.</p>\n\n<p>See the mesos-jenkins plugin for more documentation, and see dockerhub for pre-built images</p>\n\n<ul>\n<li><a href=\"https://github.com/jenkinsci/mesos-plugin\" rel=\"nofollow\">https://github.com/jenkinsci/mesos-plugin</a></li>\n<li><a href=\"https://registry.hub.docker.com/u/folsomlabs/jenkins-mesos/\" rel=\"nofollow\">https://registry.hub.docker.com/u/folsomlabs/jenkins-mesos/</a> (latest)</li>\n<li><a href=\"https://registry.hub.docker.com/u/thefactory/jenkins-mesos/\" rel=\"nofollow\">https://registry.hub.docker.com/u/thefactory/jenkins-mesos/</a> (documented)</li>\n</ul>\n", "answer_id": 27938966, "last_activity_date": 1421225689, "creation_date": 1421225689, "score": 3, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 27932567}], "score": 0, "link": "https://stackoverflow.com/questions/27932567/jenkins-mesos-and-slave-dependencies", "answer_count": 1, "owner": {"user_id": 4024633, "profile_image": "https://www.gravatar.com/avatar/ae9d707ef8cdec841b7fd68d26d5cac1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 65, "link": "https://stackoverflow.com/users/4024633/blanco", "display_name": "Blanco"}, "view_count": 1070, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 27932567}{"body": "<p>we are looking to build a cluster of Compute Nodes for Deep Learning model training jobs, some of them on the cloud and others locally, that have NVIDIA GPUs in them. We felt that using Mesos and the framework Marathon (M&amp;M) would be our best options to schedule the cluster. However the documentations for (M&amp;M) seem to be very ambiguous (or at least to me, sorry I'm an intern) and I'm running into a lot of issues concerning Zookeeper and the connections between the nodes. </p>\n\n<p>Plus, it seems like Mesosphere are giving much more importance to DC/OS when it comes to tutorials and docs, and I guess it will also be patched more regularly and its interfaces (GUI and CLI) look much more user-friendly.</p>\n\n<p>So I was wondering if by dropping the exploration of (M&amp;M) and moving to  DC/OS, would we lose a lot of control over the cluster? In M&amp;M do we have perks that cannot be given in the Open Source Edition of DC/OS? like monitoring the machines, logging results etc.. If I ask my manager we might also get the Enterprise edition so that's not really a problem, but does DC/OS apply an abstraction layer that isn't really preferable to advanced users? </p>\n", "is_answered": true, "tags": ["cluster-computing", "mesos", "marathon", "mesosphere", "dcos"], "title": "DC/OS vs just plain Mesos+Marathon", "last_activity_date": 1500840516, "answer_count": 1, "creation_date": 1499825451, "score": -1, "link": "https://stackoverflow.com/questions/45047185/dc-os-vs-just-plain-mesosmarathon", "answers": [{"body": "<p>DC/OS is build around Apache Mesos and Marathon and gives a good default setup for zookeeper, networking, .... So IMO it is a good place to start as you can still use all M&amp;M and Mesos features + the DC/OS features and ease of setup.</p>\n\n<p>Disclaimer: I am working for Mesosphere.</p>\n", "answer_id": 45269450, "last_activity_date": 1500840516, "creation_date": 1500840516, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 45047185}], "owner": {"user_id": 7917068, "profile_image": "https://graph.facebook.com/1472988066084722/picture?type=large", "user_type": "registered", "reputation": 4, "link": "https://stackoverflow.com/users/7917068/leonardo-aoun", "display_name": "Leonardo Aoun"}, "view_count": 54, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45047185}{"body": "<p>Can someone suggest ELK configuration which is installed from DC/OS Local Universe.? I've followed the <a href=\"https://docs.mesosphere.com/1.9/monitoring/logging/aggregating/elk/\" rel=\"nofollow noreferrer\">link</a> from docs. </p>\n\n<p>The above link is about connecting DCOS nodes to ELK node which is another server(i.e ELK server is different from dcos nodes). I'm looking for configuration/making pipeline for ELK which is installed from Local Universe package.  </p>\n\n<p>My setup is like following.</p>\n\n<p>I've 1 master, 1 public and 4 private nodes and Local Universe package having some packages along with ElasticSearch, Logstash, Kibana.\nI've installed ELK from Local Universe package and running fine. now Can someone suggest how to configure/make pipeline talking each other, get dcos logs and analyzed?</p>\n\n<p>I hope my problem is clear. please don't hesitate to ask if not clear.\nThanks in advance.</p>\n", "is_answered": false, "tags": ["mesos", "elk-stack", "mesosphere", "dcos"], "title": "How to configure ELK which are installed from Local Universe", "last_activity_date": 1499263253, "answer_count": 0, "creation_date": 1499263253, "score": 0, "link": "https://stackoverflow.com/questions/44928402/how-to-configure-elk-which-are-installed-from-local-universe", "owner": {"user_id": 1392999, "profile_image": "https://www.gravatar.com/avatar/185668d3c5790042a9ad55413541b63e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/1392999/narendra", "accept_rate": 0, "display_name": "Narendra"}, "view_count": 29, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44928402}{"body": "<p>I'm trying to achieve HA with three machines and having masters &amp; slaves like below. I'm using VM's for local test setup and my observations are below. </p>\n\n<p>Case 1:</p>\n\n<p>m1 -> leader master </p>\n\n<p>m2 -> non-leader master, slave1 </p>\n\n<p>m3 -> non-leader master, slave2</p>\n\n<ul>\n<li><p>Case1.1: When I power off VM m1 machine, one of non-leader becomes\nleading and able to access cluster, working properly.</p></li>\n<li><p>Case1.2: I power off m2 or m3 (any one of the vm with non-master &amp; slave). \nI've seen message on webpage of m3 or m2 'No Master is currently leading'. when I try to access mesos in m1 and any one of the available machine(m2 or m3).</p></li>\n</ul>\n\n<p>Case2:</p>\n\n<p>m1->non-leader </p>\n\n<p>m2->leader,slave1, </p>\n\n<p>m3->non-leader,slave2 </p>\n\n<ul>\n<li><p>Case2.1: When I power off VM m1 machine, leader in m2 will be sustained and cluster works properly.</p></li>\n<li><p>Case2.2: When I power off m2 (leader with slave), cluster becomes unavailable with error message 'No Master is currently leading' on web page.</p></li>\n<li><p>Case2.3: When I power off m3 (non-leader with slave),cluster becomes unavailable with error message 'No Master is currently leading' on web page.</p></li>\n</ul>\n\n<p>Apologies for trying HA with only 3 machines and lengthy problem explanation.</p>\n\n<p><strong>Questions :</strong> </p>\n\n<ul>\n<li><p>Killing machine with both master(leading/non-leading) and slave will always lead to cluster unavailability? (case 1.2,2.2,2.3)</p></li>\n<li><p>Can we achieve HA with three machines like above i.e having 3 masters and 2 slaves with masters and slaves on same machines?</p>\n\n<p>Following are the configuration.</p></li>\n</ul>\n\n<p><strong>Masters :</strong> </p>\n\n<blockquote>\n  <p>m1 : mesos-master --ip=192.168.1.36 --hostname=192.168.1.36 --port=6060 --quorum=2 --cluster=mesosCluster --zk=zk://192.168.1.36:2181,192.168.1.42:2181,192.168.1.45:2181/mesos --work_dir=/opt/ncms/mesosWorkDir/ --log_dir=/opt/ncms/mesosWorkDir/logs</p>\n  \n  <p>m2 : mesos-master --ip=192.168.1.42 --hostname=192.168.1.42 --port=6060 --quorum=2 --cluster=mesosCluster --zk=zk://192.168.1.36:2181,192.168.1.42:2181,192.168.1.45:2181/mesos --work_dir=/opt/ncms/mesosWorkDir/ --log_dir=/opt/ncms/mesosWorkDir/logs</p>\n  \n  <p>m3 : mesos-master --ip=192.168.1.45 --hostname=192.168.1.45 --port=6060 --quorum=2 --cluster=mesosCluster --zk=zk://192.168.1.36:2181,192.168.1.42:2181,192.168.1.45:2181/mesos --work_dir=/opt/ncms/mesosWorkDir/ --log_dir=/opt/ncms/mesosWorkDir/logs</p>\n</blockquote>\n\n<p><strong>Slaves :</strong> </p>\n\n<blockquote>\n  <p>m2 : mesos-slave --ip=192.168.1.42 --hostname=192.168.1.42 --executor_registration_timeout=10mins --systemd_enable_support=false --master=zk://192.168.1.42:2181,192.168.1.45:2181,192.168.1.36:2181/mesos --containerizers=mesos,docker</p>\n  \n  <p>m3 : mesos-slave --ip=192.168.1.45 --hostname=192.168.1.45 --executor_registration_timeout=10mins --systemd_enable_support=false --master=zk://192.168.1.42:2181,192.168.1.45:2181,192.168.1.36:2181/mesos --containerizers=mesos,docker</p>\n</blockquote>\n\n<p><strong>Zookeeper Config :</strong></p>\n\n<p>tickTime=2000</p>\n\n<p>initLimit=10</p>\n\n<p>syncLimit=5</p>\n\n<p>dataDir=/opt/ncms/zkWorkDir</p>\n\n<p>clientPort=2181</p>\n\n<p>server.1=192.168.1.42:2888:3888\nserver.3=192.168.1.36:2888:3888</p>\n\n<p>server.5=192.168.1.45:2888:3888</p>\n\n<p><strong>Setup :</strong> </p>\n\n<blockquote>\n  <p>Host: Windows 7 (64GB RAM, 24 Cores ) </p>\n  \n  <p>Virtual Box :  each vm(m1, m2,\n  m3) has 2 cores and 2 GB RAM with RHEL 7.2</p>\n</blockquote>\n", "is_answered": false, "tags": ["linux", "apache-zookeeper", "mesos", "marathon", "dcos"], "title": "does mesos cluster unacceesable when mesos master and agent goes down at same time?", "last_activity_date": 1490118737, "answer_count": 1, "creation_date": 1490089653, "score": 0, "link": "https://stackoverflow.com/questions/42923412/does-mesos-cluster-unacceesable-when-mesos-master-and-agent-goes-down-at-same-ti", "answers": [{"body": "<p>In scenarios you describe, the number of active masters falls below <a href=\"https://en.wikipedia.org/wiki/Quorum_(distributed_computing)\" rel=\"nofollow noreferrer\">quorum</a>, which is 2 in your case. This is considered an exceptional situation and certain operations will not succeed, for example, any operation <a href=\"https://github.com/apache/mesos/blob/05e9a1d40572b8383a582e15663d861b134a7dad/src/log/consensus.cpp#L464-L468\" rel=\"nofollow noreferrer\">modifying the distributed registry</a>.</p>\n", "answer_id": 42934662, "last_activity_date": 1490118737, "creation_date": 1490118737, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 42923412}], "owner": {"user_id": 1392999, "profile_image": "https://www.gravatar.com/avatar/185668d3c5790042a9ad55413541b63e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 55, "link": "https://stackoverflow.com/users/1392999/narendra", "accept_rate": 0, "display_name": "Narendra"}, "view_count": 49, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42923412}{"is_answered": true, "tags": ["amazon-web-services", "mesos", "amazon-vpc", "docker-registry", "mesosphere"], "last_edit_date": 1435828546, "title": "How should a .dockercfg file be hosted in a Mesosphere-on-AWS setup so that only Mesosphere can use it?", "last_activity_date": 1468195626, "answer_count": 4, "creation_date": 1435328759, "score": 5, "link": "https://stackoverflow.com/questions/31075733/how-should-a-dockercfg-file-be-hosted-in-a-mesosphere-on-aws-setup-so-that-only", "accepted_answer_id": 31180422, "owner": {"user_id": 1475135, "profile_image": "https://www.gravatar.com/avatar/dfe94797d25802c4c40ec38b963a7ba5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 380, "link": "https://stackoverflow.com/users/1475135/user1475135", "accept_rate": 100, "display_name": "user1475135"}, "view_count": 1514, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 31075733}{"is_answered": false, "tags": ["azure", "dcos"], "title": "How do I enable multiple public applications on DCOS on Azure?", "last_activity_date": 1488082264, "answer_count": 0, "creation_date": 1488082264, "score": 0, "link": "https://stackoverflow.com/questions/42464662/how-do-i-enable-multiple-public-applications-on-dcos-on-azure", "owner": {"user_id": 4833540, "profile_image": "https://www.gravatar.com/avatar/615ded8934e0f57a9bb681415f5ff800?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/4833540/zwitterion", "display_name": "Zwitterion"}, "view_count": 20, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42464662}{"body": "<p>I'm trying to setup a stateful app in DC/OS by assigning an external (EBS) volume to the docker container. I've ran the demo app provided in the docs and it created a 100GB EBS volume in AWS. Is there a way to specify the size of the volume in the <code>marathon.json</code> file? Can I use the same EBS volume for multiple apps? Here's the demo app I've tested.</p>\n\n<pre><code>{\n  \"id\": \"/test-docker\",\n  \"instances\": 1,\n  \"cpus\": 0.1,\n  \"mem\": 32,\n  \"cmd\": \"date &gt;&gt; /data/test-rexray-volume/test.txt; cat /data/test-rexray-volume/test.txt\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"alpine:3.1\",\n      \"network\": \"HOST\",\n      \"forcePullImage\": true\n    },\n    \"volumes\": [\n      {\n        \"containerPath\": \"/data/test-rexray-volume\",\n        \"external\": {\n          \"name\": \"my-test-vol\",\n          \"provider\": \"dvdi\",\n          \"options\": { \"dvdi/driver\": \"rexray\" }\n        },\n        \"mode\": \"RW\"\n      }\n    ]\n  },\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 0,\n    \"maximumOverCapacity\": 0\n  }\n}\n</code></pre>\n", "is_answered": false, "tags": ["amazon-ec2", "mesosphere", "dcos"], "title": "DC/OS stateful app with persistent external storage", "last_activity_date": 1503575464, "answer_count": 1, "creation_date": 1503397748, "score": 1, "link": "https://stackoverflow.com/questions/45815191/dc-os-stateful-app-with-persistent-external-storage", "answers": [{"body": "<p>You cannot attach one EBS volume to multiple EC2 instances. My bad! I ditched the rexray persistent storage option in favor of EFS. </p>\n\n<p>I had to create an EFS share and attach it to the cluster's VPC. Then I had to ssh into every slave node, mount it like an NFS share under the same folder on all nodes and finally mount it in the container from marathon.json.</p>\n", "answer_id": 45860884, "last_activity_date": 1503575464, "creation_date": 1503575464, "score": 0, "owner": {"user_id": 1759948, "profile_image": "https://i.stack.imgur.com/po0MK.jpg?s=128&g=1", "user_type": "registered", "reputation": 668, "link": "https://stackoverflow.com/users/1759948/r%c4%83zvan", "accept_rate": 85, "display_name": "R\u0103zvan"}, "is_accepted": false, "question_id": 45815191}], "owner": {"user_id": 1759948, "profile_image": "https://i.stack.imgur.com/po0MK.jpg?s=128&g=1", "user_type": "registered", "reputation": 668, "link": "https://stackoverflow.com/users/1759948/r%c4%83zvan", "accept_rate": 85, "display_name": "R\u0103zvan"}, "view_count": 28, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45815191}{"body": "<p>Apologies for the noob question; I am new to using DC/OS (using v1.8.7) and have learnt that DC/OS has Marathon built in (Source: <a href=\"https://docs.mesosphere.com/1.8/administration/release-notes/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.8/administration/release-notes/</a>).</p>\n\n<p>When I go to the 'Universe' browser in DC/OS, I find that I can download and install the Marathon (v1.3.3) package.</p>\n\n<ol>\n<li><p>Is this package now redundant for the version of DC/OS that I am using? </p></li>\n<li><p>Why would I use the Marathon package in DC/OS - what features does it give to me that I don't already get from DC/OS?</p></li>\n</ol>\n\n<p>I'm basically fumbling through setting up my first cluster and trying to learn as I go along, so I would appreciate any insight!</p>\n\n<p>I have also posted the same question here: <a href=\"https://unix.stackexchange.com/questions/325103/what-benefits-does-the-marathon-package-bring-to-dc-os\">https://unix.stackexchange.com/questions/325103/what-benefits-does-the-marathon-package-bring-to-dc-os</a> - but this forum doesn't seem to be any where near as active as StackOverflow; If i get an answer here, I will delete the other question or vice-versa.</p>\n", "is_answered": true, "title": "What benefits does the Marathon package bring to DC/OS?", "tags": ["docker", "centos7", "mesos", "marathon", "dcos"], "last_activity_date": 1479808788, "accepted_answer_id": 40738792, "creation_date": 1479807219, "answers": [{"body": "<p>Great question, happy to provide some clarification since I think we don't do a great job explaining this.</p>\n\n<blockquote>\n  <p>Is this package now redundant for the version of DC/OS that I am using?</p>\n</blockquote>\n\n<p>No. The use case for this package (called Marathon-on-Marathon or MoM for short) is to give users a user-land supervisor. You don't want to share the System Marathon with your users and allow everyone to install stuff from the Universe? OK, no problem, install a MoM for each of your users/teams/projects and they can do whatever they like within it (for example, install Jenkins, Spark, etc.)</p>\n\n<blockquote>\n  <p>Why would I use the Marathon package in DC/OS - what features does it give to me that I don't already get from DC/OS?</p>\n</blockquote>\n\n<p>See above. No additional feature (there are even some limitations, that is, there's stuff you can do on the System Marathon you can't do in MoM) but think of it as a multi-tenant and/or security feature (well, a poor-man's, really\u2014the Mesosphere DC/OS Enterprise Edition provides a full-featured environment like <a href=\"https://docs.mesosphere.com/1.8/administration/id-and-access-mgt/\" rel=\"nofollow noreferrer\">authn/authz, ACLs, secrets, etc.</a>).</p>\n", "answer_id": 40738792, "last_activity_date": 1479808788, "creation_date": 1479808788, "score": 4, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 40738209}], "score": 2, "link": "https://stackoverflow.com/questions/40738209/what-benefits-does-the-marathon-package-bring-to-dc-os", "answer_count": 1, "owner": {"user_id": 685341, "profile_image": "https://www.gravatar.com/avatar/60164718921efb89bfff0212de34f177?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 2612, "link": "https://stackoverflow.com/users/685341/jay", "accept_rate": 90, "display_name": "Jay"}, "view_count": 93, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40738209}{"body": "<p>I have a dockerized spring-boot app, which needs to be scheduled in mesos / chronos (DC/OS).\nThere are 2 places, which (I think) can be used to accomplish Chronos scheduling:</p>\n\n<p>1) by using the \"command\" tag\n2) by using the \"container\" tag</p>\n\n<p>An example of Chronos command tag would be:</p>\n\n<pre><code>{\n    \"name\": \"my-dockerized-app\",\n    \"command\": \"docker login -u my_username -p my_password -e dev-my_user@my_company.com;docker run -e id=123 my_owner/my_dockerized_app_image:latest\",\n    \"shell\": true,\n    \"epsilon\": \"PT60S\",\n    \"executor\": \"\",\n    \"executorFlags\": \"\",\n    \"retries\": 2,\n    \"owner\": \"\",\n    \"ownerName\": \"\",\n    \"description\": \"\",\n    \"async\": false,\n    \"successCount\": 0,\n    \"errorCount\": 264,\n    \"lastSuccess\": \"\",\n    \"lastError\": \"\",\n    \"cpus\": 0.5,\n    \"disk\": 256.0,\n    \"mem\": 512.0,\n    \"disabled\": false,\n    \"softError\": false,\n    \"dataProcessingJobType\": false,\n    \"errorsSinceLastSuccess\": 264,\n    \"uris\": [],\n    \"environmentVariables\": [{\n        \"name\": \"id\",\n        \"value\": \"1\"\n    }],\n    \"arguments\": [],\n    \"highPriority\": false,\n    \"runAsUser\": \"root\",\n    \"constraints\": [],\n    \"schedule\": \"R/2016-11-21T05:06:00.000Z/PT2M\",\n    \"scheduleTimeZone\": \"\"\n}\n</code></pre>\n\n<p>An example of Chronos \"container\" tag:</p>\n\n<pre><code>  {\n     \"schedule\": \"R\\/2014-09-25T17:22:00Z\\/PT2M\",\n     \"name\": \"my_docker_job\",\n     \"container\": {\n      \"type\": \"DOCKER\",\n      \"image\": \"my_owner/my_dockerized_app\",\n      \"network\": \"BRIDGE\"\n     },\n     \"cpus\": \"0.5\",\n     \"mem\": \"512\",\n     \"uris\": [],\n     \"\"\n    }\n</code></pre>\n\n<p>Which of these scheduling methods should really be used in Mesos / Chronos production environments?</p>\n", "is_answered": false, "tags": ["mesos", "dcos"], "title": "what is a better way to run docker under chronos?", "last_activity_date": 1480026795, "answer_count": 1, "creation_date": 1479756930, "score": 0, "link": "https://stackoverflow.com/questions/40727972/what-is-a-better-way-to-run-docker-under-chronos", "answers": [{"body": "<p><strong>You should use second option</strong></p>\n\n<p>The difference in this two configurations is the way Mesos will interact with docker. </p>\n\n<ol>\n<li>you are creating Mesos task that is launching docker so Mesos doesn't know about docker and you need to monitor it.</li>\n<li>Mesos will launch docker for you and keep a track of it. So if docker fails Mesos will notify Chronos. </li>\n</ol>\n", "answer_id": 40795329, "last_activity_date": 1480026795, "creation_date": 1480026795, "score": 0, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": false, "question_id": 40727972}], "owner": {"user_id": 518012, "profile_image": "https://www.gravatar.com/avatar/7792f4858924a9c1b47c7422bd84864d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3135, "link": "https://stackoverflow.com/users/518012/eugene-goldberg", "accept_rate": 66, "display_name": "Eugene Goldberg"}, "view_count": 127, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40727972}{"body": "<p>I have setup up a VM cluster using Azure Container Service. The container orchestrator is DC/OS. There are 3 Master nodes and 3 slave agents.</p>\n\n<p>I have a Docker app that I am trying to launch on my cluster using Marathon. Each time I launch, I notice that the CPU utilization of 3 nodes is always 0 i.e. the app is never scheduled on them. The other 3 nodes, on the other hand, have almost 100% CPU utilization. (As I scale the application.) At that point, the scaling stops and Marathon shows state \"waiting\" for resource ads from Mesos.</p>\n\n<p>I don't understand why Marathon is not scheduling more containers, despite there being empty nodes when I try to scale the application.</p>\n\n<p>I know that Marathon runs on the Master nodes; is it unaware of the presence of the slave agents? (Assuming that the 3 free nodes are the slaves.)</p>\n\n<p>Here is the config file of the application: <a href=\"http://pastebin.com/FBpZBTDc\" rel=\"nofollow\">pastebin-config-file</a></p>\n\n<p>How can I make full use of the machines using Marathon?</p>\n", "is_answered": false, "tags": ["azure", "mesos", "marathon", "dcos", "azure-container-service"], "title": "Marathon on Azure Container Service - cannot scale to all nodes", "last_activity_date": 1475508227, "answer_count": 1, "creation_date": 1467767656, "score": 1, "link": "https://stackoverflow.com/questions/38215081/marathon-on-azure-container-service-cannot-scale-to-all-nodes", "answers": [{"body": "<p>Tasks are not scheduled to the masters. They are reserved for management of the cluster.</p>\n", "answer_id": 39835087, "last_activity_date": 1475508227, "creation_date": 1475508227, "score": 0, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "question_id": 38215081}], "owner": {"user_id": 3766324, "profile_image": "https://www.gravatar.com/avatar/7b47c4490221b1c6fc367d1cdffff8e9?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 35, "link": "https://stackoverflow.com/users/3766324/as1901", "accept_rate": 67, "display_name": "as1901"}, "view_count": 131, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 38215081}{"body": "<p>Mesos frameworks like Marathon or Chronos have <code>forcePull</code>-like options for this, to make mesos agents pull the image from the registry. </p>\n\n<p>Is the same possible with <code>mesos-execute</code>? Do I have to specify an option in TaskInfo or TaskGroupInfo?</p>\n\n<p>I have searched in the mesos source for words like \"force pull\" / \"forcepull\" or \"cached\", but no dice.</p>\n", "is_answered": true, "title": "How do I make mesos force-pull images when using mesos-execute?", "tags": ["mesos", "marathon", "dcos"], "last_activity_date": 1496396932, "accepted_answer_id": 44325872, "creation_date": 1496346938, "answers": [{"body": "<p>You should specify a corresponding option in <code>TaskInfo</code> to force pull the image. Where exactly \u2014 depends on which container type (read: containerizer) you use.</p>\n\n<p>If you use docker containerizer, i.e. your <code>TaskInfo.container.type = DOCKER</code>, then have a look at <a href=\"https://github.com/apache/mesos/blob/396cda9cef532b9be980002d97e4aadf12ccec85/include/mesos/mesos.proto#L2522\" rel=\"nofollow noreferrer\"><code>ContainerInfo.DockerInfo.force_pull_image</code></a>. What you want to set in your JSON for <code>TaskInfo</code> is <code>TaskInfo.container.docker.force_pull_image = true</code>.</p>\n\n<p>If you use mesos containerizer, i.e. your <code>TaskInfo.container.type = Mesos</code>, then you specify <code>TaskInfo.container.mesos.image</code>, which might be a docker or an appc container, and hence should look at <a href=\"https://github.com/apache/mesos/blob/396cda9cef532b9be980002d97e4aadf12ccec85/include/mesos/mesos.proto#L2110\" rel=\"nofollow noreferrer\"><code>Image</code></a>, which has a <a href=\"https://github.com/apache/mesos/blob/396cda9cef532b9be980002d97e4aadf12ccec85/include/mesos/mesos.proto#L2164\" rel=\"nofollow noreferrer\"><code>cached</code> flag</a>. What you want to set in your JSON for <code>TaskInfo</code> is <code>TaskInfo.container.mesos.image.cached = false</code>.</p>\n", "answer_id": 44325872, "last_activity_date": 1496396932, "creation_date": 1496396932, "score": 3, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": true, "question_id": 44316074}], "score": 1, "link": "https://stackoverflow.com/questions/44316074/how-do-i-make-mesos-force-pull-images-when-using-mesos-execute", "answer_count": 1, "owner": {"user_id": 781938, "profile_image": "https://www.gravatar.com/avatar/189e7e1ecd0a7516152f0e2d2d5d6130?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 697, "link": "https://stackoverflow.com/users/781938/grisaitis", "accept_rate": 100, "display_name": "grisaitis"}, "view_count": 39, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44316074}{"is_answered": true, "tags": ["arangodb", "dcos"], "title": "How to install ArangoDb in DCOS with customized options in arangod.conf file", "last_activity_date": 1490261902, "answer_count": 1, "creation_date": 1490249576, "score": 0, "link": "https://stackoverflow.com/questions/42968495/how-to-install-arangodb-in-dcos-with-customized-options-in-arangod-conf-file", "owner": {"user_id": 1642790, "profile_image": "https://i.stack.imgur.com/OvpjC.jpg?s=128&g=1", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/1642790/pjesudhas", "accept_rate": 71, "display_name": "pjesudhas"}, "view_count": 37, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42968495}{"body": "<p>when I launch the next marathon app </p>\n\n<pre><code>{\n    \"id\": \"my-docker-task\",\n    \"cpus\": 0.1,\n    \"mem\": 64.0,\n    \"container\": {\n        \"type\": \"DOCKER\",\n        \"docker\": {\n            \"image\": \"nginx\",\n            \"parameters\": [\n              {\"key\": \"net\", \"value\": \"my-calico-net\"}\n            ]\n        }\n    },\n    \"ipAddress\": {},\n    \"healthChecks\": [{\n        \"protocol\": \"HTTP\",\n        \"path\": \"/\",\n        \"port\": 80,\n        \"gracePeriodSeconds\": 300,\n        \"intervalSeconds\": 60,\n        \"timeoutSeconds\": 20,\n        \"maxConsecutiveFailures\": 3\n    }]\n}\n</code></pre>\n\n<p>It throws the next error: </p>\n\n<pre><code>{\n\"message\":\"Object is not valid\",\n\"details\":[{\n    \"path\":\"/healthChecks(0)\",\n\"errors\":[\n    \"Health check port indices must address an element of the ports array or container port mappings.\"\n]}]}\n</code></pre>\n\n<p>It would be of calico configuration or a error of the marathon cluster?</p>\n", "is_answered": false, "tags": ["mesosphere", "marathon", "calico", "project-calico"], "last_edit_date": 1489825453, "title": "Error with calico and marathon", "last_activity_date": 1489825453, "answer_count": 1, "creation_date": 1472806455, "score": 0, "link": "https://stackoverflow.com/questions/39288244/error-with-calico-and-marathon", "answers": [{"body": "<p>Health Checks have to use a port defined in portMappings or portDefinitions, so you should probably have those defined. The way you have things configured is such that the docker image won't have any ports defined.</p>\n", "answer_id": 39623247, "last_activity_date": 1474479850, "creation_date": 1474479850, "score": 0, "owner": {"user_id": 6850253, "profile_image": "https://lh3.googleusercontent.com/-qXfKyRUsFO4/AAAAAAAAAAI/AAAAAAAAAA0/N934NCfqIFM/photo.jpg?sz=128", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6850253/jason-gilanfarr", "display_name": "Jason Gilanfarr"}, "is_accepted": false, "question_id": 39288244}], "owner": {"user_id": 5621509, "profile_image": "https://www.gravatar.com/avatar/2ade806eb7a16154fb3d627a687383d4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 662, "link": "https://stackoverflow.com/users/5621509/asier-gomez", "accept_rate": 98, "display_name": "Asier Gomez"}, "view_count": 97, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 39288244}{"body": "<p>I'm trying cassandra-mesos framework on my local mesos cluster. My cluster has:</p>\n\n<ul>\n<li>ip: 10.10.10.30 name: vcmms os: CentOs 6.7 {mesos-master, mesos-slave, marathon, zookeeper}</li>\n<li>ip: 10.10.10.31 name: vcmss1 os: CentOs 6.7 {mesos-slave}</li>\n<li>ip: 10.10.10.32 name: vcmss2 os: CentOs 6.7 {mesos-slave}</li>\n</ul>\n\n<p>I'm using a restrictive security policy with iptables to avoid network attack.</p>\n\n<p>The <code>iptable -L</code> on mesos-slaves:</p>\n\n<pre><code>Chain INPUT (policy DROP)                                                                                                \ntarget     prot opt source               destination                                                                     \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:apani1 flags:FIN,SYN,RST,ACK/SYN                    \nACCEPT     all  --  anywhere             anywhere            state RELATED,ESTABLISHED                                   \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:ssh                                                 \nDROP       tcp  --  anywhere             anywhere            tcp flags:FIN,SYN,RST,PSH,ACK,URG/NONE                      \nDROP       tcp  --  anywhere             anywhere            tcp flags:!FIN,SYN,RST,ACK/SYN state NEW                    \nDROP       tcp  --  anywhere             anywhere            tcp flags:FIN,SYN,RST,PSH,ACK,URG/FIN,SYN,RST,PSH,ACK,URG   \nACCEPT     all  --  anywhere             anywhere                                                                        \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:ita-agent                                           \nACCEPT     tcp  --  anywhere             anywhere            tcp dpts:31000:32000                                        \nACCEPT     tcp  --  anywhere             anywhere            tcp dpts:afs3-fileserver:afs3-callback                      \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:7199                                                \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:9042                                                \nACCEPT     tcp  --  anywhere             anywhere            tcp dpt:apani1                                              \n\nChain FORWARD (policy ACCEPT)                                                                                            \ntarget     prot opt source               destination                                                                     \n\nChain OUTPUT (policy ACCEPT)                                                                                             \ntarget     prot opt source               destination                                                                     \n\nChain DOCKER (0 references)                                                                                              \ntarget     prot opt source               destination                                                                     \n</code></pre>\n\n<p>my app.json:</p>\n\n<pre><code>{\n  \"id\": \"/cassandra/dev-test\",\n  \"instances\": 1,\n  \"cpus\": 0.5,\n  \"mem\": 512,\n  \"ports\": [\n    0\n  ],\n  \"uris\": [\n    \"http://mypublicstorage/cassandra-mesos-0.2.0-1.tar.gz\",\n    \"http://mypublicstorage/jre-7u76-linux-x64.tar.gz\"\n  ],\n  \"env\": {\n    \"MESOS_ZK\": \"zk://10.10.10.30:2181/mesos\",\n    \"JAVA_OPTS\": \"-Xms256m -Xmx256m\",\n    \"CASSANDRA_CLUSTER_NAME\": \"dev-test\",\n    \"CASSANDRA_ZK\": \"zk://10.10.10:2181/cassandra-mesos\",\n    \"CASSANDRA_NODE_COUNT\": \"3\",\n    \"CASSANDRA_RESOURCE_CPU_CORES\": \"2.0\",\n    \"CASSANDRA_RESOURCE_MEM_MB\": \"2048\",\n    \"CASSANDRA_RESOURCE_DISK_MB\": \"2048\",\n    \"CASSANDRA_HEALTH_CHECK_INTERVAL_SECONDS\": \"60\",\n    \"CASSANDRA_ZK_TIMEOUT_MS\": \"10000\"\n  },\n  \"cmd\": \"$(pwd)/jre*/bin/java $JAVA_OPTS -classpath cassandra-mesos-framework.jar io.mesosphere.mesos.frameworks.cassandra.framework.Main\",\n  \"healthChecks\": [\n    {\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 30,\n      \"maxConsecutiveFailures\": 0,\n      \"path\": \"/health/cluster\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    },\n    {\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 30,\n      \"maxConsecutiveFailures\": 3,\n      \"path\": \"/health/process\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    }\n  ]\n}\n</code></pre>\n\n<p>After submit app on marathon the framework is registered but health check failed. When I access to the page stats:\"<a href=\"http://vcmms.domain:31329/health/cluster/report\" rel=\"nofollow\">http://vcmms.domain:31329/health/cluster/report</a>\" the result it's:</p>\n\n<pre><code>{\n  \"healthy\": false,\n  \"results\": [\n    {\n      \"name\": \"nodeCount\",\n      \"ok\": true,\n      \"expected\": 3,\n      \"actual\": 3\n    },\n    {\n      \"name\": \"seedCount\",\n      \"ok\": true,\n      \"expected\": 2,\n      \"actual\": 2\n    },\n    {\n      \"name\": \"allHealthy\",\n      \"ok\": false,\n      \"expected\": [\n        true,\n        true,\n        true\n      ],\n      \"actual\": [\n        true\n      ]\n    },\n    {\n      \"name\": \"operatingModeNormal\",\n      \"ok\": false,\n      \"expected\": [\n        \"NORMAL\",\n        \"NORMAL\",\n        \"NORMAL\"\n      ],\n      \"actual\": [\n        \"NORMAL\"\n      ]\n    },\n    {\n      \"name\": \"lastHealthCheckNewerThan\",\n      \"ok\": false,\n      \"expected\": [\n        1443544996737,\n        1443544996737,\n        1443544996737\n      ],\n      \"actual\": [\n        1443545237676\n      ]\n    },\n    {\n      \"name\": \"nodesHaveServerTask\",\n      \"ok\": true,\n      \"expected\": [\n        true,\n        true,\n        true\n      ],\n      \"actual\": [\n        true,\n        true,\n        true\n      ]\n    }\n  ]\n}\n</code></pre>\n\n<p><strong>NOTE</strong> \nWhen I disable all iptable restrictions all work fine, but I don't know the ports missing in my iptable rules that cause health check problems. </p>\n", "is_answered": false, "tags": ["cassandra", "iptables", "mesos", "mesosphere"], "last_edit_date": 1443548049, "title": "cassandra-mesos health check fail when deploy with marathon", "last_activity_date": 1443548049, "answer_count": 0, "creation_date": 1443470723, "score": 2, "link": "https://stackoverflow.com/questions/32830901/cassandra-mesos-health-check-fail-when-deploy-with-marathon", "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "view_count": 280, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32830901}{"body": "<p>My problem is that I have a set of net core applications that I created and I send them to Docker Hub:</p>\n\n<pre><code>$ docker push username/appname\n</code></pre>\n\n<p>On the other side I create on Azure Container Service with DC/OS, and login the server with terminal </p>\n\n<pre><code>$ ssh -i /Users/username/.ssh/id_rsa -L 80:localhost:80 -f -N username@servernamemgmt.westeurope.cloudapp.azure.com -p 2200 -v\n</code></pre>\n\n<p>but I cant understand how to install my docker images.</p>\n", "is_answered": false, "tags": ["azure", "asp.net-core", "containers", "dcos"], "last_edit_date": 1484300123, "title": "Azure container service DC/OS install net core images", "last_activity_date": 1486374047, "answer_count": 2, "creation_date": 1484299339, "score": 0, "link": "https://stackoverflow.com/questions/41631160/azure-container-service-dc-os-install-net-core-images", "answers": [{"body": "<p>In DC/OS, in order to deploy and run your Docker containers, you use <a href=\"https://dcos.io/docs/1.8/usage/marathon/\" rel=\"nofollow noreferrer\">Marathon</a> (for long-running services such as an app server, etc.) or <a href=\"https://dcos.io/docs/1.8/usage/jobs/\" rel=\"nofollow noreferrer\">Jobs</a> for one-off or scheduled tasks (think: distributed cron). You don't ssh into nodes and manually pull/run them.</p>\n", "answer_id": 41631367, "last_activity_date": 1484300017, "creation_date": 1484300017, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 41631160}, {"body": "<p>If your docker images are already on Docker hub, in order to use them on your DC/OS cluster you typically use Marathon.\nSince you say you configured an SSH tunnel with port forwarding (this is an important step), you should be able to access the Marathon UI using <a href=\"http://localhost/Marathon\" rel=\"nofollow noreferrer\">http://localhost/Marathon</a> . Then, click on 'Create Application' where you can specify it's settings. The part you are probably looking for is in the second menu item - 'Docker Container' (menu to the left inside the Create Container dialog). There you can specify an image. This by default goes to Docker Hub, so you can write 'username/appname' in the 'Image' text box.\nThere are additional settings but I think this is what your question was about.</p>\n\n<p>More information:<a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-mesos-marathon-ui\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-mesos-marathon-ui</a></p>\n", "answer_id": 42064563, "last_activity_date": 1486374047, "creation_date": 1486374047, "score": 0, "owner": {"user_id": 310298, "profile_image": "https://i.stack.imgur.com/PkUnq.png?s=128&g=1", "user_type": "registered", "reputation": 1128, "link": "https://stackoverflow.com/users/310298/itaysk", "accept_rate": 63, "display_name": "itaysk"}, "is_accepted": false, "question_id": 41631160}], "owner": {"user_id": 1254257, "profile_image": "https://www.gravatar.com/avatar/1be115afa54114b04f660e11f70821e6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 306, "link": "https://stackoverflow.com/users/1254257/shaharnakash", "accept_rate": 59, "display_name": "shaharnakash"}, "view_count": 99, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41631160}{"body": "<p>Is there any way to get the number of instances of application running in marathon ? I am running a basic python webapp of 2 instances in marathon. I want to write a script to increase or decrease the number of instances automatically when the load of the mesos-slave spikes up or down. For that I need to get the applications initial no of instances running. Can someone please help on this ?</p>\n", "is_answered": true, "tags": ["mesos", "marathon", "mesosphere", "dcos"], "title": "Number of instances of application in marathon", "last_activity_date": 1481871973, "answer_count": 2, "creation_date": 1481261115, "score": 0, "link": "https://stackoverflow.com/questions/41053625/number-of-instances-of-application-in-marathon", "answers": [{"body": "<p>Marathon REST API is your friend. Have a look <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html#get-v2-apps-appid-embed-embed\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html#put-v2-apps-appid\" rel=\"nofollow noreferrer\">here</a>. In pseudo-python, a script you want may look something like this:</p>\n\n<pre><code>def scaleTo(instances, force=False):\n  marathon = 'http://localhost:8080'\n  url = '{}/v2/apps/&lt;your-app-id&gt;'.format(marathon)\n  headers = {\n             'Content-Type': 'application/json',\n             'Accept': 'application/json'\n            }\n  params = {'force': 'true' if force else 'false'}\n  payload = {'instances': instances}\n\n  r = requests.put(url, headers=headers, params=params, json=payload, verify=False)\n\n  r.raise_for_status()\n</code></pre>\n", "answer_id": 41060186, "last_activity_date": 1481285403, "creation_date": 1481285403, "score": 2, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 41053625}, {"body": "<p>I think you are interested in auto scaling applications on Marathon. Take a look at <a href=\"https://github.com/mesosphere/marathon-autoscale\" rel=\"nofollow noreferrer\">marathon-autoscale</a> repository. Those scripts might be useful although those are just for PoC.</p>\n", "answer_id": 41179005, "last_activity_date": 1481871973, "creation_date": 1481871973, "score": 0, "owner": {"user_id": 1920644, "profile_image": "https://www.gravatar.com/avatar/20f88d0afee3416af846ea7fc4a27b90?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/1920644/blurblah", "display_name": "blurblah"}, "is_accepted": false, "question_id": 41053625}], "owner": {"user_id": 3848047, "profile_image": "https://www.gravatar.com/avatar/f7c2e27db9eb11d3d639a3b4e7262a31?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/3848047/manoj-prabhakar", "display_name": "Manoj Prabhakar"}, "view_count": 146, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41053625}{"body": "<p>I'm interested in having my mesos-slave instances inherit attributes from the EC2 tags that the slave is running on. After some searching, I don't think such a setup exists. I would like to write one and contribute it back to the community.</p>\n\n<p>Our slaves are running Ubuntu and we're using the mesos packages from the mesosphere repo. This creates a beautiful <a href=\"https://github.com/deric/mesos-deb-packaging/blob/master/mesos-init-wrapper\" rel=\"nofollow noreferrer\">mesos-init-wrapper</a> that allows mesos configuration (command line arguments) to be represented as files in <code>/etc/mesos-slave/</code> or <code>/etc/mesos/</code>. I want to write a script which will:</p>\n\n<ol>\n<li>Use the ec2 API to get the instance tags (<a href=\"https://stackoverflow.com/a/7122649/379482\">see here</a>)</li>\n<li>Generate corresponding files in <code>[/etc/mesos/attributes/][3]</code></li>\n<li>Run this script at an early run-level</li>\n</ol>\n\n<p>Mesos community folks: is this the right way to go? Is it reasonable to build an implementation that is tied to <code>mesos-init-wrapper</code>?</p>\n\n<p>Thanks!</p>\n\n<p>Advait</p>\n", "is_answered": true, "title": "Mesos Attributes: Source from EC2 Tags", "last_edit_date": 1495535061, "tags": ["amazon-web-services", "amazon-ec2", "mesos", "mesosphere", "marathon"], "view_count": 177, "accepted_answer_id": 30064987, "last_activity_date": 1430868975, "answers": [{"body": "<p><code>mesos-aws-tags</code> is now available here: <a href=\"https://github.com/goguardian/mesos-aws-tags\" rel=\"nofollow\">https://github.com/goguardian/mesos-aws-tags</a></p>\n", "answer_id": 30064987, "last_activity_date": 1430868975, "creation_date": 1430868975, "score": 1, "owner": {"user_id": 379482, "profile_image": "https://www.gravatar.com/avatar/d890d7f1ddeb893a8f810bdaf086e13f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4003, "link": "https://stackoverflow.com/users/379482/advait", "accept_rate": 73, "display_name": "advait"}, "is_accepted": true, "question_id": 30064060}], "score": 0, "link": "https://stackoverflow.com/questions/30064060/mesos-attributes-source-from-ec2-tags", "answer_count": 1, "owner": {"user_id": 379482, "profile_image": "https://www.gravatar.com/avatar/d890d7f1ddeb893a8f810bdaf086e13f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4003, "link": "https://stackoverflow.com/users/379482/advait", "accept_rate": 73, "display_name": "advait"}, "creation_date": 1430863571, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 30064060}{"body": "<p>I am trying to run a batch process in Spark on DC/OS on AWS. For each batch process, I have some specific parameters I send when I do spark submit (for example for which users to perform the batch process).</p>\n\n<p>I have a Spark cluster on DC/OS, with one master and 3 private nodes.</p>\n\n<p>I have created a <code>application.conf</code> file and uploaded it to S3, and enabled the permissions for accessing that file.</p>\n\n<p>My spark submit command looks like this:</p>\n\n<blockquote>\n  <p>dcos spark run --submit-args='-Dspark.mesos.coarse=true --driver-class-path <a href=\"https://path_to_the_folder_root_where_is_the_file\" rel=\"nofollow\">https://path_to_the_folder_root_where_is_the_file</a> --conf spark.driver.extraJavaOptions=-Dconfig.file=application.conf --conf spark.executor.extraJavaOptions=-Dconfig.file=application.conf  --class class_name jar_location_on_S3'</p>\n</blockquote>\n\n<p>And I get the error that job.properties file is not found:</p>\n\n<blockquote>\n  <p>Exception in thread \"main\" com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'wattio-batch'\n      at com.typesafe.config.impl.SimpleConfig.findKey(SimpleConfig.java:124)\n      at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:145)\n      at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:159)\n      at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:164)\n      at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:218)\n      at com.typesafe.config.impl.SimpleConfig.getConfig(SimpleConfig.java:224)\n      at com.typesafe.config.impl.SimpleConfig.getConfig(SimpleConfig.java:33)\n      at com.enerbyte.spark.jobs.wattiobatch.WattioBatchJob$.main(WattioBatchJob.scala:31)\n      at com.enerbyte.spark.jobs.wattiobatch.WattioBatchJob.main(WattioBatchJob.scala)\n      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n      at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n      at java.lang.reflect.Method.invoke(Method.java:498)\n      at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:786)\n      at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:183)\n      at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:208)\n      at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:123)\n      at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)</p>\n</blockquote>\n\n<p>How to set this properly? Although one of the private slaves executes the driver, does it have the access to Internet(is it able to go to S3 and download conf file)?</p>\n\n<p>Thank you </p>\n", "is_answered": false, "tags": ["apache-spark", "mesos", "mesosphere", "dcos"], "last_edit_date": 1463669262, "title": "Spark job on DC/OS cluster on AWS", "last_activity_date": 1463680818, "answer_count": 1, "creation_date": 1463668023, "score": 1, "link": "https://stackoverflow.com/questions/37326270/spark-job-on-dc-os-cluster-on-aws", "answers": [{"body": "<p>I didn't succeed to send conf file from spark submit command, but what I did is to hard-code the location of application.conf file at the beginning of my program using:</p>\n\n<p><code>System.setProperty(\"config.url\", \"https://s3_location/application.conf\")\nConfigFactory.invalidateCaches()</code></p>\n\n<p>This way, program was able to read the application.conf file every time at launching.</p>\n", "answer_id": 37330832, "last_activity_date": 1463680818, "creation_date": 1463680818, "score": 0, "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "is_accepted": false, "question_id": 37326270}], "owner": {"user_id": 4714252, "profile_image": "https://graph.facebook.com/965496480128700/picture?type=large", "user_type": "registered", "reputation": 189, "link": "https://stackoverflow.com/users/4714252/srdjan-nikitovic", "accept_rate": 60, "display_name": "Srdjan Nikitovic"}, "view_count": 158, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 37326270}{"body": "<p>I understand the basic concepts of running a Docker container on Mesos with <a href=\"http://mesos.apache.org/documentation/latest/docker-containerizer/\" rel=\"nofollow\">this</a> and <a href=\"https://open.mesosphere.com/advanced-course/deploying-a-web-app-using-docker/\" rel=\"nofollow\">this</a> as an Marathon application. I have two questions:</p>\n\n<ol>\n<li><p>Does Mesos/Marathon has a REST API to list Docker containers started by a Marathon application? I went through <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html\" rel=\"nofollow\">REST API reference</a> but could not find a way to do this. What I'm looking for is the IP addresses of the Docker containers within the Mesos cluster/network.</p></li>\n<li><p>Does Mesos provide a <a href=\"https://github.com/coreos/flannel\" rel=\"nofollow\">Flannel</a> like SDN for Docker or is it just local IP addresses containers would get for each Mesos slave? I checked <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">this</a> but could not figure this out.</p></li>\n</ol>\n\n<p>Many Thanks!</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "marathon"], "title": "How to list Docker containers of a Mesos Marathon Application?", "last_activity_date": 1450726855, "answer_count": 1, "creation_date": 1450495281, "score": 1, "link": "https://stackoverflow.com/questions/34366914/how-to-list-docker-containers-of-a-mesos-marathon-application", "answers": [{"body": "<p>Have a look at <a href=\"https://mesosphere.github.io/marathon/docs/generated/api.html#v2_tasks_get\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/generated/api.html#v2_tasks_get</a> </p>\n\n<p>There you can see that the task objects contain <code>host</code> and <code>ports</code> properties.</p>\n", "answer_id": 34403170, "last_activity_date": 1450726855, "creation_date": 1450726855, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 34366914}], "owner": {"user_id": 524089, "profile_image": "https://www.gravatar.com/avatar/44a8d08d1f8cd6b193486f873e5aa672?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 538, "link": "https://stackoverflow.com/users/524089/imesh", "accept_rate": 43, "display_name": "imesh"}, "view_count": 129, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34366914}{"body": "<p>I have a local deployment with DC/OS where I also installed chronos. My setup is one master, one agent and the boot image: <code>m1</code>, <code>a1</code>, <code>boot</code>. </p>\n\n<p>The problem is that the jobs I send to chronos either don't get into queue or seem to not execute or...they get executed really late even tough I specified that I want them running right away. I always resort to restarting chronos so I can have 10 minutes of a responsive stack.</p>\n\n<p>I tried with multiple masters and multiple agents as well with the same results. I also tried raising the <code>RAM</code> and <code>CPUs</code> on both the master and agent with no luck. There seems to be a time window after which the stack lags out badly.</p>\n\n<p>My second issue after some testing. I tried adding jobs to chronos that would keep the agent's cpu capped at 100% for a while to see how it performs under load and, after 2 mins chronos crashed and my jobs all failed at once. Is this also something I could expect in production?</p>\n\n<p>I'm asking this in hopes that it's only a matter with the test local deployment under vagrant before I go on with my project and enter production spending quite a few bucks.</p>\n", "is_answered": false, "tags": ["mesos", "marathon", "dcos", "mesos-chronos"], "title": "DC/OS with chronos on localhost vagrant very unreliable", "last_activity_date": 1482140019, "answer_count": 0, "creation_date": 1482140019, "score": 0, "link": "https://stackoverflow.com/questions/41219530/dc-os-with-chronos-on-localhost-vagrant-very-unreliable", "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "view_count": 38, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41219530}{"is_answered": true, "tags": ["amazon-web-services", "hdfs", "mesos", "mesosphere", "dcos"], "title": "Can&#39;t access HDFS on Mesosphere DC/OS despite &quot;healthy&quot; status", "last_activity_date": 1471366613, "answer_count": 1, "creation_date": 1470760430, "score": 1, "link": "https://stackoverflow.com/questions/38856140/cant-access-hdfs-on-mesosphere-dc-os-despite-healthy-status", "accepted_answer_id": 38882369, "owner": {"user_id": 4557098, "profile_image": "https://i.stack.imgur.com/hPu30.jpg?s=128&g=1", "user_type": "registered", "reputation": 323, "link": "https://stackoverflow.com/users/4557098/dbernard", "display_name": "dbernard"}, "view_count": 347, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 38856140}{"body": "<p>i have started Jenkins Scheduler (Framework) as Marathon app. Now if the Jenkins Scheduler dies somehow, the Marathon will  restart it. But all the jobs and settings will be gone. How to persist jobs in Jenkins Mesos framework if it dies and started again?</p>\n", "is_answered": true, "tags": ["jenkins", "mesos", "mesosphere", "marathon"], "last_edit_date": 1436233433, "title": "How to persist jobs in Jenkins Mesos framework?", "last_activity_date": 1436233433, "answer_count": 1, "creation_date": 1436191146, "score": 0, "link": "https://stackoverflow.com/questions/31247825/how-to-persist-jobs-in-jenkins-mesos-framework", "answers": [{"body": "<p>The Jenkins plugin for Mesos does not yet support scheduler HA. To do so, the scheduler would need to persist the frameworkId remotely somewhere (ZK?) and try to reregister with the same frameworkId when it restarts. We'd also need to set the failover_timeout to a sufficient duration. Bonus points: persist task state and perform task reconciliation on reregistration.</p>\n\n<p>I filed a new github issue for this: <a href=\"https://github.com/jenkinsci/mesos-plugin/issues/147\" rel=\"nofollow\">https://github.com/jenkinsci/mesos-plugin/issues/147</a></p>\n", "answer_id": 31258058, "last_activity_date": 1436230379, "creation_date": 1436230379, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 31247825}], "owner": {"user_id": 3785351, "profile_image": "https://www.gravatar.com/avatar/a72b0ec1f103492e225ef9fd893bd21f?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 396, "link": "https://stackoverflow.com/users/3785351/manish", "accept_rate": 9, "display_name": "manish"}, "view_count": 76, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31247825}{"body": "<p>I am trying to configure Chronos to use custom mesos-docker executor present at <a href=\"https://github.com/mesosphere/mesos-docker/\" rel=\"nofollow\">https://github.com/mesosphere/mesos-docker/</a> . Everytime I try to run the command it fails.</p>\n\n<p>I created the task using below command</p>\n\n<pre><code>echo '{\"schedule\":\"R/2014-02-14T00:52:00Z/PT90M\", \"name\":\"testing_docker_executor\", \"command\":\"docker_ubuntu_test /root/docker_test.sh\", \"epsilon\":\"PT15M\", \"executor\":\"/var/lib/mesos/executors/docker\" }' | http POST localhost:8080/scheduler/iso8601\n</code></pre>\n\n<p>I also configured logging in executor and below are the logs I get when it fails</p>\n\n<pre><code>Feb 11 13:51:36 ip6-localhost docker[13895]: Ready to serve!\nFeb 11 13:51:36 ip6-localhost docker[13895]: Registered with Mesos slave\nFeb 11 13:51:36 ip6-localhost docker[13895]: Task is: ct:1392126755612:2:testing_docker_executor\nFeb 11 13:51:36 ip6-localhost docker[13895]: JSON from framework is rubbish\nFeb 11 13:51:36 ip6-localhost docker[13895]: No JSON object could be decoded\nFeb 11 13:51:36 ip6-localhost docker[13895]: Traceback (most recent call last):\nFeb 11 13:51:36 ip6-localhost docker[13895]:   File \"/var/lib/mesos/executors/docker\", line 120, in launchTask\nFeb 11 13:51:36 ip6-localhost docker[13895]:     self.data = json.loads(task.data) if task.data else {}\nFeb 11 13:51:36 ip6-localhost docker[13895]:   File \"/usr/lib/python2.7/json/__init__.py\", line 338, in loads\nFeb 11 13:51:36 ip6-localhost docker[13895]:     return _default_decoder.decode(s)\nFeb 11 13:51:36 ip6-localhost docker[13895]:   File \"/usr/lib/python2.7/json/decoder.py\", line 365, in decode\nFeb 11 13:51:36 ip6-localhost docker[13895]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())\nFeb 11 13:51:36 ip6-localhost docker[13895]:   File \"/usr/lib/python2.7/json/decoder.py\", line 383, in raw_decode\nFeb 11 13:51:36 ip6-localhost docker[13895]:     raise ValueError(\"No JSON object could be decoded\")\nFeb 11 13:51:36 ip6-localhost docker[13895]: ValueError: No JSON object could be decoded\nFeb 11 13:51:36 ip6-localhost docker[13895]: []\nFeb 11 13:51:36 ip6-localhost docker[13895]: Traceback (most recent call last):\nFeb 11 13:51:36 ip6-localhost docker[13895]:   File \"/var/lib/mesos/executors/docker\", line 67, in run\nFeb 11 13:51:36 ip6-localhost docker[13895]:     img  = self.args[0]\nFeb 11 13:51:36 ip6-localhost docker[13895]: IndexError: list index out of range\n</code></pre>\n\n<p>Is there something I am missing. Do I need to provide JSON in command.</p>\n", "is_answered": true, "title": "Custom mesos executor for docker in chronos", "tags": ["python", "docker", "executors", "mesos", "mesosphere"], "last_activity_date": 1435288675, "accepted_answer_id": 21792698, "creation_date": 1392127679, "answers": [{"body": "<p>There seems to be data provided in the <code>TaskInfo</code> but I am not sure where this is coming from. The Docker executor expects that, if there is data provided, it was provided by Marathon, and should be JSON. Evidently something else is in there.</p>\n\n<p>As regards the second error -- <code>list index out of range</code> -- this suggests that <code>docker_ubuntu_test /root/docker_test.sh</code> is not being passed to the Docker executor. Which is indeed odd.</p>\n", "answer_id": 21719806, "last_activity_date": 1392184549, "creation_date": 1392184549, "score": 0, "owner": {"user_id": 48251, "profile_image": "https://www.gravatar.com/avatar/94064636d740f54a1ea944b46f4dd8bd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1014, "link": "https://stackoverflow.com/users/48251/solidsnack", "accept_rate": 60, "display_name": "solidsnack"}, "is_accepted": false, "question_id": 21704149}, {"body": "<p>I have forked and customized the mesos-docker script by @solidsnack. It can be found at \n<a href=\"https://github.com/mudasirmirza/chronos-docker\" rel=\"nofollow\">https://github.com/mudasirmirza/chronos-docker</a></p>\n\n<p>This script works perfectly fine with Mesos and Chronos without Marathon.</p>\n\n<p>Usage and examples are in the readme.</p>\n", "answer_id": 21792698, "last_activity_date": 1392431912, "creation_date": 1392431912, "score": 0, "owner": {"user_id": 1213542, "profile_image": "https://i.stack.imgur.com/OMRch.jpg?s=128&g=1", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/1213542/mudasir-mirza", "accept_rate": 50, "display_name": "Mudasir Mirza"}, "is_accepted": true, "question_id": 21704149}, {"body": "<p>You need to provide a docker <code>image</code> for mesos to run in your json. It should look more like this.</p>\n\n<pre><code>{ \n    \"schedule\" : \"R5/2014-11-12T05:31:00.000Z/PT10S\",  \n    \"epsilon\" : \"PT10M\",  \n    \"name\" : \"ECHO_DATE_DOCKER\",\n    \"container\": {\n    \"type\": \"DOCKER\",\n    \"image\": \"libmesos/ubuntu\"\n    },\n    \"cpus\": \"0.5\",\n    \"mem\": \"256\",   \n    \"command\" : \"date &gt;&gt; /tmp/ECHO_DATE_01\",  \n    \"owner\" : \"chronos-user@example.com\",  \n    \"async\" : false \n}\n</code></pre>\n\n<p>There are more examples <a href=\"https://github.com/mesosphere/docker-screencasts/tree/master/chronos\" rel=\"nofollow\">here</a></p>\n", "answer_id": 31064316, "last_activity_date": 1435288675, "creation_date": 1435288675, "score": 0, "owner": {"user_id": 914763, "profile_image": "https://i.stack.imgur.com/9BYZw.jpg?s=128&g=1", "user_type": "registered", "reputation": 4808, "link": "https://stackoverflow.com/users/914763/jeremyjjbrown", "accept_rate": 83, "display_name": "jeremyjjbrown"}, "is_accepted": false, "question_id": 21704149}], "score": 2, "link": "https://stackoverflow.com/questions/21704149/custom-mesos-executor-for-docker-in-chronos", "answer_count": 3, "owner": {"user_id": 1213542, "profile_image": "https://i.stack.imgur.com/OMRch.jpg?s=128&g=1", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/1213542/mudasir-mirza", "accept_rate": 50, "display_name": "Mudasir Mirza"}, "view_count": 1998, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 21704149}{"body": "<p>I'm trying DCOS to setup a spark/mesos cluster. \nI deployed the mesos cluster on AWS, and everything went smoothly, except that the cluster is put in a dedicated VPC almost inaccessible from anywhere.</p>\n\n<p>The rest of my apps are in another VPC (default one), how am I supposed to access the services hosted on from there ?\nI tried to setup a VPC peering, with routes, and new rules in security groups, but I'm stuck, and I don't feel I'm in the right direction.</p>\n", "is_answered": true, "tags": ["amazon-web-services", "apache-spark", "mesos", "mesosphere"], "title": "access to spark, in a mesos cluster setup by dcos", "last_activity_date": 1442249147, "answer_count": 1, "creation_date": 1442245426, "score": 1, "link": "https://stackoverflow.com/questions/32568791/access-to-spark-in-a-mesos-cluster-setup-by-dcos", "answers": [{"body": "<p>Did you setup a dcos cluster via <a href=\"https://mesosphere.com/amazon/\" rel=\"nofollow\">the Mesosphere site</a>? In that case I would actually recommend to use the chat button on the lower left of the DCOS UI. </p>\n\n<p>Otherwise -if I understand your problem correctly- you should have a look at <a href=\"https://docs.mesosphere.com/tutorials/publicapp/\" rel=\"nofollow\">this tutorial</a> in order to make applications available to the public. A general overview of the security model can be found <a href=\"https://docs.mesosphere.com/getting-started/dcosarchitecture/#security\" rel=\"nofollow\">here</a>.</p>\n\n<p>So basically there are two options:</p>\n\n<ul>\n<li>Start your tasks on public nodes (by setting acceptedResourceRoles\": [\"slave_public\"])</li>\n<li>Add an Edge Router making the tasks running on private slaves available to the outside.</li>\n</ul>\n\n<p>For more details check <a href=\"https://docs.mesosphere.com/tutorials/publicapp/\" rel=\"nofollow\">the above link</a>.</p>\n", "answer_id": 32569627, "last_activity_date": 1442249147, "creation_date": 1442248364, "score": 2, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "last_edit_date": 1442249147, "question_id": 32568791}], "owner": {"user_id": 418293, "profile_image": "https://www.gravatar.com/avatar/27f9aaab969a228b72e0a42c01647e53?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 909, "link": "https://stackoverflow.com/users/418293/mathieu", "accept_rate": 55, "display_name": "mathieu"}, "view_count": 135, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32568791}{"is_answered": true, "tags": ["dcos"], "title": "dcos - kafka broker add - No such command &quot;add&quot;", "last_activity_date": 1461523207, "answer_count": 2, "creation_date": 1461245729, "score": 1, "link": "https://stackoverflow.com/questions/36771288/dcos-kafka-broker-add-no-such-command-add", "accepted_answer_id": 36790502, "owner": {"user_id": 203968, "profile_image": "https://www.gravatar.com/avatar/6997fba55dbbc76de7fb267b29e3bddd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 12012, "link": "https://stackoverflow.com/users/203968/oluies", "accept_rate": 91, "display_name": "oluies"}, "view_count": 232, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 36771288}{"body": "<p>I have HBase master and few region servers deployed on Mesos (as dockers).My Zookeeper is not managed by HBase.</p>\n\n<p>I would like to add backup master and I have started with this documentation\n<a href=\"http://hbase.apache.org/book.html#quickstart_fully_distributed\" rel=\"nofollow noreferrer\">http://hbase.apache.org/book.html#quickstart_fully_distributed</a></p>\n\n<p>Problem starts here...\n<em>Procedure: Configure Passwordless SSH Access</em></p>\n\n<p>Is there any way to skip step this and create backup master node, without generating and sharing key pairs, since I can't do that on current setup?</p>\n", "is_answered": false, "tags": ["hbase", "mesos", "mesosphere"], "title": "HBase multiple masters on Mesos", "last_activity_date": 1486644178, "answer_count": 0, "creation_date": 1486644178, "score": 0, "link": "https://stackoverflow.com/questions/42137057/hbase-multiple-masters-on-mesos", "owner": {"user_id": 3194326, "profile_image": "https://www.gravatar.com/avatar/33bffbf34d3822f0f44dd0a299a3fb9a?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/3194326/dino-l", "display_name": "Dino L."}, "view_count": 65, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42137057}{"body": "<p>I'm trying to setup a cluster using Mesos Zookeeper and Marathon. I've done some initial setup following the docs in each website.</p>\n\n<p>I'm using a virtual box which runs Ubuntu 16.0.4 to run the whole setup.</p>\n\n<p>Now I'm starting the mesos master with the following command :</p>\n\n<pre><code>./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos\n</code></pre>\n\n<p>Next I start the mesos agent in the same virtualbox with the below command :</p>\n\n<pre><code>./bin/mesos-agent.sh --master=127.0.0.1:5050 --work_dir=/var/lib/mesos\n</code></pre>\n\n<p>When I navigate to <code>localhost:5050</code> , I can see that Mesos has started with an agent registered as well.</p>\n\n<p>Now I ran Marathon with the below command :</p>\n\n<pre><code>./bin/start --master zk://127.0.0.1:2181/mesos --zk zk://localhost:2181/marathon\n</code></pre>\n\n<p>When I navigate to <code>localhost:8080</code> , I can find that Marathon is running. But it is not connected to Marathon yet. I searched thru some docs and found <a href=\"http://mesos.apache.org/documentation/latest/authentication/\" rel=\"nofollow noreferrer\">this</a> and did as it said.</p>\n\n<p>But still I don't see Marathon in the Frameworks tab in Mesos dashboard.</p>\n\n<p>If I try to start the basic Hello process in Marathon, it just goes to <code>Waiting</code> state. I found that this is due to Mesos not able to allocate resources for Marathon.</p>\n\n<p>I have not done any other configuration except for running <code>make install</code> in Mesos dir so that it has created the <code>libmesos.so</code>. I have added that file's path as a environment variable with the name <code>MESOS_NATIVE_LIBRARY</code></p>\n\n<p>Please tell me if there is anything else that I need to do. I'm just trying out the cluster and am not setting it up for production yet.</p>\n\n<p><strong>All the logs :</strong>\n<a href=\"https://plnkr.co/edit/Ja5g8zZjzdIW0uTH0htG\" rel=\"nofollow noreferrer\">https://plnkr.co/edit/Ja5g8zZjzdIW0uTH0htG</a></p>\n", "is_answered": false, "tags": ["ubuntu", "mesos", "marathon", "mesosphere"], "last_edit_date": 1483974215, "title": "Marathon does not register with Mesos", "last_activity_date": 1483974215, "answer_count": 0, "creation_date": 1483955624, "score": 0, "link": "https://stackoverflow.com/questions/41545187/marathon-does-not-register-with-mesos", "owner": {"user_id": 4242499, "profile_image": "https://i.stack.imgur.com/rxvJy.png?s=128&g=1", "user_type": "registered", "reputation": 855, "link": "https://stackoverflow.com/users/4242499/v1shnu", "accept_rate": 53, "display_name": "v1shnu"}, "view_count": 188, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41545187}{"is_answered": false, "tags": ["amazon-ec2", "docker", "mesosphere", "flannel"], "last_edit_date": 1495535285, "title": "AWS Mesosphere: parameters for docker daemon", "last_activity_date": 1443662515, "answer_count": 0, "creation_date": 1443662515, "score": 1, "link": "https://stackoverflow.com/questions/32878052/aws-mesosphere-parameters-for-docker-daemon", "owner": {"user_id": 2621528, "profile_image": "https://www.gravatar.com/avatar/1d80900651d0fe9d18bf336508732487?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 48, "link": "https://stackoverflow.com/users/2621528/g-rodriguez", "display_name": "G Rodriguez"}, "view_count": 160, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 32878052}{"is_answered": true, "tags": ["tomcat", "docker", "mesos", "mesosphere", "marathon"], "title": "docker mesosphere marathon - unable to see running process inside a docker container", "last_activity_date": 1423493287, "answer_count": 1, "creation_date": 1423490107, "score": 0, "link": "https://stackoverflow.com/questions/28411365/docker-mesosphere-marathon-unable-to-see-running-process-inside-a-docker-conta", "accepted_answer_id": 28412456, "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 740, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 28411365}{"body": "<p>Is this a regEx? </p>\n\n<p>As per <a href=\"http://mesos.apache.org/documentation/latest/attributes-resources/\" rel=\"nofollow noreferrer\">Mesos' documentation</a>:</p>\n\n<pre><code>scalar : floatValue\n\nfloatValue : ( intValue ( \".\" intValue )? ) | ...\n</code></pre>\n\n<p>Would I read it the same way as I'd read the scalar via the <a href=\"http://mesos.apache.org/documentation/latest/attributes-resources/\" rel=\"nofollow noreferrer\">documentation</a>?</p>\n\n<p>I'm trying to figure out how to add attribute to Mesos Cluster nodes, but the sample Heat Template I have has nothing to the tune of 'node attributes' in it, and I'm kind of shooting for the moon here.</p>\n\n<p>As It goes into a HEAT template, would each attribute for a specific node be added into the preferences section? I have been trying to find this answer for days now, and all my attempts seem to fail when I deploy the template.</p>\n\n<p>I have tried adding an attributes section, to no avail:</p>\n\n<pre><code>parameters:\n\n  name:\n    type: string\n\nresources:\n\n  # Boot script\n  boot_script:\n    etc, etc...\n\nattributes:\n  server_group:\n    group_1\n</code></pre>\n", "is_answered": true, "title": "Would ( intValue ( \".\" intValue )? ) be read as 1.9 ?? Also, how to add attribute to Heat Template", "last_edit_date": 1497417224, "tags": ["mesos", "mesosphere", "heat", "openstack-heat"], "view_count": 21, "accepted_answer_id": 44545092, "last_activity_date": 1497537089, "answers": [{"body": "<blockquote>\n  <p>Would ( intValue ( \u201c.\u201d intValue )? ) be read as 1.9 ?</p>\n</blockquote>\n\n<p><strong>Yes</strong></p>\n\n<p>This definition is a <a href=\"https://en.wikipedia.org/wiki/Formal_grammar\" rel=\"nofollow noreferrer\">formal grammar definiton</a> of a scalar value. You can find similar definition for programming lanugage for example <a href=\"https://github.com/antlr/grammars-v4/blob/1f7290565c5cc14970edeba8385e34886eea432c/golang/Golang.g4#L822-L847\" rel=\"nofollow noreferrer\">Golang looks like this (from antlr-4 examples)</a></p>\n\n<p>To read grammar this you need to take a look at whole definition</p>\n\n<pre><code>scalar : floatValue\n\nfloatValue : ( intValue ( \".\" intValue )? ) | ...\n\nintValue : [0-9]+\n</code></pre>\n\n<p>and flatten it to following regexp (I do not know what <code>...</code> means):</p>\n\n<pre><code>scalar : [0-9]+(.[0-9]+)?\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/wuBrr.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/wuBrr.png\" alt=\"regexp\"></a> <a href=\"https://regexper.com/#%5B0-9%5D%2B(%5C.%5B0-9%5D%2B)%3F\" rel=\"nofollow noreferrer\">source</a> </p>\n\n<blockquote>\n  <p>How to add attribute to Heat Template</p>\n</blockquote>\n\n<p>Not enoutght information to answer this.</p>\n", "answer_id": 44545092, "last_activity_date": 1497537089, "creation_date": 1497444020, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "last_edit_date": 1497537089, "question_id": 44525030}], "score": 0, "link": "https://stackoverflow.com/questions/44525030/would-intvalue-intvalue-be-read-as-1-9-also-how-to-add-attribut", "answer_count": 1, "owner": {"user_id": 4660085, "profile_image": "https://lh6.googleusercontent.com/-ow1h4mC7gb4/AAAAAAAAAAI/AAAAAAAAB4s/pVxhd8v3YrA/photo.jpg?sz=128", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/4660085/conedmiro", "accept_rate": 73, "display_name": "conedmiro"}, "creation_date": 1497365797, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44525030}{"body": "<p>I have a Kafka cluster running on Mesos. I'm trying to increase number of partitions on a topic. That usually works with <strong>bin/kafka-topics.sh --alter</strong> command. Is this option exposed via dcos cli or kafka-mesos rest API? From what I see its not exposed.</p>\n\n<p>If not, what is the best way to access kafka's cli within mesos installation?\nRight now I use dcos cli to get broker IP and then in an adhoc way get to </p>\n\n<pre><code>/var/lib/mesos/slave/slaves/11aaafce-f12f-4aa8-9e5c-200b2a657225-S3/frameworks/11aaafce-f12f-4aa8-9e5c-200b2a657225-0001/executors/broker-1-7cf26bed-aa40-464b-b146-49b45b7800c7/runs/849ba6fb-b99e-4194-b90b-8c9b2bfabd7c/kafka_2.10-0.9.0.0/bin/kafka-console-consumer.sh\n</code></pre>\n\n<p>Is there a more direct way?</p>\n", "is_answered": false, "tags": ["apache-kafka", "mesos", "mesosphere", "dcos"], "last_edit_date": 1460754116, "title": "DCOS/Mesos Kafka command to increase partition", "last_activity_date": 1461618931, "answer_count": 1, "creation_date": 1460753538, "score": 1, "link": "https://stackoverflow.com/questions/36656615/dcos-mesos-kafka-command-to-increase-partition", "answers": [{"body": "<p>We've just released a new version of the Kafka framework with DC/OS 1.7. The new version supports changing the partition count via <code>dcos kafka [--name=frameworkname] topic partitions &lt;topicname&gt; &lt;count&gt;</code>.</p>\n\n<p>See also: <a href=\"https://docs.mesosphere.com/kafka-1-7/\" rel=\"nofollow\">Service documentation</a> (\"Alter Topic Partition Count\" reference)</p>\n", "answer_id": 36851207, "last_activity_date": 1461618931, "creation_date": 1461618931, "score": 0, "owner": {"user_id": 6252585, "profile_image": "https://www.gravatar.com/avatar/7d417ac7bcd1caca822d4704f4e6b380?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/6252585/nickbp", "display_name": "nickbp"}, "is_accepted": false, "question_id": 36656615}], "owner": {"user_id": 3349257, "profile_image": "https://www.gravatar.com/avatar/f37b803a3616d628a6ec3ff4e646cf70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 287, "link": "https://stackoverflow.com/users/3349257/cheeko", "accept_rate": 78, "display_name": "Cheeko"}, "view_count": 167, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36656615}{"body": "<p>Is there a way to automate the provisioning of open stack VM for Docker Containers? For example I have 3 mesos slaves running on 3 open stack vms and now there are no more VM's left. My next docker containers is waiting to be run and I want open stack to know that my docker container needs a VM and it should automatically instantiate a VM. How to go about it? What open source technologies are available to make this work?</p>\n", "is_answered": true, "title": "Automatic provisioning of Open stack VM for Docker containers", "tags": ["docker", "openstack", "mesos", "mesosphere"], "last_activity_date": 1426695974, "accepted_answer_id": 29127435, "creation_date": 1423550873, "answers": [{"body": "<p>As Adam points out this is out of band of Mesos and would require some coding / scripting on your part.   You could however use the mesos-master REST API to determine capacity of the cluster.  {mesos-master ip}:5050/master/stats.json or {mesos-master ip}:5050/system/stats.json should provide good information </p>\n\n<p>Based on values there, you could automate <a href=\"https://www.openstack.org/\" rel=\"nofollow\">OpenStack</a>.  </p>\n", "answer_id": 29127435, "last_activity_date": 1426695974, "creation_date": 1426695974, "score": 0, "owner": {"user_id": 1375187, "profile_image": "https://www.gravatar.com/avatar/54ce5c4133119bd3791bd23f2cc2f582?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 219, "link": "https://stackoverflow.com/users/1375187/ken", "display_name": "Ken"}, "is_accepted": true, "question_id": 28425706}], "score": 0, "link": "https://stackoverflow.com/questions/28425706/automatic-provisioning-of-open-stack-vm-for-docker-containers", "answer_count": 1, "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 285, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28425706}{"body": "<p>What if I run a Mesos cluster, with both development and say, mission critical applications. Is it possible to have \"privileged\" task to be executed in the cluster for these type of cases, and even have nodes shut down lesser privileged services to make sure the privileged service gets processing power?</p>\n", "is_answered": true, "title": "Ensuring SLA with Mesos and privileged tasks", "tags": ["mesos", "mesosphere"], "last_activity_date": 1444262899, "accepted_answer_id": 33004486, "creation_date": 1444153800, "answers": [{"body": "<p>Currently, there is no notion of privileged tasks in Mesos (<code>0.24.1</code> at the time of writing). <em>Preemption</em> is likely an upcoming feature to be introduced to support other features such as <em>Quota</em> and <em>Optimistic Offers</em>. However, there are <strong>reserved resources</strong> in which critical tasks can run on.</p>\n\n<p>Resources can be reserved for a <strong>role</strong>, and frameworks are registered under a certain role. For example, if a framework <code>F</code> registers under role <code>R</code>, <code>F</code> receives resources with role <code>*</code> (i.e. unreserved) as well as resources with role <code>R</code> (i.e. reserved for <code>R</code>).</p>\n\n<p>The privileged tasks then would be launched on these reserved resources. Since reserved resources are only offered to the frameworks in the role, the resources will be available for the relaunch of the critical task even if the critical task were to crash.</p>\n\n<p><strong>NOTE:</strong> Since many frameworks can register under <code>R</code>, you can assign <code>R</code> uniquely to <code>F</code> to grant it sole ownership of the resources (Refer to <code>register_frameworks</code> under <a href=\"http://mesos.apache.org/documentation/latest/authorization/\" rel=\"nofollow\">Authorization</a>).</p>\n\n<p>Refer to <a href=\"http://mesos.apache.org/documentation/latest/reservation/\" rel=\"nofollow\">Reservation</a> documentation for further information</p>\n", "answer_id": 33004486, "last_activity_date": 1444262899, "creation_date": 1444262899, "score": 1, "owner": {"user_id": 2968284, "profile_image": "https://www.gravatar.com/avatar/2ab9cab3a7cf782261c583c1f48a81b0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3899, "link": "https://stackoverflow.com/users/2968284/mpark", "display_name": "mpark"}, "is_accepted": true, "question_id": 32976369}], "score": 0, "link": "https://stackoverflow.com/questions/32976369/ensuring-sla-with-mesos-and-privileged-tasks", "answer_count": 1, "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 65, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32976369}{"is_answered": false, "tags": ["dcos"], "title": "Why dcos can not create pods?", "last_activity_date": 1493203966, "answer_count": 0, "creation_date": 1493203966, "score": 1, "link": "https://stackoverflow.com/questions/43632115/why-dcos-can-not-create-pods", "owner": {"user_id": 1487402, "profile_image": "https://www.gravatar.com/avatar/c385f83daf9287c516d8c090abb779cb?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/1487402/song", "display_name": "song"}, "view_count": 33, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 43632115}{"is_answered": true, "tags": ["mesos", "mesosphere", "prometheus"], "last_edit_date": 1439454198, "title": "Configuring prometheus mesos-exporter running on mesosphere DCOS", "last_activity_date": 1439535761, "answer_count": 2, "creation_date": 1439190306, "score": 1, "link": "https://stackoverflow.com/questions/31913461/configuring-prometheus-mesos-exporter-running-on-mesosphere-dcos", "accepted_answer_id": 32004131, "owner": {"user_id": 5188802, "profile_image": "https://www.gravatar.com/avatar/96fdffb493ccaef2a9b3bb57a332ffe1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5188802/rajasi-kulkarni", "accept_rate": 100, "display_name": "Rajasi Kulkarni"}, "view_count": 990, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 31913461}{"body": "<p>I have successfully created host and bridge mode marathon apps without issue, and used l4lb and marathon-lb to host them. That all works without a problem.</p>\n\n<p>I'm now trying to use USER mode networking, using the default \"dcos\" 9.0.0.0/8 network. In this mode my apps can only talk to other containers on the same agent. The host OS's can only talk to containers hosted on themselves. It appears that nodes can't route traffic between each other on the virtual network.</p>\n\n<p>For testing I'm using the docker \"nginx:alpine\" container, with 2 instances, on different hosts. Their IPs are 9.0.6.130 and 9.0.3.130. No L4LB or Marathon-LB config, no service endpoints, no ports exposed on the host network. Basically:</p>\n\n<pre><code>\"container\": {\n    \"docker\": {\n      \"image\": \"nginx:alpine\",\n      \"forcePullImage\": false,\n      \"privileged\": false,\n      \"network\": \"USER\"\n    }\n  },\n  \"labels\": null,\n  \"ipAddress\": {\n    \"networkName\": \"dcos\"\n  },\n}\n</code></pre>\n\n<p>in a shell in one of them, I have:</p>\n\n<pre><code>/ # ip addr list | grep 'inet 9'\ninet 9.0.6.130/25 scope global eth0\n\n/ # nc -vz 9.0.6.130:80\n9.0.6.130:80 (9.0.6.130:80) open\n\n/ # nc -vz 9.0.3.130:80\nnc: 9.0.3.130:80 (9.0.3.130:80): Operation timed out\n\n/ # traceroute to 9.0.3.130 (9.0.3.130), 30 hops max, 46 byte packets\ntraceroute to 9.0.3.130 (9.0.3.130), 30 hops max, 46 byte packets\n 1  9.0.6.129 (9.0.6.129)  0.006 ms  0.002 ms  0.001 ms\n 2  44.128.0.4 (44.128.0.4)  0.287 ms  0.272 ms  0.100 ms\n 3  *  *  *\n 4  *  *  *\n</code></pre>\n\n<p>From the other side:</p>\n\n<pre><code>/ # ip addr list | grep 'inet 9'\ninet 9.0.3.130/25 scope global eth0\n/ # nc -vz 9.0.3.130:80\n9.0.3.130:80 (9.0.3.130:80) open\n/ # nc -vz 9.0.6.130:80\n/ # traceroute 9.0.6.130\ntraceroute to 9.0.6.130 (9.0.6.130), 30 hops max, 46 byte packets\n 1  9.0.3.129 (9.0.3.129)  0.005 ms  0.003 ms  0.001 ms\n 2  44.128.0.7 (44.128.0.7)  0.299 ms  0.241 ms  0.098 ms\n 3  *  *  *\n 4  *  *  *\n</code></pre>\n\n<p>Interestingly, I can ping what I think should be the next (virtual) hop, and all intermediate hops, despite traceroute not showing it. The only thing that doesn't ping is the end container's virtual IP. (These are from within one of the containers)</p>\n\n<pre><code>64 bytes from 44.128.0.7: seq=0 ttl=63 time=0.269 ms\n64 bytes from 44.128.0.4: seq=0 ttl=64 time=0.094 ms\n64 bytes from 9.0.3.129: seq=0 ttl=64 time=0.072 ms\n64 bytes from 9.0.6.129: seq=0 ttl=63 time=0.399 ms\nPING 9.0.6.130 (9.0.6.130): 56 data bytes (no response)\n</code></pre>\n\n<p>Any ideas?</p>\n", "is_answered": true, "title": "DC/OS virtual network doesn't work across agents", "tags": ["dcos"], "last_activity_date": 1487986169, "accepted_answer_id": 42450895, "creation_date": 1486676107, "answers": [{"body": "<p>Figured this out with help from the DC/OS community mailing list.</p>\n\n<p>RHEL7 installs firewalld by default, which DC/OS needs disabled. I had done that, but that still leaves the FORWARD policy as DROP until the node is rebooted. DC/OS's firewall manipulation only changes the rules, not the default policy.</p>\n\n<p>This fixes it:</p>\n\n<pre><code>iptables -P FORWARD ACCEPT\n</code></pre>\n\n<p>That's the default on reboot anyway unless specified somewhere (like firewalld), so it should persist across reboots without any further action.</p>\n", "answer_id": 42450895, "last_activity_date": 1487986169, "creation_date": 1487986169, "score": 0, "owner": {"user_id": 3670017, "profile_image": "https://www.gravatar.com/avatar/ee001234e7b17102bdd94e73e5b98ac7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 111, "link": "https://stackoverflow.com/users/3670017/jakem", "display_name": "jakem"}, "is_accepted": true, "question_id": 42147318}], "score": 1, "link": "https://stackoverflow.com/questions/42147318/dc-os-virtual-network-doesnt-work-across-agents", "answer_count": 1, "owner": {"user_id": 3670017, "profile_image": "https://www.gravatar.com/avatar/ee001234e7b17102bdd94e73e5b98ac7?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 111, "link": "https://stackoverflow.com/users/3670017/jakem", "display_name": "jakem"}, "view_count": 58, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42147318}{"body": "<p>I am running a mesos cluster with 3 mesos masters. I have enable authentication and saved a credentials.json file in one of the master. I would like to know if we have to put this file in all 3 mesos masters? Same applies to other files like acls.json and other parameter files. </p>\n", "is_answered": true, "title": "Do we need to have configuration files in all mesos masters?", "tags": ["bigdata", "cluster-computing", "mesos", "mesosphere"], "last_activity_date": 1485510770, "accepted_answer_id": 41891109, "creation_date": 1485457742, "answers": [{"body": "<p>Yes you have to copy your config files to all masters in the cluster.</p>\n\n<p>Mesos masters do not exchange this configuration information, nor it is persisted across failover. If a currently leading master fails over to another one, you probably want the new leader have the same configuration around authentication and authorization.</p>\n", "answer_id": 41891109, "last_activity_date": 1485510770, "creation_date": 1485510770, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": true, "question_id": 41881081}], "score": 0, "link": "https://stackoverflow.com/questions/41881081/do-we-need-to-have-configuration-files-in-all-mesos-masters", "answer_count": 1, "owner": {"user_id": 5003970, "profile_image": "https://www.gravatar.com/avatar/f644389a1ef05582c6b26343c2aa48f8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/5003970/midhun-mathew-sunny", "accept_rate": 65, "display_name": "Midhun Mathew Sunny"}, "view_count": 27, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41881081}{"body": "<p>I have a dcos cluster that is running a website. The website runs on 20 docker instances. When I'm looking at my application I see that I have 24 instances. Where 2 instances have status started but <strong>health unknown</strong> and 2 have status <strong>staged</strong>. The old instance where from a previous deploy\nI tried the follow things: </p>\n\n<ul>\n<li>destroy the application (result: Error destroying /azure-tracking-api: Futures timed out after [10000 milliseconds])</li>\n<li>kill all instances (result: they all restart )</li>\n</ul>\n\n<p>In the log I don't see any major errors  except </p>\n\n<p><em>Cannot kill task azure-tracking-api.908a6c3e-8948-11e6-be5a-7e591cfeda59 of framework 517c75b9-0a13-4b3b-a29d-8d754239991b-0000 (marathon) at scheduler-93d96b66-c66e-4d28-b56e-8b2b2b959bf8@172.16.0.7:42546 because it is unknown; performing reconciliation</em></p>\n\n<p>The version that I use is 0.28.1</p>\n\n<p>My question is can I fix this with a couple of commands. The only way that I know how to fix this is to setup a new cluster.</p>\n", "is_answered": true, "title": "Mesos marathon cannot destroy job", "tags": ["mesos", "marathon", "dcos"], "last_activity_date": 1475587272, "accepted_answer_id": 39853483, "creation_date": 1475508357, "answers": [{"body": "<p>The Marathon version you're using (1.1.2) has known <a href=\"https://github.com/mesosphere/marathon/issues/4039\" rel=\"nofollow\">issues</a> with lost tasks. Once DC/OS 1.8 is available on Azure the best option is to upgrade. As a workaround, for now, you can manually delete a task using Marathon's <a href=\"https://mesosphere.github.io/marathon/docs/generated/api.html#v2_apps__app_id__tasks__task_id__delete\" rel=\"nofollow\">HTTP API</a>:</p>\n\n<pre><code>$ curl -X DELETE $MARATHON_URL/v2/apps/azure-tracking-api/tasks/$TASKID?force=true\n</code></pre>\n", "answer_id": 39853483, "last_activity_date": 1475587272, "creation_date": 1475587272, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 39835130}], "score": 2, "link": "https://stackoverflow.com/questions/39835130/mesos-marathon-cannot-destroy-job", "answer_count": 1, "owner": {"user_id": 535200, "profile_image": "https://www.gravatar.com/avatar/74f68483e68c99d573dead52d99de6d1?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 299, "link": "https://stackoverflow.com/users/535200/geoffrey-samper", "accept_rate": 50, "display_name": "Geoffrey Samper"}, "view_count": 451, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39835130}{"body": "<p>Trying to spin up a docker container using marathon.\nI am  using <code>docker 1.8</code>, <code>marathon 0.11</code>, <code>mesos 0.23</code>, <code>boot2docker</code></p>\n\n<p>Here are how my docker images look like and how they are run</p>\n\n<blockquote>\n  <blockquote>\n    <p><a href=\"https://gist.github.com/manishrajkarnikar/3dad3cfb149384d080aa\" rel=\"nofollow\">https://gist.github.com/manishrajkarnikar/3dad3cfb149384d080aa</a></p>\n  </blockquote>\n</blockquote>\n\n<p>Here is how my marathon post request look like and the logs from mess master and slave </p>\n\n<blockquote>\n  <blockquote>\n    <p><a href=\"https://gist.github.com/manishrajkarnikar/96d2031e621201d94f7f\" rel=\"nofollow\">https://gist.github.com/manishrajkarnikar/96d2031e621201d94f7f</a></p>\n  </blockquote>\n</blockquote>\n\n<p><strong>Note</strong> that in the containers started have \"executer\"  at the end of container name, while mess-slave info log put this warning where it  looks like its searching for container without executor at the end of container name and docker inspect is failing causing status of task failed</p>\n\n<pre><code>Failed to get resource statistics for executor 'helloworld.ed922c9d-6ed4-11e5-a8fb-aa13c24df26f' of framework 20151009-222455-1731963072-5050-5-0000: Failed to 'docker inspect mesos-20151009-222455-1731963072-5050-5-S0.79b421f0-2135-437c-b4be-c95dd841ba9a': exit status = exited with status 1 stderr = Error: No such image or container: mesos-20151009-222455-1731963072-5050-5-S0.79b421f0-2135-437c-b4be-c95dd841ba9a\n</code></pre>\n\n<p>This is causing multiple failed containers and all the tasks are getting status of task_failed</p>\n\n<p>What am I doing wrong??</p>\n", "is_answered": true, "tags": ["docker", "boot2docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1444854216, "title": "Marathon not loading docker container: Failed to get resource statistics for executor", "last_activity_date": 1444854216, "answer_count": 1, "creation_date": 1444449607, "score": 2, "link": "https://stackoverflow.com/questions/33050112/marathon-not-loading-docker-container-failed-to-get-resource-statistics-for-exe", "answers": [{"body": "<p>I would have to double check whether this is the exact issue.\nBut Docker version 1.8 changed the version output (see <a href=\"https://issues.apache.org/jira/browse/MESOS-2986\" rel=\"nofollow\">MESOS-2986</a>) which was fixed in <a href=\"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12311242&amp;version=12333553\" rel=\"nofollow\">MESOS 0.23.1</a>. \nCould you check whether 0.23.1 solves that problem?</p>\n\n<p>Thanks!</p>\n", "answer_id": 33097412, "last_activity_date": 1444723851, "creation_date": 1444723851, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 33050112}], "owner": {"user_id": 3783981, "profile_image": "https://www.gravatar.com/avatar/9c41caff34ad10fa5b5ddd0182e633eb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 45, "link": "https://stackoverflow.com/users/3783981/manish-rajkarnikar", "display_name": "manish.rajkarnikar"}, "view_count": 772, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 33050112}{"body": "<p>I installed Mesos in an OpenStack environment using these instructions from Mesosphere: <a href=\"https://open.mesosphere.com/getting-started/datacenter/install/\">https://open.mesosphere.com/getting-started/datacenter/install/</a>.  I ran the verification test as described and it was successful.  UI for both Mesos and Marathon are working as expected.</p>\n\n<p>When I run the Spark shell from my laptop I cannot connect.  The shell hangs with the output below.  I don't see anything in the Mesos master or slave logs that would indicate an error, so am not sure what to investigate next.</p>\n\n<p>Any help would be appreciated.</p>\n\n<pre><code>TOMWATER-M-60SN:bin tomwater$ ./spark-shell --master mesos://zk://10.93.193.78:2181,10.93.193.79:2181,10.93.193.80:2181/mesos\nlog4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n15/08/06 15:39:02 INFO SecurityManager: Changing view acls to: tomwater\n15/08/06 15:39:02 INFO SecurityManager: Changing modify acls to: tomwater\n15/08/06 15:39:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(tomwater); users with modify permissions: Set(tomwater)\n15/08/06 15:39:02 INFO HttpServer: Starting HTTP Server\n15/08/06 15:39:02 INFO Utils: Successfully started service 'HTTP class server' on port 63056.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.4.1\n      /_/\n\nUsing Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_51)\nType in expressions to have them evaluated.\nType :help for more information.\n15/08/06 15:39:05 INFO SparkContext: Running Spark version 1.4.1\n15/08/06 15:39:05 INFO SecurityManager: Changing view acls to: tomwater\n15/08/06 15:39:05 INFO SecurityManager: Changing modify acls to: tomwater\n15/08/06 15:39:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(tomwater); users with modify permissions: Set(tomwater)\n15/08/06 15:39:05 INFO Slf4jLogger: Slf4jLogger started\n15/08/06 15:39:05 INFO Remoting: Starting remoting\n15/08/06 15:39:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.93.235.120:63057]\n15/08/06 15:39:05 INFO Utils: Successfully started service 'sparkDriver' on port 63057.\n15/08/06 15:39:05 INFO SparkEnv: Registering MapOutputTracker\n15/08/06 15:39:05 INFO SparkEnv: Registering BlockManagerMaster\n15/08/06 15:39:05 INFO DiskBlockManager: Created local directory at /private/var/folders/7g/p1nw5zg94yx5cck_6c4jgwh80000gp/T/spark-74145a91-396f-4989-b2c0-5902e32e9e16/blockmgr-511d3fdf-f84a-40dc-b6e5-daace4d3f786\n15/08/06 15:39:05 INFO MemoryStore: MemoryStore started with capacity 265.1 MB\n15/08/06 15:39:05 INFO HttpFileServer: HTTP File server directory is /private/var/folders/7g/p1nw5zg94yx5cck_6c4jgwh80000gp/T/spark-74145a91-396f-4989-b2c0-5902e32e9e16/httpd-4ce76073-5636-4656-9fba-633fbc1c16f4\n15/08/06 15:39:05 INFO HttpServer: Starting HTTP Server\n15/08/06 15:39:05 INFO Utils: Successfully started service 'HTTP file server' on port 63058.\n15/08/06 15:39:05 INFO SparkEnv: Registering OutputCommitCoordinator\n15/08/06 15:39:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n15/08/06 15:39:05 INFO SparkUI: Started SparkUI at http://10.93.235.120:4040\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@712: Client environment:zookeeper.version=zookeeper C client 3.4.5\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@716: Client environment:host.name=TOMWATER-M-60SN\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@723: Client environment:os.name=Darwin\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@724: Client environment:os.arch=14.4.0\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@725: Client environment:os.version=Darwin Kernel Version 14.4.0: Thu May 28 11:35:04 PDT 2015; root:xnu-2782.30.5~1/RELEASE_X86_64\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@733: Client environment:user.name=tomwater\nI0806 15:39:06.235976 547205120 sched.cpp:157] Version: 0.23.0\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@741: Client environment:user.home=/Users/tomwater\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@log_env@753: Client environment:user.dir=/Users/tomwater/development/tools/spark-1.4.1-bin-hadoop2.6/bin\n2015-08-06 15:39:06,236:30782(0x1210e7000):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=10.93.193.78:2181,10.93.193.79:2181,10.93.193.80:2181 sessionTimeout=10000 watcher=0x11eca0d00 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f8f7cffbaf0 flags=0\n2015-08-06 15:39:06,333:30782(0x12147c000):ZOO_INFO@check_events@1703: initiated connection to server [10.93.193.78:2181]\n2015-08-06 15:39:06,705:30782(0x12147c000):ZOO_INFO@check_events@1750: session establishment complete on server [10.93.193.78:2181], sessionId=0x14f0502209a0006, negotiated timeout=10000\nI0806 15:39:06.707475 544960512 group.cpp:313] Group process (group(1)@10.93.235.120:63059) connected to ZooKeeper\nI0806 15:39:06.707785 544960512 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0806 15:39:06.707952 544960512 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI0806 15:39:06.712241 547741696 detector.cpp:138] Detected a new leader: (id='126')\nI0806 15:39:06.712530 555130880 group.cpp:656] Trying to get '/mesos/info_0000000126' in ZooKeeper\nW0806 15:39:06.714071 544960512 detector.cpp:444] Leading master master@192.168.1.69:5050 is using a Protobuf binary format when registering with ZooKeeper (info): this will be deprecated as of Mesos 0.24 (see MESOS-2340)\nI0806 15:39:06.714269 544960512 detector.cpp:481] A new leading master (UPID=master@192.168.1.69:5050) is detected\nI0806 15:39:06.714498 544960512 sched.cpp:254] New master detected at master@192.168.1.69:5050\nI0806 15:39:06.714643 544960512 sched.cpp:264] No credentials provided. Attempting to register without authentication\n</code></pre>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Spark shell connect to Mesos hangs: No credentials provided. Attempting to register without authentication", "last_activity_date": 1459522692, "answer_count": 1, "creation_date": 1438901921, "score": 8, "link": "https://stackoverflow.com/questions/31867136/spark-shell-connect-to-mesos-hangs-no-credentials-provided-attempting-to-regis", "answers": [{"body": "<p>I've just had this - obviously check that you can talk to the master mesos node (on port 5050 normally).  However you <em>also</em> need to allow the mesos master to talk <em>back</em> to your client (it's an emphemeral port annoyingly).</p>\n\n<p>If you strace it you can see what's going on.</p>\n\n<pre><code>strace -e trace=network -f -s 16384 -o /tmp/strace.log pyspark\n</code></pre>\n\n<p>Looking at the strace.log - first we ask for a random socket and listen on it:</p>\n\n<pre><code>28462 socket(PF_INET, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_IP) = 254\n28462 setsockopt(254, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0\n28462 bind(254, {sa_family=AF_INET, sin_port=htons(0), sin_addr=inet_addr(\"0.0.0.0\")}, 16) = 0\n28462 getsockname(254, {sa_family=AF_INET, sin_port=htons(46975), sin_addr=inet_addr(\"0.0.0.0\")}, [16]) = 0\n28462 listen(254, 500000)               = 0\n</code></pre>\n\n<p>Now's the interesting part - we talk to the mesos master (10.1.201.191:5050) and we tell it our IP and that port we opened (10.1.200.212:46975)</p>\n\n<p>It then talks back to us (the accept()):</p>\n\n<pre><code>28507 connect(258, {sa_family=AF_INET, sin_port=htons(5050), sin_addr=inet_addr(\"10.1.201.191\")}, 16) = -1 EINPROGRESS (Operation now in progress)\n28510 getsockopt(258, SOL_SOCKET, SO_ERROR, [0], [4]) = 0\n28510 sendto(258, \"POST /master/mesos.scheduler.Call HTTP/1.1\\r\\nUser-Agent: libprocess/scheduler-52db362e-d5dd-4109-97d3-e28e80f2391b@10.1.200.212:46975\\r\\nLibproce\nss-From: scheduler-52db362e-d5dd-4109-97d3-e28e80f2391b@10.1.200.212:46975\\r\\nConnection: Keep-Alive\\r\\nHost: \\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n54\\r\\n\\20\\1\\32P\\n\nN\\n\\6ubuntu\\22\\fPySparkShell:\\34ip-10-1-200-212.ec2.internalJ\\30http://10.1.200.212:4040\\r\\n0\\r\\n\\r\\n\", 375, MSG_NOSIGNAL, NULL, 0) = 375\n28510 accept(254, {sa_family=AF_INET, sin_port=htons(33743), sin_addr=inet_addr(\"10.1.201.191\")}, [16]) = 259\n</code></pre>\n", "answer_id": 36359492, "last_activity_date": 1459522692, "creation_date": 1459522443, "score": 2, "owner": {"user_id": 4693721, "profile_image": "https://lh4.googleusercontent.com/-zkL3Am2FbVo/AAAAAAAAAAI/AAAAAAAAAF4/KoWpn54YA2A/photo.jpg?sz=128", "user_type": "registered", "reputation": 61, "link": "https://stackoverflow.com/users/4693721/adrian-bridgett", "display_name": "Adrian Bridgett"}, "is_accepted": false, "last_edit_date": 1459522692, "question_id": 31867136}], "owner": {"user_id": 5200011, "profile_image": "https://www.gravatar.com/avatar/075cece225b7f82731b06ad594d29e8c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 41, "link": "https://stackoverflow.com/users/5200011/tww", "display_name": "tww"}, "view_count": 2043, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 31867136}{"body": "<p>HDFS is not necessary but recommendations appear in some places.</p>\n\n<p>To help evaluate the effort spent in getting HDFS running:</p>\n\n<p><strong>What are the benefits of using HDFS for Spark workloads?</strong> </p>\n", "is_answered": true, "tags": ["hadoop", "apache-spark", "hdfs", "mesos", "mesosphere"], "last_edit_date": 1452758068, "title": "Is HDFS necessary for Spark workloads?", "last_activity_date": 1481812836, "answer_count": 4, "creation_date": 1442671924, "score": 3, "link": "https://stackoverflow.com/questions/32669187/is-hdfs-necessary-for-spark-workloads", "answers": [{"body": "<p>So you could go with Cloudera or Hortenworks distro and load up an entire stack very easily. CDH will be used with YARN though I find it so much more difficult to configure mesos in CDH. Horten is much easier to customize.</p>\n\n<p>HDFS is great because of datanodes = data locality (process where the data is) as shuffling/data transfer is very expensive. HDFS also naturally blocks files which allows Spark to partition on the blocks. (128mb blocks, you can change this). </p>\n\n<p>You could use S3 and Redshift.</p>\n\n<p>See here:\n<a href=\"https://github.com/databricks/spark-redshift\" rel=\"nofollow\">https://github.com/databricks/spark-redshift</a></p>\n", "answer_id": 32670201, "last_activity_date": 1442680828, "creation_date": 1442678011, "score": -1, "owner": {"user_id": 4375248, "profile_image": "https://www.gravatar.com/avatar/a2f5a09b097029781ab2857e0d91be08?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 779, "link": "https://stackoverflow.com/users/4375248/themadking", "accept_rate": 69, "display_name": "theMadKing"}, "is_accepted": false, "last_edit_date": 1442680828, "question_id": 32669187}, {"body": "<p>HDFS (or any distributed Filesystems) makes distributing your data much simpler. Using a local filesystem you would have to partition/copy the data by hand to the individual nodes and be aware of the data distribution when running your jobs. In addition HDFS also handles failing nodes failures.\nFrom an integration between Spark and HDFS, you can imagine spark knowing about the data distribution so it will try to schedule tasks to the same nodes where the required data resides.</p>\n\n<p>Second: which problems did you face exactly with the instruction?</p>\n\n<p>BTW: if you are just looking for an easy setup on AWS, <a href=\"https://mesosphere.com/product/\" rel=\"nofollow\">DCOS</a> allows you to install HDFS with a single command...</p>\n", "answer_id": 32694578, "last_activity_date": 1442836457, "creation_date": 1442836457, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 32669187}, {"body": "<p>The shortest answer is:\"No, you don't need it\". You can analyse data even without HDFS, but off course you need to replicate the data on all your nodes.</p>\n\n<p>The long answer is quite counterintuitive and i'm still tryng to understand it with the help stackoverflow community.</p>\n\n<p><a href=\"https://stackoverflow.com/questions/34763437/spark-local-vs-hdfs-permormance\">Spark local vs hdfs permormance</a></p>\n", "answer_id": 34784217, "last_activity_date": 1452757986, "creation_date": 1452757986, "score": 0, "owner": {"user_id": 4779666, "profile_image": "https://www.gravatar.com/avatar/5a1e944a0c49fccb153e9da4f0d5bb13?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 163, "link": "https://stackoverflow.com/users/4779666/arj", "accept_rate": 55, "display_name": "arj"}, "is_accepted": false, "last_edit_date": 1495542632, "question_id": 32669187}, {"body": "<p><strong><em>Spark</em></strong> is a distributed processing engine and <strong><em>HDFS</em></strong> is a distributed storage system. </p>\n\n<p>If <strong>HDFS</strong> is not an option, then Spark has to use some other alternative in form of Apache Cassandra Or Amazon S3.</p>\n\n<p>Have a look at this <a href=\"http://blog.takipi.com/apache-spark-5-pitfalls-you-must-solve-before-changing-your-architecture/\" rel=\"nofollow noreferrer\">comparision</a></p>\n\n<p><strong>S3</strong> \u2013 Non urgent batch jobs. S3 fits very specific use cases, when data locality isn\u2019t critical.</p>\n\n<p><strong>Cassandra</strong> \u2013 Perfect for streaming data analysis and an overkill for batch jobs.</p>\n\n<p><strong>HDFS</strong> \u2013 Great fit for batch jobs without compromising on data locality. </p>\n\n<p><strong>When to use HDFS as storage engine for Spark distributed processing?</strong></p>\n\n<ol>\n<li><p>If you have big <strong>Hadoop cluster</strong> already in place and looking for real time analytics of your data, Spark can use existing Hadoop cluster.  It will reduce development time.</p></li>\n<li><p>Spark is in-memory computing engine. Since data can't fit into memory always, data has to be <strong>spilled to disk</strong> for some operations. Spark will benifit from HDFS in this case. <em>The Teragen sorting record achieved by Spark used HDFS storage for sorting operation.</em> </p></li>\n<li><p><strong>HDFS</strong> is scalable, reliable and fault tolerant distributed file system ( since Hadoop 2.x release). With data locality principle, processing speed is improved. </p></li>\n<li><p>Best for <strong>Batch-processing</strong> jobs. </p></li>\n</ol>\n", "answer_id": 34789554, "last_activity_date": 1481812836, "creation_date": 1452774286, "score": 2, "owner": {"user_id": 4999394, "profile_image": "https://i.stack.imgur.com/nAGmt.png?s=128&g=1", "user_type": "registered", "reputation": 19622, "link": "https://stackoverflow.com/users/4999394/ravindra-babu", "accept_rate": 100, "display_name": "Ravindra babu"}, "is_accepted": false, "last_edit_date": 1481812836, "question_id": 32669187}], "owner": {"user_id": 417896, "profile_image": "https://i.stack.imgur.com/ujjJo.jpg?s=128&g=1", "user_type": "registered", "reputation": 5070, "link": "https://stackoverflow.com/users/417896/bar", "accept_rate": 72, "display_name": "BAR"}, "view_count": 1081, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 32669187}{"body": "<p>I'm benchmarking a tool that monitors docker containers. To do that I need to launch several dummy containers with an orchestration tool such Kubernetes. The containers should be lightweight and shouldn't take any of the machine resources (e.g. ports), since the idea is to run 15 or more of these dummy containers in each machine of a cluster. I don't care about what the container does as long as it keeps running as a daemon and I can monitor it for a long period of time.</p>\n\n<p>Is there any Docker image that meets these requirements and that I can use straight out of the box?. </p>\n", "is_answered": true, "title": "dummy docker container for benchmarking", "last_edit_date": 1504018808, "tags": ["docker", "kubernetes", "dcos"], "view_count": 24, "accepted_answer_id": 45942480, "last_activity_date": 1504018969, "answers": [{"body": "<p>You can just run an alpine container with a sleep command.</p>\n\n<p>Something like this:</p>\n\n<p><code>docker run -d alpine sh -c 'while sleep 3600; do :; done'</code></p>\n", "answer_id": 45942480, "last_activity_date": 1504018969, "creation_date": 1504018969, "score": 3, "owner": {"user_id": 6156340, "profile_image": "https://lh5.googleusercontent.com/-hQfBBXrnbpI/AAAAAAAAAAI/AAAAAAAABP4/BK5aW9CX7S4/photo.jpg?sz=128", "user_type": "registered", "reputation": 694, "link": "https://stackoverflow.com/users/6156340/wassim-dhif", "display_name": "Wassim Dhif"}, "is_accepted": true, "question_id": 45942277}], "score": 2, "link": "https://stackoverflow.com/questions/45942277/dummy-docker-container-for-benchmarking", "answer_count": 1, "owner": {"user_id": 1076540, "profile_image": "https://www.gravatar.com/avatar/9259c7987a33698c2a9354cae71d984c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 119, "link": "https://stackoverflow.com/users/1076540/brandon", "accept_rate": 67, "display_name": "Brandon"}, "creation_date": 1504018407, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45942277}{"body": "<p>I've been trying to configure Apache Ignite on DC/OS (1.8.7) marathon using the official docs at <a href=\"http://apacheignite.gridgain.org/docs/mesos-deployment\" rel=\"nofollow noreferrer\">http://apacheignite.gridgain.org/docs/mesos-deployment</a> but short of some hacks I haven't been able to get it to work following the docs. One of the core reasons appear to be that the cmd </p>\n\n<pre><code>\"cmd\": \"java -jar ignite-mesos-1.8.0.jar\"\n</code></pre>\n\n<p>will through an error \"sh: java: command not found\". This would indicate that java is not in the path but on the marathon hosts I've validated that java is in fact accessible on the path for my regular user at least.  </p>\n\n<p>I suspect that somehow java needs to be added to the path of mesos-container that is trying to run the cmd but I've been unable to find any documentation on how to set the path or default environment variables (ignite-mesos spawns tasks that need JAVA_HOME set as well, which is also missing in the tasks) in the containers that get created. For reference my marathon.json file is below...</p>\n\n<pre><code>{\n  \"id\": \"/ignition\",\n  \"cmd\": \"java -jar ignite-mesos-1.8.0.jar\",\n  \"args\": null,\n  \"user\": null,\n  \"env\": {\n    \"IGNITE_MEMORY_PER_NODE\": \"2048\",\n    \"IGNITE_NODE_COUNT\": \"3\",\n    \"IGNITE_VERSION\": \"1.8.0\",\n    \"MESOS_MASTER_URL\": \"zk://master.mesos:2181/mesos\",\n    \"IGNITE_RUN_CPU_PER_NODE\": \"0.1\"\n  },\n  \"instances\": 0,\n  \"cpus\": 0.25,\n  \"mem\": 2048,\n  \"disk\": 0,\n  \"gpus\": 0,\n  \"executor\": null,\n  \"constraints\": null,\n  \"fetch\": [\n    {\n      \"uri\": \"http://SERVER_HERE/ignite-mesos-1.8.0.jar\"\n    }\n  ],\n  \"storeUrls\": null,\n  \"backoffSeconds\": 1,\n  \"backoffFactor\": 1.15,\n  \"maxLaunchDelaySeconds\": 3600,\n  \"container\": null,\n  \"healthChecks\": null,\n  \"readinessChecks\": null,\n  \"dependencies\": null,\n  \"upgradeStrategy\": {\n    \"minimumHealthCapacity\": 1,\n    \"maximumOverCapacity\": 1\n  },\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"acceptedResourceRoles\": null,\n  \"ipAddress\": null,\n  \"residency\": null,\n  \"secrets\": null,\n  \"taskKillGracePeriodSeconds\": null,\n  \"portDefinitions\": [\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 10108\n    }\n  ],\n  \"requirePorts\": false\n}\n</code></pre>\n", "is_answered": true, "title": "Apache Ignite on on DC/OS marathon (or any other java app)", "tags": ["java", "mesos", "ignite", "marathon", "dcos"], "last_activity_date": 1484059950, "accepted_answer_id": 41571668, "creation_date": 1484009854, "answers": [{"body": "<p>Ignite seems to expect a JDK 1.7/1.8 installation on each agent node, and the <code>JAVA_HOME</code> environment variable set accordingly.</p>\n\n<p>Unfortunately, the Mesos framework doesn't seem to be well-maintained, as it still uses Mesos 0.22 libraries.</p>\n", "answer_id": 41571668, "last_activity_date": 1484059950, "creation_date": 1484059950, "score": 1, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 41559559}], "score": 0, "link": "https://stackoverflow.com/questions/41559559/apache-ignite-on-on-dc-os-marathon-or-any-other-java-app", "answer_count": 1, "owner": {"user_id": 1848507, "profile_image": "https://www.gravatar.com/avatar/3da09d331e55983b7a131a93cf565d54?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 70, "link": "https://stackoverflow.com/users/1848507/dance-machine", "display_name": "Dance machine"}, "view_count": 149, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41559559}{"body": "<p>I have three server A,B,C on each machine I'm running Chronos, ZooKeeper, mesos-master, mesos-slave. </p>\n\n<p>Chronos contact mesos-master using ZooKeeper url hence it automatically picks leading master even if some node is down. I'm having high availability here.</p>\n\n<p>Even Chronos run in cluster mode so accessing any of the Chronos I see same list of jobs and everything works fine.</p>\n\n<p>Problem I have here is, Chronos is accessible with any of the three URLs</p>\n\n<ul>\n<li><code>http://server_node_1:4400</code></li>\n<li><code>http://server_node_2:4400</code></li>\n<li><code>http://server_node_3:4400</code></li>\n</ul>\n\n<p>I have another application which schedules jobs in Chronos using Rest API. Which URL my application has to talk to in order in run in high availabiity mode?</p>\n\n<p>Let's say my application talks to <code>http://server_node_1:4400</code> for scheduling the job, if Chronos on node <code>server_node_1</code> is down I'm not able to schedule the Job.</p>\n\n<p>My application needs to talk to single URL in order to schedule job in Chronos. Even if some Chronos node is down, I should be able to schedule the job. Do I need to have some kind of load balancer between my application and Chronos cluster to pick running chronos node for job scheduling? How can I achieve high availability in my scenario?</p>\n", "is_answered": true, "title": "Chronos Cluster with High Availability", "last_edit_date": 1455976860, "tags": ["apache-zookeeper", "mesos", "mesosphere"], "view_count": 227, "accepted_answer_id": 35524264, "last_activity_date": 1455976860, "answers": [{"body": "<p>Use HAProxy for routing to a Chronos instance. This way you can access a Chronos instance using e.g. <code>curl loadbalancer:8081</code>.</p>\n\n<p><code>haproxy.cfg</code>:</p>\n\n<pre><code>listen chronos_8081\n  bind 0.0.0.0:8081\n  mode http\n  balance roundrobin\n  option  allbackups\n  option http-no-delay\n  server chronos01 server_node_1:4400\n  server chronos02 server_node_2:4400\n  server chronos03 server_node_3:4400\n</code></pre>\n\n<p>Or even better, start Chronos via Marathon, which will ensure given number of instances. Then HAProxy configuration could be generated by:</p>\n\n<ul>\n<li><a href=\"https://github.com/mesosphere/marathon-lb\" rel=\"nofollow\">marathon-lb</a></li>\n<li><a href=\"https://github.com/QubitProducts/bamboo\" rel=\"nofollow\">bamboo</a></li>\n</ul>\n", "answer_id": 35524264, "last_activity_date": 1455976662, "creation_date": 1455976662, "score": 0, "owner": {"user_id": 334831, "profile_image": "https://www.gravatar.com/avatar/bf2a7f4d71e1d892ce564fe4bd81193f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 14392, "link": "https://stackoverflow.com/users/334831/tombart", "accept_rate": 83, "display_name": "Tombart"}, "is_accepted": true, "question_id": 35524108}], "score": 1, "link": "https://stackoverflow.com/questions/35524108/chronos-cluster-with-high-availability", "answer_count": 1, "owner": {"user_id": 2621477, "profile_image": "https://www.gravatar.com/avatar/28f83b19d3586c0cbb02e08ff5f39d34?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 75, "link": "https://stackoverflow.com/users/2621477/chandu", "accept_rate": 70, "display_name": "chandu"}, "creation_date": 1455975900, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35524108}{"is_answered": true, "tags": ["vagrant", "virtualbox", "mesos", "dcos"], "title": "Error while installing DCOS &quot;vagrant up m1 a1 boot&quot;", "last_activity_date": 1475091715, "answer_count": 1, "creation_date": 1475087984, "score": 1, "link": "https://stackoverflow.com/questions/39755280/error-while-installing-dcos-vagrant-up-m1-a1-boot", "accepted_answer_id": 39756325, "owner": {"user_id": 4084039, "profile_image": "https://i.stack.imgur.com/I0Z2X.jpg?s=128&g=1", "user_type": "registered", "reputation": 65, "link": "https://stackoverflow.com/users/4084039/krishna", "display_name": "krishna"}, "view_count": 389, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 39755280}{"body": "<p>I was looking at Mesos + Marathon to manage Docker containers.</p>\n\n<p>What we're trying to achieve is a way of getting an external DNS entry (test.example.com) to point to a specific set of docker containers.\nThe DNS entry for test.example.com points to a load balancer which translate and send the connection to one of our backend servers app.</p>\n\n<p>To do this I looked into <strong>Mesos-dns</strong>. With mesos-dns I can get DNS name for each container and can resolve DNS with container IP but couldn't find out way to load balance between set of servers.</p>\n\n<p>Can someone confirm if Mesos-dns provides load balancing? If yes, how can I achieve load balancing with it?</p>\n\n<p>Do I need to use some other solutions like <strong>HAProxy</strong> or <strong>Bamboo</strong> to achieve this?</p>\n\n<p>Thanks!!</p>\n\n<p>Sumit</p>\n", "is_answered": true, "title": "Does Mesos-dns provides load balancing?", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1464075238, "accepted_answer_id": 37407117, "creation_date": 1464028118, "answers": [{"body": "<p>Yes with Mesos-DNS you can do load balancing, see for example the respective <a href=\"http://mesosphere.github.io/mesos-dns/docs/http.html\" rel=\"nofollow\">HTTP API</a> endpoints, but it's really <strong>not recommended</strong> in the context of DC/OS: see the internal (Minuteman) and external (Marathon-lb, HAProxy-based) load balancing and service discover options in the <a href=\"https://dcos.io/docs/1.7/usage/service-discovery/\" rel=\"nofollow\">docs</a>.</p>\n", "answer_id": 37407117, "last_activity_date": 1464075238, "creation_date": 1464075238, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 37398033}], "score": 1, "link": "https://stackoverflow.com/questions/37398033/does-mesos-dns-provides-load-balancing", "answer_count": 1, "owner": {"user_id": 4551655, "profile_image": "https://i.stack.imgur.com/5Vcos.jpg?s=128&g=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/4551655/sumit-nagariya", "display_name": "Sumit Nagariya"}, "view_count": 418, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37398033}{"body": "<p>In DCOS, I want to deploy a mesos container with a self-defined image which stored in a local secure docker registry, and it has been secured by CA (not username and password!)</p>\n\n<p>The json is </p>\n\n<p><code>{\n  \"id\": \"/gpu-tflinker\",\n  \"cmd\": \"while [ true ] ; do nvidia-smi; sleep 5; done\",\n  \"cpus\": 0.1,\n  \"mem\": 1024,\n  \"gpus\": 1,\n  \"instances\": 1,\n  \"constraints\": [\n    [\n      \"hostname\",\n      \"CLUSTER\",\n      \"10.140.0.22\"\n    ]\n  ],\n  \"container\": {\n    \"type\": \"MESOS\",\n    \"docker\": {\n      \"image\": \"tflinker:test-gpu\",\n      \"credential\": null\n    }\n  }\n}</code></p>\n\n<p>The above json failed to run on marathon, and there is no content on mesos's stderr and stdout file, on mesos-agent log, the error message is :</p>\n\n<pre><code>E0721 05:01:57.726367 22498 slave.cpp:3976] Container 'e2c68720-0fb7-41bc-9d3b-a2b5e4793816' for executor 'gpu-t\nflinker.b6f96725-6dd1-11e7-ba5d-0242b2c758c0' of framework 1079aaea-6dde-4dc1-8990-d926a895de78-0000 failed to s\ntart: Unexpected HTTP response '401 Unauthorized' when trying to get the manifest\nW0721 05:01:57.726478 22497 composing.cpp:541] Container 'e2c68720-0fb7-41bc-9d3b-a2b5e4793816' is already destr\noyed\nI0721 05:01:57.726583 22497 slave.cpp:4082] Executor 'gpu-tflinker.b6f96725-6dd1-11e7-ba5d-0242b2c758c0' of fram\nework 1079aaea-6dde-4dc1-8990-d926a895de78-0000 has terminated with unknown status\nI0721 05:01:57.726603 22497 slave.cpp:4193] Cleaning up executor 'gpu-tflinker.b6f96725-6dd1-11e7-ba5d-0242b2c75\n8c0' of framework 1079aaea-6dde-4dc1-8990-d926a895de78-0000\nI0721 05:01:57.726794 22497 slave.cpp:4281] Cleaning up framework 1079aaea-6dde-4dc1-8990-d926a895de78-0000\n</code></pre>\n\n<p>so it seems mesos failed to fetch the docker image. I've configed CA file for dockerd(move ca files to /etc/docker/certs.d/), so I can 'docker pull' the image to local machine, but I am not sure how to config CA file for mesos~\n   in mesos-agent configurations, there exist a item \"--docker_config=VALUE\", but it seems this item can only be used for username/password secured registry, I don't know how to config for CA secured registry.</p>\n\n<p>anybody can help me out?!  thanks! </p>\n", "is_answered": false, "tags": ["mesos", "dcos"], "title": "how to use secure docker registry(by CA) for mesos container?", "last_activity_date": 1500639782, "answer_count": 1, "creation_date": 1500622179, "score": 0, "link": "https://stackoverflow.com/questions/45231638/how-to-use-secure-docker-registryby-ca-for-mesos-container", "answers": [{"body": "<p>I think CA file is just for encryption. you will need username and password in ca file way I think.</p>\n\n<p>In my way, I put auth file into the container to authorize my private registry.</p>\n\n<ol>\n<li><p>I wrote a web service for downloading the auth file \nxxx.tar.gz(format: <code>.docker/config.json</code> in the tar.gz)\nin the config.json, <code>{\"auths\": {\"test.com:6999\": {\"auth\": \"(username:password) [base64 encode]\"}}}</code> like <code>{\"auths\": {\"test.com:6999\": {\"auth\": \"Y2NjOjEyMw==\"}}}</code></p></li>\n<li><p>use Mesos uris to download auth files prepared into the containers. then, it would authorized.\n<code>\n\"uris\":  [\n   \"http:your download url\"\n]\n</code></p></li>\n</ol>\n", "answer_id": 45237283, "last_activity_date": 1500639782, "creation_date": 1500638868, "score": 0, "owner": {"user_id": 3775049, "profile_image": "https://www.gravatar.com/avatar/f70574791370eda0270f46eac13901dc?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 191, "link": "https://stackoverflow.com/users/3775049/edwardramsey", "display_name": "edwardramsey"}, "is_accepted": false, "last_edit_date": 1500639782, "question_id": 45231638}], "owner": {"user_id": 8170671, "profile_image": "https://www.gravatar.com/avatar/a587027b0f0fa5800625da27fdb52963?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/8170671/%e5%88%98%e5%b7%8d%e9%94%8b", "accept_rate": 0, "display_name": "\u5218\u5dcd\u950b"}, "view_count": 49, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 45231638}{"is_answered": false, "tags": ["apache-kafka", "mesos", "marathon"], "title": "How can I delete a topic from DCOS Kafka?", "last_activity_date": 1481033736, "answer_count": 1, "creation_date": 1452613497, "score": 4, "link": "https://stackoverflow.com/questions/34747930/how-can-i-delete-a-topic-from-dcos-kafka", "owner": {"user_id": 3931143, "profile_image": "https://www.gravatar.com/avatar/9ff3ddc6a2f345eb888c090f14f73b70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 236, "link": "https://stackoverflow.com/users/3931143/wade", "accept_rate": 71, "display_name": "Wade"}, "view_count": 234, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 34747930}{"body": "<p>I am using marathon to deploy my containers on mesos cluster. My marathon spec is as </p>\n\n<pre><code> {\n  \"id\": \"app-name\",\n  \"cmd\": null,\n  \"cpus\": 2,\n  \"mem\": 6500,\n  \"disk\": 34000,\n  \"instances\": 1,\n  \"container\": {\n    \"docker\": {\n      \"image\": \"path-to-private-docker-registry\",\n      \"network\": \"HOST\",\n      \"privileged\": true,\n      \"forcePullImage\": true,\n      \"parameters\": [\n        {\n          \"key\": \"log-driver\",\n          \"value\": \"none\"\n        },\n        {\n          \"key\": \"oom-kill-disable\",\n          \"value\": \"\"\n        }\n      ]\n    },\n    \"volumes\": [\n      {\n        \"containerPath\": \"/app/logs\",\n        \"hostPath\": \"/home/ubuntu/app/logs\",\n        \"mode\": \"RW\"\n      }\n    ],\n    \"type\": \"DOCKER\"\n  }\n}\n</code></pre>\n\n<p>Initial deployment is successful. But after some days when I rebuild my docker image with changes in it and try to redeploy the application it does not result in a success. Some logs that I was able to salvage are: </p>\n\n<p>marathon logs :</p>\n\n<pre><code>   [2016-06-27 20:24:19,658] INFO Received offers NOT WANTED notification, canceling 2 revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-13)\n[2016-06-27 20:24:19,659] INFO Finished processing fd99193f-56a9-4653-ab8e-4b2d86d048a0-O20. Matched 1 ops after 2 passes. ports(*) 8000-&gt;8568,8570-&gt;9000,31000-&gt;32000; mem(*) 459.0; disk(*) 11140.0 left. (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-15)\n[2016-06-27 20:24:19,659] INFO Processing LaunchEphemeral(LaunchedEphemeral(task [application.06f03939-3c77-11e6-963c-e2736a05f0b5],AgentInfo(ip-172-30-2-84,Some(abd14501-6f19-4443-b5f3-22a44a2f3d4f-S3),Buffer()),2016-06-27T14:53:52.324Z,Status(2016-06-27T14:54:19.657Z,None,None),Vector(8569))) for task [application.06f03939-3c77-11e6-963c-e2736a05f0b5] (mesosphere.marathon.core.launcher.impl.OfferProcessorImpl:ForkJoinPool-2-worker-13)\n[2016-06-27 20:24:19,667] INFO receiveTaskUpdate: updating status of task [application.06f03939-3c77-11e6-963c-e2736a05f0b5] (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-16)\n[2016-06-27 20:24:19,667] INFO Task launch for 'task [application.06f03939-3c77-11e6-963c-e2736a05f0b5]' was accepted. 0 tasksToLaunch, 0 in flight, 1 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-16)\n[2016-06-27 20:24:22,362] INFO 111.93.51.122 - - [27/Jun/2016:14:54:22 +0000] \"GET //52.76.213.44:7070/v2/deployments HTTP/1.1\" 200 364 \"&lt;marathon-webui&gt;\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"  (mesosphere.chaos.http.ChaosRequestLog$$EnhancerByGuice$$38de1910:qtp1620041759-33)\n[2016-06-27 20:24:22,368] INFO 111.93.51.122 - - [27/Jun/2016:14:54:22 +0000] \"GET //52.76.213.44:7070/v2/groups?embed=group.groups&amp;embed=group.apps&amp;embed=group.apps.deployments&amp;embed=group.apps.counts&amp;embed=group.apps.readiness HTTP/1.1\" 200 1247 \"&lt;marathon-webui&gt;\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"  (mesosphere.chaos.http.ChaosRequestLog$$EnhancerByGuice$$38de1910:qtp1620041759-36)\n[2016-06-27 20:24:22,467] INFO 111.93.51.122 - - [27/Jun/2016:14:54:22 +0000] \"GET //52.76.213.44:7070/v2/queue HTTP/1.1\" 200 12 \"http://&lt;marathon-webui&gt;/ui/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"  (mesosphere.chaos.http.ChaosRequestLog$$EnhancerByGuice$$38de1910:qtp1620041759-31)\n[2016-06-27 20:24:25,372] INFO Received status update for task application.06f03939-3c77-11e6-963c-e2736a05f0b5: TASK_FAILED (Docker container run error: Container exited on error: exited with status 125) (mesosphere.marathon.MarathonScheduler$$EnhancerByGuice$$388f7d52:Thread-44)\n[2016-06-27 20:24:25,379] INFO Removed app [/application] from tracker (mesosphere.marathon.core.task.tracker.TaskTracker$TasksByApp$:marathon-akka.actor.default-dispatcher-13)\n[2016-06-27 20:24:25,380] INFO Increasing delay. Task launch delay for [/application] changed from [0 milliseconds] to [1 seconds]. (mesosphere.marathon.core.launchqueue.impl.RateLimiter$:marathon-akka.actor.default-dispatcher-16)\n[2016-06-27 20:24:25,381] INFO receiveTaskUpdate: task [application.06f03939-3c77-11e6-963c-e2736a05f0b5] finished (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-8)\n[2016-06-27 20:24:25,382] INFO Sending event notification for task [application.06f03939-3c77-11e6-963c-e2736a05f0b5] of app [/application]: TASK_FAILED (mesosphere.marathon.core.task.update.impl.steps.PostToEventStreamStepImpl$$EnhancerByGuice$$1cb38257:marathon-akka.actor.default-dispatcher-20)\n[2016-06-27 20:24:25,382] WARN New task [task [application.06f03939-3c77-11e6-963c-e2736a05f0b5]] failed during app /application scaling, queueing another task (mesosphere.marathon.upgrade.TaskStartActor:marathon-akka.actor.default-dispatcher-8)\n[2016-06-27 20:24:25,382] INFO initiating a scale check for app [/application] after task [application.06f03939-3c77-11e6-963c-e2736a05f0b5] terminated (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl$$EnhancerByGuice$$d6da0d15:marathon-akka.actor.default-dispatcher-8)\n[2016-06-27 20:24:25,382] INFO schedulerActor: Actor[akka://marathon/user/MarathonScheduler#513692909] (mesosphere.marathon.core.task.update.impl.steps.ScaleAppUpdateStepImpl$$EnhancerByGuice$$d6da0d15:marathon-akka.actor.default-dispatcher-8)\n[2016-06-27 20:24:26,401] INFO activating matcher ActorOfferMatcher(Actor[akka://marathon/user/launchQueue/1/1-application#492133230]). (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-12)\n[2016-06-27 20:24:26,401] INFO Received offers WANTED notification (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-12)\n[2016-06-27 20:24:26,401] INFO =&gt; revive offers NOW, canceling any scheduled revives (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-12)\n[2016-06-27 20:24:26,402] INFO 2 further revives still needed. Repeating reviveOffers according to --revive_offers_repetitions 3 (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-21)\n[2016-06-27 20:24:26,402] INFO =&gt; Schedule next revive at 2016-06-27T14:54:31.401Z in 5000 milliseconds, adhering to --min_revive_offers_interval 5000 (ms) (mesosphere.marathon.core.flow.impl.ReviveOffersActor:marathon-akka.actor.default-dispatcher-21)\n[2016-06-27 20:24:26,407] INFO Request Launch for task 'application.0af6311a-3c77-11e6-963c-e2736a05f0b5', version '2016-06-27T14:53:52.324Z'. 1 tasksToLaunch, 0 in flight, 0 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-16)\n[2016-06-27 20:24:26,407] INFO No tasks left to launch. Stop receiving offers for /application, 2016-06-27T14:53:52.324Z (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-13)\n[2016-06-27 20:24:26,407] INFO removing matcher ActorOfferMatcher(Actor[akka://marathon/user/launchQueue/1/1-application#492133230]) (mesosphere.marathon.core.matcher.manager.impl.OfferMatcherManagerActor:marathon-akka.actor.default-dispatcher-13)\n</code></pre>\n\n<p>Interestingly, marathon is getting much less resources like memory and disk space from mesos-master when all these resources are available.</p>\n\n<p>mesos-slave logs: </p>\n\n<pre><code>I0627 20:19:33.232674 12123 slave.cpp:1520] Got assigned task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:19:33.234148 12120 gc.cpp:83] Unscheduling '/tmp/mesos/slaves/d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0/frameworks/ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000' from gc\nI0627 20:19:33.234454 12120 gc.cpp:83] Unscheduling '/tmp/mesos/meta/slaves/d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0/frameworks/ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000' from gc\nI0627 20:19:33.234699 12122 slave.cpp:1639] Launching task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:19:33.236215 12122 paths.cpp:528] Trying to chown '/tmp/mesos/slaves/d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0/frameworks/ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000/executors/application.c04407a4-3c76-11e6-963c-e2736a05f0b5/runs/89668c43-35ac-4a55-976c-a66481296f69' to user 'ubuntu'\nI0627 20:19:33.238883 12122 slave.cpp:5644] Launching executor application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 with resources cpus(*):0.1; mem(*):32 in work directory '/tmp/mesos/slaves/d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0/frameworks/ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000/executors/application.c04407a4-3c76-11e6-963c-e2736a05f0b5/runs/89668c43-35ac-4a55-976c-a66481296f69'\nI0627 20:19:33.239861 12122 slave.cpp:1865] Queuing task 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' for executor 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:19:33.242758 12122 docker.cpp:1011] Starting container '89668c43-35ac-4a55-976c-a66481296f69' for task 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' (and executor 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5') of framework 'ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000'\nI0627 20:19:33.436872 12121 docker.cpp:627] Checkpointing pid 12462 to '/tmp/mesos/meta/slaves/d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0/frameworks/ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000/executors/application.c04407a4-3c76-11e6-963c-e2736a05f0b5/runs/89668c43-35ac-4a55-976c-a66481296f69/pids/forked.pid'\nI0627 20:19:33.495285 12127 slave.cpp:2860] Got registration for executor 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 from executor(1)@172.30.2.145:59715\nI0627 20:19:33.496909 12127 docker.cpp:1322] Ignoring updating container '89668c43-35ac-4a55-976c-a66481296f69' with resources passed to update is identical to existing resources\nI0627 20:19:33.497323 12127 slave.cpp:2030] Sending queued task 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' to executor 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 at executor(1)@172.30.2.145:59715\nI0627 20:19:38.940521 12126 slave.cpp:3219] Handling status update TASK_FAILED (UUID: 433ac498-3926-4e81-ae3b-d8701a5f6963) for task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 from executor(1)@172.30.2.145:59715\nE0627 20:19:38.972251 12127 slave.cpp:3469] Failed to update resources for container 89668c43-35ac-4a55-976c-a66481296f69 of executor 'application.c04407a4-3c76-11e6-963c-e2736a05f0b5' running task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 on status update for terminal task, destroying container: Failed to 'docker -H unix:///var/run/docker.sock inspect mesos-d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0.89668c43-35ac-4a55-976c-a66481296f69': exit status = exited with status 1 stderr = Error: No such image or container: mesos-d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0.89668c43-35ac-4a55-976c-a66481296f69\nI0627 20:19:38.972554 12127 status_update_manager.cpp:320] Received status update TASK_FAILED (UUID: 433ac498-3926-4e81-ae3b-d8701a5f6963) for task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:19:38.972686 12124 docker.cpp:1731] Destroying container '89668c43-35ac-4a55-976c-a66481296f69'\nI0627 20:19:38.972718 12124 docker.cpp:1817] Sending SIGTERM to executor with pid: 12462\nI0627 20:19:38.977213 12127 status_update_manager.cpp:824] Checkpointing UPDATE for status update TASK_FAILED (UUID: 433ac498-3926-4e81-ae3b-d8701a5f6963) for task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:19:38.981940 12121 slave.cpp:3617] Forwarding the update TASK_FAILED (UUID: 433ac498-3926-4e81-ae3b-d8701a5f6963) for task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 to master@172.30.2.96:5050\nI0627 20:19:38.982400 12121 slave.cpp:3527] Sending acknowledgement for status update TASK_FAILED (UUID: 433ac498-3926-4e81-ae3b-d8701a5f6963) for task application.c04407a4-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 to executor(1)@172.30.2.145:59715\nI0627 20:19:38.986201 12124 docker.cpp:1859] Running docker stop on container '89668c43-35ac-4a55-976c-a66481296f69'\nI0627 20:19:38.988855 12123 slave.cpp:3745] executor(1)@172.30.2.145:59715 exited\n</code></pre>\n\n<p>mesos-master logs: </p>\n\n<pre><code>I0627 20:21:25.094447  5875 master.cpp:4829] Re-registered agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145) with ports(*):[8000-9000, 31000-32000]; cpus(*):2; mem(*):6959; disk(*):45140\nI0627 20:21:25.094547  5875 master.cpp:4864] Sending updated checkpointed resources  to agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145)\nI0627 20:21:25.094853  5872 hierarchical.cpp:473] Added agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 (ip-172-30-2-145) with ports(*):[8000-9000, 31000-32000]; cpus(*):2; mem(*):6959; disk(*):45140 (allocated: )\nI0627 20:21:25.096194  5873 leveldb.cpp:341] Persisting action (18 bytes) to leveldb took 2.77403ms\nI0627 20:21:25.096230  5873 replica.cpp:712] Persisted action at 961\nI0627 20:21:25.097221  5872 master.cpp:4926] Received update of agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145) with total oversubscribed resources \nI0627 20:21:25.097904  5872 hierarchical.cpp:531] Agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 (ip-172-30-2-145) updated with oversubscribed resources  (total: ports(*):[8000-9000, 31000-32000]; cpus(*):2; mem(*):6959; disk(*):45140, allocated: )\nI0627 20:21:25.098150  5870 replica.cpp:691] Replica received learned notice for position 961 from @0.0.0.0:0\nI0627 20:21:25.100486  5870 leveldb.cpp:341] Persisting action (20 bytes) to leveldb took 2.302917ms\nI0627 20:21:25.100553  5870 leveldb.cpp:399] Deleting ~2 keys from leveldb took 32386ns\nI0627 20:21:25.100579  5870 replica.cpp:712] Persisted action at 961\nI0627 20:21:25.100605  5870 replica.cpp:697] Replica learned TRUNCATE action at position 961\nI0627 20:21:25.803926  5868 http.cpp:313] HTTP GET for /master/state from 111.93.51.122:4363 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\nI0627 20:21:33.465710  5868 master.cpp:2465] Received SUBSCRIBE call for framework 'marathon' at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:21:33.466069  5868 master.cpp:2541] Subscribing framework marathon with checkpointing enabled and capabilities [  ]\nI0627 20:21:33.467990  5868 hierarchical.cpp:264] Added framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:21:33.469707  5868 master.cpp:5632] Sending 1 offers to framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:21:33.622820  5872 master.cpp:3949] Processing DECLINE call for offers: [ fd99193f-56a9-4653-ab8e-4b2d86d048a0-O0 ] for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:21:35.989673  5874 http.cpp:313] HTTP GET for /master/state from 111.93.51.122:60515 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\nI0627 20:21:47.045994  5872 http.cpp:313] HTTP GET for /master/state from 111.93.51.122:4363 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\nI0627 20:21:48.465175  5875 master.cpp:5305] Performing implicit task state reconciliation for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:21:58.040252  5874 http.cpp:313] HTTP GET for /master/state from 111.93.51.122:60515 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\nI0627 20:22:02.247869  5869 master.cpp:4028] Processing REVIVE call for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:22:02.248029  5869 hierarchical.cpp:989] Removed offer filters for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:22:02.249119  5869 master.cpp:5632] Sending 1 offers to framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:22:02.414969  5869 master.cpp:3412] Processing ACCEPT call for offers: [ fd99193f-56a9-4653-ab8e-4b2d86d048a0-O1 ] on agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145) for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:22:02.418418  5871 master.hpp:177] Adding task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 with resources cpus(*):2; mem(*):6500; disk(*):32000; ports(*):[8488-8488] on agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 (ip-172-30-2-145)\nI0627 20:22:02.418742  5871 master.cpp:3897] Launching task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020 with resources cpus(*):2; mem(*):6500; disk(*):32000; ports(*):[8488-8488] on agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145)\nI0627 20:22:03.241605  5873 master.cpp:5632] Sending 1 offers to framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:22:03.244705  5874 master.cpp:3949] Processing DECLINE call for offers: [ fd99193f-56a9-4653-ab8e-4b2d86d048a0-O2 ] for framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (marathon) at scheduler-18a0602a-d587-4395-8eef-b63050d3f1e8@172.30.2.96:37020\nI0627 20:22:09.048271  5870 http.cpp:313] HTTP GET for /master/state from 111.93.51.122:4363 with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\nI0627 20:22:20.003542  5869 master.cpp:5071] Status update TASK_FAILED (UUID: 41eb819c-d132-4449-8a97-c6a9751514c7) for task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 from agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145)\nI0627 20:22:20.003643  5869 master.cpp:5119] Forwarding status update TASK_FAILED (UUID: 41eb819c-d132-4449-8a97-c6a9751514c7) for task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000\nI0627 20:22:20.004073  5869 master.cpp:6727] Updating the state of task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 (latest state: TASK_FAILED, status update state: TASK_FAILED)\n</code></pre>\n\n<p>So what could be the problem here?? I don't seem to get it work after initial deployment. </p>\n\n<p>Furthermore, I have tested my new docker container using docker run and it works fine. </p>\n", "is_answered": false, "tags": ["docker", "mesos", "marathon", "dcos"], "title": "Mesos failing to deploy container with same spec after destroying initial application", "last_activity_date": 1467112941, "answer_count": 1, "creation_date": 1467047372, "score": 0, "link": "https://stackoverflow.com/questions/38059548/mesos-failing-to-deploy-container-with-same-spec-after-destroying-initial-applic", "answers": [{"body": "<p>Marathon launched the task here:</p>\n\n<pre><code>[2016-06-27 20:24:19,667] INFO Task launch for 'task [application.06f03939-3c77-11e6-963c-e2736a05f0b5]' was accepted. 0 tasksToLaunch, 0 in flight, 1 confirmed.  not backing off (mesosphere.marathon.core.launchqueue.impl.AppTaskLauncherActor:marathon-akka.actor.default-dispatcher-16)\n</code></pre>\n\n<p>It looks like the task was dispatched by Marathon just fine.</p>\n\n<p>The task (or one just like it) actually fails here:</p>\n\n<pre><code>I0627 20:22:20.003542  5869 master.cpp:5071] Status update TASK_FAILED (UUID: 41eb819c-d132-4449-8a97-c6a9751514c7) for task application.b50fd5d3-3c76-11e6-963c-e2736a05f0b5 of framework ce1d562f-9cfd-494e-8e23-b7e0fa4110f2-0000 from agent d2a2a152-aa17-4e21-8af4-b5e5e91cf770-S0 at slave(1)@172.30.2.145:5051 (ip-172-30-2-145)\n</code></pre>\n\n<p>You can check the Mesos Sandbox to look for Docker logs in the stdout/stderr files.</p>\n", "answer_id": 38074861, "last_activity_date": 1467112941, "creation_date": 1467112941, "score": 0, "owner": {"user_id": 5343540, "profile_image": "https://www.gravatar.com/avatar/68c554bc26aa5bcb590d40a3c40d3493?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/5343540/john", "display_name": "John"}, "is_accepted": false, "question_id": 38059548}], "owner": {"user_id": 6315572, "profile_image": "https://i.stack.imgur.com/R0sLG.jpg?s=128&g=1", "user_type": "registered", "reputation": 186, "link": "https://stackoverflow.com/users/6315572/t6nand", "accept_rate": 54, "display_name": "t6nand"}, "view_count": 1141, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 38059548}{"body": "<p>I'm using marathon 0.8.2 and the mesosphere docker image (tag v0.8.2). I'm passing the <code>--logging_level warn</code> flag to the daemon, but I'm still seeing all the health checks come through (log level INFO).</p>\n\n<pre><code>47f1eff08164        mesosphere/marathon:v0.8.2            \"./bin/start --maste   About an hour ago   Up About an hour                        mesos_marathon\n</code></pre>\n\n<p>A snippet from docker inspect:</p>\n\n<pre><code>  \"CMD\": [\n        \"--master\",\n        \"zk://zk_host1:2181,zk_host2:2181,zk_host3:2181/mesos\",\n        \"--zk\",\n        \"zk://zk_host1:2181,zk_host2:2181,zk_host3:2181/marathon\",\n        \"--hostname\",\n        \"marathon_host\",\n        \"--max_tasks_per_offer\",\n        \"10\",\n        \"--http_port\",\n        \"80\",\n        \"--logging_level\",\n        \"warn\"\n    ],\n</code></pre>\n\n<p>The parameters via <code>ps</code>:</p>\n\n<pre><code>java -jar ./bin/../target/marathon-assembly-0.8.2.jar --master zk://zk_host1:2181,zk_host2:2181,zk_host3:2181/mesos --zk zk://zk_host1:2181,zk_host2:2181,zk_host3:2181/marathon --hostname marathon_host --max_tasks_per_offer 10 --http_port 80 --logging_level warn\n</code></pre>\n\n<p>However, when I look at <code>docker logs mesos_marathon</code>, I see lots of INFO:</p>\n\n<blockquote>\n  <p>[INFO] [06/16/2015 15:49:25.302] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result [Healthy(microbot.edb72ab0-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.206Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.302] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result:[Healthy(microbot.e6946214-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.206Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.302] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result: [Healthy(microbot.ea257847-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.206Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.302] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result: [Healthy(microbot.ff9ac8c5-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.207Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.302] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result:  [Healthy(microbot.edbf8e46-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.207Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.303] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result:  [Healthy(microbot.f888a2eb-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.208Z)] </p>\n  \n  <p>[INFO] [06/16/2015 15:49:25.303] [marathon-akka.actor.default-dispatcher-7] [akka://marathon/user/$f] Received health result:  [Healthy(microbot.edbc80f0-143e-11e5-8fb0-56847afe9799,2015-06-16T15:46:24.346Z,2015-06-16T15:49:25.208Z)]</p>\n</blockquote>\n\n<p>I'm certainly missing something.</p>\n", "is_answered": false, "tags": ["logging", "docker", "mesos", "mesosphere", "marathon"], "last_edit_date": 1434488378, "title": "Log level in 0.8.2 not correctly configured?", "last_activity_date": 1444767381, "answer_count": 1, "creation_date": 1434473109, "score": 1, "link": "https://stackoverflow.com/questions/30873520/log-level-in-0-8-2-not-correctly-configured", "answers": [{"body": "<p>Akka does not use a particular logging backend, it just prints to standard out. To configure Akka logging please refer to :<a href=\"http://doc.akka.io/docs/akka/snapshot/java/logging.html\" rel=\"nofollow\">http://doc.akka.io/docs/akka/snapshot/java/logging.html</a>. </p>\n\n<p>You can also get a more fine grained control over marathon logging using the <code>/logging</code> endpoint. So visit <code>&lt;marathon_url&gt;/logging</code> to configure logging in Marathon at runtime</p>\n", "answer_id": 33111833, "last_activity_date": 1444767381, "creation_date": 1444767381, "score": 0, "owner": {"user_id": 4851450, "profile_image": "https://www.gravatar.com/avatar/a08b58c81d6fd180debbb083d162c17c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 46, "link": "https://stackoverflow.com/users/4851450/surdy", "display_name": "surdy"}, "is_accepted": false, "question_id": 30873520}], "owner": {"user_id": 5016295, "profile_image": "https://www.gravatar.com/avatar/c5ea9eab67473533826b8693f209c1b1?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/5016295/dontrebootme", "display_name": "dontrebootme"}, "view_count": 118, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 30873520}{"body": "<p>I am sorry about this question but I am new to mesos and I am curious to know, how should I go about building my own mesos framework. Any step by step guide or good resources would be much helpful. </p>\n", "is_answered": true, "title": "How to build my own mesos framework?", "tags": ["frameworks", "mesos", "mesosphere"], "last_activity_date": 1468443438, "accepted_answer_id": 38344893, "creation_date": 1468346683, "answers": [{"body": "<p>You should start with docs. There is whole <a href=\"http://mesos.apache.org/documentation/latest/\" rel=\"nofollow\">Developing Mesos Frameworks</a> section about developing own framework.</p>\n\n<p>New approach in developing frameworks is to use HTTP API which provides more features (like reverse offers) so definietely read about <a href=\"http://mesos.apache.org/documentation/latest/scheduler-http-api/\" rel=\"nofollow\">scheduler</a> and <a href=\"http://mesos.apache.org/documentation/latest/executor-http-api/\" rel=\"nofollow\">executor</a> HTTP API.</p>\n\n<p>Of course taking a look on other frameworks will be good point to start. Depending on your need this could be <a href=\"http://aurora.apache.org/\" rel=\"nofollow\">Aurora</a>, <a href=\"https://github.com/Netflix/Fenzo\" rel=\"nofollow\">Fenzo</a>, <a href=\"https://github.com/mesosphere/marathon\" rel=\"nofollow\">Marathon</a>. Whole list is <a href=\"http://mesos.apache.org/documentation/latest/frameworks/\" rel=\"nofollow\">here</a></p>\n\n<p>There is a framework to build Mesos frameworks called <a href=\"https://github.com/ContainerSolutions/mesos-starter\" rel=\"nofollow\">Mesos-starter</a>.\nIf you want to use native API there are official bindings for C++, Python and Java but there are unofficial bindings for other languages like <a href=\"https://github.com/mesos/mesos-go\" rel=\"nofollow\">Go</a>, <a href=\"https://github.com/tobilg/mesos-framework\" rel=\"nofollow\">JS</a> or <a href=\"https://github.com/dgrnbrg/clj-mesos\" rel=\"nofollow\">Clojure</a>.</p>\n", "answer_id": 38344893, "last_activity_date": 1468443438, "creation_date": 1468393874, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "last_edit_date": 1468443438, "question_id": 38336037}], "score": 0, "link": "https://stackoverflow.com/questions/38336037/how-to-build-my-own-mesos-framework", "answer_count": 1, "owner": {"user_id": 4883694, "profile_image": "https://i.stack.imgur.com/DqIWh.jpg?s=128&g=1", "user_type": "registered", "reputation": 440, "link": "https://stackoverflow.com/users/4883694/techiee", "accept_rate": 100, "display_name": "Techiee"}, "view_count": 86, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38336037}{"body": "<p>I am using Cassandra framework on Mesosphere which is launching Cassandra nodes on Mesos containers.</p>\n\n<p>I run the following command to install</p>\n\n<pre><code>dcos package install --options=cassandra.json cassandra\n</code></pre>\n\n<p>Can I limit the deployment on specific nodes rather than mesosphere deploying randomly? I am aware we can do it with docker container using the parameter <strong>constraints</strong> in the JSON file, but when I use the same for mesos it says <strong>constraints</strong> is an invalid parameter.</p>\n\n<p>Am I doing something wrong? or is there a way around?</p>\n\n<p>My cassandra.json looks like</p>\n\n<pre><code>    {\n    \"service\" : {\n                \"name\": \"cassandra-test\",\n       \"cpus\": 1,\n       \"mem\": 512,\n       \"heap\": 256\n    },\n    \"constraints\" : {\n    {\n      \"hostname\",\n      \"CLUSTER\",\n      \"10.2.1.81,10.2.1.89,10.2.1.74,10.2.1.72\"\n    }\n  },\n    \"nodes\": {\n        \"cpus\": 2,\n        \"mem\": 2048,\n        \"disk\": 4096,\n        \"heap\": {\n            \"size\": 1024,\n            \"new\": 100\n        },\n        \"count\": 2,\n        \"seeds\": 1\n    },\n    \"executor\" : {\n       \"cpus\": 1,\n       \"mem\": 512,\n       \"heap\": 256\n    },\n    \"task\" : {\n       \"cpus\": 1,\n       \"mem\": 128\n    }\n}\n</code></pre>\n", "is_answered": false, "tags": ["docker", "cassandra", "mesos", "mesosphere"], "title": "Cassandra on Mesos", "last_activity_date": 1487357152, "answer_count": 1, "creation_date": 1487271824, "score": 0, "link": "https://stackoverflow.com/questions/42282534/cassandra-on-mesos", "answers": [{"body": "<p>Given your config example, the constraints would be provided like this:</p>\n\n<pre><code>{\n    \"service\": {\n        \"name\": \"cassandra-test\",\n        \"cpus\": 1,\n        \"mem\": 512,\n        \"heap\": 256,\n        \"placement_constraint\": \"hostname:CLUSTER:10.2.1.81,10.2.1.89,10.2.1.74,10.2.1.72\"\n    },\n    \"nodes\": {\n        \"cpus\": 2,\n        \"mem\": 2048,\n        \"disk\": 4096,\n        \"heap\": {\n            \"size\": 1024,\n            \"new\": 100\n        },\n        \"count\": 2,\n        \"seeds\": 1\n    },\n    \"executor\": {\n        \"cpus\": 1,\n        \"mem\": 512,\n        \"heap\": 256\n    },\n    \"task\": {\n        \"cpus\": 1,\n        \"mem\": 128\n    }\n}\n</code></pre>\n\n<p>See examples in the docs here:</p>\n\n<p><a href=\"https://github.com/mesosphere/dcos-cassandra-service/blob/master/docs/configuration.md#service-configuration\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/dcos-cassandra-service/blob/master/docs/configuration.md#service-configuration</a></p>\n\n<p>You can see the config schema that controls this here:</p>\n\n<p><a href=\"https://github.com/mesosphere/dcos-cassandra-service/blob/master/universe/config.json\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/dcos-cassandra-service/blob/master/universe/config.json</a></p>\n", "answer_id": 42305294, "last_activity_date": 1487357152, "creation_date": 1487357152, "score": 0, "owner": {"user_id": 6252585, "profile_image": "https://www.gravatar.com/avatar/7d417ac7bcd1caca822d4704f4e6b380?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/6252585/nickbp", "display_name": "nickbp"}, "is_accepted": false, "question_id": 42282534}], "owner": {"user_id": 5045323, "profile_image": "https://www.gravatar.com/avatar/7b66336f1600c65cd0e6e0a62366af22?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 139, "link": "https://stackoverflow.com/users/5045323/nahush", "accept_rate": 50, "display_name": "Nahush"}, "view_count": 169, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42282534}{"body": "<p>We have a backend module which listen ActiveMQ, after changing the backend arch, we are using Mesos,Marathon and Zookeeper, </p>\n\n<p>Now we want to listen Zookeeper events, if any update come to zookeeper.</p>\n\n<p>Is there any Client or anything, for connect to Zookeeper and listen the Zookeeper Queues/Events.</p>\n\n<p>Thanks in advance.</p>\n", "is_answered": true, "tags": ["apache-zookeeper", "mesos", "mesosphere", "marathon", "php-zookeeper"], "title": "Need help on Zookeeper events and Queues", "last_activity_date": 1439231035, "answer_count": 2, "creation_date": 1439197523, "score": 0, "link": "https://stackoverflow.com/questions/31915566/need-help-on-zookeeper-events-and-queues", "answers": [{"body": "<p>We're using apache curator framework for this purpose. There is watch method which allow you to subscribe for specific path and listen for different events from it. Like: node created, updated, deleted or child changed...</p>\n", "answer_id": 31915687, "last_activity_date": 1439197894, "creation_date": 1439197894, "score": 0, "owner": {"user_id": 3641023, "profile_image": "https://www.gravatar.com/avatar/4f81ad516118e653e638fc9a392612d6?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 4134, "link": "https://stackoverflow.com/users/3641023/rumoku", "accept_rate": 71, "display_name": "Rumoku"}, "is_accepted": false, "question_id": 31915566}, {"body": "<p>There are ZooKeeper bindings (client libraries) for a variety of languages, you can use those libraries to interact with ZooKeeper. The <a href=\"http://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html\" rel=\"nofollow\">ZooKeeper Programmer's Guide</a> is a great place to start. And here is the link to <a href=\"http://techblog.netflix.com/2011/11/introducing-curator-netflix-zookeeper.html\" rel=\"nofollow\">Curator</a>. </p>\n", "answer_id": 31926531, "last_activity_date": 1439231035, "creation_date": 1439231035, "score": 1, "owner": {"user_id": 43668, "profile_image": "https://www.gravatar.com/avatar/2fb130a1a2f63e782fe2345cd48452c2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 361, "link": "https://stackoverflow.com/users/43668/hartem", "display_name": "hartem"}, "is_accepted": false, "question_id": 31915566}], "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "view_count": 66, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31915566}{"body": "<p>I just created a DC/OS cluster and am trying to run simple Spark task that reads data from <code>/mnt/mesos/sandbox</code>.</p>\n\n<pre><code>object SimpleApp {\n  def main(args: Array[String]) {\n    val conf = new SparkConf()\n      .setAppName(\"Simple Application\")\n\n    println(\"STARTING JOB!\")\n\n    val sc = new SparkContext(conf)\n\n    val rdd = sc.textFile(\"file:///mnt/mesos/sandbox/foo\")\n\n    println(rdd.count)\n\n    println(\"ENDING JOB!\")\n  }\n}\n</code></pre>\n\n<p>And I'm deploying the app using</p>\n\n<pre><code>dcos spark run --submit-args='--conf spark.mesos.uris=https://dripit-spark.s3.amazonaws.com/foo --class SimpleApp https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar' --verbose\n</code></pre>\n\n<p>Unfortunately, task keeps failing with following exception</p>\n\n<pre><code>I0701 18:47:35.782994 30997 logging.cpp:188] INFO level logging started!\nI0701 18:47:35.783197 30997 fetcher.cpp:424] Fetcher Info: {\"cache_directory\":\"\\/tmp\\/mesos\\/fetch\\/slaves\\/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2\",\"items\":[{\"action\":\"BYPASS_CACHE\",\"uri\":{\"extract\":true,\"value\":\"https:\\/\\/dripit-spark.s3.amazonaws.com\\/foobar-assembly-1.0.jar\"}},{\"action\":\"BYPASS_CACHE\",\"uri\":{\"extract\":true,\"value\":\"https:\\/\\/dripit-spark.s3.amazonaws.com\\/foo\"}}],\"sandbox_directory\":\"\\/var\\/lib\\/mesos\\/slave\\/slaves\\/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2\\/frameworks\\/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002\\/executors\\/driver-20160701184530-0001\\/runs\\/67b94f34-a9d3-4662-bedc-8578381e9305\"}\nI0701 18:47:35.784752 30997 fetcher.cpp:379] Fetching URI 'https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar'\nI0701 18:47:35.784791 30997 fetcher.cpp:250] Fetching directly into the sandbox directory\nI0701 18:47:35.784818 30997 fetcher.cpp:187] Fetching URI 'https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar'\nI0701 18:47:35.784835 30997 fetcher.cpp:134] Downloading resource from 'https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar' to '/var/lib/mesos/slave/slaves/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2/frameworks/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002/executors/driver-20160701184530-0001/runs/67b94f34-a9d3-4662-bedc-8578381e9305/foobar-assembly-1.0.jar'\nW0701 18:47:36.057448 30997 fetcher.cpp:272] Copying instead of extracting resource from URI with 'extract' flag, because it does not seem to be an archive: https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar\nI0701 18:47:36.057673 30997 fetcher.cpp:456] Fetched 'https://dripit-spark.s3.amazonaws.com/foobar-assembly-1.0.jar' to '/var/lib/mesos/slave/slaves/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2/frameworks/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002/executors/driver-20160701184530-0001/runs/67b94f34-a9d3-4662-bedc-8578381e9305/foobar-assembly-1.0.jar'\nI0701 18:47:36.057696 30997 fetcher.cpp:379] Fetching URI 'https://dripit-spark.s3.amazonaws.com/foo'\nI0701 18:47:36.057714 30997 fetcher.cpp:250] Fetching directly into the sandbox directory\nI0701 18:47:36.057741 30997 fetcher.cpp:187] Fetching URI 'https://dripit-spark.s3.amazonaws.com/foo'\nI0701 18:47:36.057770 30997 fetcher.cpp:134] Downloading resource from 'https://dripit-spark.s3.amazonaws.com/foo' to '/var/lib/mesos/slave/slaves/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2/frameworks/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002/executors/driver-20160701184530-0001/runs/67b94f34-a9d3-4662-bedc-8578381e9305/foo'\nW0701 18:47:36.114565 30997 fetcher.cpp:272] Copying instead of extracting resource from URI with 'extract' flag, because it does not seem to be an archive: https://dripit-spark.s3.amazonaws.com/foo\nI0701 18:47:36.114600 30997 fetcher.cpp:456] Fetched 'https://dripit-spark.s3.amazonaws.com/foo' to '/var/lib/mesos/slave/slaves/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2/frameworks/c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002/executors/driver-20160701184530-0001/runs/67b94f34-a9d3-4662-bedc-8578381e9305/foo'\nI0701 18:47:36.307576 31006 exec.cpp:143] Version: 0.28.1\nI0701 18:47:36.310127 31022 exec.cpp:217] Executor registered on slave c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-S2\n16/07/01 18:47:37 INFO SparkContext: Running Spark version 1.6.1\n16/07/01 18:47:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n16/07/01 18:47:37 WARN SparkConf: \nSPARK_JAVA_OPTS was detected (set to '-Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.0-1.6.1-2 ').\nThis is deprecated in Spark 1.0+.\n\nPlease instead use:\n - ./spark-submit with conf/spark-defaults.conf to set defaults for an application\n - ./spark-submit with --driver-java-options to set -X options for a driver\n - spark.executor.extraJavaOptions to set -X options for executors\n - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)\n\n16/07/01 18:47:37 WARN SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.0-1.6.1-2 ' as a work-around.\n16/07/01 18:47:37 WARN SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.mesos.executor.docker.image=mesosphere/spark:1.0.0-1.6.1-2 ' as a work-around.\n16/07/01 18:47:37 INFO SecurityManager: Changing view acls to: root\n16/07/01 18:47:37 INFO SecurityManager: Changing modify acls to: root\n16/07/01 18:47:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)\n16/07/01 18:47:37 INFO Utils: Successfully started service 'sparkDriver' on port 47358.\n16/07/01 18:47:38 INFO Slf4jLogger: Slf4jLogger started\n16/07/01 18:47:38 INFO Remoting: Starting remoting\n16/07/01 18:47:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.1.107:54467]\n16/07/01 18:47:38 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 54467.\n16/07/01 18:47:38 INFO SparkEnv: Registering MapOutputTracker\n16/07/01 18:47:38 INFO SparkEnv: Registering BlockManagerMaster\n16/07/01 18:47:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-96092a9a-3164-4d65-8c0b-df5403abb056\n16/07/01 18:47:38 INFO MemoryStore: MemoryStore started with capacity 511.1 MB\n16/07/01 18:47:38 INFO SparkEnv: Registering OutputCommitCoordinator\n16/07/01 18:47:38 INFO Server: jetty-8.y.z-SNAPSHOT\n16/07/01 18:47:38 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040\n16/07/01 18:47:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n16/07/01 18:47:38 INFO SparkUI: Started SparkUI at http://10.0.1.107:4040\n16/07/01 18:47:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-37696e45-5e8b-4328-81e6-deec1f185d75/httpd-69184304-7ffd-4420-b020-5f8a1bafecbd\n16/07/01 18:47:38 INFO HttpServer: Starting HTTP Server\n16/07/01 18:47:38 INFO Server: jetty-8.y.z-SNAPSHOT\n16/07/01 18:47:38 INFO AbstractConnector: Started SocketConnector@0.0.0.0:49074\n16/07/01 18:47:38 INFO Utils: Successfully started service 'HTTP file server' on port 49074.\n16/07/01 18:47:38 INFO SparkContext: Added JAR file:/mnt/mesos/sandbox/foobar-assembly-1.0.jar at http://10.0.1.107:49074/jars/foobar-assembly-1.0.jar with timestamp 1467398858626\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@712: Client environment:zookeeper.version=zookeeper C client 3.4.5\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@716: Client environment:host.name=ip-10-0-1-107.eu-west-1.compute.internal\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@723: Client environment:os.name=Linux\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@724: Client environment:os.arch=4.1.7-coreos-r1\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@725: Client environment:os.version=#2 SMP Thu Nov 5 02:10:23 UTC 2015\nI0701 18:47:38.778355   103 sched.cpp:164] Version: 0.25.0\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@733: Client environment:user.name=(null)\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@741: Client environment:user.home=/root\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@log_env@753: Client environment:user.dir=/opt/spark/dist\n2016-07-01 18:47:38,778:6(0x7f74cafc9700):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=master.mesos:2181 sessionTimeout=10000 watcher=0x7f74d587c600 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f7540003f70 flags=0\n2016-07-01 18:47:38,786:6(0x7f74c6ec0700):ZOO_INFO@check_events@1703: initiated connection to server [10.0.7.83:2181]\n2016-07-01 18:47:38,787:6(0x7f74c6ec0700):ZOO_INFO@check_events@1750: session establishment complete on server [10.0.7.83:2181], sessionId=0x155a57d07f60050, negotiated timeout=10000\nI0701 18:47:38.788107    99 group.cpp:331] Group process (group(1)@10.0.1.107:35064) connected to ZooKeeper\nI0701 18:47:38.788147    99 group.cpp:805] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0701 18:47:38.788162    99 group.cpp:403] Trying to create path '/mesos' in ZooKeeper\nI0701 18:47:38.789402    99 detector.cpp:156] Detected a new leader: (id='1')\nI0701 18:47:38.789512    99 group.cpp:674] Trying to get '/mesos/json.info_0000000001' in ZooKeeper\nI0701 18:47:38.790228    99 detector.cpp:481] A new leading master (UPID=master@10.0.7.83:5050) is detected\nI0701 18:47:38.790293    99 sched.cpp:262] New master detected at master@10.0.7.83:5050\nI0701 18:47:38.790473    99 sched.cpp:272] No credentials provided. Attempting to register without authentication\nI0701 18:47:38.792147    97 sched.cpp:641] Framework registered with c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002-driver-20160701184530-0001\n16/07/01 18:47:38 INFO CoarseMesosSchedulerBackend: Registered as framework ID c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002-driver-20160701184530-0001\n16/07/01 18:47:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38752.\n16/07/01 18:47:38 INFO NettyBlockTransferService: Server created on 38752\n16/07/01 18:47:38 INFO BlockManagerMaster: Trying to register BlockManager\n16/07/01 18:47:38 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.1.107:38752 with 511.1 MB RAM, BlockManagerId(driver, 10.0.1.107, 38752)\n16/07/01 18:47:38 INFO BlockManagerMaster: Registered BlockManager\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n16/07/01 18:47:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 117.2 KB, free 117.2 KB)\n16/07/01 18:47:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.6 KB, free 129.8 KB)\n16/07/01 18:47:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.107:38752 (size: 12.6 KB, free: 511.1 MB)\n16/07/01 18:47:39 INFO SparkContext: Created broadcast 0 from textFile at SimpleApp.scala:13\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: Mesos task 4 is now TASK_RUNNING\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: Mesos task 2 is now TASK_RUNNING\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: Mesos task 0 is now TASK_RUNNING\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: Mesos task 1 is now TASK_RUNNING\n16/07/01 18:47:39 INFO CoarseMesosSchedulerBackend: Mesos task 3 is now TASK_RUNNING\n16/07/01 18:47:39 WARN DFSUtil: Namenode for hdfs remains unresolved for ID nn1.  Check your hdfs-site.xml file to ensure namenodes are configured properly.\n16/07/01 18:47:39 WARN DFSUtil: Namenode for hdfs remains unresolved for ID nn2.  Check your hdfs-site.xml file to ensure namenodes are configured properly.\nException in thread \"main\" java.lang.IllegalArgumentException: java.net.UnknownHostException: namenode1.hdfs.mesos\n    at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:377)\n    at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:240)\n    at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:124)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.&lt;init&gt;(RetryInvocationHandler.java:74)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.&lt;init&gt;(RetryInvocationHandler.java:65)\n    at org.apache.hadoop.io.retry.RetryProxy.create(RetryProxy.java:58)\n    at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:152)\n    at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:579)\n    at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:524)\n    at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:146)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2397)\n    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2431)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2413)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:167)\n    at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:653)\n    at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:427)\n    at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:400)\n    at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)\n    at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)\n    at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)\n    at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)\n    at scala.Option.map(Option.scala:145)\n    at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)\n    at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)\n    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n    at scala.Option.getOrElse(Option.scala:120)\n    at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n    at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n    at scala.Option.getOrElse(Option.scala:120)\n    at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n    at org.apache.spark.rdd.RDD.count(RDD.scala:1157)\n    at SimpleApp$.main(SimpleApp.scala:15)\n    at SimpleApp.main(SimpleApp.scala)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:786)\n    at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:183)\n    at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:208)\n    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:123)\n    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.net.UnknownHostException: namenode1.hdfs.mesos\n    ... 48 more\n16/07/01 18:47:39 INFO SparkContext: Invoking stop() from shutdown hook\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}\n16/07/01 18:47:39 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}\n16/07/01 18:47:40 INFO SparkUI: Stopped Spark web UI at http://10.0.1.107:4040\n16/07/01 18:47:40 INFO CoarseMesosSchedulerBackend: Shutting down all executors\n16/07/01 18:47:40 INFO CoarseMesosSchedulerBackend: Asking each executor to shut down\nI0701 18:47:40.051103   111 sched.cpp:1771] Asked to stop the driver\nI0701 18:47:40.051283    96 sched.cpp:1040] Stopping framework 'c4bf7f81-1cf7-413a-b9be-8dc3b36137ee-0002-driver-20160701184530-0001'\n16/07/01 18:47:40 INFO CoarseMesosSchedulerBackend: driver.run() returned with code DRIVER_STOPPED\n16/07/01 18:47:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n16/07/01 18:47:40 INFO MemoryStore: MemoryStore cleared\n16/07/01 18:47:40 INFO BlockManager: BlockManager stopped\n16/07/01 18:47:40 INFO BlockManagerMaster: BlockManagerMaster stopped\n16/07/01 18:47:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n16/07/01 18:47:40 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.\n16/07/01 18:47:40 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.\n16/07/01 18:47:40 INFO SparkContext: Successfully stopped SparkContext\n16/07/01 18:47:40 INFO ShutdownHookManager: Shutdown hook called\n16/07/01 18:47:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-37696e45-5e8b-4328-81e6-deec1f185d75/httpd-69184304-7ffd-4420-b020-5f8a1bafecbd\n16/07/01 18:47:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-37696e45-5e8b-4328-81e6-deec1f185d75\n</code></pre>\n\n<p><strong>Why is Spark trying to connect to HDFS although file type is explicitly set to <code>file://</code>?</strong> </p>\n\n<p>I thought that <code>sc.textFile(\"file:///\")</code> doesn\u2019t require HDFS setup.</p>\n", "is_answered": true, "title": "When reading text file from file system, Spark still tries to connect to HDFS", "last_edit_date": 1467399090, "tags": ["scala", "apache-spark", "mesos", "dcos"], "view_count": 460, "accepted_answer_id": 38154297, "last_activity_date": 1467409851, "answers": [{"body": "<p>Spark will still use the hdfs to write the intermediate results of the stages (in your case, I guess the partial counts).</p>\n", "answer_id": 38146829, "last_activity_date": 1467380018, "creation_date": 1467380018, "score": 2, "owner": {"user_id": 2404988, "profile_image": "https://www.gravatar.com/avatar/0321c5453dcc53bff22351bcf96c1892?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4463, "link": "https://stackoverflow.com/users/2404988/c4stor", "accept_rate": 75, "display_name": "C4stor"}, "is_accepted": false, "question_id": 38143535}, {"body": "<p>Spark always use the Hadoop API to access a file, regardless of that file is local or in HDFS. </p>\n\n<p>I think the problem is your Spark is inheriting an invalid HDFS configuration and hit this bug <a href=\"https://issues.apache.org/jira/browse/SPARK-11227\" rel=\"nofollow\">https://issues.apache.org/jira/browse/SPARK-11227</a></p>\n\n<p>You should try some workarounds in that ticket to see if it works for you:</p>\n\n<ul>\n<li>Use an older Spark &lt; 1.5.0</li>\n<li>Disable HA in HDFS configuration.</li>\n</ul>\n", "answer_id": 38154297, "last_activity_date": 1467409851, "creation_date": 1467409851, "score": 2, "owner": {"user_id": 205528, "profile_image": "https://www.gravatar.com/avatar/39f09c8427daf8fbed0a12999868bc3f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 8919, "link": "https://stackoverflow.com/users/205528/dikei", "display_name": "Dikei"}, "is_accepted": true, "question_id": 38143535}], "score": 1, "link": "https://stackoverflow.com/questions/38143535/when-reading-text-file-from-file-system-spark-still-tries-to-connect-to-hdfs", "answer_count": 2, "owner": {"user_id": 1484115, "profile_image": "https://www.gravatar.com/avatar/2cf2ec4d9d378b6b41d11d0aeafd7611?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 577, "link": "https://stackoverflow.com/users/1484115/kristaps-taube", "accept_rate": 75, "display_name": "Kristaps Taube"}, "creation_date": 1467370243, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 38143535}{"body": "<p>The <code>Mesos</code> Slave is using <code>posix isolation</code> by default:    </p>\n\n<pre><code>......  \nI0105 06:26:28.479199  1869 containerizer.cpp:142] Using isolation: posix/cpu,posix/mem,filesystem/posix  \n......  \n</code></pre>\n\n<p>What is \"<code>posix isolation</code>\"? I can't google it.</p>\n", "is_answered": true, "title": "What is \"posix isolation\"?", "tags": ["posix", "virtualization", "mesos", "lxc", "mesosphere"], "last_activity_date": 1453124904, "accepted_answer_id": 34767231, "creation_date": 1451987641, "answers": [{"body": "<p>When we have different databases in a single server,\nposix isolation is to make sure that files, processes and databases are protected from other users and data that may exist in the same system</p>\n", "answer_id": 34613126, "last_activity_date": 1452001232, "creation_date": 1452001232, "score": 0, "owner": {"user_id": 2270160, "profile_image": "https://www.gravatar.com/avatar/0d8826621a8aeb690cfaa2a646e3d1d3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 747, "link": "https://stackoverflow.com/users/2270160/kassav", "accept_rate": 91, "display_name": "Kassav'"}, "is_accepted": false, "question_id": 34608691}, {"body": "<p>Mesos uses isolators in its containerizer to isolate the resource usage of each started task. The <code>posix</code> isolators provide separation of task as standard Unix processes. Each Mesos task is running under <code>mesos-executor</code> process, which makes sure that the task is running. These don't really perform any actual isolation but only report the current resource usage of running tasks.</p>\n\n<p>Under Linux, there is also <a href=\"https://en.wikipedia.org/wiki/Cgroups\" rel=\"nofollow\">cgroups</a> isolator available that can do actual isolation (CPU and memory).</p>\n\n<p>You can find more about <a href=\"http://mesos.apache.org/documentation/latest/containerizer/\" rel=\"nofollow\">Mesos Containerizer</a> and <a href=\"http://mesos.apache.org/documentation/latest/docker-containerizer/\" rel=\"nofollow\">Docker Containerizer</a> on the <a href=\"http://mesos.apache.org/\" rel=\"nofollow\">Apache Mesos website</a>.</p>\n", "answer_id": 34767231, "last_activity_date": 1453124904, "creation_date": 1452689449, "score": 2, "owner": {"user_id": 5638996, "profile_image": "https://lh4.googleusercontent.com/-J48otEXVjsE/AAAAAAAAAAI/AAAAAAAAACM/y0AUz8Cfojk/photo.jpg?sz=128", "user_type": "registered", "reputation": 46, "link": "https://stackoverflow.com/users/5638996/nfnt", "display_name": "nfnt"}, "is_accepted": true, "last_edit_date": 1453124904, "question_id": 34608691}], "score": 2, "link": "https://stackoverflow.com/questions/34608691/what-is-posix-isolation", "answer_count": 2, "owner": {"user_id": 2106207, "profile_image": "https://www.gravatar.com/avatar/960430ab7aba908bb9aa62d530618a75?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4686, "link": "https://stackoverflow.com/users/2106207/nan-xiao", "accept_rate": 78, "display_name": "Nan Xiao"}, "view_count": 328, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 34608691}{"body": "<p>I'm using the Vagrant DC/OS installation, and have added swap space to my guest to simulate a larger amount of memory.  How do I force the amount of memory available to a mesos agent</p>\n", "is_answered": false, "tags": ["mesos", "dcos"], "title": "On DC/OS how do you force the amount of memory available to an agent", "last_activity_date": 1486804260, "answer_count": 1, "creation_date": 1486784578, "score": 0, "link": "https://stackoverflow.com/questions/42171963/on-dc-os-how-do-you-force-the-amount-of-memory-available-to-an-agent", "answers": [{"body": "<p>In Mesos, you can do that via adjusting <code>--resources</code> agent flag, <a href=\"http://mesos.apache.org/documentation/latest/configuration/\" rel=\"nofollow noreferrer\">see here</a>. In DC/OS I believe it is highly discouraged to play with Mesos configuration directly. Use it at your own risk.</p>\n", "answer_id": 42174163, "last_activity_date": 1486804260, "creation_date": 1486804260, "score": 0, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 42171963}], "owner": {"user_id": 1734628, "profile_image": "https://i.stack.imgur.com/xzu0z.jpg?s=128&g=1", "user_type": "registered", "reputation": 261, "link": "https://stackoverflow.com/users/1734628/steven-lowenthal", "accept_rate": 0, "display_name": "Steven Lowenthal"}, "view_count": 28, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42171963}{"body": "<p>My application needs to run a lot of containers as worker nodes (to do various batch processing jobs) and I'm not really interested in keeping up web servers or databases - just short jobs that can take anywhere between 1 second to 1 hour. My idea is to work against a cloud of nodes without me having to worry about what machine from these nodes has the available resources to process my job (mesos is pretty good at this - as advertised). </p>\n\n<p>I'm playing right now with DC/OS and I was wondering if any of the other clustering technologies offer this feature: <code>given I need 1CPU, 2GB RAM and 2GB of disk - run X docker container against my nodes</code>.</p>\n\n<p>I like the idea of swarm due to the fact that I'm very familiar with docker itself and I believe it's the easiest to setup and automate (scale up or down). I like kubernetes (no experience however) because it's free and I'm pretty sure it will stay that way for a long time. I like DC/OS because it bundles a lot but I'm not sure of their future plans and I'm used to projects cutting off features to include them in a plan that charges your soul for x number of nodes.</p>\n\n<p>What are your thoughts?</p>\n", "is_answered": true, "tags": ["docker", "kubernetes", "docker-swarm", "dcos", "fleet"], "title": "swarm, kubernetes or mesos for batch processing jobs", "last_activity_date": 1483749629, "answer_count": 1, "creation_date": 1482255935, "score": 5, "link": "https://stackoverflow.com/questions/41248317/swarm-kubernetes-or-mesos-for-batch-processing-jobs", "answers": [{"body": "<p>Kubernetes, Swarm, and Mesos can all technically schedule jobs for you and handle constraining resources for you. </p>\n\n<p>Unlike the other two, Mesos was designed primarily to handle distribution, task, and resource management at a lower level. Focusing on these bits led to greater power and flexibility, but also more complexity at a lower level. That's why DC/OS exists, to give you a bundle of microservice tools that work well as a higher level platform.</p>\n\n<p>Mesos was also designed to allow you to bring your own scheduler to handle task lifecycle needs, which tend to be needed for stateful tasks. Kubernetes and Swarm were designed primarily to handle the stateless services use case and then adapted later to handle stateful services and jobs, with the included scheduler. </p>\n\n<p>DC/OS is built on Mesos and comes with built-in schedulers for jobs and services, while still allowing you to build your own custom scheduler if needed.</p>\n\n<p>Kubernetes recently added support for custom schedulers as well, but its significantly less mature than the Mesos implementation and ecosystem and also still revolves around using the core pods &amp; replica set primitives, which may be empowering or limiting, depending on your needs.</p>\n\n<p>Mesosphere recently built a new dcos-commons framework to make it trivial to build JVM-based Mesos schedulers, as well. So that may boost your productivity on DC/OS. <a href=\"https://github.com/mesosphere/dcos-commons\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/dcos-commons</a></p>\n\n<p>Mesos &amp; DC/OS also gives you more options on containerization. You can use Docker images and Docker containers, if you like. Or you can use the Mesos container runtime with or without Docker images, which gives you more flexibility in terms of workloads and packaging.</p>\n\n<p>DC/OS and Kubernetes both have package managers, as well, which can be useful for installing dependencies like Spark, Kafka, or Cassandra. But DC/OS tends to have more robust data services, because they're built with their own custom schedulers, whereas the Kubernetes ecosystem tends to make complex lifecycle managing Docker container wrappers around their systems due to the late arrival of custom schedulers. Docker also sort of includes package management if you consider docker images \"packages\". The difference is that DC/OS and Kubernetes package higher level abstractions (apps &amp; pods) which may include multiple containers. More recently, Docker has added \"stacks\" which are higher level abstractions, but I don't think there's any external repository mechanism or much package management around them.</p>\n\n<p>Swarm is definitely the simplest, but its original API was designed to be the same as the node API, which was great for familiarity and onboarding, but rather limiting as a higher level abstraction. They've since effectively rewritten the swarm API and bundled it into docker-engine as \"swarm-mode\". This bundling of the orchestration engine and container runtime makes it easier for the user to install and manage but also combines what was previously two different abstraction levels. So instead of being just a dependency of orchestration engines, Docker engine now competes with them as well, going against the unix philosophy of doing one thing well and making for a bit of a political mess in the respective open source communities. Twitter, hacker news, and chat conversations escalated into talk of <a href=\"http://thenewstack.io/docker-fork-talk-split-now-table/\" rel=\"nofollow noreferrer\">forking docker</a> which lead to <a href=\"http://thenewstack.io/oci-building-way-kubernetes-run-containers-without-docker/\" rel=\"nofollow noreferrer\">K8s experimenting on alternatives</a>, <a href=\"https://mesosphere.com/blog/2016/09/30/dcos-universal-container-runtime/\" rel=\"nofollow noreferrer\">DC/OS supporting Docker images without using Docker engine</a>, and <a href=\"https://www.docker.com/docker-news-and-press/docker-extracts-and-donates-containerd-its-core-container-runtime-accelerate\" rel=\"nofollow noreferrer\">Docker extracting containerd</a>.</p>\n\n<p>They all work fine. Selecting one kind of depends on your needs. I generally recommend DC/OS because it tackles a larger set of problems and is made up of many distinct microservice tools and layers, allowing you support multiple use cases by programming against the layer than makes the most sense. Disclosure tho, I do work for Mesosphere! ;)</p>\n", "answer_id": 41249030, "last_activity_date": 1483749629, "creation_date": 1482258715, "score": 6, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "last_edit_date": 1483749629, "question_id": 41248317}], "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "view_count": 494, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41248317}{"body": "<p>I am quite new to Service Discovery and clustered systems. I started experimenting with Mesos and Marathon for the deployment of Docker containers, the Marathon REST API and UI seem to do a good job. </p>\n\n<p>My problem is the actual discovery of deployed services. For testing purposes I deployed a Kafka Cluster scaled to 3 instances via Marathon, as so I did with a MongoDB test-cluster. The Mesos-DNS client gives me a record like <code>kafka.marathon.mesos</code> and <code>mongo.marathon.mesos</code> which implies the dynamically mapped port from the host to the container. The problem is, that my client explicitly needs information about the target port. Is there a general way to get those port information from the service automatically and dymanically? What about apps exposing multiple ports?</p>\n\n<p>My thougts so far: \n- Doing a REST call to get a status about the deployed app and somehow extract the relevant data\n- Doing a DNS SRV lookup and somehow extract the relevant data\n- Having some kind of \"master\", statically bound to a port, with dynamic \"clients\".</p>\n\n<p>I searched a lot for those informations but in the end most of the tutorials ended with a manual lookup which is not what I aim for. </p>\n", "is_answered": true, "tags": ["dns", "mesos", "service-discovery", "mesosphere", "marathon"], "title": "mesos-dns, best practice for working with ports", "last_activity_date": 1434889037, "answer_count": 1, "creation_date": 1434626889, "score": 11, "link": "https://stackoverflow.com/questions/30914110/mesos-dns-best-practice-for-working-with-ports", "answers": [{"body": "<p>You're spot on. I recently gave a <a href=\"https://xebicon.nl/slides/michael-hausenblas.pdf\" rel=\"nofollow\">presentation</a> at XebiCon around this topic and plan to publish a blog post with details about the setup incl. GitHub repo. For starters you could have a look at a <a href=\"https://github.com/mhausenblas/mc\" rel=\"nofollow\">Python implementation</a> for the HTTP API consumption part.</p>\n\n<p>UPDATE: the blog post is now available <a href=\"https://mesosphere.com/blog/2015/06/21/web-application-analytics-using-docker-and-marathon/\" rel=\"nofollow\">here</a>.</p>\n", "answer_id": 30919580, "last_activity_date": 1434889037, "creation_date": 1434641071, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "last_edit_date": 1434889037, "question_id": 30914110}], "owner": {"user_id": 1398661, "profile_image": "https://www.gravatar.com/avatar/35f3ba49dbbb0827a0c325894355b55a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 90, "link": "https://stackoverflow.com/users/1398661/ummecasino", "accept_rate": 50, "display_name": "ummecasino"}, "view_count": 1069, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30914110}{"is_answered": true, "tags": ["dcos"], "title": "DCOS navstar service failed to start on agent nodes", "last_activity_date": 1490053618, "answer_count": 2, "creation_date": 1489863169, "score": 2, "link": "https://stackoverflow.com/questions/42878527/dcos-navstar-service-failed-to-start-on-agent-nodes", "accepted_answer_id": 42880652, "owner": {"user_id": 7723636, "profile_image": "https://i.stack.imgur.com/w8wQQ.jpg?s=128&g=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7723636/don-cook", "display_name": "Don Cook"}, "view_count": 491, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 42878527}{"body": "<p>I'm new to Mesos. I would like to know how do I know whether Mesos master is set up correctly in the node?</p>\n\n<p>I have follow the set up given by <a href=\"http://mesos.apache.org/gettingstarted/\" rel=\"nofollow\">http://mesos.apache.org/gettingstarted/</a></p>\n\n<p>I am unable to run the following command:</p>\n\n<p>Comment: Start mesos master (Ensure work directory exists and has proper permissions).</p>\n\n<blockquote>\n  <p>$ ./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos</p>\n</blockquote>\n\n<p>but it shown error given:</p>\n\n<blockquote>\n  <p>./bin/mesos-master.sh: line 24: /home/user/mesos-0.20.0/build/src/mesos-master: No such file or directory</p>\n</blockquote>\n\n<p>What ways should I proceed? </p>\n", "is_answered": true, "tags": ["mesos", "mesosphere"], "title": "How to check Mesos Master?", "last_activity_date": 1489480834, "answer_count": 3, "creation_date": 1420682882, "score": 0, "link": "https://stackoverflow.com/questions/27831872/how-to-check-mesos-master", "answers": [{"body": "<p>First, a few questions to help us debug your build:</p>\n\n<ul>\n<li>Did the mesos build (<code>make</code>) complete successfully, and did <code>make check</code> pass all the tests?</li>\n<li>If <code>/home/user/mesos-0.20.0/build/src/mesos-master</code> does exist, do you have execute permissions on it?</li>\n<li>Are you running <code>./bin/mesos-master.sh</code> from within <code>/home/user/mesos-0.20.0/build/</code>, or did you move the directory elsewhere?</li>\n</ul>\n\n<p>If this is your first attempt at Mesos and you just want to run it and try it out (rather than fix bugs and develop features for it). I would recommend using a pre-built or cloud-deployed version of Mesos, rather than trying to build it yourself. See:</p>\n\n<ul>\n<li><a href=\"http://mesosphere.com/downloads/\" rel=\"nofollow\">http://mesosphere.com/downloads/</a></li>\n<li><a href=\"http://mesosphere.com/downloads/details/index.html#apache-mesos\" rel=\"nofollow\">http://mesosphere.com/downloads/details/index.html#apache-mesos</a></li>\n</ul>\n", "answer_id": 27836289, "last_activity_date": 1420707635, "creation_date": 1420707635, "score": 2, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 27831872}, {"body": "<p>I'd suggest to follow <a href=\"http://mesos.apache.org/documentation/latest/getting-started/\" rel=\"nofollow noreferrer\">Mesos Getting Started documentation</a>.</p>\n\n<p>After your system requirements are satisfied, following the section:</p>\n\n<blockquote>\n  <p>System Requirements</p>\n</blockquote>\n\n<p>Once you reach the following section:</p>\n\n<blockquote>\n  <p>Building Mesos</p>\n</blockquote>\n\n<p>when you execute the <code>make</code> without disabling verbosity, ensure that all process completed successfully. If it stops (e.g. tipically for proxy related issues) try to fix it accordingly or otherwise post your stack somewhere and I would be happy to help (if I can).</p>\n\n<p>Unfortunately, running <code>make check</code> could not reveal the problem sometimes.</p>\n", "answer_id": 40512077, "last_activity_date": 1478710145, "creation_date": 1478710145, "score": 0, "owner": {"user_id": 2215073, "profile_image": "https://www.gravatar.com/avatar/a4850327599b06ea896ff438f7a6049d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 36, "link": "https://stackoverflow.com/users/2215073/momo", "accept_rate": 25, "display_name": "Momo"}, "is_accepted": false, "question_id": 27831872}, {"body": "<p>Have you run the <code>make check</code> command ? It is said in the documentation that the binaries will only be available after running the <code>make check</code>command.\u00cc faced the same issue and it was because i didn't run that command.</p>\n", "answer_id": 42781245, "last_activity_date": 1489480834, "creation_date": 1489480834, "score": 0, "owner": {"user_id": 7683446, "profile_image": "https://www.gravatar.com/avatar/1236166dde8af45ebd5ab4830d0b2472?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/7683446/the-irick", "display_name": "The iRick"}, "is_accepted": false, "question_id": 27831872}], "owner": {"user_id": 4136080, "profile_image": "https://www.gravatar.com/avatar/b285808edcd401bf4ac7d8cb42b943d3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 50, "link": "https://stackoverflow.com/users/4136080/user4136080", "accept_rate": 16, "display_name": "user4136080"}, "view_count": 843, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 27831872}{"body": "<p>I recently came across Apache Mesos and successfully deployed my Storm topology over Mesos.</p>\n\n<p>I want to try running Storm topology/Hadoop jobs over Apache Marathon (had issues running Storm directly on Apache Mesos using mesos-storm framework).</p>\n\n<p>I couldn't find any tutorial/article that could list steps how to launch a Hadoop/Spark tasks from Apache Marathon.</p>\n\n<p>It would be great if anyone could provide any help or information on this topic (possibly a Json job definition for Marathon for launching storm/hadoop job).</p>\n\n<p>Thanks a lot</p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "title": "Running Hadoop/Storm tasks on Apache Marathon", "last_activity_date": 1420819046, "answer_count": 2, "creation_date": 1417990928, "score": 1, "link": "https://stackoverflow.com/questions/27348576/running-hadoop-storm-tasks-on-apache-marathon", "answers": [{"body": "<p>Marathon is intended for long-running services, so you could use it to start your JobTracker or Spark scheduler, but you're better off launching the actual batch jobs like Hadoop/Spark tasks on a batch framework like Chronos (<a href=\"https://github.com/airbnb/chronos\" rel=\"nofollow\">https://github.com/airbnb/chronos</a>). Marathon will restart tasks when the complete/fail, whereas Chronos (a distributed cron with dependencies) lets you set up scheduled jobs and complex workflows.</p>\n\n<p>While a little outdated, the following tutorial gives a good example.</p>\n\n<p><a href=\"http://mesosphere.com/docs/tutorials/etl-pipelines-with-chronos-and-hadoop/\" rel=\"nofollow\">http://mesosphere.com/docs/tutorials/etl-pipelines-with-chronos-and-hadoop/</a></p>\n", "answer_id": 27641196, "last_activity_date": 1419447541, "creation_date": 1419447541, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 27348576}, {"body": "<p>Thanks for your reply, I went ahead and deployed a Storm-Docker cluster on Apache Mesos with Marathon. For service discovery I used HAProxy. This setup allows services (nimbus or zookeeper etc) to talk to each other with the help of ports, so for example adding multiple instances for a service is not a problem since the cluster will find them using the ports and loadbalance the requests between all the instances of a service. Following is the GitHub project which has the Marathon recipes and Docker images: <a href=\"https://github.com/obaidsalikeen/storm-marathon\" rel=\"nofollow\">https://github.com/obaidsalikeen/storm-marathon</a></p>\n", "answer_id": 27864396, "last_activity_date": 1420819046, "creation_date": 1420819046, "score": 1, "owner": {"user_id": 3938228, "profile_image": "https://www.gravatar.com/avatar/4c843756c8312dc9c607415e0a35bc28?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/3938228/obaid", "accept_rate": 50, "display_name": "obaid"}, "is_accepted": false, "question_id": 27348576}], "owner": {"user_id": 3938228, "profile_image": "https://www.gravatar.com/avatar/4c843756c8312dc9c607415e0a35bc28?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 60, "link": "https://stackoverflow.com/users/3938228/obaid", "accept_rate": 50, "display_name": "obaid"}, "view_count": 1688, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 27348576}{"body": "<p>I recently installed DC / OS ( <a href=\"https://dcos.io/\" rel=\"nofollow noreferrer\">https://dcos.io/</a> ) . For now, I use it for testing , so my architecture is composed of:\n- 1 node Boostrap\n- 1 Master node\n- 2 Slave node</p>\n\n<p>However, can you explain why DC / OS does not properly distributed services based on available resources on the various nodes ?</p>\n\n<p><img src=\"https://i.stack.imgur.com/5K2Vy.png\" alt=\"node-repartition-ressources\"></p>\n\n<p>In my case, all services are installed on the same node. If I have more resources on this node , DC / OS no longer allows me to install new services.</p>\n\n<p>Thank you in advance !</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "dcos"], "last_edit_date": 1469780049, "title": "DC/OS - Distributed services", "last_activity_date": 1470300816, "answer_count": 1, "creation_date": 1469779196, "score": 0, "link": "https://stackoverflow.com/questions/38653506/dc-os-distributed-services", "answers": [{"body": "<p>You have configured the second node as a public agent.</p>\n\n<p>If you want to deploy your service on the public agent, you have to set \"slave_public\" in Deploy New(or Edit) Service -> Optional -> Accepted Resource Roles.</p>\n", "answer_id": 38762766, "last_activity_date": 1470300816, "creation_date": 1470300816, "score": 0, "owner": {"user_id": 5005578, "profile_image": "https://www.gravatar.com/avatar/9e8ec328bdfb6b711d823e675442de6a?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5005578/olek", "display_name": "olek"}, "is_accepted": false, "question_id": 38653506}], "owner": {"user_id": 6591122, "profile_image": "https://graph.facebook.com/10209978931139251/picture?type=large", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/6591122/benjamin-carriou", "display_name": "Benjamin Carriou"}, "view_count": 66, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38653506}{"body": "<p>I am trying to install mesos package according to <a href=\"https://open.mesosphere.com/getting-started/install/#slave-setup\" rel=\"nofollow\">https://open.mesosphere.com/getting-started/install/#slave-setup</a> but, when  I run <code>yum install mesos</code>, transaction abort with error message: </p>\n\n<pre><code>Error unpacking rpm package mesos-1.0.1-2.0.93.centos65.x86_64\nerror: unpacking of archive failed on file /usr/lib/libmesos-1.0.1.so;57c7a348: cpio: read\nFailed:\n  mesos.x86_64 0:1.0.1-2.0.93.centos65\n</code></pre>\n\n<p>any pointers? or is the packaging of this particular version corrupted?</p>\n\n<p>I tried <code>mesos.x86_64 0:1.0.0-2.0.89.centos65</code> which seems to be working.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1472823160, "title": "Unable to install mesos on centos 6.5", "last_activity_date": 1480361070, "answer_count": 2, "creation_date": 1472702216, "score": 0, "link": "https://stackoverflow.com/questions/39262475/unable-to-install-mesos-on-centos-6-5", "answers": [{"body": "<p>[Updated:]  A new RPM which fixes this error, 1.0.1-2.0.96, has been generated and is available for download at <a href=\"https://open.mesosphere.com/downloads/mesos/\" rel=\"nofollow\">https://open.mesosphere.com/downloads/mesos/</a>.  (Thanks @js84)</p>\n", "answer_id": 39375163, "last_activity_date": 1476711238, "creation_date": 1473265873, "score": -1, "owner": {"user_id": 4995291, "profile_image": "https://www.gravatar.com/avatar/2f1d94d1cc4303b99605d2f455b935c5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/4995291/david-mcwhorter", "display_name": "David McWhorter"}, "is_accepted": false, "last_edit_date": 1476711238, "question_id": 39262475}, {"body": "<p>The current mesos 1.x.x RPM installers do not handle upgrades from mesos versions &lt; 1.0 gracefully in CentOS 6.X. A yum update of mesos from 0.28 to 1.1.0 produces the following error:</p>\n\n<pre><code>Running Transaction\n  Updating   : mesos-1.1.0-2.0.107.centos65.x86_64\nError unpacking rpm package mesos-1.1.0-2.0.107.centos65.x86_64\nerror: unpacking of archive failed on file /usr/include/mesos/slave: cpio: rename\n</code></pre>\n\n<p>The workaround is to run:</p>\n\n<pre><code>rm -rf /usr/include/mesos/slave\n</code></pre>\n\n<p>And then re-run yum update (or whatever RPM management command you are using to upgrade mesos).</p>\n\n<p>Source: <a href=\"https://github.com/mesosphere/mesos-deb-packaging/issues/87\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/mesos-deb-packaging/issues/87</a></p>\n", "answer_id": 40851938, "last_activity_date": 1480361070, "creation_date": 1480361070, "score": 0, "owner": {"user_id": 2487185, "profile_image": "https://i.stack.imgur.com/SvOvk.jpg?s=128&g=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/2487185/dt", "display_name": "DT_"}, "is_accepted": false, "question_id": 39262475}], "owner": {"user_id": 6781384, "profile_image": "https://www.gravatar.com/avatar/ba49f12d347089dcfbf5cad9de53b09d?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6781384/sanjay", "display_name": "Sanjay"}, "view_count": 213, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 39262475}{"body": "<p>How to deploy and run DC/OS on AWS Free Tier?\nThe Free Tier allows only <code>t2.micro</code> instances only and gives 750h/month free.</p>\n\n<p>I tried to edit the DC/OS Amazon S3 template replacing the <code>m3.xlarge</code> instances with <code>t2.micro</code> but the deployment failed.</p>\n\n<p>The error I got was:</p>\n\n<pre><code>The following resource(s) failed to create: [PublicSlaveServerGroup, SlaveServerGroup]. . Rollback requested by user.\n\nCREATE_FAILED   AWS::AutoScaling::AutoScalingGroup  PublicSlaveServerGroup  Virtualization type 'hvm' is required for instances of type 't2.micro'. \n\nEnsure that you are using an AMI with virtualization type 'hvm'. For more information, see http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/virtualization_types.html. Launching EC2 instance failed.\n</code></pre>\n", "is_answered": true, "title": "DC/OS on AWS Free Tier", "last_edit_date": 1502692775, "tags": ["amazon-web-services", "dcos"], "view_count": 38, "accepted_answer_id": 45680279, "last_activity_date": 1502992715, "answers": [{"body": "<p>DC/OS does not operate within a small enough resource envelope to be run on free-tier AWS EC2 instances.</p>\n\n<p>Specifically, DC/OS networking components require at least 2 cores per node.</p>\n\n<p>t2.micro (free tier) has only 1 vCPU and 1 GB memory.</p>\n\n<p>Aside from the hard CPU constraint, DC/OS consists of >30 component services which can use a significant amount of memory, especially on master nodes. While it may be possible to deploy DC/OS masters with 1 GB memory, virtual memory, and swapping, the experience will not be enjoyable. Agents with 1 GB memory will have half of that reserved for the system, and half for user tasks, which means you wont be able to deploy much.</p>\n\n<p>If you want to try DC/OS for free, try the containerized or virtualized local deployments: </p>\n\n<ul>\n<li><a href=\"https://github.com/dcos/dcos-docker\" rel=\"nofollow noreferrer\">https://github.com/dcos/dcos-docker</a></li>\n<li><a href=\"https://github.com/dcos/dcos-vagrant\" rel=\"nofollow noreferrer\">https://github.com/dcos/dcos-vagrant</a></li>\n</ul>\n", "answer_id": 45680279, "last_activity_date": 1502992715, "creation_date": 1502733403, "score": 1, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "last_edit_date": 1502992715, "question_id": 45668620}], "score": 0, "link": "https://stackoverflow.com/questions/45668620/dc-os-on-aws-free-tier", "answer_count": 1, "owner": {"user_id": 5314214, "profile_image": "https://lh4.googleusercontent.com/-6GDfPZnUjLg/AAAAAAAAAAI/AAAAAAAAAEE/7shbkutOcvM/photo.jpg?sz=128", "user_type": "registered", "reputation": 169, "link": "https://stackoverflow.com/users/5314214/beckham", "accept_rate": 89, "display_name": "Beckham"}, "creation_date": 1502692209, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45668620}{"body": "<p>How can I communicate a Rails application with a Postgres DB using Zookeeper, Marathon and Mesos? Obviously I can't hardcode storage locations under database.yml</p>\n", "is_answered": true, "title": "Connecting rails with storage services on a mesos cluster", "tags": ["ruby-on-rails", "postgresql", "service-discovery", "mesos", "mesosphere"], "last_activity_date": 1407768572, "accepted_answer_id": 25246124, "creation_date": 1407267514, "answers": [{"body": "<p>Task storage on Mesos is currently ephemeral, meaning if you were to run Postgres via Marathon and the task was somehow lost, you would lose your database's data. The Mesos team is currently (as of 2014-08-11) discussing ways to support persistent storage: <a href=\"https://issues.apache.org/jira/browse/MESOS-1554\" rel=\"noreferrer\">https://issues.apache.org/jira/browse/MESOS-1554</a></p>\n\n<p>Until Mesos supports persistent storage, you should run your database separate from Mesos and give your Rails app (running on Marathon + Mesos) static credentials to it in \"database.yml\".</p>\n", "answer_id": 25246124, "last_activity_date": 1407768572, "creation_date": 1407768572, "score": 5, "owner": {"user_id": 368697, "profile_image": "https://www.gravatar.com/avatar/c475e54af82ab6d5ee5bffea9b948c14?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 26795, "link": "https://stackoverflow.com/users/368697/ross-allen", "display_name": "Ross Allen"}, "is_accepted": true, "question_id": 25146954}], "score": 1, "link": "https://stackoverflow.com/questions/25146954/connecting-rails-with-storage-services-on-a-mesos-cluster", "answer_count": 1, "owner": {"user_id": 829928, "profile_image": "https://www.gravatar.com/avatar/8f2a2dbbd68def108e07d81b32f1df53?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1334, "link": "https://stackoverflow.com/users/829928/carlos-castellanos", "accept_rate": 83, "display_name": "Carlos Castellanos"}, "view_count": 842, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 25146954}{"body": "<p>I have been following this tutorial <a href=\"https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04\" rel=\"nofollow\">How to configure a production ready Mesos cluster</a> and have been creating an ansible playbook along the way which you can see here <a href=\"https://github.com/Ir1sh/mesosplaybook\" rel=\"nofollow\">mesos ansible playbook</a></p>\n\n<p>Ansible runs successfully and I can visit my port 5050 on a master and see the mesos dashboard.  However there seems to be 3 problems which are hopefully all connected but seem seperate at face value.</p>\n\n<ol>\n<li>At the top of mesos dashboard it says no masters are currently leading</li>\n<li>No slaves are registered</li>\n<li>The Marathon dashboard does not work when I visit port 8080 on any of the masters</li>\n</ol>\n\n<p>Any ideas of what I have done wrong or if anything has changed since this tutorial was published?</p>\n\n<p>Edit: tried to dig in deeper.  After running ansible I logged into each node and restarted the mesos and marathon services myself manually.  This appeared to do the trick as I got to the marathon dashboard and then after a bit of fiddling on the slaves I could see those where activated as well.  Unfortunately I was not able to reproduce after nuking the nodes and rebuilding.  My settings are consistent with the tutorial I linked and the tutorial linked by Celine so I think it is the order I am doing my service restarts.  Still looking for any help</p>\n\n<p>Edit2: \nCopy of logs from one of the masters on startup the last http call just repeats and repeats</p>\n\n<blockquote>\n  <p>I1014 18:56:32.746968 11494 logging.cpp:172] INFO level logging\n  started! I1014 18:56:32.748177 11494 main.cpp:229] Build: 2015-10-12\n  20:57:28 by root I1014 18:56:32.748277 11494 main.cpp:231] Version:\n  0.25.0 I1014 18:56:32.748345 11494 main.cpp:234] Git tag: 0.25.0 I1014 18:56:32.748406 11494 main.cpp:238] Git SHA:\n  2dd7f7ee115fe00b8e098b0a10762a4fa8f4600f I1014 18:56:32.748615 11494\n  main.cpp:252] Using 'HierarchicalDRF' allocator I1014 18:56:32.759768\n  11494 leveldb.cpp:176] Opened db in 10.929155ms I1014 18:56:32.763638\n  11494 leveldb.cpp:183] Compacted db in 3.722708ms I1014\n  18:56:32.763713 11494 leveldb.cpp:198] Created db iterator in 33931ns\n  I1014 18:56:32.763761 11494 leveldb.cpp:204] Seeked to beginning of db\n  in 8624ns I1014 18:56:32.764142 11494 leveldb.cpp:273] Iterated\n  through 1 keys in the db in 352415ns I1014 18:56:32.764263 11494\n  replica.cpp:744] Replica recovered with log positions 0 -> 0 with 1\n  holes and 0 unlearned I1014 18:56:32.767266 11520 log.cpp:238]\n  Attempting to join replica to ZooKeeper group I1014 18:56:32.767493\n  11520 recover.cpp:449] Starting replica recovery I1014 18:56:32.767623\n  11520 recover.cpp:475] Replica is in VOTING status I1014\n  18:56:32.767695 11520 recover.cpp:464] Recover process terminated\n  I1014 18:56:32.775274 11494 main.cpp:465] Starting Mesos master I1014\n  18:56:32.779567 11516 master.cpp:376] Master\n  75abeaaa-a949-45a3-bd85-bebf100eecad (159.203.107.10) started on\n  159.203.107.10:5050 I1014 18:56:32.779597 11516 master.cpp:378] Flags at startup: --allocation_interval=\"1secs\"\n  --allocator=\"HierarchicalDRF\" --authenticate=\"false\" --authenticate_slaves=\"false\" --authenticators=\"crammd5\" --authorizers=\"local\" --framework_sorter=\"drf\" --help=\"false\" --hostname=\"159.203.107.10\" --hostname_lookup=\"true\" --initialize_driver_logging=\"true\" --ip=\"159.203.107.10\" --log_auto_initialize=\"true\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --max_slave_ping_timeouts=\"5\" --port=\"5050\" --quiet=\"false\" --quorum=\"1\" --recovery_slave_removal_limit=\"100%\" --registry=\"replicated_log\" --registry_fetch_timeout=\"1mins\" --registry_store_timeout=\"5secs\" --registry_strict=\"false\" --root_submissions=\"true\" --slave_ping_timeout=\"15secs\" --slave_reregister_timeout=\"10mins\" --user_sorter=\"drf\" --version=\"false\" --webui_dir=\"/usr/share/mesos/webui\" --work_dir=\"/var/lib/mesos\" --zk=\"zk://159.203.107.10:2181,159.203.107.151:2181,159.203.107.162:2181/mesos\"\n  --zk_session_timeout=\"10secs\" I1014 18:56:32.779762 11516 master.cpp:425] Master allowing unauthenticated frameworks to register\n  I1014 18:56:32.779770 11516 master.cpp:430] Master allowing\n  unauthenticated slaves to register I1014 18:56:32.779778 11516\n  master.cpp:467] Using default 'crammd5' authenticator W1014\n  18:56:32.779798 11516 authenticator.cpp:505] No credentials provided,\n  authentication requests will be refused I1014 18:56:32.779906 11516\n  authenticator.cpp:512] Initializing server SASL I1014 18:56:32.791836\n  11515 master.cpp:1542] Successfully attached file\n  '/var/log/mesos/mesos-master.INFO' I1014 18:56:32.792043 11519\n  contender.cpp:149] Joining the ZK group I1014 18:56:34.968217 11517\n  http.cpp:336] HTTP GET for /master/state.json from 12.228.115.34:40863\n  with User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)\n  AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101\n  Safari/537.36' I1014 18:56:45.242039 11518 http.cpp:336] HTTP GET for\n  /master/state.json from 12.228.115.34:63018 with\n  User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)\n  AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101\n  Safari/537.36' I1014 18:56:55.319259 11519 http.cpp:336] HTTP GET for\n  /master/state.json from 12.228.115.34:50024 with\n  User-Agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 1</p>\n</blockquote>\n\n<p>Thanks</p>\n", "is_answered": true, "title": "Setting up Mesos with Ansible on Ubuntu 14.04 on Digital Ocean", "last_edit_date": 1444863513, "tags": ["ansible", "digital-ocean", "mesos", "mesosphere", "marathon"], "view_count": 667, "accepted_answer_id": 33680177, "last_activity_date": 1447358099, "answers": [{"body": "<p>The first problem <em>\"no masters are currently leading\"</em> is usually due to an issue with zookeeper. </p>\n\n<p>Check that zookeeper is running on your server. This would also explain the issue you have with Marathon and the mesos slaves. </p>\n\n<p>This documentation seems more up to date: <a href=\"http://open.mesosphere.com/getting-started/datacenter/install/\" rel=\"nofollow\">http://open.mesosphere.com/getting-started/datacenter/install/</a></p>\n", "answer_id": 32997630, "last_activity_date": 1444236591, "creation_date": 1444235304, "score": 2, "owner": {"user_id": 2339082, "profile_image": "https://www.gravatar.com/avatar/16dcbdda62178dd82d4599393bdd590f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4411, "link": "https://stackoverflow.com/users/2339082/c%c3%a9line-aussourd", "display_name": "C\u00e9line Aussourd"}, "is_accepted": false, "last_edit_date": 1444236591, "question_id": 32874064}, {"body": "<p>This was a zookeeper config problem.  None of the tutorials mention needing to set values in zoo.cfg besides listing the server ips.  You also need to set dataDir, syncLimit, initLimit, tickTime and clientPort</p>\n", "answer_id": 33680177, "last_activity_date": 1447358099, "creation_date": 1447358099, "score": 1, "owner": {"user_id": 2535126, "profile_image": "https://www.gravatar.com/avatar/9ba5862bd06ed58daef0b0592e2971b9?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1325, "link": "https://stackoverflow.com/users/2535126/ir1sh", "accept_rate": 88, "display_name": "Ir1sh"}, "is_accepted": true, "question_id": 32874064}], "score": 6, "link": "https://stackoverflow.com/questions/32874064/setting-up-mesos-with-ansible-on-ubuntu-14-04-on-digital-ocean", "answer_count": 2, "owner": {"user_id": 2535126, "profile_image": "https://www.gravatar.com/avatar/9ba5862bd06ed58daef0b0592e2971b9?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1325, "link": "https://stackoverflow.com/users/2535126/ir1sh", "accept_rate": 88, "display_name": "Ir1sh"}, "creation_date": 1443640949, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 32874064}{"is_answered": true, "tags": ["dcos"], "title": "Why does dcos package fail with &quot;URL is unreachable: Max retries exceeded with url: /package/list&quot; after installing another DC/OS cluster?", "last_activity_date": 1483969305, "answer_count": 1, "creation_date": 1483969305, "score": 0, "link": "https://stackoverflow.com/questions/41549398/why-does-dcos-package-fail-with-url-is-unreachable-max-retries-exceeded-with-u", "owner": {"user_id": 1305344, "profile_image": "https://i.stack.imgur.com/G1CaA.png?s=128&g=1", "user_type": "registered", "reputation": 27951, "link": "https://stackoverflow.com/users/1305344/jacek-laskowski", "accept_rate": 70, "display_name": "Jacek Laskowski"}, "view_count": 109, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41549398}{"body": "<p>I'm attempting the (potentially foolish) task of Dockerizing Zookeeper/Marathon/Mesos and deploying Docker containers <em>from</em> the Dockerized Mesos cluster.</p>\n\n<p>So far, I have a working Mesos cluster on two physically separate nodes: one node is running both a Mesos <a href=\"https://registry.hub.docker.com/u/magsol/lj-mesos-master/dockerfile/\" rel=\"nofollow noreferrer\">master</a> and a <a href=\"https://registry.hub.docker.com/u/magsol/lj-mesos-slave/dockerfile/\" rel=\"nofollow noreferrer\">slave</a> (container Dockerfiles linked), and the second node is running just a slave. They seem to be functioning just fine; I am able to submit very simple jobs through Marathon (also its own container, running on the node with the master and slave) and they complete successfully.</p>\n\n<p>However, when I attempt to <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow noreferrer\">submit Docker containers through the Marathon API</a>, it <em>seems</em> to hang. The Marathon interface hangs at \"Deploying\" and never changes, even after letting it sit for 15 minutes, stopping, resubmitting, and letting it sit for another 15 minutes.</p>\n\n<p><img src=\"https://i.stack.imgur.com/1C6rJ.png\" alt=\"Marathon UI, depicting seemingly frozen deployment of Docker task\"></p>\n\n<p>At the same time, tasks are nonetheless being submitted to the Mesos slaves; the Mesos UI is reporting FAILED tasks left and right.</p>\n\n<p><img src=\"https://i.stack.imgur.com/7QvZt.png\" alt=\"Mesos UI, depicting failed tasks\"></p>\n\n<p><strong><em>EDIT 1</em></strong></p>\n\n<p>The resulting Sandbox logs for each of the executors are also completely empty.</p>\n\n<p><img src=\"https://i.stack.imgur.com/JUbgo.png\" alt=\"empty sandbox\"></p>\n\n<p><strong><em>EDIT 2</em></strong></p>\n\n<p>Found something interesting buried in the slave logs:</p>\n\n<p><img src=\"https://i.stack.imgur.com/TQ1KU.png\" alt=\"slave logs\"></p>\n\n<p>Line of interest:</p>\n\n<blockquote>\n  <p>None of the enabled containerizers (mesos) could create a container for the provided TaskInfo/ExecutorInfo message.</p>\n</blockquote>\n\n<p>It looks like the containerizer is failing to run, and from what I can see, it's not even considering docker as a containerizer. I followed the configuration <a href=\"https://open.mesosphere.com/tutorials/launch-docker-container-on-mesosphere/\" rel=\"nofollow noreferrer\">here</a> to deploy Docker jobs; does this change if the Mesos slaves are themselves Docker containers?</p>\n\n<p>I'm somewhat out of my element and can't find any references along these lines. Any idea what's happening?</p>\n", "is_answered": true, "title": "Docker app deployment hangs on Marathon, fails on Mesos", "last_edit_date": 1436808005, "tags": ["docker", "mesos", "mesosphere", "marathon"], "view_count": 2018, "accepted_answer_id": 31400697, "last_activity_date": 1436860008, "answers": [{"body": "<p>What's your <code>docker run</code> command for the slave?\nHere are a few parameters others have found useful:</p>\n\n<blockquote>\n<pre><code>--net host \\\n--pid host \\\n--privileged \\\n--env MESOS_CONTAINERIZERS=docker,mesos \\\n--env MESOS_EXECUTOR_REGISTRATION_TIMEOUT=5mins \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-v /sys:/sys:ro \\\n-v /usr/bin/docker:/usr/bin/docker:ro \\\n-v /lib64/libdevmapper.so.1.02:/lib/libdevmapper.so.1.02:ro \\\n-v /home/core/.dockercfg:/root/.dockercfg:ro \\\n</code></pre>\n</blockquote>\n\n<p>Also note that you shouldn't name the container <code>mesos-slave</code> as the slave will try to remove any containers prefixed with <code>mesos-</code> upon recovery.</p>\n\n<p>FYI, Mesos uses the <code>docker --version</code> command to see if the docker containerizer can be used. Try launching a Marathon task that just runs <code>docker --version</code> to see if that would work inside your dockerized slave's environment.</p>\n", "answer_id": 31400697, "last_activity_date": 1436860008, "creation_date": 1436860008, "score": 4, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "question_id": 31350372}], "score": 2, "link": "https://stackoverflow.com/questions/31350372/docker-app-deployment-hangs-on-marathon-fails-on-mesos", "answer_count": 1, "owner": {"user_id": 13604, "profile_image": "https://www.gravatar.com/avatar/5d68b1da6452d49f95cfcc937cd5a39d?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2235, "link": "https://stackoverflow.com/users/13604/magsol", "accept_rate": 95, "display_name": "Magsol"}, "creation_date": 1436562804, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31350372}{"body": "<p>I was wondering if Google Kubernetes is able to run Apache Mesos frameworks, such as Hadoop or Cassandra etc.., like applications running on top of it. If yes or no, please justify your answers. Thank you.</p>\n", "is_answered": true, "tags": ["docker", "kubernetes", "mesos", "mesosphere"], "last_edit_date": 1445961306, "title": "Can Google Kubernetes run Apache Mesos frameworks on top of it?", "last_activity_date": 1448583722, "answer_count": 4, "creation_date": 1445818369, "score": 0, "link": "https://stackoverflow.com/questions/33336591/can-google-kubernetes-run-apache-mesos-frameworks-on-top-of-it", "answers": [{"body": "<p>Yes and no - you can run applications in containers on kubernetes, and you can run kubernetes on mesos.</p>\n\n<p>In fact, Cassandra is one of the <a href=\"https://github.com/kubernetes/kubernetes/tree/master/examples/cassandra\" rel=\"nofollow\">standard kubernetes examples.</a> And there is an example of <a href=\"https://github.com/mesosphere/kubernetes-mesos\" rel=\"nofollow\">kubernetes on mesos</a>.</p>\n", "answer_id": 33336706, "last_activity_date": 1446030001, "creation_date": 1445819325, "score": 1, "owner": {"user_id": 2051454, "profile_image": "https://i.stack.imgur.com/sZBFW.jpg?s=128&g=1", "user_type": "registered", "reputation": 8799, "link": "https://stackoverflow.com/users/2051454/engineer-dollery", "accept_rate": 60, "display_name": "Engineer Dollery"}, "is_accepted": false, "last_edit_date": 1446030001, "question_id": 33336591}, {"body": "<p>No. In fact it's the other way round. Concerning benefits see also my presentation <a href=\"https://speakerdeck.com/mhausenblas/can-i-have-mesos-and-kubernetes\" rel=\"nofollow\">here</a>.</p>\n", "answer_id": 33375862, "last_activity_date": 1445970676, "creation_date": 1445970676, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 33336591}, {"body": "<p>Yes!</p>\n\n<p>The new \"DaemonSet\" abstraction in Kubernetes provides great support for running data processing and storage systems like HDFS and others relying on daemon-based architectures...</p>\n\n<p>\"Users might want to implement a sharded datastore in their (Kubernetes) cluster. A few nodes in the cluster, labeled \u2018app=datastore\u2019, might be responsible for storing data shards, and pods running on these nodes might serve data. This architecture requires a way to bind pods to specific nodes, so it cannot be achieved using a Replication Controller. A DaemonSet is a convenient way to implement such a datastore.\"</p>\n\n<p>See: <a href=\"https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/design/daemon.md\" rel=\"nofollow\">https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/design/daemon.md</a> </p>\n", "answer_id": 33769841, "last_activity_date": 1447807314, "creation_date": 1447807314, "score": 0, "owner": {"user_id": 4664490, "profile_image": "https://i.stack.imgur.com/h1K5Z.jpg?s=128&g=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/4664490/joseph-jacks", "display_name": "Joseph Jacks"}, "is_accepted": false, "question_id": 33336591}, {"body": "<p>There's conflicting answers, here. Let me try to clarify.</p>\n\n<p>Kubernetes and Mesos are both frameworks/platforms that are more like pets than cattle. In fact, they're a little bit of both. </p>\n\n<ul>\n<li>Both are backed by consistent, replicated, stateful storage (etcd/zookeeper). </li>\n<li>Both have master components that can be replicated (tho the k8s solution for this is somewhat immature and complicated). </li>\n<li>Both have agents that run on nodes that are not replicated and can be scaled out, to run other applications.</li>\n</ul>\n\n<p>Running pets is something that Kubernetes CAN now do, with the recent DaemonSets functionality, but it wasn't really designed with this capability in mind. And, IMO, it doesn't quite do well enough yet for production use. Kubernetes was originally designed to run cattle-like replicated containers. However, there is active development to improve running pet-like applications, especially to support bootstrapping, to run Kubernetes itself on Kubernetes nodes, using DaemonSets.</p>\n\n<p>Mesos, on the other hand, was designed explicitly to make these pet-like distributed systems easier to write and manage. It does this by effectively outsourcing the consistent state management, and providing a standard interface against with to write a framework/controller which can respond to cluster events with custom logic. It doesn't just treat every application the same way, it lets you program your own event handler code, specific to your pet-like application. This allows for more control. Obviously, cattle-like applications don't need this extra control. So to run cattle-like applications on Mesos you use an intermediate framework, like Marathon or Kubernetes, to implement the scheduling and event handling logic in a generic, declaratively configurable way.</p>\n\n<p>Disclaimer: I work on the <a href=\"https://github.com/mesosphere/kubernetes-mesos\" rel=\"nofollow\">Kubernetes-Mesos project</a> for running Kubernetes on Mesos/DCOS.</p>\n", "answer_id": 33948746, "last_activity_date": 1448583722, "creation_date": 1448583722, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 33336591}], "owner": {"user_id": 5487281, "profile_image": "https://graph.facebook.com/758873014217421/picture?type=large", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5487281/ahmed-azri", "display_name": "Ahmed Azri"}, "view_count": 524, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33336591}{"body": "<p>After I installed DC/OS, it prompts a login dialog with <code>login with Google/Github/Microsoft</code>, is it possible to login with a customized <code>user/pass</code> like <code>admin/admin</code>?</p>\n", "is_answered": true, "title": "Can I use other login method other than defaults in DC/OS", "tags": ["mesosphere", "dcos"], "last_activity_date": 1498661679, "accepted_answer_id": 44806007, "creation_date": 1496374532, "answers": [{"body": "<p>Open Source DC/OS does not allow for basic authentication. You can either use OAuth or \"NoAuth\". You can disable authentication via these instructions: <a href=\"https://dcos.io/docs/1.9/security/managing-authentication/#authentication-opt-out\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.9/security/managing-authentication/#authentication-opt-out</a>. However, if you go the \"NoAuth\" route you would not want to leave your cluster wide-open. You should set up a firewall or other means of access control around your DC/OS cluster.</p>\n", "answer_id": 44806007, "last_activity_date": 1498661679, "creation_date": 1498661679, "score": 1, "owner": {"user_id": 7451831, "profile_image": "https://www.gravatar.com/avatar/54f5aa0f205b100f309b95bf358b32e6?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/7451831/ashahan", "display_name": "ashahan"}, "is_accepted": true, "question_id": 44320351}], "score": 1, "link": "https://stackoverflow.com/questions/44320351/can-i-use-other-login-method-other-than-defaults-in-dc-os", "answer_count": 1, "owner": {"user_id": 2038901, "profile_image": "https://www.gravatar.com/avatar/88a2242eb110fda489eee0bcbde6f2bd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1980, "link": "https://stackoverflow.com/users/2038901/sato", "accept_rate": 97, "display_name": "Sato"}, "view_count": 17, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44320351}{"is_answered": true, "tags": ["cassandra", "mesos"], "last_edit_date": 1448011010, "title": "Why does installing Cassandra on Mesos via dcos package fail with &quot;Max retries exceeded with url: /marathon/v2/info&quot;?", "last_activity_date": 1448361625, "answer_count": 1, "creation_date": 1447958960, "score": 2, "link": "https://stackoverflow.com/questions/33812064/why-does-installing-cassandra-on-mesos-via-dcos-package-fail-with-max-retries-e", "owner": {"user_id": 3378649, "profile_image": "https://www.gravatar.com/avatar/247ba138c61c281fef494d080210bc11?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1392, "link": "https://stackoverflow.com/users/3378649/user3378649", "accept_rate": 36, "display_name": "user3378649"}, "view_count": 220, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 33812064}{"body": "<p>Q: I wish to SSH into a DC/OS public agent to mount my file share with Docker credentials, so I can deploy Docker via Marathon. <strong>How can I ssh directly into this agent node?</strong> Without going through master?</p>\n\n<hr>\n\n<p>Backstory: I did a vanilla DC/OS installation on Azure. I got two nodes provisioned (a master and an agent). I installed Marathon on the master.</p>\n\n<p><strong>First</strong>, I tried to deploy a container from an image/repo I created on Azure Container Registry, through Marathon. It failed because of CPU resource not being satisfied; that's partly understandable because it seems like Marathon sucks up the entire CPU of the master node. But I couldn't figure out how to make Marathon notice that there was another node around - the public agent node. The public agent node is running nothing.</p>\n\n<p><strong>Second</strong>, I figured I can just use the \"Service\" interface provided on the DC/OS layer itself (which I believe is just a UI layer for marathon or similar).</p>\n\n<p>This time, it accurately recognizes the agent node and that there is compute available on it. But to make it pull from my private registry, I need to put my Docker credentials on this node. Here's where I get stuck.  can't SSH to the agent node to mount the shared storage (which is mounted on the master already). Since this node is provisioned through the virtual machine scale set, I really can't figure out the right inbound NAT rules and network security configuration to map to this node and get me a reliable FQDN and port that will allow me to SSH in and run <code>cifs</code>. Honestly, DC/OS should have taken care of this for me, since I am doing the most standard thing.</p>\n\n<p>I tried this, but it isn't sufficient/correct (even though it creates the rule):</p>\n\n<pre><code>az network lb inbound-nat-rule create --resource-group production --lb-name &lt;lb-name&gt; --name NATRule --protocol TCP --frontend-port 2200 --backend-port 22\n</code></pre>\n\n<p>(All elaborate VMSS videos from Microsoft are for the old interface, and this idea of port range mapping, which I can't seem to figure out from the CLI. Plus, the portal is still in progress when it comes to inbound NAT rules)</p>\n\n<p>I am new to the Azure and DC/OS world (moving resources from AWS), so I'd appreciate the help.</p>\n\n<hr>\n\n<p><strong>UPDATE</strong>: Fwiw, turns out I tried the in-preview <em>DC/OS on Azure</em> service, as opposed to <em>DC/OS on Azure Container Service</em>, which is slightly unstable still. Launch containers through the \"Services\" interface on main DC/OS instead of on Marathon.</p>\n", "is_answered": true, "title": "SSH into a DC/OS created public agent node to deploy a Docker container?", "last_edit_date": 1497338235, "tags": ["azure", "docker", "marathon", "dcos"], "view_count": 205, "accepted_answer_id": 44493069, "last_activity_date": 1497338235, "answers": [{"body": "<blockquote>\n  <p>I really can't figure out the right inbound NAT rules and network\n  security configuration to map to this node and get me a reliable FQDN\n  and port that will allow me to SSH in and run cifs.</p>\n</blockquote>\n\n<p>For now, we can add inbound rule to VMss load balancer via CLI 2.0, but we can't use CLI 2.0 to sepcify target NIC, so we can't use NAT to ssh VMss instances.\n<a href=\"https://i.stack.imgur.com/uQKY2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/uQKY2.png\" alt=\"enter image description here\"></a></p>\n\n<p>If you only <strong>one</strong> instance in this VMSS, we can add a <strong>load balancer rule</strong> to ssh it. Add probe of port 22, and add load balancer rule of 22, after that we can ssh the VMSS public IP address with port 22.</p>\n\n<p>Another way, to login the DCOS node, we can <strong>via master  ssh to other nodes</strong>. For example, we can ssh to master then ssh to public agent. \n<a href=\"https://i.stack.imgur.com/CNaj1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CNaj1.png\" alt=\"enter image description here\"></a>\nHere a case talk about <strong>how to login DCOS agent via master</strong>, please refer to <a href=\"https://stackoverflow.com/questions/43638792/how-to-login-into-dc-os-slave-through-master/43647929#43647929\">it</a>.  </p>\n\n<p>After that, we can follow this <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-dcos-acr\" rel=\"nofollow noreferrer\">article</a> to <strong>mount Azure file share</strong> to your cluster nodes.</p>\n\n<p>By the way, we can create container via DC/OS UI, please refer to <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-mesos-marathon-ui\" rel=\"nofollow noreferrer\">it</a>.</p>\n", "answer_id": 44493069, "last_activity_date": 1497332110, "creation_date": 1497250491, "score": 1, "owner": {"user_id": 6851908, "profile_image": "https://www.gravatar.com/avatar/96ae2cbc5ed313e05565f7f869b5d3b2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 4831, "link": "https://stackoverflow.com/users/6851908/jason-ye-msft", "display_name": "Jason Ye - MSFT"}, "is_accepted": true, "last_edit_date": 1497332110, "question_id": 44490340}, {"body": "<p>Can you please describe what you are trying to achieve. You do describe what you have done and it all seems rather. There seem to be two things here:</p>\n\n<p>1) Use ACR with DC/OS - <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-dcos-acr\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-dcos-acr</a></p>\n\n<p>2) Provide access to a public container - see <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-enable-public-access</a></p>\n\n<p>If these don't give you what you need please edit your question to describe what you are trying to achieve.</p>\n", "answer_id": 44504929, "last_activity_date": 1497286862, "creation_date": 1497286862, "score": 1, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "question_id": 44490340}], "score": 0, "link": "https://stackoverflow.com/questions/44490340/ssh-into-a-dc-os-created-public-agent-node-to-deploy-a-docker-container", "answer_count": 2, "owner": {"user_id": 701723, "profile_image": "https://www.gravatar.com/avatar/1b9d0d1e4f25a6330354a9e7cce2422a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 127, "link": "https://stackoverflow.com/users/701723/varun-arora", "accept_rate": 75, "display_name": "Varun Arora"}, "creation_date": 1497231903, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44490340}{"body": "<p>I'm trying cassandra-mesos on my private cluster os mesos. I'm using Readme instruction to deploy with marathon but some error occure on wake up task and <strong>the framework never was registered:</strong></p>\n\n<p><strong>Stderr</strong> output:</p>\n\n<pre><code>I0925 15:55:06.185039  8383 fetcher.cpp:214] Fetching URI 'https://downloads.mesosphere.io/cassandra-mesos/artifacts/0.2.1-SNAPSHOT-589-master-4c6502b0a6/cassandra-mesos-0.2.1-SNAPSHOT-589-master-4c6502b0a6.tar.gz'\nI0925 15:55:06.185165  8383 fetcher.cpp:125] Fetching URI 'https://downloads.mesosphere.io/cassandra-mesos/artifacts/0.2.1-SNAPSHOT-589-master-4c6502b0a6/cassandra-mesos-0.2.1-SNAPSHOT-589-master-4c6502b0a6.tar.gz' with os::net\nI0925 15:55:06.185180  8383 fetcher.cpp:135] Downloading 'https://downloads.mesosphere.io/cassandra-mesos/artifacts/0.2.1-SNAPSHOT-589-master-4c6502b0a6/cassandra-mesos-0.2.1-SNAPSHOT-589-master-4c6502b0a6.tar.gz' to '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4/cassandra-mesos-0.2.0-1.tar.gz'\nI0925 15:56:07.968350  8383 fetcher.cpp:78] Extracted resource '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4/cassandra-mesos-0.2.0-1.tar.gz' into '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4'\nI0925 15:56:07.971684  8383 fetcher.cpp:214] Fetching URI 'https://downloads.mesosphere.io/java/jre-7u76-linux-x64.tar.gz'\nI0925 15:56:07.971709  8383 fetcher.cpp:125] Fetching URI 'https://downloads.mesosphere.io/java/jre-7u76-linux-x64.tar.gz' with os::net\nI0925 15:56:07.971725  8383 fetcher.cpp:135] Downloading 'https://downloads.mesosphere.io/java/jre-7u76-linux-x64.tar.gz' to '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4/jre-7u76-linux-x64.tar.gz'\nI0925 15:56:51.630692  8383 fetcher.cpp:78] Extracted resource '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4/jre-7u76-linux-x64.tar.gz' into '/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4'\nI0925 15:56:51.720883  8381 exec.cpp:132] Version: 0.22.1\nI0925 15:56:51.723655  8426 exec.cpp:206] Executor registered on slave 20150925-135709-503717292-5050-2136-S0\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@712: Client environment:zookeeper.version=zookeeper C client 3.4.5\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@716: Client environment:host.name=vcmms.domain.com\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@723: Client environment:os.name=Linux\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@724: Client environment:os.arch=3.19.3-1.el6.x86_64\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@725: Client environment:os.version=#1 SMP Mon Mar 30 13:50:16 EDT 2015\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@733: Client environment:user.name=(null)\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@741: Client environment:user.home=/root\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@log_env@753: Client environment:user.dir=/tmp/mesos/slaves/20150925-135709-503717292-5050-2136-S0/frameworks/20150925-144548-503717292-5050-5066-0001/executors/cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799/runs/e0aaadd9-9c86-47e1-8df8-d2c437f960f4\n2015-09-25 15:56:52,376:8432(0x7f3cb2ffd700):ZOO_INFO@zookeeper_init@786: Initiating client connection, host=172.29.6.30:2181 sessionTimeout=10000 watcher=0x7f3cee4ceeb0 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f3c9c000930 flags=0\n2015-09-25 15:56:52,377:8432(0x7f3cb17fa700):ZOO_INFO@check_events@1703: initiated connection to server [172.29.6.30:2181]\n2015-09-25 15:56:52,382:8432(0x7f3cb17fa700):ZOO_INFO@check_events@1750: session establishment complete on server [172.29.6.30:2181], sessionId=0x15005d328430014, negotiated timeout=10000\n</code></pre>\n\n<p>and <strong>Stdout</strong> output:</p>\n\n<pre><code>Registered executor on vcmms.domain.com\nStarting task cassandra-dev-test.51620664-63bf-11e5-b350-56847afe9799\nForked command at 8432\nsh -c '$(pwd)/jre*/bin/java $JAVA_OPTS -classpath cassandra-mesos-framework.jar io.mesosphere.mesos.frameworks.cassandra.framework.Main'\nCommand exited with status 10 (pid: 8432)\n</code></pre>\n\n<p><strong>Cluster description</strong>:\nmesos masters: 1 \nmesos slaves:  3 with\nslave1 4 CPU    6.8 GB RAM  139.9 GB DISK\nslave2 4 CPU    6.8 GB RAM  139.9 GB DISK\nslave3 4 CPU    6.8 GB RAM  31.6  GB DISK</p>\n", "is_answered": true, "title": "Deploy cassandra-mesos framework with marathon", "last_edit_date": 1443445599, "tags": ["cassandra", "mesos", "mesosphere", "marathon"], "view_count": 255, "accepted_answer_id": 32825818, "last_activity_date": 1443451465, "answers": [{"body": "<p>The problem was solved changing environment variable <strong>CASSANDRA_SEED_COUNT</strong>, because by default <strong>CASSANDRA_SEED_COUNT = 2</strong> and I was configured the app.json to deploy cassandra with only one node (CASSANDRA_NODE_COUNT=1).</p>\n\n<p>If you are trying with all default config it's work fine with the environment variable, only you need be sure to has 3 or more slave nodes availables in the mesos cluster.</p>\n\n<pre><code># The number of nodes in the cluster (default 3)\nCASSANDRA_NODE_COUNT=3\n\n# The number of seed nodes in the cluster (default 2)\n# set this to 1, if you only want to spawn one node\nCASSANDRA_SEED_COUNT=2\n</code></pre>\n", "answer_id": 32825818, "last_activity_date": 1443451465, "creation_date": 1443451465, "score": 0, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "is_accepted": true, "question_id": 32790119}], "score": 0, "link": "https://stackoverflow.com/questions/32790119/deploy-cassandra-mesos-framework-with-marathon", "answer_count": 1, "owner": {"user_id": 896830, "profile_image": "https://www.gravatar.com/avatar/051beda6c82ec9fa642a966820161b89?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1753, "link": "https://stackoverflow.com/users/896830/kikicarbonell", "accept_rate": 79, "display_name": "kikicarbonell"}, "creation_date": 1443212689, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32790119}{"body": "<p>I've been trying to set up apache mesos, with two machines, one as a slave, the other with a master and a slave. I've been using the mesosphere packages for this.</p>\n\n<p>The slave on the master machine (james-pc) connects fine, but the slave on the other machine doesn't seem to connect. Log messages below.</p>\n\n<p><strong>these are samples. The timestamps may not match</strong>. I've run the same commands and read the og files a lot :(</p>\n\n<p>Thanks!!</p>\n\n<p><strong>Slave</strong></p>\n\n<pre><code>I1015 13:44:40.098458 16485 main.cpp:126] Build: 2014-09-23 05:36:09 by root\nI1015 13:44:40.098520 16485 main.cpp:128] Version: 0.20.1\nI1015 13:44:40.098530 16485 main.cpp:131] Git tag: 0.20.1\nI1015 13:44:40.098537 16485 main.cpp:135] Git SHA: fe0a39112f3304283f970f1b08b322b1e970829d\nI1015 13:44:40.098558 16485 containerizer.cpp:89] Using isolation: posix/cpu,posix/mem\nI1015 13:44:40.100411 16485 main.cpp:149] Starting Mesos slave\nI1015 13:44:40.101066 16485 slave.cpp:167] Slave started on 1)@127.0.1.1:5051\nI1015 13:44:40.101238 16485 slave.cpp:278] Slave resources: cpus(*):4; mem(*):6649; disk(*):109050; ports(*):[31000-32000]\nI1015 13:44:40.101335 16485 slave.cpp:306] Slave hostname: riri-desktop\nI1015 13:44:40.101346 16485 slave.cpp:307] Slave checkpoint: true\nI1015 13:44:40.102597 16489 state.cpp:33] Recovering state from '/tmp/mesos/meta'\nI1015 13:44:40.102684 16489 state.cpp:62] Failed to find the latest slave from '/tmp/mesos/meta'\nI1015 13:44:40.102777 16493 status_update_manager.cpp:193] Recovering status update manager\nI1015 13:44:40.102821 16493 containerizer.cpp:252] Recovering containerizer\nI1015 13:44:40.102982 16491 slave.cpp:3198] Finished recovery\nI1015 13:44:40.103219 16488 slave.cpp:589] New master detected at master@10.117.149.130:5050\nI1015 13:44:40.103313 16488 slave.cpp:625] No credentials provided. Attempting to register without authentication\nI1015 13:44:40.103317 16491 status_update_manager.cpp:167] New master detected at master@10.117.149.130:5050\nI1015 13:44:40.103333 16488 slave.cpp:636] Detecting new master\n\nI1015 13:45:40.109150 16487 slave.cpp:3053] Current usage 27.72%. Max allowed age: 4.359784084743518days\nI1015 13:46:40.119501 16489 slave.cpp:3053] Current usage 27.72%. Max allowed age: 4.359794862235926days\n</code></pre>\n\n<p><strong>master</strong></p>\n\n<pre><code>I1015 13:47:55.462615  5670 hierarchical_allocator_process.hpp:563] Recovered cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000] (total allocatable: cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000]) on slave 20141015-130401-16842879-5050-3432-0 from framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:47:58.048534  5671 http.cpp:466] HTTP request for '/master/state.json'\nI1015 13:48:01.461993  5667 master.cpp:3559] Sending 1 offers to framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:01.464038  5670 master.cpp:2169] Processing reply for offers: [ 20141015-134423-16842879-5050-5654-36 ] on slave 20141015-130401-16842879-5050-3432-0 at slave(1)@127.0.1.1:5051 (james-pc.syd.local) for framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:01.464246  5670 hierarchical_allocator_process.hpp:563] Recovered cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000] (total allocatable: cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000]) on slave 20141015-130401-16842879-5050-3432-0 from framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:06.464457  5669 master.cpp:3559] Sending 1 offers to framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:06.466624  5667 master.cpp:2169] Processing reply for offers: [ 20141015-134423-16842879-5050-5654-37 ] on slave 20141015-130401-16842879-5050-3432-0 at slave(1)@127.0.1.1:5051 (james-pc.syd.local) for framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:06.466841  5671 hierarchical_allocator_process.hpp:563] Recovered cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000] (total allocatable: cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000]) on slave 20141015-130401-16842879-5050-3432-0 from framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:08.064483  5673 http.cpp:466] HTTP request for '/master/state.json'\nI1015 13:48:12.465992  5674 master.cpp:3559] Sending 1 offers to framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:12.468195  5670 master.cpp:2169] Processing reply for offers: [ 20141015-134423-16842879-5050-5654-38 ] on slave 20141015-130401-16842879-5050-3432-0 at slave(1)@127.0.1.1:5051 (james-pc.syd.local) for framework 20141015-134423-16842879-5050-5654-0000\nI1015 13:48:12.468408  5670 hierarchical_allocator_process.hpp:563] Recovered cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000] (total allocatable: cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000]) on slave 20141015-130401-16842879-5050-3432-0 from framework 20141015-134423-16842879-5050-5654-0000\n</code></pre>\n\n<p><strong>james@james-pc:/var/log/mesos$ cat mesos-slave.james-pc.invalid-user.log.INFO.20141015-134946.6069</strong></p>\n\n<pre><code>Log file created at: 2014/10/15 13:49:46\nRunning on machine: james-pc\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nI1015 13:49:46.323657  6069 logging.cpp:142] INFO level logging started!\nI1015 13:49:46.323825  6069 main.cpp:126] Build: 2014-09-23 05:36:09 by root\nI1015 13:49:46.323837  6069 main.cpp:128] Version: 0.20.1\nI1015 13:49:46.323842  6069 main.cpp:131] Git tag: 0.20.1\nI1015 13:49:46.323846  6069 main.cpp:135] Git SHA: fe0a39112f3304283f970f1b08b322b1e970829d\nI1015 13:49:46.323860  6069 containerizer.cpp:89] Using isolation: posix/cpu,posix/mem\nI1015 13:49:46.324012  6069 main.cpp:149] Starting Mesos slave\nI1015 13:49:46.324472  6084 slave.cpp:167] Slave started on 1)@127.0.1.1:5051\nI1015 13:49:46.324604  6084 slave.cpp:278] Slave resources: cpus(*):4; mem(*):6659; disk(*):107176; ports(*):[31000-32000]\nI1015 13:49:46.324697  6084 slave.cpp:306] Slave hostname: james-pc.syd.local\nI1015 13:49:46.324709  6084 slave.cpp:307] Slave checkpoint: true\nI1015 13:49:46.326089  6079 state.cpp:33] Recovering state from '/tmp/mesos/meta'\nI1015 13:49:46.326375  6084 status_update_manager.cpp:193] Recovering status update manager\nI1015 13:49:46.326452  6079 containerizer.cpp:252] Recovering containerizer\nI1015 13:49:46.326608  6083 slave.cpp:3198] Finished recovery\nI1015 13:49:46.327335  6084 group.cpp:313] Group process (group(1)@127.0.1.1:5051) connected to ZooKeeper\nI1015 13:49:46.327352  6084 group.cpp:787] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI1015 13:49:46.327360  6084 group.cpp:385] Trying to create path '/mesos' in ZooKeeper\nI1015 13:49:46.328199  6085 detector.cpp:138] Detected a new leader: (id='5')\nI1015 13:49:46.328272  6085 group.cpp:658] Trying to get '/mesos/info_0000000005' in ZooKeeper\nI1015 13:49:46.328738  6084 detector.cpp:426] A new leading master (UPID=master@127.0.1.1:5050) is detected\nI1015 13:49:46.328806  6085 slave.cpp:589] New master detected at master@127.0.1.1:5050\nI1015 13:49:46.328881  6085 slave.cpp:625] No credentials provided. Attempting to register without authentication\nI1015 13:49:46.328886  6078 status_update_manager.cpp:167] New master detected at master@127.0.1.1:5050\nI1015 13:49:46.328897  6085 slave.cpp:636] Detecting new master\nI1015 13:49:46.662595  6085 slave.cpp:816] Re-registered with master master@127.0.1.1:5050\nW1015 13:50:19.134799  6078 slave.cpp:791] Already registered with master master@127.0.1.1:5050\nI1015 13:50:46.338639  6082 slave.cpp:3053] Current usage 59.91%. Max allowed age: 2.106364690479491days\nW1015 13:51:07.704756  6082 slave.cpp:791] Already registered with master master@127.0.1.1:5050\nW1015 13:51:15.611064  6078 slave.cpp:791] Already registered with master master@127.0.1.1:5050\nW1015 13:51:18.703999  6082 slave.cpp:791] Already registered with master master@127.0.1.1:5050\nW1015 13:51:21.911741  6079 slave.cpp:791] Already registered with master master@127.0.1.1:5050\n</code></pre>\n", "is_answered": true, "title": "Apache Mesos slave cannot connect to master", "tags": ["hadoop", "apache-spark", "mesos", "mesosphere"], "last_activity_date": 1455028904, "accepted_answer_id": 26386791, "creation_date": 1413341756, "answers": [{"body": "<p>You're using local ip adresses:</p>\n\n<pre><code>I1015 13:49:46.324472  6084 slave.cpp:167] Slave started on 1)@127.0.1.1:5051\n</code></pre>\n\n<p>try setting those to the appropriate ips, it might be that they cannot talk to each other properly</p>\n\n<p>couple of places to look (I use the mesosphere google deploy):</p>\n\n<p>Slave (some need master IP, some slave IP):</p>\n\n<pre><code>/etc/mesos-slave/hostname\n/etc/mesos-slave/attributes/host\n/etc/mesos/zk\n/etc/hadoop/conf/core-site.xml\n/etc/hadoop/conf/mapred-site.xml\n</code></pre>\n\n<p>Hope it helps!</p>\n", "answer_id": 26386791, "last_activity_date": 1413444575, "creation_date": 1413388234, "score": 1, "owner": {"user_id": 2576092, "profile_image": "https://www.gravatar.com/avatar/8d4b93b8550e7a5282a525f8448248ac?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 576, "link": "https://stackoverflow.com/users/2576092/elmalto", "accept_rate": 70, "display_name": "elmalto"}, "is_accepted": true, "last_edit_date": 1413444575, "question_id": 26373738}, {"body": "<p>The problem indeed is that you're using a local ip address for the slave. Probably the easiest way to fix it is to first check out the external ip address of your NIC (assuming eth0 with IPv4):</p>\n\n<pre><code>ifconfig eth0 | grep \"inet addr\"\n</code></pre>\n\n<p>will yield something like this</p>\n\n<pre><code>inet addr:10.110.1.123  Bcast:10.100.1.255  Mask:255.255.255.0\n</code></pre>\n\n<p>Then edit the file /etc/default/mesos-slave and add the line</p>\n\n<pre><code>IP=10.110.1.123\n</code></pre>\n", "answer_id": 35294845, "last_activity_date": 1455028904, "creation_date": 1455028904, "score": 0, "owner": {"user_id": 736868, "profile_image": "https://www.gravatar.com/avatar/3b78e85fb93ae2ade5c9b0ad2ef5e2cb?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2258, "link": "https://stackoverflow.com/users/736868/bj%c3%b6rn-jacobs", "accept_rate": 85, "display_name": "Bj\u00f6rn Jacobs"}, "is_accepted": false, "question_id": 26373738}], "score": 0, "link": "https://stackoverflow.com/questions/26373738/apache-mesos-slave-cannot-connect-to-master", "answer_count": 2, "owner": {"user_id": 617026, "profile_image": "https://www.gravatar.com/avatar/0a54e615e381f93cc6306a93317ba371?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 387, "link": "https://stackoverflow.com/users/617026/riri", "accept_rate": 75, "display_name": "riri"}, "view_count": 4881, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 26373738}{"body": "<p>I'm trying to get DCOS running with Vagrant 1.8.4 and VirtualBox.  DCOS comes up and I can get to the dashboard, but I cannot see the \"Universe\" repo.  The computer on which DC/OS Vagrant is running is behind a proxy, so I followed the directions <a href=\"https://docs.mesosphere.com/1.8/administration/installing/custom/configure-proxy/\" rel=\"nofollow\">here</a>, but I still see the following error:</p>\n\n<pre><code>[object Object] You can go to the Repositories Settings page to change installed repositories.\n</code></pre>\n\n<p>The master node can reach the outside world, in particular I can (vagrant) ssh into the master node and successfully ping machines outside the proxy.</p>\n\n<p>Finally, as an alternative I've tried downloading and setting up a local repo, but encountered a <a href=\"https://dcosjira.atlassian.net/browse/DCOS-323\" rel=\"nofollow\">known issue</a>.  </p>\n\n<p>A similar question has been asked (as a stackoverflow beginner I've exhausted my link budget) about difficulty finding the Universe when there are two repos, but that doesn't seem applicable to the issue I'm facing. </p>\n\n<p>Any advice would be appreciated.  Thank you for your time.</p>\n\n<p>As an addendum here is some more information from recent tests: On my host laptop (A Mac) I can ping both google.com and mesosphere.com.  However, when I vagrant ssh into the master node, I can ping google.com, but when I try to ping mesosphere.com, I see the error:</p>\n\n<pre><code>ping: unknown host mesosphere.com\n</code></pre>\n\n<p>Naively I would assume that since the Universe repo lives at universe.mesosphere.com, I would need to resolve mesosphere.com.</p>\n", "is_answered": true, "tags": ["vagrant", "dcos"], "last_edit_date": 1474482759, "title": "How can I get DC/OS to see the Universe repo", "last_activity_date": 1475258263, "answer_count": 2, "creation_date": 1474326197, "score": 1, "link": "https://stackoverflow.com/questions/39583351/how-can-i-get-dc-os-to-see-the-universe-repo", "answers": [{"body": "<p>After a bit of digging it seems the file cosmos reads the proxy config from changed in DC/OS 1.8 from <code>/var/lib/dcos/environment.proxy</code> to <code>/opt/mesosphere/etc/proxy.env</code></p>\n\n<p>Try running the following commands: </p>\n\n<pre><code>cp /var/lib/dcos/environment.proxy /opt/mesosphere/etc/proxy.env\nsystemctl restart dcos-cosmos\n</code></pre>\n\n<p>---- Edit -----</p>\n\n<p>Bug to track the documentation being updated <a href=\"https://dcosjira.atlassian.net/browse/DCOS-398\" rel=\"nofollow\">https://dcosjira.atlassian.net/browse/DCOS-398</a></p>\n", "answer_id": 39626160, "last_activity_date": 1474495400, "creation_date": 1474490275, "score": 2, "owner": {"user_id": 4607350, "profile_image": "https://lh3.googleusercontent.com/-HkhCOYc7b4g/AAAAAAAAAAI/AAAAAAAAHXs/OiYKUyob39Q/photo.jpg?sz=128", "user_type": "registered", "reputation": 129, "link": "https://stackoverflow.com/users/4607350/ben-whitehead", "display_name": "Ben Whitehead"}, "is_accepted": false, "last_edit_date": 1474495400, "question_id": 39583351}, {"body": "<p>DC/OS 1.8.4 added a new way to configure a proxy at install time in config.yaml. Unfortunately there was <a href=\"https://github.com/dcos/dcos/pull/734\" rel=\"nofollow\">a bug</a> with it that's been fixed on master and will be in DC/OS 1.8.5.</p>\n\n<p>DC/OS proxy docs: <a href=\"https://dcos.io/docs/1.8/administration/installing/custom/configuration-parameters/#use_proxy\" rel=\"nofollow\">https://dcos.io/docs/1.8/administration/installing/custom/configuration-parameters/#use_proxy</a></p>\n\n<p>DC/OS Vagrant proxy docs: <a href=\"https://github.com/dcos/dcos-vagrant/blob/master/docs/configure.md#configure-a-proxy\" rel=\"nofollow\">https://github.com/dcos/dcos-vagrant/blob/master/docs/configure.md#configure-a-proxy</a></p>\n\n<p>For posterity, there are new fields:</p>\n\n<ul>\n<li><code>use_proxy</code> (boolean)</li>\n<li><code>http_proxy</code> (string)</li>\n<li><code>https_proxy</code> (string)</li>\n<li><code>no_proxy</code> (array of strings)</li>\n</ul>\n", "answer_id": 39797391, "last_activity_date": 1475258263, "creation_date": 1475258263, "score": 0, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": false, "question_id": 39583351}], "owner": {"user_id": 6850831, "profile_image": "https://lh5.googleusercontent.com/-SKnRNKqbHWk/AAAAAAAAAAI/AAAAAAAAFDU/BR5iGNdJgKQ/photo.jpg?sz=128", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6850831/matthew-calef", "display_name": "Matthew Calef"}, "view_count": 399, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39583351}{"body": "<p>I'm new in Azure and DC/OS. I deployed a DC/OS cluster using the next document: <a href=\"https://docs.microsoft.com/en-us/azure/container-service/container-service-deployment\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/container-service/container-service-deployment</a>. What should I do in case I want change SSH RSA public key   which I used in deploying? I couldn't find a document with description such situation. </p>\n\n<p>After deploying a DC/OS cluster I have a resource group which contains virtual machine with name like dcos-master-* . I can change public key for this virtual machine using azure web portal: resourcegroup->'dcos-master-* '->Reset password. But as I understand it's not enough. I see also  that my resource group contains virtual machine scale sets like dcos-agent-private-* and dcos-agent-public-*. But I can't find how to reset passwords there.</p>\n\n<p>Explain me please what should I do in such case?</p>\n", "is_answered": true, "title": "Azure DC/OS cluster. How to change SSH RSA public key", "last_edit_date": 1496710914, "tags": ["azure", "dcos", "azure-container-service"], "view_count": 97, "accepted_answer_id": 44381406, "last_activity_date": 1497019257, "answers": [{"body": "<blockquote>\n  <p>What should I do in case I want change SSH RSA public key which I used\n  in deploying?</p>\n</blockquote>\n\n<p>Sorry, I have not find how to change the public key of VMSS, I will do some search, if I get anything new, I'll keep you updated.</p>\n\n<p>As a workaround, we can <strong>add</strong> a new public key to VMSS, here is the script:</p>\n\n<pre><code>$vmssName = \"dcos-agent-private-EAF6BCA8-vmss0\"\n$vmssResourceGroup = \"dcos\"\n$vmss = Get-AzureRmVmss -ResourceGroupName $vmssResourceGroup -VMScaleSetName $vmssName\nAdd-AzureRmVmssSshPublicKey -VirtualMachineScaleSet $VMSS -KeyData \"ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAr1ftAx4QhtzAeqei9ukw32nrM8kmB6t2UVdBpuUjAeBAI3/cln/0vmekCt2OPJof5/mdaMTYoMleMsPxQWcm19fZviiMS0rkmLU9qwTeJf8+T8RWEUB75wRH5aDdrit1eYZ9bwJGL1LbkECKWoB02HZGLRH24Z5BLLXCkXjGI8LTLTTZobAnM4EC1QGMCsuMUl0mlhchaK0yQifx+GHOsbFuqe+E40akAzzh7tt+O4I/TjigrE4YHUJlmGNlY3grXFPE5oaszzb97/yyglt1cW2KucjAI4qm7ZTQ6wz5asW8IoN+jya4h2O4Au0ymNVgw1EQG1p8UJ2qByyxxJNMSw==\" -Path \"/home/admin/.ssh/authorized_keys\"\n</code></pre>\n\n<p>Here is the result:</p>\n\n<p><a href=\"https://i.stack.imgur.com/cZCOG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cZCOG.png\" alt=\"enter image description here\"></a></p>\n\n<p>By the way, if you don't want user can use your original public key to login VMSS instance, we can <strong>login</strong> this instance and <strong>delete</strong> the original public key in <code>authorized_key</code>.</p>\n\n<pre><code>jason@dcos-agent-public-EAF6BCA8000001:~$ cd .ssh/\njason@dcos-agent-public-EAF6BCA8000001:~/.ssh$ ls\nauthorized_keys\njason@dcos-agent-public-EAF6BCA8000001:~/.ssh$ cat authorized_keys \nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAr1ftAx4QhtzAeqei9ukw32nrM8kmB6t2UVdBpuUjAeBAI3/cln/0vmekCt2OPJof5/mdaMTYoMleMsPxQWcm19fZviiMS0rkmLU9qwTeJf8+T8RWEUB75wRH5aDdrit1eYZ9bwJGL1LbkECKWoB02HZGLRH24Z5BLLXCkXjGI8LTLTTZobAnM4EC1QGMCsuMUl0mlhchaK0yQifx+GHOsbFuqe+E40akAzzh7tt+O4I/TjigrE4YHUJlmGNlY3grXFPE5oaszzb97/yyglt1cW2KucjAI4qm7ZTQ6wz5asW8IoN+jya4h2O4Au0ymNVgw1EQG1p8UJ2qByyxxJNMSw==\n</code></pre>\n\n<p><strong>Update</strong>:<br>\nwe can use this command to list public key.</p>\n\n<p><a href=\"https://i.stack.imgur.com/nQ8zn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nQ8zn.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/jCPX2.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jCPX2.png\" alt=\"enter image description here\"></a></p>\n", "answer_id": 44381406, "last_activity_date": 1497019257, "creation_date": 1496723226, "score": 1, "owner": {"user_id": 6851908, "profile_image": "https://www.gravatar.com/avatar/96ae2cbc5ed313e05565f7f869b5d3b2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 4831, "link": "https://stackoverflow.com/users/6851908/jason-ye-msft", "display_name": "Jason Ye - MSFT"}, "is_accepted": true, "last_edit_date": 1497019257, "question_id": 44373626}, {"body": "<p>Jessica Deen published a video that should help... <a href=\"https://channel9.msdn.com/Shows/Azure-Container-Service/Azure-Container-Service-How-to-change-your-public-key\" rel=\"nofollow noreferrer\">https://channel9.msdn.com/Shows/Azure-Container-Service/Azure-Container-Service-How-to-change-your-public-key</a></p>\n", "answer_id": 44395640, "last_activity_date": 1496767787, "creation_date": 1496767787, "score": 1, "owner": {"user_id": 939606, "profile_image": "https://www.gravatar.com/avatar/e2c6d0a2b4ecd5709c8ae1f1455b1d4b?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 488, "link": "https://stackoverflow.com/users/939606/rgardler", "display_name": "rgardler"}, "is_accepted": false, "question_id": 44373626}], "score": 0, "link": "https://stackoverflow.com/questions/44373626/azure-dc-os-cluster-how-to-change-ssh-rsa-public-key", "answer_count": 2, "owner": {"user_id": 1762235, "profile_image": "https://www.gravatar.com/avatar/dc7c67de0d402c845d12fbdc58967dd7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 57, "link": "https://stackoverflow.com/users/1762235/andryusha2006", "accept_rate": 83, "display_name": "Andryusha2006"}, "creation_date": 1496680828, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 44373626}{"body": "<p>I installed OpenDC/OS 1.9, I found there are some differencies between mesos binaries. In my OpenDC/OS's agent node,  it stores mesos-agent binary under:/opt/mesosphere/packages/mesos--aaedd03eee0d57f5c0d49c74ff1e5721862cad98/bin/ </p>\n\n<pre><code>[root@localhost mesosphere]# ls -lh packages/mesos--aaedd03eee0d57f5c0d49c74ff1e5721862cad98/bin/\ntotal 1.8M\n-rwxr-xr-x. 1 root root 5.0K Mar 24 07:46 make_disk_resources.py\n-rwxr-xr-x. 1 root root  44K Mar 24 07:46 mesos\n-rwxr-xr-x. 1 root root 278K Mar 24 07:46 mesos-agent\n-rwxr-xr-x. 1 root root 4.6K Mar 24 07:46 mesos-cat\n........\n</code></pre>\n\n<p>mesos-agent size is only 278K</p>\n\n<p>I follow below steps to build mesos source code(same version as above),\n<a href=\"http://mesos.apache.org/gettingstarted\" rel=\"nofollow noreferrer\">http://mesos.apache.org/gettingstarted</a>\nI got all binary and other files under xx/build/src/.libs folder\uff1a</p>\n\n<pre><code>-rwxr-xr-x. 1 root root 2.0M Jun 20 06:50 mesos-agent\n-rwxr-xr-x. 1 root root 781K Jun 20 06:49 mesos-containerizer\n-rwxr-xr-x. 1 root root 4.7M Jun 20 06:50 mesos-docker-executor\n-rwxr-xr-x. 1 root root 3.5M Jun 20 06:48 mesos-execute\n-rwxr-xr-x. 1 root root 3.8M Jun 20 06:49 mesos-executor\n-rwxr-xr-x. 1 root root 2.4M Jun 20 06:48 mesos-fetcher\n-rwxr-xr-x. 1 root root 3.1M Jun 20 06:49 mesos-health-check\n-rwxr-xr-x. 1 root root 1.6M Jun 20 06:48 mesos-local\n-rwxr-xr-x. 1 root root 591K Jun 20 06:48 mesos-log\n</code></pre>\n\n<p>this mesos-agent size is more than 2.0M</p>\n\n<p>what's the differencies between these two mesos-agent? Can I replace the first mesos-agent binary\uff08278K\uff09 with my self build one(2.0M)  ?\nif I install mesos by apt-get install or yum install, the mesos-agent size is almost the same as first one (278K)\nHow does OpenDC/OS build and use mesos ?</p>\n\n<p>thanks!</p>\n", "is_answered": false, "tags": ["build", "dcos"], "title": "Differencies between mesos-agent binary", "last_activity_date": 1497942102, "answer_count": 0, "creation_date": 1497942102, "score": 1, "link": "https://stackoverflow.com/questions/44646011/differencies-between-mesos-agent-binary", "owner": {"user_id": 8170671, "profile_image": "https://www.gravatar.com/avatar/a587027b0f0fa5800625da27fdb52963?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/8170671/%e5%88%98%e5%b7%8d%e9%94%8b", "accept_rate": 0, "display_name": "\u5218\u5dcd\u950b"}, "view_count": 25, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44646011}{"closed_date": 1416128396, "is_answered": false, "closed_reason": "off-topic", "tags": ["docker", "akka-cluster", "mesos", "mesosphere", "marathon"], "title": "Beginners guide for Mesos, Marathon, Docker Integration", "body": "<p>I am scratching my head, to figure out how the combination of docker, mess and marathon can help me in building my distributed application. </p>\n\n<p>Application has a backend comprising of services processing client requests and returning json data, which is consumed by the fronted UI layer.Services need to be highly available and scalable. User interaction supported through REST and Web UI.</p>\n\n<p>I would appreciate if some one can answer my following queries :</p>\n\n<ul>\n<li>Any example/ebook/guide for building an application using all of the above?</li>\n<li>Does mess/maraton offer built in support for clustering? or you need to use akka<br>\nclustering or netty within containers?</li>\n<li>How load balancing works with mess/marathon?</li>\n<li>is my application a good use case for these technlogies?</li>\n</ul>\n\n<p>Thanks</p>\n", "view_count": 1126, "answer_count": 0, "last_activity_date": 1415166880, "score": 5, "link": "https://stackoverflow.com/questions/26750589/beginners-guide-for-mesos-marathon-docker-integration", "owner": {"user_id": 1799767, "profile_image": "https://www.gravatar.com/avatar/89299971f03ea19479a26a9e6e940236?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 111, "link": "https://stackoverflow.com/users/1799767/thegeek", "display_name": "thegeek"}, "creation_date": 1415166880, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 26750589}{"is_answered": true, "tags": ["mesos", "dcos"], "title": "Where exactly is the dcos src directory on github?", "last_activity_date": 1499763198, "answer_count": 1, "creation_date": 1499672937, "score": -1, "link": "https://stackoverflow.com/questions/45006464/where-exactly-is-the-dcos-src-directory-on-github", "owner": {"user_id": 6798486, "profile_image": "https://lh6.googleusercontent.com/-FjLs1ymLZ2c/AAAAAAAAAAI/AAAAAAAAAEs/d3sD9S6FJVo/photo.jpg?sz=128", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6798486/michael-chang", "display_name": "Michael Chang"}, "view_count": 21, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45006464}{"body": "<p>I am creating a Marathon apps using POST on the 'v2/apps' REST interface. If I attempt to create an app which does not have available resources on the underlying mesos cluster (in this case host_port), the app creation still returns an S_OK while the app is stuck in deploying forever (status never switches to running). </p>\n\n<p>Is there a way to fail the application creation API in case resources are unavailable - or atleast - to query the state and identify that the application is stuck deploying due to resource exhaustion to fail fast?</p>\n", "is_answered": true, "tags": ["mesosphere", "marathon"], "title": "How to identify Marathon App deployment failure due to resource exhaustion via API?", "last_activity_date": 1457470960, "answer_count": 2, "creation_date": 1455673235, "score": 1, "link": "https://stackoverflow.com/questions/35446407/how-to-identify-marathon-app-deployment-failure-due-to-resource-exhaustion-via-a", "answers": [{"body": "<p>Marathon is \"the second layer\" scheduler running on top of Mesos. It is exposed only to the resources allocated to it by Mesos. Marathon has no global cluster view, and hence it has no idea whether requested resources are available somewhere in the cluster or will be available in the future.</p>\n\n<p>When you submit an app to Marathon, it validates the request, accepts it, and waits for a suitable offer from Mesos. In your case, you know a suitable offer will not come in the near future (I suppose because there is another task using that particular port on that particular agent), but Marathon is not aware of it.</p>\n", "answer_id": 35478692, "last_activity_date": 1455790854, "creation_date": 1455790854, "score": 1, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "question_id": 35446407}, {"body": "<p>Here are the statuses that marathon-ui uses:\n<a href=\"https://mesosphere.github.io/marathon/docs/marathon-ui.html#application-status-reference\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/marathon-ui.html#application-status-reference</a> </p>\n\n<p>The one you are looking for is likely the <code>waiting</code> state which you can identify by querying <code>v2/queue</code> and checking if <code>queueEntry.delay.overdue === true</code> for an extended period.</p>\n\n<p>I've just built some <code>prometheus</code> alarms to be alarmed for similar issues like the one you describe, see the MarathonAppCantGetSuitableOffers alarm here:\n<a href=\"https://github.com/bergerx/prom_marathon_app_exporter#alerts-on-prometheus\" rel=\"nofollow\">https://github.com/bergerx/prom_marathon_app_exporter#alerts-on-prometheus</a></p>\n", "answer_id": 35877948, "last_activity_date": 1457470960, "creation_date": 1457470960, "score": 0, "owner": {"user_id": 140651, "profile_image": "https://www.gravatar.com/avatar/6ac86fe8acb81d8eafa7009be74ec034?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 141, "link": "https://stackoverflow.com/users/140651/bekir-dogan", "display_name": "Bekir Dogan"}, "is_accepted": false, "question_id": 35446407}], "owner": {"user_id": 5937964, "profile_image": "https://www.gravatar.com/avatar/21358f8c702f1773625ce4a416967eaa?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/5937964/thefacelessman", "display_name": "TheFacelessMan"}, "view_count": 287, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35446407}{"body": "<p>I'm working on developing some Docker containers to run in a Mesos cluster. We're doing job submission via Chronos which is managed by Marathon. However, I noticed a significant performance decrease when running my containers in Mesos vs. executing them directly via Docker. Normally, these containers could do the job in about 1.5 minutes, but I've seen times ranging form 3-12 minutes when running with Mesos. The core process I'm running does a lot of disk I/O, so perhaps there's something with how I/O is handled in Mesos that's causing this?</p>\n\n<p>Any thoughts would be great, though just in case someone suggests it, I can't change the core process that's run. I don't have control over it and it's quite complex.</p>\n\n<p>Thanks.</p>\n\n<p>EDIT: Did some additional testing with just running the job through Marathon and performance is as expected.  Perhaps it's Chronos that's causing this degradation?  If so, why would that be?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1422885236, "title": "Mesos Performance Overhead", "last_activity_date": 1423194686, "answer_count": 2, "creation_date": 1422882313, "score": 1, "link": "https://stackoverflow.com/questions/28278409/mesos-performance-overhead", "answers": [{"body": "<p>As drexin mentioned, what resource settings are used in the case of marathon and chronos? There shouldn't be a difference since in both cases the image is downloaded and the mesos containerizer will be called directly.</p>\n", "answer_id": 28356921, "last_activity_date": 1423184668, "creation_date": 1423184668, "score": 0, "owner": {"user_id": 4103259, "profile_image": "https://www.gravatar.com/avatar/6f608fdcdfd652006ff47e0041b74587?s=128&d=identicon&r=PG", "user_type": "unregistered", "reputation": 1, "link": "https://stackoverflow.com/users/4103259/user4103259", "display_name": "user4103259"}, "is_accepted": false, "question_id": 28278409}, {"body": "<p>Most likely you're using the default resources, which I believe for Chronos is 0.1 CPUs and 256MiB of memory. Try increasing this to 1 CPU and 1024MiB of memory.</p>\n", "answer_id": 28358277, "last_activity_date": 1423194686, "creation_date": 1423194686, "score": 0, "owner": {"user_id": 4488486, "profile_image": "https://lh5.googleusercontent.com/-B_euLGuvgb4/AAAAAAAAAAI/AAAAAAAAUMI/XbYweAvxML0/photo.jpg?sz=128", "user_type": "registered", "reputation": 169, "link": "https://stackoverflow.com/users/4488486/brenden-matthews", "display_name": "Brenden Matthews"}, "is_accepted": false, "question_id": 28278409}], "owner": {"user_id": 290541, "profile_image": "https://i.stack.imgur.com/92EyJ.jpg?s=128&g=1", "user_type": "registered", "reputation": 934, "link": "https://stackoverflow.com/users/290541/blockcipher", "accept_rate": 61, "display_name": "blockcipher"}, "view_count": 543, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 13}, "question_id": 28278409}{"body": "<p>My marathon-lb configuration:</p>\n\n<pre><code>\"labels\": {\n    \"HAPROXY_GROUP\": \"external\",\n    \"HAPROXY_0_VHOST\": \"test.com\",\n    \"HAPROXY_0_MODE\": \"http\"\n  }\n</code></pre>\n\n<p>I want it route only requests like <code>test.com/12345</code> to internal endpoint\n<code>/results?q=123</code>. How to achieve that?</p>\n\n<p>P.S. Nginx rule for the same purpose looks like:</p>\n\n<pre><code>location ~* /[\\w\\-]+?$ {\n         proxy_pass http://127.0.0.1:8094;\n         rewrite ^/([\\w\\-]+?)$ //results?q=$1? break;\n    }\n</code></pre>\n", "is_answered": true, "title": "Marathon-lb rules for different paths", "tags": ["haproxy", "marathon", "dcos"], "last_activity_date": 1501750709, "accepted_answer_id": 45479492, "creation_date": 1501141423, "answers": [{"body": "<p>As you probably know marathon-lb is HAProxy plus some wrappers. You can add a redirect to <a href=\"https://www.haproxy.com/doc/aloha/7.0/haproxy/http_rewriting.html\" rel=\"nofollow noreferrer\">HAProxy configuration</a>, by using HAPROXY_0_BACKEND_HTTP_OPTIONS label. There's a legacy reqrep statement which you may find convenient and you can also go for 301 redirect. For example you can do:</p>\n\n<p><code>\"HAPROXY_0_BACKEND_HTTP_OPTIONS\": \"  reqrep ^/([\\w\\-]+?)$ /results?q=\\\\1 \\n\",\n</code></p>\n\n<p>or</p>\n\n<p><code>\"HAPROXY_0_BACKEND_HTTP_OPTIONS\": \"  acl is_foo path -i /foo \\n  redirect code 301 location /bar if is_foo\\n\",\n</code></p>\n\n<p>Note double spaces for indent. Not that you'll have to play with escapes to make it work.</p>\n", "answer_id": 45479492, "last_activity_date": 1501750709, "creation_date": 1501750709, "score": 1, "owner": {"user_id": 1661204, "profile_image": "https://www.gravatar.com/avatar/b6d8debae0c2654a22d93ac1df3a7609?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/1661204/pawe%c5%82-rein", "display_name": "Pawe\u0142 Rein"}, "is_accepted": true, "question_id": 45344394}], "score": 0, "link": "https://stackoverflow.com/questions/45344394/marathon-lb-rules-for-different-paths", "answer_count": 1, "owner": {"user_id": 3744640, "profile_image": "https://i.stack.imgur.com/f6iu9.jpg?s=128&g=1", "user_type": "registered", "reputation": 3019, "link": "https://stackoverflow.com/users/3744640/ipoteka", "accept_rate": 83, "display_name": "ipoteka"}, "view_count": 42, "_params_": {"filter": "_ba", "body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45344394}{"is_answered": false, "tags": ["performance", "mesos", "marathon"], "last_edit_date": 1472124876, "title": "Mesosphere Marathon API performance", "last_activity_date": 1472136764, "answer_count": 1, "creation_date": 1472121538, "score": 1, "link": "https://stackoverflow.com/questions/39143058/mesosphere-marathon-api-performance", "owner": {"user_id": 1023876, "profile_image": "https://www.gravatar.com/avatar/e0135ac69dd8ad56c9cdea4c1f742bb5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 232, "link": "https://stackoverflow.com/users/1023876/pavel", "accept_rate": 60, "display_name": "Pavel"}, "view_count": 129, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 39143058}{"body": "<p>I have a spark streaming application packaged as a docker image and deployed in DC/OS via Marathon as suggested below:</p>\n\n<p><a href=\"https://github.com/mesosphere/iot-demo\" rel=\"nofollow noreferrer\">https://github.com/mesosphere/iot-demo</a></p>\n\n<p>The following command for triggering the spark job in marathon works perfectly:</p>\n\n<pre><code>/opt/spark/dist/bin/spark-submit \n--master mesos://spark.marathon.mesos:8130 \n--deploy-mode client  \n--driver-memory 4g \n--executor-memory 2g \n--conf \"spark.driver.extraJavaOptions=-Dhttp.proxyHost=xx.yy.zz.aa -Dhttp.proxyPort=3128 -Dhttps.proxyHost=xx.yy.zz.aa -Dhttps.proxyPort=3128\" --conf spark.mesos.executor.docker.image=private_registry/myimage-name:version \n--conf spark.mesos.executor.home=/opt/spark/dist \n--packages org.apache.spark:spark-streaming-kafka-0-10_2.11:2.0.1,com.datastax.spark:spark-cassandra-connector_2.11:2.0.1 \n--class app.MyApp file:///my.jar\n</code></pre>\n\n<p>However, if I change the deploy-mode from client to cluster, it is not recognizing the proxy settings and fails with connection refused when trying to download the packages specified. </p>\n\n<p>Can somebody suggest what could be wrong?</p>\n\n<p>Thanks in advance.</p>\n\n<p>best regards</p>\n\n<p>Sriraman.</p>\n", "is_answered": false, "tags": ["apache-spark", "docker", "proxy", "mesosphere", "dcos"], "last_edit_date": 1499446210, "title": "spark-submit proxy host / port configuration not respected when deploy mode is cluster", "last_activity_date": 1499446210, "answer_count": 0, "creation_date": 1499439729, "score": 0, "link": "https://stackoverflow.com/questions/44974019/spark-submit-proxy-host-port-configuration-not-respected-when-deploy-mode-is-c", "owner": {"user_id": 1617791, "profile_image": "https://www.gravatar.com/avatar/5f651adfcc7246c8adf026f594013cab?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 144, "link": "https://stackoverflow.com/users/1617791/user1617791", "display_name": "user1617791"}, "view_count": 36, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44974019}{"body": "<p>I have a vagrant box which is running Mesos, Marathon and Chronos (publicly packaged as <code>playa-mesos</code>). It is a sane environment (I have customized to a 192.168.<em>.</em> ip address though) and I can launch different apps incl. docker containerized ones.\nI have tried a new demo, where there is a DNS requirement and the mesos application launch definition is as below :</p>\n\n<pre><code>{\n \"id\": \"mesos-dns\",\n \"instances\": 1,\n \"cpus\": 0.2,\n \"mem\": 50,\n \"cmd\": \"/mesos-dns -config=/config.json\",\n \"container\": {\n  \"type\": \"DOCKER\",\n  \"docker\": {\n  \"image\": \"mesosphere/mesos-dns:latest\",\n  \"network\": \"HOST\"\n},\n\"volumes\": [\n  {\n    \"containerPath\": \"/config.json\",\n    \"hostPath\": \"/etc/mesos-dns/config.json\",\n    \"mode\": \"RO\"\n  }\n]\n}\n}\n</code></pre>\n\n<p>The <code>config.json</code> is as under :</p>\n\n<pre><code>{\n\"zk\": \"zk://127.0.0.1:2181/mesos\",\n\"refreshSeconds\": 60,\n\"ttl\": 60,\n\"domain\": \"mesos\",\n\"port\": 53,\n\"resolvers\": [\"10.0.2.3\"],\n\"timeout\": 5,\n\"email\": \"root.mesos-dns.mesos\"\n}\n</code></pre>\n\n<p>The <code>/etc/resolv.conf</code> contains <code>nameserver 10.0.2.3</code></p>\n\n<p>Below is the <code>dig</code> response I get to my DNS query; both are shown below :-</p>\n\n<pre><code>dig _webdis-site-m-shop._tcp.marathon.mesos SRV\n\n; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.1-Ubuntu &lt;&lt;&gt;&gt; _webdis-site-m-shop._tcp.marathon.mesos SRV\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NXDOMAIN, id: 4759\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 8192\n;; QUESTION SECTION:\n;_webdis-site-m-shop._tcp.marathon.mesos. IN SRV\n\n;; AUTHORITY SECTION:\n.                       56521   IN      SOA     a.root-servers.net. nstld.verisign-grs.com. 2016021800 1\n800 900 604800 86400\n\n;; Query time: 155 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: Thu Feb 18 13:38:21 UTC 2016\n;; MSG SIZE  rcvd: 143`\n</code></pre>\n\n<p>As you can see there is <strong>no</strong> <code>ANSWER</code> and the status <code>NXDOMAIN</code> means that this query resulted in a non-existent domain.</p>\n\n<p>Can someone help me fix this ?</p>\n\n<p>TIA.</p>\n", "is_answered": true, "title": "Why does Mesos-DNS not provide a SRV answer?", "last_edit_date": 1456238200, "tags": ["dns", "mesos", "mesosphere"], "view_count": 142, "accepted_answer_id": 35487834, "last_activity_date": 1456238200, "answers": [{"body": "<p>This is now fixed. I have taken some thoughts from other posts on SO. I have changed the OOTB setting for ip address etc...\nBroadly I added the 127.0.0.1 loopback ip addr, virtualbox generated ip addr (which in my case is 192.168.x.y) and retained the existing nameserver entry.\nThe results of the dig command is now :-</p>\n\n<pre><code>dig _webdis-site-m-shop._tcp.marathon.mesos SRV\n\n; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.1-Ubuntu &lt;&lt;&gt;&gt; _webdis-site-m-shop._tcp.marathon.mesos SRV\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 6284\n;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; QUESTION SECTION:\n;_webdis-site-m-shop._tcp.marathon.mesos. IN SRV\n\n;; ANSWER SECTION:\n_webdis-site-m-shop._tcp.marathon.mesos. 60 IN SRV 0 0 31720 webdis-site-m-shop-39847-s0.marathon.mesos.\n\n\n;; ADDITIONAL SECTION:\nwebdis-site-m-shop-39847-s0.marathon.mesos. 60 IN A 192.168.56.106\n\n;; Query time: 2 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Thu Feb 18 16:55:57 UTC 2016\n;; MSG SIZE  rcvd: 216\n</code></pre>\n", "answer_id": 35487834, "last_activity_date": 1455814914, "creation_date": 1455814914, "score": 1, "owner": {"user_id": 2092716, "profile_image": "https://www.gravatar.com/avatar/89e440a681b4690573b00a0e1f1facc6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 310, "link": "https://stackoverflow.com/users/2092716/zerograviti", "accept_rate": 54, "display_name": "ZeroGraviti"}, "is_accepted": true, "question_id": 35483284}], "score": 0, "link": "https://stackoverflow.com/questions/35483284/why-does-mesos-dns-not-provide-a-srv-answer", "answer_count": 1, "owner": {"user_id": 2092716, "profile_image": "https://www.gravatar.com/avatar/89e440a681b4690573b00a0e1f1facc6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 310, "link": "https://stackoverflow.com/users/2092716/zerograviti", "accept_rate": 54, "display_name": "ZeroGraviti"}, "creation_date": 1455803426, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35483284}{"body": "<p>Hi I have been successfull so far with simple jobs in marathon but it stuck when i have tried deploying a deocker job in mesos through marathon framework.</p>\n\n<p>I am using a json file as below to deploy a docker job:</p>\n\n<pre><code>{\n  \"id\": \"pga-docker\",\n  \"cpus\": 0.2,\n  \"mem\": 1024.0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"pga\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"containerPort\": 80, \"hostPort\": 6565, \"servicePort\": 0, \"protocol\": \"tcp\" }\n      ]\n    }\n  }\n}\n</code></pre>\n\n<p>My pga docker image have no problem when run as container, but through marathon its just not working. Its staying in the deploying state forever.</p>\n\n<p>I am using the below command line:</p>\n\n<pre><code>curl -X POST http://10.141.141.10:8080/v2/apps -d @basic-3.json -H \"Content-type: application/json\"\n</code></pre>\n\n<p>But when I run the same image from marathon UI, its working. To run from marathon I used \"docker run --publish 6060:80 --name test --rm pga\" in the cmd field of the UI new job page.</p>\n\n<p>Any one have idea why this is hanged in the command line approach? </p>\n", "is_answered": false, "tags": ["docker", "mesosphere", "marathon"], "title": "marathon docker jobs hanged in deployment state", "last_activity_date": 1438272344, "answer_count": 1, "creation_date": 1438268272, "score": 0, "link": "https://stackoverflow.com/questions/31727255/marathon-docker-jobs-hanged-in-deployment-state", "answers": [{"body": "<p>This is what i have found during some trial and error with the json file.</p>\n\n<p>I found that when we run docker image in local system, if we have mentioned an entry point or a cmd then that will execute while running the container. But this is not same for mesos/marathon. my observation is that if I explicitly mentioned cmd in the deployment json then its working fine.</p>\n\n<pre><code>\"cmd\":\"sh pga-setup.sh\"\n</code></pre>\n\n<p>I will love to know if anyone faced a similar issue an solved it by another way. </p>\n", "answer_id": 31728806, "last_activity_date": 1438272344, "creation_date": 1438272344, "score": 0, "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "is_accepted": false, "question_id": 31727255}], "owner": {"user_id": 5066114, "profile_image": "https://www.gravatar.com/avatar/6f657d7f8fff1e8b0835f4c69f861888?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 107, "link": "https://stackoverflow.com/users/5066114/psaha4", "accept_rate": 0, "display_name": "psaha4"}, "view_count": 209, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31727255}{"body": "<p>In other PAAS (e.g. cloud foundry) the setup for reaching hosted services is this:</p>\n\n<ol>\n<li>PAAS is configured to accept mycloud.example.com subdomain.</li>\n<li>External DNS servers return all *.mycloud.example.com queries to point to IP of PAAS.</li>\n<li>PASS's built in proxy takes all such traffic and sends it to the correct service.</li>\n</ol>\n\n<p>How is this done in DC/OS?</p>\n", "is_answered": true, "tags": ["dcos"], "last_edit_date": 1484652756, "title": "Reaching DC/OS services via DNS", "last_activity_date": 1484652756, "answer_count": 1, "creation_date": 1484319819, "score": 0, "link": "https://stackoverflow.com/questions/41637530/reaching-dc-os-services-via-dns", "answers": [{"body": "<p>You can have a look at the service discovery docs of DC/OS:</p>\n\n<ul>\n<li><a href=\"https://dcos.io/docs/1.8/usage/service-discovery/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.8/usage/service-discovery/</a></li>\n</ul>\n\n<p>and specifically </p>\n\n<ul>\n<li><a href=\"https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/</a></li>\n<li><a href=\"https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/marathon-lb-basic-tutorial/\" rel=\"nofollow noreferrer\">https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/marathon-lb-basic-tutorial/</a></li>\n</ul>\n\n<p>You should run Marathon-LB on you public agents an point your loadbalancer to the respective IPs. Also create the appropriate A or CNAME records for your (sub-)domains pointing to your loadbalancer. </p>\n", "answer_id": 41641502, "last_activity_date": 1484333418, "creation_date": 1484333418, "score": 2, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": false, "question_id": 41637530}], "owner": {"user_id": 3586150, "profile_image": "https://www.gravatar.com/avatar/1f0969599955a953e592034929ed7a23?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 333, "link": "https://stackoverflow.com/users/3586150/neil-h-watson", "accept_rate": 68, "display_name": "Neil H Watson"}, "view_count": 48, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41637530}{"body": "<p>I'v installed DC/OS v1.8.4, the destination node has gpu resources and nvidia driver has also been installed, I tried to deploy tensorflow in mesos container, but it  failed, there is only one error message in mesos's stderr:</p>\n\n<pre><code>mesos-containerizer: error while loading shared libraries: libmesos-1.0.1.so: cannot open shared object file: No such file or directory\n</code></pre>\n\n<p>But I can deploy other services successfuly, such as nginx, wordpress (also in mesos container)</p>\n\n<p>The problem may be caused by tensorflow image, in its parent image CUDA, it reset LD_LIBRARY_PATH :</p>\n\n<pre><code>ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH} ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n</code></pre>\n\n<p>In OpenDCOS, before mesos-agent startup, it sets its executor's environment variable LD_LIBRARY_PATH to \"/opt/mesosphere/lib\", so that executor can locate necessary so files, but in above case, LD_LIBRARY_PATH is reset by tensorflow, so it failed to startup!</p>\n\n<p>Anyone knows how OpenDCOS handle this problem ?   Modify these public CUDA images? </p>\n", "is_answered": false, "tags": ["gpu", "dcos"], "title": "troubles caused by tensorflow image's LD_LIBRARY_PATH", "last_activity_date": 1498621865, "answer_count": 1, "creation_date": 1498526333, "score": 0, "link": "https://stackoverflow.com/questions/44770972/troubles-caused-by-tensorflow-images-ld-library-path", "answers": [{"body": "<p>GPUs are only officially supported in DC/OS 1.9+</p>\n\n<p>For (unsupported) instructions on getting GPUs to work in 1.8, please see my answer to this question on the DC/OS mailing list:\n<a href=\"https://groups.google.com/a/dcos.io/d/msg/users/HEgcUfRRqzk/inIBmapMCQAJ\" rel=\"nofollow noreferrer\">https://groups.google.com/a/dcos.io/d/msg/users/HEgcUfRRqzk/inIBmapMCQAJ</a></p>\n\n<p>Additionally, there is also a know issue with setting LD_LIBRARY_PATH in your container image for pre 1.9 clusters (though it usually manifests as a missing libssl.so library). </p>\n\n<p>In your case, the CUDA container is setting LD_LIBRARY_PATH, which is overriding the LD_LIBRARY_PATH setting that DC/OS relies on to find it's library files. This is obviously a bug in DC/OS and has since been fixed in 1.9. The best (unsupported) workaround for this is to run</p>\n\n<pre><code>sudo ldconfig /opt/mesosphere/lib\n</code></pre>\n\n<p>on all of your nodes to put <code>/opt/mesosphere/lib</code> into the default library path. You will have to redo this on every reboot (or alternatively) add <code>/opt/mesosphere/lib</code> to a file under <code>/etc/ld.so.conf.d/</code> to make it durable (maybe <code>/etc/ld.so.conf.d/dcos.conf</code>?).</p>\n\n<p>This JIRA addressing the underlying issue can be found here:\n<a href=\"https://issues.apache.org/jira/browse/MESOS-7027\" rel=\"nofollow noreferrer\">https://issues.apache.org/jira/browse/MESOS-7027</a></p>\n", "answer_id": 44793356, "last_activity_date": 1498621865, "creation_date": 1498621865, "score": 0, "owner": {"user_id": 7096338, "profile_image": "https://lh4.googleusercontent.com/-pBkFQ07_QKQ/AAAAAAAAAAI/AAAAAAAAGbU/AqMURnQmYwg/photo.jpg?sz=128", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/7096338/kevin-klues", "display_name": "Kevin Klues"}, "is_accepted": false, "question_id": 44770972}], "owner": {"user_id": 8170671, "profile_image": "https://www.gravatar.com/avatar/a587027b0f0fa5800625da27fdb52963?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/8170671/%e5%88%98%e5%b7%8d%e9%94%8b", "accept_rate": 0, "display_name": "\u5218\u5dcd\u950b"}, "view_count": 12, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44770972}{"body": "<p>To make my homepage load super fast, I use 5 MB of my RAM to cache only the landing page layout. I'm trying to move to marathon hosting and using the Marathon-LB, to let him know that the site is ok, he needs some kind of a health check, so I added a simple get request to the root path. </p>\n\n<p>This is how it looks in logs:</p>\n\n<p><strong>healthcheck</strong></p>\n\n<pre><code>App 127 stdout: Started GET \"/\" for 10.0.0.4 at 2016-11-26 12:17:17 +0000\nApp 127 stdout: Processing by LandingPageController#landing_page as HTML\nApp 127 stdout: Read fragment views/localhost/landing_page/8c5d9464799f02903fc528fe21a76d03 (0.0ms)\nApp 127 stdout:   Rendered application/landing_page.html.erb within layouts/landing_layout (0.8ms)\nApp 127 stdout: Read fragment views/localhost/landing_page/7298641bb68fa254c1f17ffd11320f97 (0.0ms)\nApp 127 stdout: Completed 200 OK in 2ms (Views: 1.7ms)\n</code></pre>\n\n<p>regular user request to stage.cltv.site</p>\n\n<pre><code>App 127 stdout: Started GET \"/\" for 109.67.216.227 at 2016-11-26 12:17:20 +0000\nApp 127 stdout: Processing by LandingPageController#landing_page as HTML\nApp 127 stdout: Read fragment views/stage.cltv.site/landing_page/8c5d9464799f02903fc528fe21a76d03 (0.0ms)\nReceived killTask for task ctv-site.9a686be8-b3d1-11e6-9ea2-70b3d5800001\n</code></pre>\n\n<p>Both try rendering same page, the only issue I think there is with the cache key that changes because of the origin of the request. one time its from the internal network, second time is from Marathon-LB.</p>\n\n<p>As you can see the server get stuck in this point and Marathon kills it cause it's becoming unhealthy, how do I solve this issue?</p>\n", "is_answered": false, "tags": ["ruby-on-rails-4", "caching", "marathon", "dcos"], "last_edit_date": 1480223213, "title": "Rails on marathon with cache store: memory_store issue", "last_activity_date": 1480223213, "answer_count": 0, "creation_date": 1480163379, "score": 1, "link": "https://stackoverflow.com/questions/40818333/rails-on-marathon-with-cache-store-memory-store-issue", "owner": {"user_id": 67505, "profile_image": "https://www.gravatar.com/avatar/094c0ec476b95ed7619d6a4cb918da78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9919, "link": "https://stackoverflow.com/users/67505/chen-kinnrot", "accept_rate": 71, "display_name": "Chen Kinnrot"}, "view_count": 26, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40818333}{"body": "<p>We are running a DC/OS cluster, and managing it by hand right now because the container instances running in it are low in numbers and don't need much intervention.</p>\n\n<p>Now, we want to do deployments from Jenkins - while that works with the Marathon plugin, we have hit a more-or-less interesting problem: shared volumes.</p>\n\n<p>All our nodes have a NetApp mounted at /srv and the services have Docker container volumes which map certain container paths to subdirectories in /srv. Now, when the Jenkins job causes a redeploy of a service, it will leave the old container running while staging the new version and switching over once the new container reaches \"healthy\" state.</p>\n\n<p>This is a problem, because the image in question includes MongoDB and MySQL - which break because there are concurrent accesses on the backing database files.</p>\n\n<p>How can I scale the old instance to 0 and only when the old instance is cleanly stopped actually deploy the new instance?</p>\n\n<p>Setting up shared MongoDB/MySQL containers in DC/OS is something I don't really like as it would cause a difference between the containers on developer machines, as well as that the DB content with which the containers are seeded is included in the image...</p>\n\n<p>edit: this problem also regularly bites us when someone accidentally presses \"restart service\", because unlike the naming suggests, it does not do shutdown-wait-redeploy, but also stage-then-switchover...</p>\n", "is_answered": true, "title": "DC/OS and concurrent deployments", "last_edit_date": 1487803914, "tags": ["jenkins", "docker", "dcos"], "view_count": 34, "accepted_answer_id": 42410883, "last_activity_date": 1487839732, "answers": [{"body": "<p>You might have a look at </p>\n\n<ul>\n<li><a href=\"https://mesosphere.github.io/marathon/docs/deployments.html#rolling-restarts\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/deployments.html#rolling-restarts</a></li>\n<li><a href=\"https://mesosphere.github.io/marathon/docs/persistent-volumes.html#running-stateful-mysql-on-marathon\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/persistent-volumes.html#running-stateful-mysql-on-marathon</a></li>\n</ul>\n\n<p>and</p>\n\n<ul>\n<li><a href=\"https://mesosphere.github.io/marathon/docs/recipes.html#running-a-single-instance-application\" rel=\"nofollow noreferrer\">https://mesosphere.github.io/marathon/docs/recipes.html#running-a-single-instance-application</a></li>\n</ul>\n\n<p>Basically, you should use the <code>MARATHON_SINGLE_INSTANCE_APP</code> label like this</p>\n\n<pre><code>\"labels\":{\n  \"MARATHON_SINGLE_INSTANCE_APP\": \"true\",\n}\n</code></pre>\n\n<p>and specify the <code>upgradeStrategy</code> accordingly:</p>\n\n<pre><code>\"upgradeStrategy\":{\n    \"minimumHealthCapacity\": 0,\n    \"maximumOverCapacity\": 0\n}\n</code></pre>\n", "answer_id": 42410883, "last_activity_date": 1487839732, "creation_date": 1487839732, "score": 0, "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "is_accepted": true, "question_id": 42403487}], "score": 0, "link": "https://stackoverflow.com/questions/42403487/dc-os-and-concurrent-deployments", "answer_count": 1, "owner": {"user_id": 7506145, "profile_image": "https://www.gravatar.com/avatar/ceeb8d0b8e93a2d3e2fc3ccbad6b550c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7506145/marco-schuster", "display_name": "Marco Schuster"}, "creation_date": 1487802497, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 42403487}{"is_answered": true, "tags": ["mesosphere", "dcos"], "last_edit_date": 1491524985, "title": "docker image mesosphere/dcos-genconf not found", "last_activity_date": 1491525126, "answer_count": 3, "creation_date": 1462876624, "score": 1, "link": "https://stackoverflow.com/questions/37136037/docker-image-mesosphere-dcos-genconf-not-found", "accepted_answer_id": 37265241, "owner": {"user_id": 6314636, "profile_image": "https://www.gravatar.com/avatar/7f0fb2aeaf6db6d14de97e39708e34c3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/6314636/venkatesh", "display_name": "Venkatesh"}, "view_count": 781, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 37136037}{"body": "<p>When I run 3 mesos-master with QUORUM=2, they fail 1 minute after being elected as the leader, giving errors:</p>\n\n<pre><code>E1015 11:50:35.539562 19150 socket.hpp:174] Shutdown failed on fd=25: Transport endpoint is not connected [107]\n\nE1015 11:50:35.539897 19150 socket.hpp:174] Shutdown failed on fd=24: Transport endpoint is not connected [107]\n</code></pre>\n\n<p>They keep electing one another in a loop, consistently failing and re-electing.</p>\n\n<p>If I set QUORUM=1, everything works well. What could be the reason for this?</p>\n", "is_answered": true, "tags": ["apache-zookeeper", "mesos", "mesosphere"], "title": "Mesos-master: Shutdown failed on fd=25: Transport endpoint is not connected [107]", "last_activity_date": 1466080531, "answer_count": 2, "creation_date": 1444912095, "score": 2, "link": "https://stackoverflow.com/questions/33148588/mesos-master-shutdown-failed-on-fd-25-transport-endpoint-is-not-connected-107", "answers": [{"body": "<p>One problem was that AWS firewall was blocking reaching public IPs of the server and zookeeper was broadcasting public IP (set in advertise_ip) so nobody was able to connect each other. Slaves also couldn't connect to the masters with the same error. </p>\n\n<p>When I set local IP to advertise_ip (so that Zookeeper broadcasted local IPs), masters could communicate and QUORUM=2 worked. When I removed the firewall rule, slaves could connect to the master.</p>\n", "answer_id": 33346707, "last_activity_date": 1445865274, "creation_date": 1445865274, "score": 1, "owner": {"user_id": 939341, "profile_image": "https://www.gravatar.com/avatar/fbc25280c3402693d248a4c776be54bf?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 400, "link": "https://stackoverflow.com/users/939341/aladagemre", "accept_rate": 30, "display_name": "aladagemre"}, "is_accepted": false, "question_id": 33148588}, {"body": "<p>We had the same problem, the mesos-master log flooding with messages like: </p>\n\n<p>mesos-master[27499]: E0616 14:29:39.310302 27523 socket.hpp:174] Shutdown failed on fd=67: Transport endpoint is not connected [107]</p>\n\n<p>Turned out it was the loadbalancers health check to /stats.json </p>\n", "answer_id": 37859434, "last_activity_date": 1466080531, "creation_date": 1466080531, "score": 0, "owner": {"user_id": 2241329, "profile_image": "https://i.stack.imgur.com/nbaXv.jpg?s=128&g=1", "user_type": "registered", "reputation": 171, "link": "https://stackoverflow.com/users/2241329/tarwin", "display_name": "Tarwin"}, "is_accepted": false, "question_id": 33148588}], "owner": {"user_id": 939341, "profile_image": "https://www.gravatar.com/avatar/fbc25280c3402693d248a4c776be54bf?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 400, "link": "https://stackoverflow.com/users/939341/aladagemre", "accept_rate": 30, "display_name": "aladagemre"}, "view_count": 2935, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 33148588}{"body": "<p>I am trying to install mesos on centos. But during installation I get the following error when I run ./configure:</p>\n\n<p>checking dependency style of gcc... (cached) gcc3\n./configure: line 19168: syntax error near unexpected token <code>google.protobuf,'\n./configure: line 19168:</code>      AC_PYTHON_MODULE(google.protobuf, yes)' </p>\n\n<p>The solution as mentioned here\n<a href=\"https://issues.apache.org/jira/browse/MESOS-1727\" rel=\"nofollow\">https://issues.apache.org/jira/browse/MESOS-1727</a> is to update the pig-config and retry. </p>\n\n<p>Need help to understand how to update pkg-config.</p>\n", "is_answered": false, "tags": ["apache", "centos", "mesos", "mesosphere"], "title": "How to update pkg-config in cent os?", "last_activity_date": 1428506579, "answer_count": 1, "creation_date": 1428480797, "score": 0, "link": "https://stackoverflow.com/questions/29509295/how-to-update-pkg-config-in-cent-os", "answers": [{"body": "<p>You fail to mention the version and the arch of your OS. Technically, in Centos with base repo all you have to do is:</p>\n\n<pre><code>yum install pkgconfig\n</code></pre>\n\n<p>Hope this helps,</p>\n\n<p>Deeh</p>\n", "answer_id": 29518820, "last_activity_date": 1428506579, "creation_date": 1428506579, "score": 0, "owner": {"user_id": 3561302, "profile_image": "https://i.stack.imgur.com/1SMnY.jpg?s=128&g=1", "user_type": "registered", "reputation": 462, "link": "https://stackoverflow.com/users/3561302/deeh", "display_name": "Deeh"}, "is_accepted": false, "question_id": 29509295}], "owner": {"user_id": 2366051, "profile_image": "https://www.gravatar.com/avatar/da3882c798fd179efe8a7d253ab6c919?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 115, "link": "https://stackoverflow.com/users/2366051/bhargav-sarvepalli", "accept_rate": 14, "display_name": "Bhargav Sarvepalli"}, "view_count": 69, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29509295}{"body": "<p>I have installed DC/OS with Vagrant using this code:</p>\n\n<p><a href=\"https://github.com/dcos/dcos-vagrant\" rel=\"nofollow noreferrer\">https://github.com/dcos/dcos-vagrant</a></p>\n\n<p>After that I installed the package with Docker Registry.</p>\n\n<p>The installation worked and in the web panel looks healthy but I can't access the registry from the agents.</p>\n\n<p>The agents have the certificate used by the server.</p>\n\n<p>I've tried with \"docker push\" and it just keeps retrying when trying to send the image.</p>\n\n<p>Also I see an error in the registry logs trying to connect with the master and getting an unexpected EOF.</p>\n\n<p>I have followed all the steps in the documentation to install Docker Registry in DC/OS and found no additional information to resolve this.</p>\n\n<p>Can you please help me to have a working Docker Registry running in DC/OS</p>\n", "is_answered": false, "tags": ["docker", "docker-registry", "dcos"], "title": "DC/OS Docker Registry not responding", "last_activity_date": 1500327044, "answer_count": 0, "creation_date": 1500327044, "score": 0, "link": "https://stackoverflow.com/questions/45153974/dc-os-docker-registry-not-responding", "owner": {"user_id": 181337, "profile_image": "https://www.gravatar.com/avatar/471b3ac93ac8da3a68c8dd72c9225fcd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 5364, "link": "https://stackoverflow.com/users/181337/facundo-casco", "accept_rate": 65, "display_name": "Facundo Casco"}, "view_count": 23, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 45153974}{"is_answered": false, "tags": ["meteor", "mesosphere"], "title": "Mesosphere form validation call back is not working", "last_activity_date": 1422859078, "answer_count": 0, "creation_date": 1422859078, "score": 1, "link": "https://stackoverflow.com/questions/28272314/mesosphere-form-validation-call-back-is-not-working", "owner": {"user_id": 3970095, "profile_image": "https://www.gravatar.com/avatar/59caf34b7f1dce006ff8df9a9bf9cd35?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 211, "link": "https://stackoverflow.com/users/3970095/vamsi-kr", "accept_rate": 56, "display_name": "vamsi kr"}, "view_count": 74, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 28272314}{"body": "<p>I have been setting up a Mesos cluster of 3 nodes(A,B,C), with Mesos Master/Slave and ZooKeeper processes running in each Docker container.</p>\n\n<p>Since cluster setup including <code>docker run</code> is executed using Ansible,\nthere should be no difference between 3 nodes except node-specific configurations(hostname, zookeeper_myid, etc).</p>\n\n<p>Problems are...</p>\n\n<p><strong>Zookeeper Warning on node A</strong></p>\n\n<p>Zookeeper shows following message <strong>only on node A</strong>.</p>\n\n<pre><code>2015-05-25 03:28:06,060 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /&lt;ip-nodeA&gt;:58391\n2015-05-25 03:28:06,060 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@822] - Connection request from old client /&lt;ip-nodeA&gt;:58391; will be dropped if server is in r-o mode\n2015-05-25 03:28:06,060 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@841] - Refusing session request for client /&lt;ip-nodeA&gt;:58391 as it has seen zxid 0x44 our last zxid is 0xc client must try another server\n2015-05-25 03:28:06,060 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /&lt;ip-nodeA&gt;:58391 (no session established for client)\n</code></pre>\n\n<p>Zookeeper on node B shows following messages.</p>\n\n<pre><code>2015-05-25 03:12:18,594 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /&lt;ip-nodeB&gt;:42784 which had sessionid 0x14d89037c1e0000\n2015-05-25 03:12:30,000 [myid:] - INFO  [SessionTracker:ZooKeeperServer@347] - Expiring session 0x14d89037c1e0000, timeout of 10000ms exceeded\n2015-05-25 03:12:30,001 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@494] - Processed session termination for sessionid: 0x14d89037c1e0000\n2015-05-25 03:12:30,987 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /&lt;ip-nodeB&gt;:42853\n2015-05-25 03:12:30,987 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@822] - Connection request from old client /&lt;ip-nodeB&gt;:42853; will be dropped if server is in r-o mode\n2015-05-25 03:12:30,988 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /&lt;ip-nodeB&gt;:42853\n2015-05-25 03:12:30,997 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x14d89037c1e0002 with negotiated timeout 10000 for client /&lt;ip-nodeB&gt;:42853\n</code></pre>\n\n<p>Zookeeper on node C shows following messages.</p>\n\n<pre><code>2015-05-25 03:12:31,183 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /&lt;ip-nodeA&gt;:56496\n2015-05-25 03:12:31,184 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@822] - Connection request from old client /&lt;ip-nodeA&gt;:56496; will be dropped if server is in r-o mode\n2015-05-25 03:12:31,184 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /&lt;ip-nodeA&gt;:56496\n2015-05-25 03:12:31,191 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x14d89037ccd0002 with negotiated timeout 10000 for client /&lt;ip-nodeA&gt;:56496\n</code></pre>\n\n<p><strong>\"No master is currently leading...\" on node B</strong></p>\n\n<p>Node C is elected for master.\nAccessing mesos admin page on node A is successfully redirected to node C.</p>\n\n<p>But it doesn't redirect node B to node C, showing \"No master is currently leading...\" instead.</p>\n\n<p><strong>Only 2 of 3 slaves detected by master node</strong></p>\n\n<p>On master node (currently node C), 2 of 3 slaves are detected.\n2 detected slaves are; node A and C</p>\n\n<p><strong>Then, what is the possible cause of these problems?</strong></p>\n\n<p>OS: CentOS 6.5</p>\n\n<p>Docker Images:</p>\n\n<ul>\n<li>Mesos Master: redjack/mesos-master</li>\n<li>Mesos Slave: redjack/mesos-slave</li>\n<li>ZooKeeper: digitalwonderland/zookeeper</li>\n</ul>\n\n<p>Docker versions:</p>\n\n<pre><code>Client version: 1.5.0\nClient API version: 1.17\nGo version (client): go1.3.3\nGit commit (client): a8a31ef/1.5.0\nOS/Arch (client): linux/amd64\nServer version: 1.5.0\nServer API version: 1.17\nGo version (server): go1.3.3\nGit commit (server): a8a31ef/1.5.0\n</code></pre>\n", "is_answered": false, "tags": ["docker", "apache-zookeeper", "mesos", "mesosphere"], "title": "Mesos+ZooKeeper don't work fine", "last_activity_date": 1432525535, "answer_count": 0, "creation_date": 1432525535, "score": 2, "link": "https://stackoverflow.com/questions/30430915/mesoszookeeper-dont-work-fine", "owner": {"user_id": 4561679, "profile_image": "https://www.gravatar.com/avatar/8056220017224061af54439626b73add?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 652, "link": "https://stackoverflow.com/users/4561679/ai0307", "accept_rate": 57, "display_name": "ai0307"}, "view_count": 646, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30430915}{"body": "<p>I installed DC/OS with 3 masters and 3 agents and face a problem with virtual networking. Here is my Marathon app spec:</p>\n\n<pre><code>{\n  \"id\": \"/nginx\",\n  \"cmd\": null,\n  \"cpus\": 1,\n  \"mem\": 128,\n  \"disk\": 0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"nginx\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 80,\n          \"hostPort\": 0,\n          \"servicePort\": 10002,\n          \"protocol\": \"tcp\",\n          \"name\": \"main1\",\n          \"labels\": {\n            \"VIP_0\": \"9.0.0.0:34562\"\n          }\n        }\n      ],\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10002,\n      \"protocol\": \"tcp\",\n      \"labels\": {}\n    }\n  ]\n}\n</code></pre>\n\n<p>I see the following in the DC/OS virtual network section:</p>\n\n<p>VIRTUAL NETWORK NAME |  SUBNET    |   AGENT PREFIX LENGTH</p>\n\n<p>dcos            9.0.0.0/8             24</p>\n\n<p>The containers stays in waiting for a long time. If I remove the port mapping section it runs successfully. </p>\n\n<p>Basically I need to know how to work with this new virtual network, and fix the service discovery and load balancing without using any extra stuff.</p>\n", "is_answered": true, "tags": ["mesos", "marathon", "dcos", "virtual-network"], "last_edit_date": 1482039040, "title": "DC/OS marathon Virtual network not working", "last_activity_date": 1482614105, "answer_count": 1, "creation_date": 1481982828, "score": 1, "link": "https://stackoverflow.com/questions/41199304/dc-os-marathon-virtual-network-not-working", "answers": [{"body": "<p>Took me some time to figure it out as well...</p>\n\n<p>You need to:</p>\n\n<ul>\n<li>Remove all ports assignment in the task definition </li>\n<li><p>Describe the name of the network to attach to (default network created is named \"dcos\")</p>\n\n<pre><code>{\n    \"id\": \"yourtask\",\n    \"container\": {\n        \"type\": \"DOCKER\",\n        \"docker\": {\n            \"image\": \"your/image\",\n            \"network\": \"USER\"\n        }\n    },\n    \"acceptedResourceRoles\" : [\n        \"slave_public\"\n    ],\n    \"ipAddress\": {\n        \"networkName\": \"dcos\"\n    },\n    \"instances\": 2,\n    \"cpus\": 0.2,\n    \"mem\": 128\n}\n</code></pre></li>\n</ul>\n", "answer_id": 41316882, "last_activity_date": 1482614105, "creation_date": 1482614105, "score": 1, "owner": {"user_id": 505840, "profile_image": "https://www.gravatar.com/avatar/3df36dd98a06fe5ba2c53060405d6f81?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 133, "link": "https://stackoverflow.com/users/505840/leo", "display_name": "Leo"}, "is_accepted": false, "question_id": 41199304}], "owner": {"user_id": 1124447, "profile_image": "https://www.gravatar.com/avatar/38565246d552f18c291145ff05c373d0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 522, "link": "https://stackoverflow.com/users/1124447/vimal-prakash", "accept_rate": 48, "display_name": "vimal prakash"}, "view_count": 122, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41199304}{"body": "<p>I have kafka conenct running in Marathon container. If I want to update the connector plugin (jar) I have to upload the new one and then restart the Connect task.</p>\n\n<p>Is it possible to do that without restarting/downtime?</p>\n", "is_answered": false, "tags": ["dcos", "apache-kafka-connect", "confluent-kafka"], "title": "How to update running kafka connector", "last_activity_date": 1479000840, "answer_count": 1, "creation_date": 1478874520, "score": 1, "link": "https://stackoverflow.com/questions/40550090/how-to-update-running-kafka-connector", "answers": [{"body": "<p>The updated jar for the connector plugin needs to be added to the classpath and then the classloader for the worker needs to pick it up.  The best way to do this currently is to take an outage as described <a href=\"http://docs.confluent.io/3.1.0/connect/managing.html#upgrading-a-connector-plugin\" rel=\"nofollow noreferrer\" title=\"here\">here</a>.</p>\n\n<p>Depending on your connector, you might be able to do rolling upgrades, but the generic answer is that if you need to upgrade the connector plugin, you currently have to take an outage.</p>\n", "answer_id": 40569624, "last_activity_date": 1479000840, "creation_date": 1479000840, "score": 0, "owner": {"user_id": 2796894, "profile_image": "https://i.stack.imgur.com/NTxyT.jpg?s=128&g=1", "user_type": "registered", "reputation": 710, "link": "https://stackoverflow.com/users/2796894/dawsaw", "display_name": "dawsaw"}, "is_accepted": false, "question_id": 40550090}], "owner": {"user_id": 2401913, "profile_image": "https://www.gravatar.com/avatar/ae42f8c3f0c80b186c75e2da066db00a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/2401913/cattaneo", "accept_rate": 50, "display_name": "cattaneo"}, "view_count": 86, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40550090}{"body": "<p>What does offers tab on mesos-master dashboard represent? I have slaves registered to my master and has applications running on them deployed by marathon, but Offers tab shows nothing in my case. </p>\n", "is_answered": true, "title": "Offers tab on mesos dashboard", "tags": ["mesos", "mesosphere", "marathon"], "last_activity_date": 1466415803, "accepted_answer_id": 37919246, "creation_date": 1466406132, "answers": [{"body": "<p>It shows offers presented to framework but not accepted yet. That's why page state <code>outstanding offers</code> in subtitle. Once offer is accepted it is no longer an offer and gets removed, so your offers tab is empty.</p>\n\n<p><a href=\"http://search-hadoop.com/m/0Vlr6vScS5DPmxp&amp;subj=Re+mesos+0+24+1+and+0+25+0+offers+web+ui+not+appearing+to+work\" rel=\"nofollow\">Source</a></p>\n", "answer_id": 37919246, "last_activity_date": 1466415803, "creation_date": 1466415803, "score": 1, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": true, "question_id": 37916363}], "score": 0, "link": "https://stackoverflow.com/questions/37916363/offers-tab-on-mesos-dashboard", "answer_count": 1, "owner": {"user_id": 6315572, "profile_image": "https://i.stack.imgur.com/R0sLG.jpg?s=128&g=1", "user_type": "registered", "reputation": 186, "link": "https://stackoverflow.com/users/6315572/t6nand", "accept_rate": 54, "display_name": "t6nand"}, "view_count": 189, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37916363}{"is_answered": true, "tags": ["mesos", "mesosphere"], "title": "Mesosphere not allowing External Traffic", "last_activity_date": 1427317747, "answer_count": 1, "creation_date": 1427224402, "score": 0, "link": "https://stackoverflow.com/questions/29240980/mesosphere-not-allowing-external-traffic", "accepted_answer_id": 29266564, "owner": {"user_id": 1199314, "profile_image": "https://www.gravatar.com/avatar/c9e1ec8f4a89feba3039ac3df45af767?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 82, "link": "https://stackoverflow.com/users/1199314/nadi-hassan-hassan", "accept_rate": 36, "display_name": "Nadi Hassan Hassan"}, "view_count": 227, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 29240980}{"body": "<p>I have two instances of spark in my DCOS cluster, when I submit my job via CLI </p>\n\n<pre><code>dcos spark run --submit-args=\"\\\n                 --driver-cores 8 \\\n                 --driver-memory 16384M \\\n                 --conf spark.eventLog.enabled=true \\\n                 --conf spark.eventLog.dir=hdfs://hdfs/history \\\n                 --class com.CalcPi \\\n                 &lt;url to job -spark-test-assembly-0.0.5-SNAPSHOT.jar&gt; 99000000\"`\n</code></pre>\n\n<p>the job is forever stuck in the queue. But when I have only one instance everything works fine. I have already try\n<code>--deploy-mode cluster --supervise</code></p>\n", "is_answered": true, "title": "Submit job to DCOS Spark with multiple instances?", "last_edit_date": 1499949620, "tags": ["apache-spark", "cluster-computing", "mesos", "mesosphere", "dcos"], "view_count": 41, "accepted_answer_id": 45247210, "last_activity_date": 1500673963, "answers": [{"body": "<p>The following config options are hopefully the answer you are looking for:</p>\n\n<pre><code>dcos config set spark.app_id spark-one\ndcos spark run ...\ndcos config set spark.app_id spark-two\ndcos spark run ...\n</code></pre>\n", "answer_id": 45247210, "last_activity_date": 1500673963, "creation_date": 1500673963, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": true, "question_id": 45043411}], "score": 0, "link": "https://stackoverflow.com/questions/45043411/submit-job-to-dcos-spark-with-multiple-instances", "answer_count": 1, "owner": {"user_id": 3434397, "profile_image": "https://www.gravatar.com/avatar/f76cdcd4fbc55698f5f6a85bb5d77b90?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 15, "link": "https://stackoverflow.com/users/3434397/ignaciopl", "accept_rate": 50, "display_name": "IgnacioPL"}, "creation_date": 1499802745, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45043411}{"is_answered": true, "tags": ["centos", "marathon", "dcos"], "title": "Re-Attaching a DCOS agent node to DCOS", "last_activity_date": 1502092295, "answer_count": 1, "creation_date": 1502089383, "score": 1, "link": "https://stackoverflow.com/questions/45541083/re-attaching-a-dcos-agent-node-to-dcos", "accepted_answer_id": 45541877, "owner": {"user_id": 1642790, "profile_image": "https://i.stack.imgur.com/OvpjC.jpg?s=128&g=1", "user_type": "registered", "reputation": 146, "link": "https://stackoverflow.com/users/1642790/pjesudhas", "accept_rate": 71, "display_name": "pjesudhas"}, "view_count": 25, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45541083}{"body": "<p>I've set up a DC/OS container service on Azure and tried to set up a VPN according to the <a href=\"https://dcos.io/docs/1.8/administration/access-node/tunnel/#docs-article\" rel=\"nofollow\">Access by Proxy and VPN using DC/OS Tunnel</a>.</p>\n\n<p>I used:</p>\n\n<pre><code>sudo dcos tunnel vpn --sport 2200 --user=azureuser\n</code></pre>\n\n<p>I'm getting a ConnectTimeoutError</p>\n\n<p>Any suggestions?</p>\n", "is_answered": false, "tags": ["azure", "dcos"], "last_edit_date": 1477188214, "title": "DC/OS on Azure set up VPN", "last_activity_date": 1477188214, "answer_count": 0, "creation_date": 1477176123, "score": 1, "link": "https://stackoverflow.com/questions/40197754/dc-os-on-azure-set-up-vpn", "owner": {"user_id": 67505, "profile_image": "https://www.gravatar.com/avatar/094c0ec476b95ed7619d6a4cb918da78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9919, "link": "https://stackoverflow.com/users/67505/chen-kinnrot", "accept_rate": 71, "display_name": "Chen Kinnrot"}, "view_count": 85, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40197754}{"is_answered": true, "tags": ["python", "dcos"], "last_edit_date": 1467907364, "title": "dcos client installation failure - import concurrent.futures ImportError: No module named concurrent.futures", "last_activity_date": 1467991079, "answer_count": 1, "creation_date": 1467907008, "score": 2, "link": "https://stackoverflow.com/questions/38250107/dcos-client-installation-failure-import-concurrent-futures-importerror-no-mod", "owner": {"user_id": 5394011, "profile_image": "https://www.gravatar.com/avatar/e3c479380f100afa9b8ae130a0fb2c02?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/5394011/cruizpollino", "display_name": "cruizpollino"}, "view_count": 1142, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 38250107}{"is_answered": true, "tags": ["mesos", "marathon", "dcos"], "last_edit_date": 1476382753, "title": "Unable to install Kafka on DCOS", "last_activity_date": 1477333754, "answer_count": 1, "creation_date": 1476381489, "score": 4, "link": "https://stackoverflow.com/questions/40027877/unable-to-install-kafka-on-dcos", "accepted_answer_id": 40225091, "owner": {"user_id": 5426365, "profile_image": "https://www.gravatar.com/avatar/23636f151b2e311f6f0a5f6b25861e0b?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 119, "link": "https://stackoverflow.com/users/5426365/kiba", "accept_rate": 56, "display_name": "Kiba"}, "view_count": 224, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 40027877}{"closed_date": 1504369066, "is_answered": false, "closed_reason": "off-topic", "tags": ["docker", "kubernetes", "docker-swarm", "dcos", "rancher"], "title": "Any Other Package managers like DCOS Universe?", "last_activity_date": 1504357925, "answer_count": 0, "creation_date": 1504357925, "score": -1, "link": "https://stackoverflow.com/questions/46014185/any-other-package-managers-like-dcos-universe", "owner": {"user_id": 6261826, "profile_image": "https://www.gravatar.com/avatar/4abab2d399d00da920ad9a2bce0226eb?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 93, "link": "https://stackoverflow.com/users/6261826/naik3", "accept_rate": 73, "display_name": "naik3"}, "view_count": 48, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 46014185}{"body": "<p>As far as i know, DC/OS has two different types of tokens:</p>\n\n<ul>\n<li><p><strong>authentication token</strong>: retrieved via a login through\n<a href=\"https://public-master-ip/login?redirect_uri=urn:ietf:wg:oauth:2.0:oob\" rel=\"nofollow\">https://public-master-ip/login?redirect_uri=urn:ietf:wg:oauth:2.0:oob</a>. This token is used to retrieve api tokens.</p></li>\n<li><p><strong>api token</strong>: retrieved via a post call to <a href=\"https://public-master-ip/acs/api/v1/auth/login\" rel=\"nofollow\">https://public-master-ip/acs/api/v1/auth/login</a> with the authentication token in the request body. This token is used to authorize calls against the apis. Such a token expires after 5 days.</p></li>\n</ul>\n\n<p>My questions are</p>\n\n<ol>\n<li>Are my assumptions correct?</li>\n<li>Does a authentication token expire? If so, when and is there a way to refresh it?</li>\n</ol>\n", "is_answered": true, "title": "DC/OS - authentication vs. api token", "tags": ["marathon", "dcos"], "last_activity_date": 1474311558, "accepted_answer_id": 39580254, "creation_date": 1474111243, "answers": [{"body": "<p>Let me first define the goal of the current (1.8) Open DC/OS authentication procedure and then walk through your assumptions. I'll answer your questions after that.</p>\n\n<h2>Goal</h2>\n\n<p>The goal of the current Open DC/OS authentication procedure is to use <a href=\"https://auth0.com/\" rel=\"noreferrer\">Auth0</a> infrastructure for triggering a single sign-on authentication flow against one of three popular identity providers, and have the result reported back to <em>your</em> DC/OS cluster. If the DC/OS cluster is happy with the result, it will emit an authentication token specifically adjusted to that individual cluster.</p>\n\n<h2>Comments on your assumptions</h2>\n\n<blockquote>\n  <p>authentication token: retrieved via a login through <a href=\"https://public-master-ip/login?redirect_uri=urn:ietf:wg:oauth:2.0:oob\" rel=\"noreferrer\">https://public-master-ip/login?redirect_uri=urn:ietf:wg:oauth:2.0:oob</a>. This token is used to retrieve api tokens.</p>\n</blockquote>\n\n<p>That's roughly true. However, what you call \"authentication token\" actually is an <strong>OpenID Connect ID Token</strong> emitted by an OpenID Connect identity provider.</p>\n\n<p>Let us take this one slowly, as it is a little involved.</p>\n\n<p>What happens behind the scenes is an <a href=\"http://openid.net/connect/\" rel=\"noreferrer\">OpenID Connect</a> single sign-on authentication flow.</p>\n\n<p>More precisely, the DC/OS UI displays an iframe that loads a piece of JavaScript hosted by Auth0, which -- when executed in <em>your</em> browser -- performs the so-called <a href=\"http://openid.net/specs/openid-connect-core-1_0.html#ImplicitFlowAuth\" rel=\"noreferrer\">implicit flow</a> (which is one of three specified OpenID Connect authentication flow types).</p>\n\n<p>By the end of this flow(<code>*</code>) the JavaScript code executed in your browser receives a so-called OpenID Connect <a href=\"http://openid.net/specs/openid-connect-core-1_0.html#IDToken\" rel=\"noreferrer\">ID Token</a> (from the identity provider, of course, which is Auth0 in this case). This token is a JSON Web Token (JWT, see <a href=\"https://tools.ietf.org/html/rfc7519\" rel=\"noreferrer\">RFC7519</a>) signed with the private key of the identity provider (in this case it actually <em>is</em> Auth0, which basically proxies other identity providers such as Google Accounts).</p>\n\n<p>The piece of JavaScript that receives the ID token then  -- as you say -- POSTs the ID Token to your DC/OS cluster (to <a href=\"https://public-master-ip/acs/api/v1/auth/login\" rel=\"noreferrer\">https://public-master-ip/acs/api/v1/auth/login</a>). The receiving end is a web application behind DC/OS' Admin Router (the latter is just a pimped nginx). That web application inspects the ID Token's payload (which is JSON) and finds the key/value pair <code>\"iss\": \"https://dcos.auth0.com/\"</code>. So it knows who (pretends to) have issued that token! Then it goes ahead and fetches <a href=\"https://dcos.auth0.com/.well-known/openid-configuration\" rel=\"noreferrer\">https://dcos.auth0.com/.well-known/openid-configuration</a> (wooo, where does it know that URL from? This is magic defined by <a href=\"https://openid.net/specs/openid-connect-discovery-1_0.html\" rel=\"noreferrer\">OpenID Connect Discovery 1.0</a> and <a href=\"https://tools.ietf.org/html/rfc5785\" rel=\"noreferrer\">RFC5785</a>). That JSON document there defines a JSON Web Key Set (JWKS) document (specified via <a href=\"https://tools.ietf.org/html/rfc7517\" rel=\"noreferrer\">RFC7517</a>), revealing the <em>public</em> key corresponding to the <em>private</em> key that had (supposedly) signed the ID Token. So, that web application goes ahead and fetches the public key <em>directly</em> from the identity provider (through HTTPS). It then uses that public key to verify the cryptographic signature of the ID Token (and it checks the expiration time, too, of course). If ID Token validation passes, the DC/OS web application I talked about rightfully assumes that the user agent that had sent the ID Token is successfully authenticated against Auth0. And, trusting Auth0, we rightfully assume that the user agent is authenticated against e.g. Google Accounts.</p>\n\n<p>Only then it (the small web application in DC/OS I talked about) stores the identity within DC/OS, assigns a unique user ID, and emits the <strong>DC/OS authentication token</strong>. That token refers to the given identity via the named user ID.</p>\n\n<p>(<code>*</code>)Note that the identity provider <em>only</em> emits the ID Token towards your browser after you have successfully authenticated yourself towards that provider (e.g. Google Accounts) and after you have given consent to share identity details with a third-party service.</p>\n\n<blockquote>\n  <p>api token: retrieved via a post call to <a href=\"https://public-master-ip/acs/api/v1/auth/login\" rel=\"noreferrer\">https://public-master-ip/acs/api/v1/auth/login</a> with the authentication token in the request body. This token is used to authorize calls against the apis. Such a token expires after 5 days.</p>\n</blockquote>\n\n<p>In DC/OS terminology, this is <strong>the DC/OS authentication token</strong>. It is a JWT signed with a random key only known to your DC/OS cluster. The Admin Router in your DC/OS can validate such authentication tokens. Certain HTTP requests against Admin Router are <em>only</em> proxied to back-end services when they contain a valid authentication token in the request (hence, this token mainly serves <em>authentication</em>, but also a very basic coarse-grained <em>authorization</em>, if you want to say so). Otherwise, Admin Router will respond with a 401 (read: \"not authenticated\").</p>\n\n<h2>Answers to your questions</h2>\n\n<blockquote>\n  <p>Are my assumptions correct?</p>\n</blockquote>\n\n<p>I hope to have clarified</p>\n\n<ul>\n<li>that what you call \"authentication token\" is an OpenID Connect ID Token (a JWT). </li>\n<li>that what you call \"api token\" is what's called \"DC/OS authentication token\" in the DC/OS ecosystem (and it's technically a JWT, too).</li>\n</ul>\n\n<blockquote>\n  <p>Does a authentication token expire?</p>\n</blockquote>\n\n<p>I read this question as \"Does an OpenID Connect ID Token expire?\" Yes, indeed! This is what the spec says about ID Token expiration:</p>\n\n<blockquote>\n  <p>exp -- REQUIRED -- Expiration time on or after which the ID Token MUST NOT be accepted for processing. The processing of this parameter requires that the current date/time MUST be before the expiration date/time listed in the value. Implementers MAY provide for some small leeway, usually no more than a few minutes, to account for clock skew. Its value is a JSON number representing the number of seconds from 1970-01-01T0:0:0Z as measured in UTC until the date/time. See RFC 3339 [RFC3339] for details regarding date/times in general and UTC in particular.</p>\n</blockquote>\n\n<p>Note that the spec does <em>not</em> enforce a particular ID Token lifetime -- this is up to identity providers to set. In case of ID Tokens emitted by dcos.auth0.com I have just confirmed that</p>\n\n<pre><code>&gt;&gt;&gt; exp = 1474742063\n&gt;&gt;&gt; iat = 1474310063\n&gt;&gt;&gt; lifetime_days = (exp - iat) / (60.0 * 60 * 24)\n&gt;&gt;&gt; lifetime_days\n5.0\n</code></pre>\n\n<p>That is, the ID Token emitted by Auth0 expires after 5 days.</p>\n\n<blockquote>\n  <p>If so, when and is there a way to refresh it?</p>\n</blockquote>\n\n<p>You can only obtain a new ID Token emitted by Auth0 by going through an OpenID Connect authentication flow involving one of the configured identity providers. That is, the (only) intended way to obtain such a token and pass it along to DC/OS is triggered through the DC/OS UI which starts the Auth0-based flow for you (well, you could technically hack this together yourself...).</p>\n\n<p>Note that Enterprise DC/OS offers an OpenID Connect authentication flow that</p>\n\n<ul>\n<li>directly communicates the ID Token securely between DC/OS and the identity provider (no user agent ever sees that ID Token).</li>\n<li>enforces the usage of the optional <code>nonce</code> mechanism of OpenID Connect ID Tokens (described <a href=\"http://openid.net/specs/openid-connect-core-1_0.html#IDToken\" rel=\"noreferrer\">in the spec</a>), introducing more conceptual security on multiple levels (e.g.  mitigating replay attacks).</li>\n</ul>\n\n<p>We will probably merge that functionality into Open DC/OS by one of the next releases (no promises at this point!).</p>\n\n<p>I hope that helped, let me know if there are further questions.</p>\n", "answer_id": 39580254, "last_activity_date": 1474311558, "creation_date": 1474311558, "score": 11, "owner": {"user_id": 145400, "profile_image": "https://www.gravatar.com/avatar/e40548053ab6deeef715a1f7fd0aafef?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 15719, "link": "https://stackoverflow.com/users/145400/jan-philip-gehrcke", "accept_rate": 91, "display_name": "Jan-Philip Gehrcke"}, "is_accepted": true, "question_id": 39546227}], "score": 4, "link": "https://stackoverflow.com/questions/39546227/dc-os-authentication-vs-api-token", "answer_count": 1, "owner": {"user_id": 6842503, "profile_image": "https://www.gravatar.com/avatar/affdf33c7ccd167843d591011ccaf0fd?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 23, "link": "https://stackoverflow.com/users/6842503/sjahreis", "display_name": "sjahreis"}, "view_count": 658, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39546227}{"body": "<p>Have checked this URL (<a href=\"https://support.mesosphere.com/hc/en-us/articles/205575835-My-Marathon-app-isn-t-deploying-What-s-wrong-\" rel=\"nofollow\">https://support.mesosphere.com/hc/en-us/articles/205575835-My-Marathon-app-isn-t-deploying-What-s-wrong-</a>) the logs did not show any reason. Also logs in /var/log/syslog and /var/log/mesos do not give any reason. </p>\n\n<p>The JSON file of the app I'm trying to deploy:</p>\n\n<pre><code>    {\n      \"id\": \"/nodeexporter\",\n      \"instances\": 1,\n      \"constraints\": [[\"hostname\", \"UNIQUE\"]],\n      \"container\": {\n           \"type\": \"DOCKER\",\n           \"docker\": {\n           \"image\": \"prom/node-exporter\",\n           \"network\": \"BRIDGE\",\n           \"portMappings\": [\n               {\n                   \"containerPort\": 9100,\n                   \"hostPort\": 0,\n                   \"protocol\": \"tcp\"\n               }\n              ]\n           }\n       },\n      \"healthChecks\": [{\n      \"protocol\": \"TCP\",\n      \"gracePeriodSeconds\": 600,\n      \"intervalSeconds\": 30,\n      \"portIndex\": 0,\n      \"timeoutSeconds\": 10,\n      \"maxConsecutiveFailures\": 2\n      }]\n  }\n</code></pre>\n", "is_answered": true, "title": "If an marathon app running in a docker image, is in 'deploying' state, where can we check the reason why the app isn't deploying?", "tags": ["docker", "mesosphere", "marathon"], "last_activity_date": 1440085415, "accepted_answer_id": 31806277, "creation_date": 1438679482, "answers": [{"body": "<p>I faced similar issue in my Mesos + Marathon setup. The reason was lack of resources on the slaves.</p>\n\n<p>In your json file, you have not specified any value for <code>cpus</code> or <code>mem</code> directives. Default, AFAIK, for these are 1 CPU and 128 MB of memory. If no slave has enough resources available, your app will keep lurking around in the deployment state.</p>\n\n<p>On your Mesos master UI, check the total and available resources. If your app doesn't need much CPU or memory, try setting these values to something like below in your json file:</p>\n\n<pre><code>\"cpus\": 0.1,\n\"mem\": 16\n</code></pre>\n\n<p>and see if it succeeds to start.</p>\n\n<p><strong>EDIT</strong>: Just saw that you're trying to run Prometheus Node Exporter. I am running that on my setup and it's consuming just about 25 MB memory.</p>\n", "answer_id": 31806277, "last_activity_date": 1438683716, "creation_date": 1438682542, "score": 1, "owner": {"user_id": 395670, "profile_image": "https://i.stack.imgur.com/ANDAD.jpg?s=128&g=1", "user_type": "registered", "reputation": 1336, "link": "https://stackoverflow.com/users/395670/dharmit", "accept_rate": 77, "display_name": "Dharmit"}, "is_accepted": true, "last_edit_date": 1438683716, "question_id": 31805164}, {"body": "<p>In case the task fails and you see nothing in either stdout or stderr, you can check the log on the slave that is executing or has executed the task to see if there is a reason (i.e. couldn't find the container).</p>\n", "answer_id": 32122649, "last_activity_date": 1440085415, "creation_date": 1440085415, "score": 1, "owner": {"user_id": 1769505, "profile_image": "https://www.gravatar.com/avatar/bea2c42d4f4317e8f6b8eb3802f349d3?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/1769505/alex-reuter", "display_name": "Alex Reuter"}, "is_accepted": false, "question_id": 31805164}], "score": 0, "link": "https://stackoverflow.com/questions/31805164/if-an-marathon-app-running-in-a-docker-image-is-in-deploying-state-where-can", "answer_count": 2, "owner": {"user_id": 5188802, "profile_image": "https://www.gravatar.com/avatar/96fdffb493ccaef2a9b3bb57a332ffe1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/5188802/rajasi-kulkarni", "accept_rate": 100, "display_name": "Rajasi Kulkarni"}, "view_count": 154, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 31805164}{"is_answered": false, "tags": ["c++", "mesos", "mesosphere"], "title": "Compilation Error With Mesosphere RENDLER", "last_activity_date": 1432315139, "answer_count": 1, "creation_date": 1432314462, "score": 0, "link": "https://stackoverflow.com/questions/30402300/compilation-error-with-mesosphere-rendler", "owner": {"user_id": 4929824, "profile_image": "https://www.gravatar.com/avatar/d8b43efbbeac2da4602ed8287b7fcd8e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/4929824/atheatos", "display_name": "atheatos"}, "view_count": 40, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 30402300}{"is_answered": false, "tags": ["amazon-web-services", "dcos"], "last_edit_date": 1496849472, "title": "DCOS Mesos agent fails to retrieve private resources from S3 bucket", "last_activity_date": 1496849472, "answer_count": 0, "creation_date": 1496848905, "score": 1, "link": "https://stackoverflow.com/questions/44416776/dcos-mesos-agent-fails-to-retrieve-private-resources-from-s3-bucket", "owner": {"user_id": 8126054, "profile_image": "https://www.gravatar.com/avatar/3dbe939813e950425e4b1005e999d5d1?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/8126054/matt-r", "display_name": "Matt R"}, "view_count": 37, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44416776}{"body": "<p>I was wondering if there were any best practices for restricting the amount of resources available to Mesos.  Specifically, CPU resources.  We have a busy mesos cluster running CPU intensive tasks within docker containers.  Is it a good idea to reserve one or two cores for non-mesos tasks?  Or is allowing mesos to offer all of the available CPUs on the machine just fine?</p>\n\n<p>A link to some best practices regarding resources would be great as well.  The almighty Google wasn't very productive.  I'd just like some advice and hopefully evidence that this is a good idea before suggesting we move forward down this path.</p>\n\n<p>Thanks!</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "Mesos Resources Best Practices", "last_activity_date": 1464113070, "answer_count": 0, "creation_date": 1464113070, "score": 2, "link": "https://stackoverflow.com/questions/37420814/mesos-resources-best-practices", "owner": {"user_id": 290541, "profile_image": "https://i.stack.imgur.com/92EyJ.jpg?s=128&g=1", "user_type": "registered", "reputation": 934, "link": "https://stackoverflow.com/users/290541/blockcipher", "accept_rate": 61, "display_name": "blockcipher"}, "view_count": 137, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 37420814}{"body": "<p><br>\nI'm trying to setup simple mesos cluster on 2 virtual machines. IPs are:</p>\n\n<ul>\n<li>10.10.0.102 (with 1 master and 1 slave)- FQDN mesos1.mydomain</li>\n<li>10.10.0.103 (with 1 slave)- FQDN mesos2.mydomain</li>\n</ul>\n\n<p>I'm using mesos 0.27.1 (rpm's downloaded from Mesosphere) and CentOS Linux release 7.1.1503 (Core). </p>\n\n<p>I was successful in deploying 1 node cluster (10.10.0.102): master and slave works and I can deploy and scale some simple application via marathon.</p>\n\n<p>The problem comes when I try to  start second slave on 10.10.0.103. Always, when I start that slave its state is deactivated. </p>\n\n<p><strong>Logs from slave on 10.10.0.103:</strong></p>\n\n<pre><code>I0226 13:49:58.428019 14937 slave.cpp:463] Slave resources: cpus(*):1; mem(*):2768; disk(*):3409; ports(*):[31000-32000]\nI0226 13:49:58.428019 14937 slave.cpp:471] Slave attributes: [  ]\nI0226 13:49:58.428019 14937 slave.cpp:476] Slave hostname: mesos2\nI0226 13:49:58.430469 14946 state.cpp:58] Recovering state from '/tmp/mesos/meta'\nI0226 13:49:58.430922 14947 status_update_manager.cpp:200] Recovering status update manager\nI0226 13:49:58.430954 14947 containerizer.cpp:390] Recovering containerizer\nI0226 13:49:58.432219 14947 provisioner.cpp:245] Provisioner recovery complete\nI0226 13:49:58.432273 14947 slave.cpp:4495] Finished recovery\nI0226 13:49:58.448940 14948 group.cpp:349] Group process (group(1)@10.10.0.103:5051) connected to ZooKeeper\nI0226 13:49:58.449050 14948 group.cpp:831] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0226 13:49:58.449064 14948 group.cpp:427] Trying to create path '/mesos' in ZooKeeper\nI0226 13:49:58.451846 14948 detector.cpp:154] Detected a new leader: (id='3')\nI0226 13:49:58.451937 14948 group.cpp:700] Trying to get '/mesos/json.info_0000000003' in ZooKeeper\nI0226 13:49:58.453397 14948 detector.cpp:479] A new leading master (UPID=master@10.10.0.102:5050) is detected\nI0226 13:49:58.453459 14948 slave.cpp:795] New master detected at master@10.10.0.102:5050\nI0226 13:49:58.453698 14948 slave.cpp:820] No credentials provided. Attempting to register without authentication\nI0226 13:49:58.453724 14948 slave.cpp:831] Detecting new master\nI0226 13:49:58.453743 14948 status_update_manager.cpp:174] Pausing sending status updates\nI0226 13:50:58.445101 14948 slave.cpp:4304] Current disk usage 22.11%. Max allowed age: 4.752451232032847days\nI0226 13:51:58.460233 14948 slave.cpp:4304] Current disk usage 22.11%. Max allowed age: 4.752451232032847days\n</code></pre>\n\n<p><strong>Logs from master on 10.10.0.102</strong></p>\n\n<pre><code>I0226 22:55:14.240464  2021 coordinator.cpp:348] Coordinator attempting to write TRUNCATE action at position 682\nI0226 22:55:14.240542  2021 hierarchical.cpp:473] Added slave a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-S167 (mesos2) with cpus(*):1; mem(*):2768; disk(*):3409; ports(*):[31000-32000] (allocated: )\nI0226 22:55:14.240671  2021 master.cpp:5350] Sending 1 offers to framework c5a5818d-16fa-42bf-8e73-697a2d12fe97-0001 (marathon) at scheduler-91034353-1820-4020-aad1-10e11d567136@10.10.0.102:45698\nI0226 22:55:14.240767  2021 replica.cpp:537] Replica received write request for position 682 from (1259)@10.10.0.102:5050\nE0226 22:55:14.241082  2027 process.cpp:1966] Failed to shutdown socket with fd 32: Transport endpoint is not connected\nI0226 22:55:14.241143  2019 master.cpp:1172] Slave a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-S167 at slave(1)@10.10.0.103:5051 (mesos2) disconnected\nI0226 22:55:14.241153  2019 master.cpp:2633] Disconnecting slave a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-S167 at slave(1)@10.10.0.103:5051 (mesos2)\nI0226 22:55:14.241161  2019 master.cpp:2652] Deactivating slave a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-S167 at slave(1)@10.10.0.103:5051 (mesos2)\nI0226 22:55:14.241230  2019 hierarchical.cpp:560] Slave a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-S167 deactivated\nI0226 22:55:14.245923  2019 master.cpp:3673] Processing DECLINE call for offers: [ a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-O1251 ] for framework c5a5818d-16fa-42bf-8e73-697a2d12fe97-0001 (marathon) at scheduler-91034353-1820-4020-aad1-10e11d567136@10.10.0.102:45698\nW0226 22:55:14.245923  2019 master.cpp:3720] Ignoring decline of offer a61e9d9f-f85b-4c72-9780-166a7ffc0ac3-O1251 since it is no longer valid\nI0226 22:55:14.249065  2021 leveldb.cpp:341] Persisting action (18 bytes) to leveldb took 8.264893ms\nI0226 22:55:14.249107  2021 replica.cpp:712] Persisted action at 682\nI0226 22:55:14.249220  2021 replica.cpp:691] Replica received learned notice for position 682 from @0.0.0.0:0\n</code></pre>\n\n<p>I've tried to start slave using two approaches (on 10.10.0.103):</p>\n\n<ul>\n<li>sudo service mesos-slave start</li>\n<li>mesos-slave --master=10.10.0.102:5050 --ip=10.10.0.103</li>\n</ul>\n\n<p>Both give me the same results.</p>\n\n<p>Additionally in MESOS-SLAVE.WARNING I see also:</p>\n\n<pre><code>Running on machine: mesos2.mydomain\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nW0226 13:49:58.415089 14937 systemd.cpp:244] Required functionality `Delegate` was introduced in Version `218`. Your system may not function properly; however since some distributions have patched systemd packages, your system may still be functional. This is why we keep running. See MESOS-3352 for more information\n</code></pre>\n\n<p>Base on similar topics I see that this can be related to network configuration so below is some info about:</p>\n\n<p><strong>hosts file on 10.10.0.102</strong></p>\n\n<pre><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n10.10.0.103 mesos2 mesos2.mydomain\n10.10.0.102 mesos1 mesos1.mydomain\n</code></pre>\n\n<p><strong>hosts file on 10.10.0.103</strong></p>\n\n<pre><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n10.10.0.102 mesos1 mesos1.mydomain\n10.10.0.103 mesos2 mesos2.mydomain\n</code></pre>\n\n<p>both VM's have 2 network interfaces (without loopback). Below comes from 10.10.0.103- on 10.10.0.102 is similar:</p>\n\n<pre><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\n    link/ether 08:00:27:49:76:48 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3\n       valid_lft 75232sec preferred_lft 75232sec\n    inet6 fe80::a00:27ff:fe49:7648/64 scope link\n       valid_lft forever preferred_lft forever\n3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\n    link/ether 08:00:27:d9:24:2a brd ff:ff:ff:ff:ff:ff\n    inet 10.10.0.103/24 brd 10.10.0.255 scope global enp0s8\n       valid_lft forever preferred_lft forever\n    inet6 fe80::a00:27ff:fed9:242a/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>Both VMs have network connectivity.</p>\n\n<p>from 10.10.0.102 to 10.10.0.103</p>\n\n<pre><code>[root@mesos1 ~]# ping mesos2.mydomain\nPING mesos2 (10.10.0.103) 56(84) bytes of data.\n64 bytes from mesos2 (10.10.0.103): icmp_seq=1 ttl=64 time=0.578 ms\n64 bytes from mesos2 (10.10.0.103): icmp_seq=2 ttl=64 time=0.616 ms\n</code></pre>\n\n<p>from 10.10.0.103 to 10.10.0.102</p>\n\n<pre><code>[root@mesos2 ~]# ping mesos1.mydomain\nPING mesos1 (10.10.0.102) 56(84) bytes of data.\n64 bytes from mesos1 (10.10.0.102): icmp_seq=1 ttl=64 time=0.441 ms\n64 bytes from mesos1 (10.10.0.102): icmp_seq=2 ttl=64 time=0.972 ms\n</code></pre>\n\n<p>All help would be highly appreciate. \nRegards<br>\nAndrzej</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "title": "Unable to start mesos-slave on different VM. Constant Deactivated status", "last_activity_date": 1457109907, "answer_count": 1, "creation_date": 1456757464, "score": 1, "link": "https://stackoverflow.com/questions/35702550/unable-to-start-mesos-slave-on-different-vm-constant-deactivated-status", "answers": [{"body": "<p>Like always the simplest answers are the best. It's turn out that I had running iptables on slave node. Disabling this resolve my problem:</p>\n\n<p><code>systemctl disable firewalld\nsystemctl stop firewalld</code></p>\n\n<p>Thanks everyone for help!</p>\n", "answer_id": 35801498, "last_activity_date": 1457109907, "creation_date": 1457109907, "score": 0, "owner": {"user_id": 4912276, "profile_image": "https://www.gravatar.com/avatar/8e716576be47ec895b18d6dfc72c6bb2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 42, "link": "https://stackoverflow.com/users/4912276/awenclaw", "accept_rate": 67, "display_name": "awenclaw"}, "is_accepted": false, "question_id": 35702550}], "owner": {"user_id": 4912276, "profile_image": "https://www.gravatar.com/avatar/8e716576be47ec895b18d6dfc72c6bb2?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 42, "link": "https://stackoverflow.com/users/4912276/awenclaw", "accept_rate": 67, "display_name": "awenclaw"}, "view_count": 488, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35702550}{"body": "<p>I am trying to connect Apache Spark to MongoDB using Mesos. Here is my architecture: -</p>\n\n<p>MongoDB: MongoDB Cluster of 2 shards, 1 config server and 1 query server. \nMesos: 1 Mesos Master, 4 Mesos slaves</p>\n\n<p>Now I have installed Spark on just 1 node. There is not much information available on this out there. I just wanted to pose a few questions: -</p>\n\n<p>As per what I understand, I can connect Spark to MongoDB via mesos. In other words, I end up using MongoDB as a storage layer. Do I really Need Hadoop? Is it mandatory to pull all the data into Hadoop just for Spark to read it? </p>\n\n<p>Here is the reason I am asking this. The Spark Install expects the HADOOP_HOME variable to be set. This seems like very tight coupling !! Most of the posts on the net speak about MongoDB-Hadoop connector. It doesn't make sense if you're forcing me to move everything to hadoop.</p>\n\n<p>Does anyone have an answer?</p>\n\n<p>Regards\nMario</p>\n", "is_answered": false, "tags": ["mongodb", "apache-spark", "cluster-computing", "mesos", "mesosphere"], "title": "Spark to MongoDB via Mesos", "last_activity_date": 1471953033, "answer_count": 2, "creation_date": 1471434351, "score": 0, "link": "https://stackoverflow.com/questions/38995739/spark-to-mongodb-via-mesos", "answers": [{"body": "<p>Spark itself takes a dependency on Hadoop and data in HDFS can be used as a datasource. </p>\n\n<p>However, if you use the <a href=\"https://docs.mongodb.com/spark-connector/\" rel=\"nofollow\">Mongo Spark Connector</a> you can use MongoDB as a datasource for Spark without going via Hadoop at all.</p>\n", "answer_id": 39099333, "last_activity_date": 1471950014, "creation_date": 1471950014, "score": 0, "owner": {"user_id": 156427, "profile_image": "https://www.gravatar.com/avatar/630e114bb1f79c0924103b96921227c2?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 13111, "link": "https://stackoverflow.com/users/156427/ross", "accept_rate": 100, "display_name": "Ross"}, "is_accepted": false, "question_id": 38995739}, {"body": "<p><a href=\"https://docs.mongodb.com/spark-connector/\" rel=\"nofollow\">Spark-mongo connector</a> is good idea, moreover if your are executing Spark in a hadoop cluster you need set HADOOP_HOME.</p>\n\n<p>Check your requeriments and test it (<a href=\"https://www.mongodb.com/blog/post/the-new-mongodb-connector-for-apache-spark-in-action-building-a-movie-recommendation-engine\" rel=\"nofollow\">tutorial</a>)</p>\n\n<pre><code>Basic working knowledge of MongoDB and Apache Spark. Refer to the MongoDB documentation and Spark documentation.\nRunning MongoDB instance (version 2.6 or later).\nSpark 1.6.x.\nScala 2.10.x if using the mongo-spark-connector_2.10 package\nScala 2.11.x if using the mongo-spark-connector_2.11 package\n</code></pre>\n\n<p>The new MongoDB Connector for Apache Spark provides higher performance, greater ease of use and, access to more advanced Spark functionality than the MongoDB Connector for Hadoop. The following table compares the capabilities of both connectors.</p>\n\n<p>Then you need to configure Spark with mesos:</p>\n\n<p><a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html\" rel=\"nofollow\">Connecting Spark to Mesos</a></p>\n\n<pre><code>To use Mesos from Spark, you need a Spark binary package available in a place accessible by Mesos, and a Spark driver program configured to connect to Mesos.\n\nAlternatively, you can also install Spark in the same location in all the Mesos slaves, and configure spark.mesos.executor.home (defaults to SPARK_HOME) to point to that location.\n</code></pre>\n", "answer_id": 39100186, "last_activity_date": 1471953033, "creation_date": 1471952425, "score": 0, "owner": {"user_id": 2269677, "profile_image": "https://i.stack.imgur.com/QifBS.jpg?s=128&g=1", "user_type": "registered", "reputation": 330, "link": "https://stackoverflow.com/users/2269677/mrelefant", "accept_rate": 62, "display_name": "MrElefant"}, "is_accepted": false, "last_edit_date": 1471953033, "question_id": 38995739}], "owner": {"user_id": 5820456, "profile_image": "https://www.gravatar.com/avatar/afe7d90e9833a7ffd53c70244608d2b0?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 25, "link": "https://stackoverflow.com/users/5820456/mario", "accept_rate": 29, "display_name": "Mario"}, "view_count": 126, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38995739}{"body": "<p>I am wondering where can I find the Mesos rest api endpoint documentation. In my on prem Mesos 0.28 + Marathon version, I can get the statistics from endpoint <a href=\"http://agent.com:5051/monitor/statistics.json\" rel=\"nofollow noreferrer\">http://agent.com:5051/monitor/statistics.json</a>\nBut in my aws dc/os installation, I couldn't get the statistics. Actually, all the endpoints are different in DC/OS and on prem mesos. In my AWS dc/os , the url is <a href=\"http://masterIP/mesos/state\" rel=\"nofollow noreferrer\">http://masterIP/mesos/state</a>, in on prem mesos, it's <a href=\"http://master:5050/state\" rel=\"nofollow noreferrer\">http://master:5050/state</a>. I wonder where I can get the docs about endpoint definition?</p>\n", "is_answered": true, "tags": ["amazon-web-services", "mesos", "mesosphere", "dcos"], "last_edit_date": 1484128151, "title": "Where is endpoint to monitor tasks on agents?", "last_activity_date": 1484128151, "answer_count": 1, "creation_date": 1484061353, "score": 2, "link": "https://stackoverflow.com/questions/41572125/where-is-endpoint-to-monitor-tasks-on-agents", "answers": [{"body": "<p>The canonical reference in this context is a DC/OS system component called Admin Router, <a href=\"https://github.com/dcos/adminrouter\" rel=\"nofollow noreferrer\">dcos/adminrouter</a>, and from its documentation you should be able to see the mapping to vanilla Mesos (and Marathon, etc.) from DC/OS endpoints and vice versa.</p>\n", "answer_id": 41572402, "last_activity_date": 1484062139, "creation_date": 1484062139, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 41572125}], "owner": {"user_id": 3870940, "profile_image": "https://www.gravatar.com/avatar/ee24132e8507f439be1f0ea098d269a6?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/3870940/user3870940", "display_name": "user3870940"}, "view_count": 38, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41572125}{"body": "<p>Hi I am trying to setup DC/OS in Debian 8 Jessie, I got working ssh connection with the ssh key, I am able to login without password to all masters and agents (they are running CentOS 7). Strange thing is it's not working when running --preflight, it will say connection refused for all nodes.</p>\n\n<p><code>\nTASK:\n/usr/bin/ssh -oConnectTimeout=10 -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -oBatchMode=yes -oPasswordAuthentication=no -p22 -i genconf/ssh_key -tt root@192.168.122.131 sudo rm -rf /opt/dcos_install_tmp\n     STDERR:\n          ssh: connect to host 192.168.122.131 port 22: Connection refused\n     STDOUT:\n</code></p>\n\n<p>If I try to run this command in terminal, it works just fine. So it does not work only when running it via <code>bash dcos_generate_config.sh --prefligh</code>. Any idea what could be wrong please?</p>\n", "is_answered": false, "tags": ["linux", "bash", "ssh", "dcos"], "title": "DC/OS ssh connection refused on port 22 - preflight", "last_activity_date": 1491660201, "answer_count": 1, "creation_date": 1491656900, "score": 0, "link": "https://stackoverflow.com/questions/43294496/dc-os-ssh-connection-refused-on-port-22-preflight", "answers": [{"body": "<p>In bash <code>--</code> denotes the end of command-line options, so what you need to probably do is:</p>\n\n<pre><code>bash dcos_generate_config.sh -- --prefligh\n</code></pre>\n", "answer_id": 43295053, "last_activity_date": 1491660201, "creation_date": 1491660201, "score": 0, "owner": {"user_id": 2416376, "profile_image": "https://www.gravatar.com/avatar/3b9c98c72a27d95d779c0a3ea9842be4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1014, "link": "https://stackoverflow.com/users/2416376/olli-k", "display_name": "Olli K"}, "is_accepted": false, "question_id": 43294496}], "owner": {"user_id": 2066130, "profile_image": "https://www.gravatar.com/avatar/36bcff8ec682226703b78d22f29fe2ba?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 385, "link": "https://stackoverflow.com/users/2066130/tom", "accept_rate": 67, "display_name": "Tom"}, "view_count": 74, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 43294496}{"is_answered": false, "tags": ["azure", "ssh", "mesosphere", "dcos", "azure-container-service"], "last_edit_date": 1469222879, "title": "SSH Forwarding of Mesosphere in ACS fails with &quot;administratively prohibited&quot;", "last_activity_date": 1469225078, "answer_count": 1, "creation_date": 1469220127, "score": 0, "link": "https://stackoverflow.com/questions/38534946/ssh-forwarding-of-mesosphere-in-acs-fails-with-administratively-prohibited", "owner": {"user_id": 799216, "profile_image": "https://www.gravatar.com/avatar/5285ca39a1182b2594d23a40c2d13c51?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 393, "link": "https://stackoverflow.com/users/799216/nils", "accept_rate": 68, "display_name": "Nils"}, "view_count": 168, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 38534946}{"is_answered": false, "tags": ["amazon-cloudformation", "amazon-vpc", "mesosphere"], "title": "Mesosphere Cloud Formation Template Using Existing VPC/NAT", "last_activity_date": 1461003643, "answer_count": 3, "creation_date": 1447268136, "score": 0, "link": "https://stackoverflow.com/questions/33657819/mesosphere-cloud-formation-template-using-existing-vpc-nat", "owner": {"user_id": 204189, "profile_image": "https://www.gravatar.com/avatar/b30a78e7f591f4fc616dc36e22d3049e?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/204189/chris-kinsman", "display_name": "Chris Kinsman"}, "view_count": 387, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 33657819}{"body": "<p>I have three questions related to DCOS, that is launched using the AWS Cloudformation Script</p>\n\n<ol>\n<li>From where can I get the AMI ID for the HVM virtualization.</li>\n<li>How to add the Instance ephemeral Storage?</li>\n<li>How to add the Extra non-root storage for the DCOS slaves using the \nCloudformation script and make the necessary changes in the mesos-config</li>\n</ol>\n\n<p>Thanks in Advance</p>\n", "is_answered": false, "tags": ["amazon-web-services", "amazon-ec2", "amazon-cloudformation", "mesosphere", "dcos"], "title": "Adding the non-root storage for the DCOS slaves", "last_activity_date": 1501738390, "answer_count": 0, "creation_date": 1501738390, "score": 0, "link": "https://stackoverflow.com/questions/45475620/adding-the-non-root-storage-for-the-dcos-slaves", "owner": {"user_id": 5684969, "profile_image": "https://lh3.googleusercontent.com/-qb3ugL50gyo/AAAAAAAAAAI/AAAAAAAAAj4/uZEg1norkM0/photo.jpg?sz=128", "user_type": "registered", "reputation": 24, "link": "https://stackoverflow.com/users/5684969/guda-uma-shanker", "display_name": "Guda uma shanker"}, "view_count": 9, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45475620}{"body": "<p>i\u2019m trying to have my dc/os 1.8 docker containers send log messages to a logstash that is also running in dc/os by using the service address of the logstash service.</p>\n\n<p>that doesn\u2019t appear to work as docker throws an error: <code>logstash.marathon.l4lb.thisdcos.directory: no such host</code></p>\n\n<p>are service addresses not exposed to the host systems (or do i need to configure something for this)?</p>\n\n<p>on dc/os 1.7 i used a fixed host port in my logstash config and <code>logstash.marathon.mesos</code> as host, but these .marathon.mesos hostnames seem to not exist in 1.8 anymore.</p>\n\n<p>the service addresses work fine when i try to use them from within a container (for example to link my prometheus service to my alertmanager service). but from the host level they don\u2019t exist.</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>my statement about the missing marathon.mesos urls was wrong. they do work, but i uses the wrong one. for now this fixes my problem kind of. i configured logging using this host and a fixed container port.</p>\n\n<p>for everybody trying the same thing: you have to configure the fixed host port everytime you make changes to the service config in the ui via the json mode. the fixed host port config is no longer available in the network tab of the ui, so the dc/os ui will DELETE the host port config on every load.</p>\n\n<p>still no idea why the l4lb urls don't work.</p>\n\n<p>EDIT2</p>\n\n<p>still no idea, but i figured out that minuteman generates crash and error logs every other second:</p>\n\n<p>/opt/mesosphere/active/minuteman/minuteman/error.log:</p>\n\n<pre><code>CRASH REPORT Process &lt;0.25809.2&gt; with 0 neighbours exited with reason: {timeout,{gen_server,call,[{lashup_kv,'navstar@10.2.140.216'},{start_kv_sync_fsm,'minuteman@10.2.103.143',&lt;0.25809.2&gt;}]}} in gen_server:call/2 line 204\n</code></pre>\n\n<p>/opt/mesosphere/active/minuteman/minuteman/log/crash.log</p>\n\n<pre><code>2016-10-12 13:16:49 =CRASH REPORT====\n  crasher:\n    initial call: lashup_kv_sync_tx_fsm:init/1\n    pid: &lt;0.29002.2&gt;\n    registered_name: []\n    exception exit: {{timeout,{gen_server,call,[{lashup_kv,'navstar@10.2.140.216'},{start_kv_sync_fsm,'minuteman@10.2.103.143',&lt;0.29002.2&gt;}]}},[{gen_server,call,2,[{file,\"gen_server.erl\"},{line,204}]},{lashup_kv_sync_tx_fsm,init,1,[{file,\"/pkg/src/minuteman/_build/default/lib/lashup/src/lashup_kv_sync_tx_fsm.erl\"},{line,23}]},{gen_statem,init_it,6,[{file,\"gen_statem.erl\"},{line,554}]},{proc_lib,init_p_do_apply,3,[{file,\"proc_lib.erl\"},{line,247}]}]}\n    ancestors: [lashup_kv_aae_sup,lashup_kv_sup,lashup_platform_sup,lashup_sup,&lt;0.916.0&gt;]\n    messages: []\n    links: [&lt;0.992.0&gt;]\n    dictionary: []\n    trap_exit: false\n    status: running\n    heap_size: 610\n    stack_size: 27\n    reductions: 127\n  neighbours:\n</code></pre>\n\n<p>the dc/os ui claims spartan and minuteman are healthy, but while the crash.log of the dns dispatcher is empty the l4lb gets new crashes every other second.</p>\n", "is_answered": true, "title": "Are service addresses available to the dc/os host OS?", "last_edit_date": 1476278484, "tags": ["marathon", "dcos"], "view_count": 264, "accepted_answer_id": 44846028, "last_activity_date": 1498824083, "answers": [{"body": "<p>They should certainly be available from the host OS. Are these host services running the \"Spartan\" and \"Minuteman\" services?</p>\n", "answer_id": 39900308, "last_activity_date": 1475768520, "creation_date": 1475768520, "score": 2, "owner": {"user_id": 10432, "profile_image": "https://www.gravatar.com/avatar/32a4d5002ac47f7b15c573c290912286?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1033, "link": "https://stackoverflow.com/users/10432/sargun-dhillon", "accept_rate": 71, "display_name": "Sargun Dhillon"}, "is_accepted": false, "question_id": 39898923}, {"body": "<p>my problem was twofold:</p>\n\n<ol>\n<li><p>the l4b did not properly run, that was only fixed after a total reinstall of the cluster</p></li>\n<li><p>the l4b only supports TCP traffic. because i wanted to use it to send container-logs to logstash using udp (docker-gelf only supports UDP) this failed</p></li>\n</ol>\n", "answer_id": 44846028, "last_activity_date": 1498824083, "creation_date": 1498824083, "score": 0, "owner": {"user_id": 465274, "profile_image": "https://www.gravatar.com/avatar/078e4ce15fea1a8deef9b03587727c8c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2458, "link": "https://stackoverflow.com/users/465274/laures", "accept_rate": 85, "display_name": "Laures"}, "is_accepted": true, "question_id": 39898923}], "score": 2, "link": "https://stackoverflow.com/questions/39898923/are-service-addresses-available-to-the-dc-os-host-os", "answer_count": 2, "owner": {"user_id": 465274, "profile_image": "https://www.gravatar.com/avatar/078e4ce15fea1a8deef9b03587727c8c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 2458, "link": "https://stackoverflow.com/users/465274/laures", "accept_rate": 85, "display_name": "Laures"}, "creation_date": 1475764747, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 39898923}{"body": "<p>I've installed Zeppelin from the DC/OS universe.\nMy question is, and I've been unable to find any answer for this - How do I Install Thrift on Mesos in order to use SparkSQL?</p>\n\n<p>What are the steps I need to perform?</p>\n\n<p>Thanks</p>\n", "is_answered": false, "tags": ["apache-spark", "apache-spark-sql", "mesos", "mesosphere", "pyspark-sql"], "title": "Thrift on Spark on Mesos using DC/OS", "last_activity_date": 1468440674, "answer_count": 0, "creation_date": 1468440674, "score": 2, "link": "https://stackoverflow.com/questions/38360877/thrift-on-spark-on-mesos-using-dc-os", "owner": {"user_id": 1477327, "profile_image": "https://www.gravatar.com/avatar/e2dd5b9a22ef022f81517d1e67048f50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 49, "link": "https://stackoverflow.com/users/1477327/user1477327", "accept_rate": 42, "display_name": "user1477327"}, "view_count": 41, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 38360877}{"is_answered": false, "tags": ["javascript", "validation", "meteor", "mesosphere"], "last_edit_date": 1388865650, "title": "Meteor.js Validation w/ Mesosphere", "last_activity_date": 1390849441, "answer_count": 1, "creation_date": 1388759057, "score": 2, "link": "https://stackoverflow.com/questions/20905774/meteor-js-validation-w-mesosphere", "owner": {"user_id": 622184, "profile_image": "https://www.gravatar.com/avatar/8eac184149444324b77e478ff097386a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 68, "link": "https://stackoverflow.com/users/622184/colton45", "accept_rate": 69, "display_name": "Colton45"}, "view_count": 2278, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 20905774}{"body": "<p>We have setup DC/OS(version 1.9) Cluster on AWS nodes. We are creating Marathon Application definition with setting <strong>\"taskKillGracePeriodSeconds\"=60</strong>. We are also catching SIGTERM in our application to handle the application shutdown gracefully. But this is is not wroking, Marathon is immediately killing the Application (on Scale Down / Destroy) and not waits for 60 secs as expected. We are getting callback on SIGTERM but application killed immediately after that. We have also tried with starting Mesos slave agents with setting following attributes in file /var/lib/dcos/mesos-slave-common  <strong>MESOS_ATTRIBUTES=executor_shutdown_grace_period:60secs;docker_stop_timeout:60s\necs</strong> but this is also not helping.</p>\n\n<p>DCOS Cluster Agents uses <strong>centos-release-7-2.1511.el7.centos.2.10.x86_64</strong> OS.</p>\n\n<p>Does anybody able to use <strong>taskKillGracePeriodSeconds</strong> successfully.? </p>\n\n<p>Please help to work out this.</p>\n\n<p>Thanks.</p>\n", "is_answered": true, "title": "taskKillGracePeriodSeconds is not working for DC/OS Marathon Application?", "tags": ["marathon", "dcos"], "last_activity_date": 1492001932, "accepted_answer_id": 43370259, "creation_date": 1491913115, "answers": [{"body": "<p>are you using Docker containers?</p>\n\n<p>There was a problem as far as I remember when using process groups (=containers) with the forwarding of the SIGTERM signal.</p>\n\n<p>Just to test this on your cluster, can you deploy an app with the following command, just using mesos containerizer and a taskKillGracePeriodSeconds of 10 seconds?</p>\n\n<p>trap \"echo ' killing' &amp;&amp; sleep 5 &amp;&amp; echo 'test' &amp;&amp; sleep 100\" SIGTERM &amp;&amp; sleep 100000</p>\n", "answer_id": 43370259, "last_activity_date": 1492001932, "creation_date": 1492001932, "score": 0, "owner": {"user_id": 3058534, "profile_image": "https://i.stack.imgur.com/UZ79s.jpg?s=128&g=1", "user_type": "registered", "reputation": 34, "link": "https://stackoverflow.com/users/3058534/unterstein", "display_name": "unterstein"}, "is_accepted": true, "question_id": 43345712}], "score": 0, "link": "https://stackoverflow.com/questions/43345712/taskkillgraceperiodseconds-is-not-working-for-dc-os-marathon-application", "answer_count": 1, "owner": {"user_id": 6458581, "profile_image": "https://www.gravatar.com/avatar/133868f7999dabe20ed1761ba37a4268?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/6458581/sachin", "display_name": "Sachin"}, "view_count": 106, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 43345712}{"body": "<p>I have few questions around Mesos-spark:</p>\n\n<ol>\n<li>When I submit spark job with different spark context on Mesos, does it invoke different mesos-spark framework instance or use the same.</li>\n<li>How can I ensure that each time different spark framework is created.</li>\n<li>Can I specify constraints to reserve/pre-allocate the mesos-slave for a specific spark context or framework instance. I understand that it defeats the purpose of Mesos a bit and Mesos can guarantee the memory and CPU in coarse grained mode. But for some reason, I don't want to share the physical machines that run the tasks(slaves) across different spark jobs (meant for different users) </li>\n</ol>\n", "is_answered": true, "title": "Spark framework on Mesos", "tags": ["apache-spark", "mesos", "mesosphere"], "last_activity_date": 1427789728, "accepted_answer_id": 29363784, "creation_date": 1426850542, "answers": [{"body": "<p>1/2, Each Spark Context will launch a separate Mesos framework, and you should be able to confirm this by navigating to the Mesos UI and see all the frameworks created, which should correspond 1 to 1 to the Spark contexts you've created.</p>\n\n<ol start=\"3\">\n<li>You can reserve resources for a set of Spark tasks by reserving a piece of your resources on each slave and tag them with a certain role.</li>\n</ol>\n\n<p>For example if you want to reserve 4gb memory and 2 cores on a slave to run a certain set of tasks, you can specifiy --resources=\"cpus(spark1):2,mem(spark1):4098,cpus(<em>):2,mem(</em>):4098\" when you launch the slave. This gives spark1 role 4gb of ram and 2 cpus, while all other frameworks 2 cpu and 4gb ram. Frameworks that register itself with spark1 role will then receive the resources reserved plus any  available wildcard (*) resources for it to use.</p>\n\n<p>On the Spark framework side, I have a open PR that supports registering a specific role (<a href=\"https://github.com/apache/spark/pull/4960\">https://github.com/apache/spark/pull/4960</a>), that hopefully should be merged soon. So if you like to use this feature you need to apply this pull request and build Spark yourself for now.</p>\n", "answer_id": 29363784, "last_activity_date": 1427789728, "creation_date": 1427789728, "score": 7, "owner": {"user_id": 160402, "profile_image": "https://www.gravatar.com/avatar/da349c6f012bcc2723ed54e4ea04b4bb?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 360, "link": "https://stackoverflow.com/users/160402/timothy-chen", "accept_rate": 50, "display_name": "Timothy Chen"}, "is_accepted": true, "question_id": 29165365}], "score": 3, "link": "https://stackoverflow.com/questions/29165365/spark-framework-on-mesos", "answer_count": 1, "owner": {"user_id": 4559240, "profile_image": "https://www.gravatar.com/avatar/bdf731ebae6a56ec1b2d5539cb3f708e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 25, "link": "https://stackoverflow.com/users/4559240/nitin-goel", "display_name": "Nitin Goel"}, "view_count": 893, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29165365}{"body": "<p><a href=\"http://i.stack.imgur.com/pxLNC.png\" rel=\"nofollow\">screenshot of error</a></p>\n\n<p>I am setting up stratio admin, but it can't get ports. every time I am getting connection refused error. If you have experience what can be the reason, I'll be waiting your answers.</p>\n\n<p>I have made FQDN s for master and slave computers. \nmaster: reslab1.ibsu.edu.ge\nslaves: reslab2.ibsu.edu.ge ,  reslab3.ibsu.edu.ge,  reslab4.ibsu.edu.ge </p>\n", "is_answered": true, "tags": ["hadoop", "apache-zookeeper", "mesos", "mesosphere", "stratio"], "title": "Stratio setup: connection refused error", "last_activity_date": 1447145198, "answer_count": 1, "creation_date": 1447066127, "score": 1, "link": "https://stackoverflow.com/questions/33607482/stratio-setup-connection-refused-error", "answers": [{"body": "<p>I have solved the problem.\nI didn't have installed SSH server. There are some steps also after instalation of ssh server, you have to change /etc/ssh/ssd_config  file, add new ssh user.\nIf anybody have the same problem you can find out the reason here \n<a href=\"https://help.ubuntu.com/community/SSH/OpenSSH/Configuring\" rel=\"nofollow\">https://help.ubuntu.com/community/SSH/OpenSSH/Configuring</a></p>\n", "answer_id": 33625955, "last_activity_date": 1447145198, "creation_date": 1447145198, "score": 1, "owner": {"user_id": 5515598, "profile_image": "https://www.gravatar.com/avatar/8e07ce8cb8b61e811e036f5618c39a78?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 32, "link": "https://stackoverflow.com/users/5515598/ana-tsitsagi", "display_name": "Ana Tsitsagi"}, "is_accepted": false, "question_id": 33607482}], "owner": {"user_id": 5515598, "profile_image": "https://www.gravatar.com/avatar/8e07ce8cb8b61e811e036f5618c39a78?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 32, "link": "https://stackoverflow.com/users/5515598/ana-tsitsagi", "display_name": "Ana Tsitsagi"}, "view_count": 47, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33607482}{"body": "<p>I see Mesosphere building all kinds of applications on the Mesos Framework like Hadoop, Kubernetes, etc. but since there is the Marathon applications for long-running services, why not just use that? E.g. why not setup Kubernetes nodes on a bunch of Marathon services? Why implement Kubernetes directly on Framework API? Because scheduling is more efficient that way? Same question goes for Jenkins implementation, why not just run Jenkins master/slaves on top of Marathon...</p>\n", "is_answered": true, "tags": ["mesos", "kubernetes", "mesosphere"], "title": "Mesos applications, why not use Marathon for everything?", "last_activity_date": 1426694443, "answer_count": 1, "creation_date": 1424386263, "score": 5, "link": "https://stackoverflow.com/questions/28618555/mesos-applications-why-not-use-marathon-for-everything", "answers": [{"body": "<p><a href=\"http://mesos.apache.org/\" rel=\"nofollow\">Apache Mesos</a> is a <a href=\"http://en.wikipedia.org/wiki/Two-level_scheduling\" rel=\"nofollow\">2-level scheduler</a>.  The purpose of a framework is to provide the intelligence of high-level scheduling.  <a href=\"https://mesosphere.github.io/marathon/\" rel=\"nofollow\">Marathon</a> provides the ability to schedule a task in the cluster, queue that task for scheduling and re-queue tasks that have failed.  It is great at keeping long running processes running.  It is like the <code>init</code> of the datacenter.   As such, it is commonly used to make sure other frameworks are up and running such as <a href=\"https://github.com/mesosphere/kubernetes-mesos\" rel=\"nofollow\">Kubernetes-Mesos</a> or <a href=\"https://github.com/jenkinsci/mesos-plugin\" rel=\"nofollow\">Jenkins</a>.    </p>\n\n<p>There are many applications for which this level of scheduling is insufficient.  Marathon can and often is used for running things like <a href=\"http://kafka.apache.org/\" rel=\"nofollow\"> Apache Kafka</a>, however this often falls short in many failure modes.  Additionally, Marathon doesn't care if task runs multiple times on the same node, however running multiple Kafka nodes on the same slave is a bad idea.     Using Hadoop as another example (since you referred it), HDFS has several types of nodes that need to be managed; NameNode, DataNode and JournalNode.   Marathon does not know the order to start these in, or if these can be co-located on the same node or not.  It doesn't know how to scale this application.  The HDFS framework manages that intelligence.   </p>\n\n<p>As far as scheduling efficiency, I'm not sure that is the goal.  Apache Mesos is a 2-level scheduler for a reason.   It is a highly efficient 2-level scheduler.   The value of 2-level scheduling is to abstract the type of concerns I described above to a higher-level scheduler (which is termed by Mesos as frameworks).   Marathon is still a great way to schedule and ensure high availability to other frameworks.</p>\n", "answer_id": 29126875, "last_activity_date": 1426694443, "creation_date": 1426694443, "score": 4, "owner": {"user_id": 1375187, "profile_image": "https://www.gravatar.com/avatar/54ce5c4133119bd3791bd23f2cc2f582?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 219, "link": "https://stackoverflow.com/users/1375187/ken", "display_name": "Ken"}, "is_accepted": false, "question_id": 28618555}], "owner": {"user_id": 1340582, "profile_image": "https://www.gravatar.com/avatar/bf8ea1db8b578e7fab08e9a787acb911?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 4387, "link": "https://stackoverflow.com/users/1340582/user1340582", "accept_rate": 53, "display_name": "user1340582"}, "view_count": 1242, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 28618555}{"is_answered": false, "tags": ["ubuntu-14.04", "apache-zookeeper", "mesos"], "title": "Mesosphere slaves do not register", "last_activity_date": 1453756446, "answer_count": 2, "creation_date": 1453466118, "score": 0, "link": "https://stackoverflow.com/questions/34946876/mesosphere-slaves-do-not-register", "owner": {"user_id": 1004942, "profile_image": "https://www.gravatar.com/avatar/4c8ee615d726c96247bab45dce2c1098?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 18, "link": "https://stackoverflow.com/users/1004942/fergal", "accept_rate": 25, "display_name": "Fergal"}, "view_count": 604, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 34946876}{"body": "<p>I didn't find info whether it is possible to define something like an Event-hook upon up/down-scaling or deletion of an App in the Marathon Rest API docs at <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html\" rel=\"nofollow\">https://mesosphere.github.io/marathon/docs/rest-api.html</a></p>\n\n<p>What I'd like to achieve is that I'm able to backup some data from a running Docker container before be is destroyed. For example, I run a cluster of Elasticsearch nodes on Marathon, and I would like to delay the deletion of the app until the then triggered \"Create snapshot to external disk resource\" process is finished.</p>\n\n<p>Is there currently something I could use? </p>\n", "is_answered": true, "tags": ["mesos", "mesosphere", "marathon"], "title": "Event-hook upon up/down-scaling or deletion of an App", "last_activity_date": 1434115538, "answer_count": 1, "creation_date": 1434114449, "score": 0, "link": "https://stackoverflow.com/questions/30803891/event-hook-upon-up-down-scaling-or-deletion-of-an-app", "answers": [{"body": "<p>Marathon provides an <a href=\"https://mesosphere.github.io/marathon/docs/event-bus.html\" rel=\"nofollow\">Event Bus</a> covering some phases of the lifecycle. Beyond that, currently the only other option I see is to go for <a href=\"http://mesos.apache.org/documentation/latest/modules/\" rel=\"nofollow\">Mesos Modules/Hooks</a>.</p>\n", "answer_id": 30804302, "last_activity_date": 1434115538, "creation_date": 1434115538, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 30803891}], "owner": {"user_id": 1603357, "profile_image": "https://i.stack.imgur.com/hvnAN.png?s=128&g=1", "user_type": "registered", "reputation": 26475, "link": "https://stackoverflow.com/users/1603357/tobi", "accept_rate": 59, "display_name": "Tobi"}, "view_count": 503, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 30803891}{"body": "<p>I'm playing on localhost with a DC/OS installation. While everything works fine, I can't seem to run a docker image located inside a private repo. I'm using python to communicate with chronos:</p>\n\n<pre><code>@celery.task(name='add-job', soft_time_limit=5)\ndef add_job(job_id):\n    job_document = mongo.jobs.find_one({\n        '_id': job_id\n    })\n\n    if job_document:\n        worker_document = mongo.workers.find_one({\n            '_id': job_document['workerId']\n        })\n\n        if worker_document:\n            job = {\n                'async': True,\n                'name': job_document['_id'],\n                'owner': 'owner@gmail.com',\n                'command': \"python /code/run.py\",\n                \"disabled\": False,\n                \"shell\": True,\n                \"cpus\": worker_document['cpus'],\n                \"disk\": worker_document['disk'],\n                \"mem\": worker_document['memory'],\n                'schedule': 'R1//PT300S',# start now,\n                \"epsilon\": \"PT60M\",\n                \"container\": {\n                    \"type\": \"DOCKER\",\n                    \"forcePullImage\": True,\n                    \"image\": \"quay.io/username/container\",\n                    \"network\": \"HOST\",\n                    \"volumes\": [{\n                        \"containerPath\": \"/images/\",\n                        \"hostPath\": \"/images/\",\n                        \"mode\": \"RW\"\n                    }]\n                },\n                \"uris\": [\n                    \"file:///images/docker.tar.gz\"\n                ]\n            }\n            return chronos_client.add(job)\n        else:\n            return 'worker not found'\n    else:\n        return 'job not found'\n</code></pre>\n\n<p>The job runs fine with a public image (<code>alpine:latest</code>) but it fails without any error inside the dcos installation.</p>\n\n<p>The job gets executed but it fails immediately. The error log of the job inside chronos looks like this:</p>\n\n<pre><code>I1212 12:39:11.141639 25058 fetcher.cpp:498] Fetcher Info: {\"cache_directory\":\"\\/tmp\\/mesos\\/fetch\\/slaves\\/61d6d037-c9f5-482b-a441-11d85554461b-S1\\/root\",\"items\":[{\"action\":\"BYPASS_CACHE\",\"uri\":{\"cache\":false,\"executable\":false,\"extract\":false,\"value\":\"file:\\/\\/\\/images\\/docker.tar.gz\"}}],\"sandbox_directory\":\"\\/var\\/lib\\/mesos\\/slave\\/slaves\\/61d6d037-c9f5-482b-a441-11d85554461b-S1\\/docker\\/links\\/7029bbea-4c3d-439a-8720-411f6fe40eb9\",\"user\":\"root\"}\nI1212 12:39:11.143575 25058 fetcher.cpp:409] Fetching URI 'file:///images/docker.tar.gz'\nI1212 12:39:11.143587 25058 fetcher.cpp:250] Fetching directly into the sandbox directory\nI1212 12:39:11.143602 25058 fetcher.cpp:187] Fetching URI 'file:///images/docker.tar.gz'\nI1212 12:39:11.143612 25058 fetcher.cpp:167] Copying resource with command:cp '/images/docker.tar.gz' '/var/lib/mesos/slave/slaves/61d6d037-c9f5-482b-a441-11d85554461b-S1/docker/links/7029bbea-4c3d-439a-8720-411f6fe40eb9/docker.tar.gz'\nI1212 12:39:11.146726 25058 fetcher.cpp:547] Fetched 'file:///images/docker.tar.gz' to '/var/lib/mesos/slave/slaves/61d6d037-c9f5-482b-a441-11d85554461b-S1/docker/links/7029bbea-4c3d-439a-8720-411f6fe40eb9/docker.tar.gz'\n</code></pre>\n\n<p>Stdout is empty. Executed directly inside marathon as an application with the same settings the authentication works and my image is downloaded &amp; executed. Is this something that chronos does not support? It should...I mean, it has commands for docker...</p>\n\n<p>Update: digging deeper into the agent logs I found this:</p>\n\n<p><code>Failed to run 'docker -H unix:///var/run/docker.sock pull quay.io/username/container': exited with status 1; stderr='Error: Status 403 trying to pull repository username/container: \"{\\\"error\\\": \\\"Permission Denied\\\"}\"</code></p>\n\n<p>I tried the archive with it's config.json file on the agent itself and it can download when triggered from the command line. I just can't seem to understand why chronos is not using it properly. I can't find any other reference on how to put my credentials other than this.</p>\n", "is_answered": true, "title": "Chronos can't run a private Docker container", "last_edit_date": 1481669636, "tags": ["mesos", "marathon", "dcos"], "view_count": 190, "accepted_answer_id": 41175496, "last_activity_date": 1481847715, "answers": [{"body": "<p>your post looked a little like <a href=\"https://stackoverflow.com/questions/31057910/mesos-cannot-deploy-container-from-private-docker-registry\">this one</a>, which turned out to be a problem with volumes. </p>\n", "answer_id": 41175176, "last_activity_date": 1481845610, "creation_date": 1481845610, "score": 0, "owner": {"user_id": 6702425, "profile_image": "https://i.stack.imgur.com/CXJ2H.jpg?s=128&g=1", "user_type": "registered", "reputation": 86, "link": "https://stackoverflow.com/users/6702425/judith-malnick", "display_name": "Judith Malnick"}, "is_accepted": false, "last_edit_date": 1495540987, "question_id": 41109337}, {"body": "<p>As it turns out...the uris param is deprecated in favor of fetch. I started from scratch with a marathon config applied to chronos and watched the logs carefully when I saw this: <code>{'message': 'Tried to add both uri (deprecated) and fetch parameters on aBPepwhG5z33e4teG', 'status': 'Bad Request'}</code>. Then I changed my uris parameter into:</p>\n\n<pre><code>\"fetch\": [{\n    \"uri\": \"/images/docker.tar.gz\",\n    \"extract\": True,\n    \"executable\": False,\n    \"cache\": False\n}]\n</code></pre>\n\n<p>...and it worked.</p>\n", "answer_id": 41175496, "last_activity_date": 1481847715, "creation_date": 1481847715, "score": 4, "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "is_accepted": true, "question_id": 41109337}], "score": 3, "link": "https://stackoverflow.com/questions/41109337/chronos-cant-run-a-private-docker-container", "answer_count": 2, "owner": {"user_id": 1515697, "profile_image": "https://www.gravatar.com/avatar/733f4b3d2139b2faa5188c9656785e50?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1878, "link": "https://stackoverflow.com/users/1515697/romeo-mihalcea", "accept_rate": 68, "display_name": "Romeo Mihalcea"}, "creation_date": 1481575922, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41109337}{"is_answered": true, "tags": ["linux", "apache", "mesos", "mesosphere", "dcos"], "title": "What&#39;s difference between Apache Mesos, Mesosphere and DCOS?", "last_activity_date": 1495706411, "answer_count": 2, "creation_date": 1495677457, "score": 2, "link": "https://stackoverflow.com/questions/44171100/whats-difference-between-apache-mesos-mesosphere-and-dcos", "accepted_answer_id": 44174486, "owner": {"user_id": 2038901, "profile_image": "https://www.gravatar.com/avatar/88a2242eb110fda489eee0bcbde6f2bd?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1980, "link": "https://stackoverflow.com/users/2038901/sato", "accept_rate": 97, "display_name": "Sato"}, "view_count": 411, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 44171100}{"body": "<p>I follow this <a href=\"https://open.mesosphere.com/getting-started/install/#verifying-installation\" rel=\"nofollow\">doc</a> to setup mesos cluster.</p>\n\n<p>There are three vm(ubuntu 12, centos 6.5, centos 7.2).</p>\n\n<pre><code>$ cat /etc/hosts\n10.142.55.190 zk1\n10.142.55.196 zk2\n10.142.55.202 zk3\n</code></pre>\n\n<p>config in each mathine:</p>\n\n<pre><code>$ cat /etc/mesos/zk\nzk://10.142.55.190:2181,10.142.55.196:2181,10.142.55.202:2181/mesos\n</code></pre>\n\n<p>After start zookeeper, mesos-master and mesos-slave in three vm, I can view the mesos webui(10.142.55.190:5050), but agents count is 0.</p>\n\n<p>After a little time, mesos page get error:\n    Failed to connect to 10.142.55.190:5050!\n    Retrying in 16 seconds... \n(Now I found that zookeeper elect a new leader in a short interval)</p>\n\n<p>master info log:</p>\n\n<pre><code>I0919 15:54:59.677438 13281 http.cpp:2022] Redirecting request for /master/state?jsonp=angular.callbacks._1x to the leading master zk3\nI0919 15:55:00.098667 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (768)@10.142.55.202:5050\nI0919 15:55:00.385279 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (185)@10.142.55.196:5050\nI0919 15:55:00.711119 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (771)@10.142.55.202:5050\nI0919 15:55:01.347291 13284 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (188)@10.142.55.196:5050\nI0919 15:55:01.597682 13284 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (774)@10.142.55.202:5050\nI0919 15:55:02.257159 13282 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (191)@10.142.55.196:5050\nI0919 15:55:02.370692 13287 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (777)@10.142.55.202:5050\nI0919 15:55:03.205920 13285 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (780)@10.142.55.202:5050\nI0919 15:55:03.260007 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (194)@10.142.55.196:5050\nI0919 15:55:03.929611 13283 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (783)@10.142.55.202:5050\nI0919 15:55:04.033308 13287 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (197)@10.142.55.196:5050\nI0919 15:55:04.591275 13284 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (200)@10.142.55.196:5050\nI0919 15:55:04.608211 13283 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (786)@10.142.55.202:5050\nI0919 15:55:05.184682 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (789)@10.142.55.202:5050\nI0919 15:55:05.268277 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (203)@10.142.55.196:5050\nI0919 15:55:05.775377 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (206)@10.142.55.196:5050\nI0919 15:55:05.916445 13285 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (792)@10.142.55.202:5050\nI0919 15:55:06.744927 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (209)@10.142.55.196:5050\nI0919 15:55:07.378521 13283 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (5)@10.142.55.202:5050\nI0919 15:55:07.393311 13285 network.hpp:430] ZooKeeper group memberships changed\nI0919 15:55:07.393427 13285 group.cpp:706] Trying to get '/mesos/log_replicas/0000000709' in ZooKeeper\nI0919 15:55:07.393985 13285 group.cpp:706] Trying to get '/mesos/log_replicas/0000000711' in ZooKeeper\nI0919 15:55:07.394394 13285 group.cpp:706] Trying to get '/mesos/log_replicas/0000000714' in ZooKeeper\nI0919 15:55:07.394843 13285 group.cpp:706] Trying to get '/mesos/log_replicas/0000000715' in ZooKeeper\nI0919 15:55:07.395418 13285 network.hpp:478] ZooKeeper group PIDs: { log-replica(1)@10.142.55.190:5050, log-replica(1)@10.142.55.196:5050, log-replica(1)@10.142.55.202:5050 }\nI0919 15:55:08.178272 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (14)@10.142.55.202:5050\nI0919 15:55:09.059562 13282 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (21)@10.142.55.202:5050\nI0919 15:55:09.700711 13286 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (24)@10.142.55.202:5050\nI0919 15:55:09.742185 13287 http.cpp:381] HTTP GET for /master/state from 10.142.50.94:59987 with User-Agent='Mozilla/5.0 (Windows NT 6.2; WOW64; rv:47.0) Gecko/20100101 Firefox/47.0'\nI0919 15:55:09.742359 13287 http.cpp:2022] Redirecting request for /master/state?jsonp=angular.callbacks._1y to the leading master zk3\nI0919 15:55:10.660789 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (30)@10.142.55.202:5050\nI0919 15:55:11.480326 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (34)@10.142.55.202:5050\nI0919 15:55:12.386256 13286 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (37)@10.142.55.202:5050\nI0919 15:55:12.975137 13287 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (42)@10.142.55.202:5050\nI0919 15:55:13.843091 13285 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (47)@10.142.55.202:5050\nI0919 15:55:14.373478 13281 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (51)@10.142.55.202:5050\nI0919 15:55:14.937181 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (54)@10.142.55.202:5050\nI0919 15:55:15.658219 13283 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (58)@10.142.55.202:5050\nI0919 15:55:16.007822 13286 network.hpp:430] ZooKeeper group memberships changed\nI0919 15:55:16.007972 13286 group.cpp:706] Trying to get '/mesos/log_replicas/0000000711' in ZooKeeper\nI0919 15:55:16.010170 13286 group.cpp:706] Trying to get '/mesos/log_replicas/0000000714' in ZooKeeper\nI0919 15:55:16.011462 13284 detector.cpp:152] Detected a new leader: (id='702')\nI0919 15:55:16.011556 13284 group.cpp:706] Trying to get '/mesos/json.info_0000000702' in ZooKeeper\nI0919 15:55:16.011968 13286 group.cpp:706] Trying to get '/mesos/log_replicas/0000000715' in ZooKeeper\nI0919 15:55:16.012526 13286 network.hpp:478] ZooKeeper group PIDs: { log-replica(1)@10.142.55.190:5050, log-replica(1)@10.142.55.196:5050, log-replica(1)@10.142.55.202:5050 }\nI0919 15:55:16.013156 13284 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.190:5050) is detected\nI0919 15:55:16.013222 13284 master.cpp:1847] The newly elected leader is master@10.142.55.190:5050 with id 677967bc-f6f0-46b3-a44e-72eed1befd60\nI0919 15:55:16.013244 13284 master.cpp:1860] Elected as the leading master!\nI0919 15:55:16.013273 13284 master.cpp:1547] Recovering from registrar\nI0919 15:55:16.013352 13284 registrar.cpp:332] Recovering registrar\nI0919 15:55:16.014081 13280 log.cpp:553] Attempting to start the writer\nI0919 15:55:16.014515 13280 replica.cpp:493] Replica received implicit promise request from (211)@10.142.55.190:5050 with proposal 1204590\nI0919 15:55:16.018023 13282 consensus.cpp:360] Aborting implicit promise request because 2 ignores received\nI0919 15:55:16.018028 13280 leveldb.cpp:304] Persisting metadata (10 bytes) to leveldb took 3.469479ms\nI0919 15:55:16.018338 13280 replica.cpp:342] Persisted promised to 1204590\nI0919 15:55:16.018508 13282 log.cpp:565] Could not start the writer, but can be retried\nI0919 15:55:16.018645 13282 log.cpp:553] Attempting to start the writer\nI0919 15:55:16.018899 13282 replica.cpp:493] Replica received implicit promise request from (215)@10.142.55.190:5050 with proposal 1204591\nI0919 15:55:16.022183 13287 consensus.cpp:360] Aborting implicit promise request because 2 ignores received\nI0919 15:55:16.022367 13280 log.cpp:565] Could not start the writer, but can be retried\nI0919 15:55:16.022510 13280 log.cpp:553] Attempting to start the writer\nI0919 15:55:16.028880 13282 leveldb.cpp:304] Persisting metadata (10 bytes) to leveldb took 9.870818ms\nI0919 15:55:16.029024 13282 replica.cpp:342] Persisted promised to 1204591\nI0919 15:55:16.029428 13286 replica.cpp:493] Replica received implicit promise request from (219)@10.142.55.190:5050 with proposal 1204592\nI0919 15:55:16.031600 13280 consensus.cpp:360] Aborting implicit promise request because 2 ignores received\nI0919 15:55:16.036208 13283 log.cpp:565] Could not start the writer, but can be retried\nI0919 15:55:16.036454 13283 log.cpp:553] Attempting to start the writer\nI0919 15:55:16.040256 13286 leveldb.cpp:304] Persisting metadata (10 bytes) to leveldb took 10.783237ms\nI0919 15:55:16.040339 13286 replica.cpp:342] Persisted promised to 1204592\nI0919 15:55:16.040712 13286 replica.cpp:493] Replica received implicit promise request from (222)@10.142.55.190:5050 with proposal 1204593\nI0919 15:55:16.042196 13286 leveldb.cpp:304] Persisting metadata (10 bytes) to leveldb took 1.435071ms\nI0919 15:55:16.042250 13286 replica.cpp:342] Persisted promised to 1204593\nI0919 15:55:16.042981 13286 consensus.cpp:360] Aborting implicit promise request because 2 ignores received\nI0919 15:55:16.043099 13286 log.cpp:565] Could not start the writer, but can be retried\nI0919 15:55:16.043303 13283 log.cpp:553] Attempting to start the writer\n</code></pre>\n\n<p>All later logs are looping </p>\n\n<pre><code>I0919 15:55:16.043676 13286 replica.cpp:493] Replica received implicit promise request from (225)@10.142.55.190:5050 with proposal 1204594\nI0919 15:55:16.044122 13286 leveldb.cpp:304] Persisting metadata (10 bytes) to leveldb took 404769ns\nI0919 15:55:16.044209 13286 replica.cpp:342] Persisted promised to 1204594\nI0919 15:55:16.044837 13281 consensus.cpp:360] Aborting implicit promise request because 2 ignores received\nI0919 15:55:16.044926 13281 log.cpp:565] Could not start the writer, but can be retried\nI0919 15:55:16.045038 13281 log.cpp:553] Attempting to start the writer\n</code></pre>\n\n<p>slave info log:</p>\n\n<pre><code>Log file created at: 2016/09/19 15:41:16\nRunning on machine: ubuntu12\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\nI0919 15:41:16.346844 12986 logging.cpp:194] INFO level logging started!\nI0919 15:41:16.363313 12986 containerizer.cpp:196] Using isolation: posix/cpu,posix/mem,filesystem/posix,network/cni\nI0919 15:41:16.370334 12986 main.cpp:434] Starting Mesos agent\nI0919 15:41:16.371184 12986 slave.cpp:198] Agent started on 1)@127.0.1.1:5051\nI0919 15:41:16.371636 12986 slave.cpp:199] Flags at startup: --appc_simple_discovery_uri_prefix=\"http://\" --appc_store_dir=\"/tmp/mesos/store/appc\" --authenticate_http_readonly=\"false\" --authenticate_http_readwrite=\"false\" --authenticatee=\"crammd5\" --authentication_backoff_factor=\"1secs\" --authorizer=\"local\" --cgroups_cpu_enable_pids_and_tids_count=\"false\" --cgroups_enable_cfs=\"false\" --cgroups_hierarchy=\"/sys/fs/cgroup\" --cgroups_limit_swap=\"false\" --cgroups_root=\"mesos\" --container_disk_watch_interval=\"15secs\" --containerizers=\"mesos\" --default_role=\"*\" --disk_watch_interval=\"1mins\" --docker=\"docker\" --docker_kill_orphans=\"true\" --docker_registry=\"https://registry-1.docker.io\" --docker_remove_delay=\"6hrs\" --docker_socket=\"/var/run/docker.sock\" --docker_stop_timeout=\"0ns\" --docker_store_dir=\"/tmp/mesos/store/docker\" --docker_volume_checkpoint_dir=\"/var/run/mesos/isolators/docker/volume\" --enforce_container_disk_quota=\"false\" --executor_registration_timeout=\"1mins\" --executor_shutdown_grace_period=\"5secs\" --fetcher_cache_dir=\"/tmp/mesos/fetch\" --fetcher_cache_size=\"2GB\" --frameworks_home=\"\" --gc_delay=\"1weeks\" --gc_disk_headroom=\"0.1\" --hadoop_home=\"\" --help=\"false\" --hostname_lookup=\"true\" --http_authenticators=\"basic\" --http_command_executor=\"false\" --image_provisioner_backend=\"copy\" --initialize_driver_logging=\"true\" --isolation=\"posix/cpu,posix/mem\" --launcher=\"posix\" --launcher_dir=\"/usr/libexec/mesos\" --log_dir=\"/var/log/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --master=\"zk://10.142.55.190:2181,10.142.55.196:2181,10.142.55.202:2181/mesos\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --port=\"5051\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registration_backoff_factor=\"1secs\" --revocable_cpu_low_priority=\"true\" --sandbox_directory=\"/mnt/mesos/sandbox\" --strict=\"true\" --switch_user=\"true\" --systemd_enable_support=\"true\" --systemd_runtime_directory=\"/run/systemd/system\" --version=\"false\" --work_dir=\"/var/lib/mesos\"\nI0919 15:41:16.373072 12986 slave.cpp:519] Agent resources: cpus(*):2; mem(*):2930; disk(*):4469; ports(*):[31000-32000]\nI0919 15:41:16.373291 12986 slave.cpp:527] Agent attributes: [  ]\nI0919 15:41:16.373347 12986 slave.cpp:532] Agent hostname: ubuntu12\nI0919 15:41:16.379895 13005 state.cpp:57] Recovering state from '/var/lib/mesos/meta'\nI0919 15:41:16.382519 13005 group.cpp:349] Group process (group(1)@127.0.1.1:5051) connected to ZooKeeper\nI0919 15:41:16.382593 13005 group.cpp:837] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI0919 15:41:16.382663 13005 group.cpp:427] Trying to create path '/mesos' in ZooKeeper\nI0919 15:41:16.382910 13009 status_update_manager.cpp:200] Recovering status update manager\nI0919 15:41:16.383419 13009 containerizer.cpp:522] Recovering containerizer\nI0919 15:41:16.392206 13004 provisioner.cpp:253] Provisioner recovery complete\nI0919 15:41:16.392354 13004 slave.cpp:4782] Finished recovery\nI0919 15:41:16.405709 13004 detector.cpp:152] Detected a new leader: (id='678')\nI0919 15:41:16.406067 13005 group.cpp:706] Trying to get '/mesos/json.info_0000000678' in ZooKeeper\nI0919 15:41:16.407572 13002 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.190:5050) is detected\nI0919 15:41:16.407977 13002 slave.cpp:895] New master detected at master@10.142.55.190:5050\nI0919 15:41:16.408043 13002 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:41:16.408140 13002 slave.cpp:927] Detecting new master\nI0919 15:41:16.408223 13005 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:42:08.418956 13006 slave.cpp:3732] master@10.142.55.190:5050 exited\nW0919 15:42:08.419035 13006 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:42:16.374977 13007 slave.cpp:4591] Current disk usage 72.41%. Max allowed age: 1.231186482451933days\nI0919 15:42:20.007169 13007 detector.cpp:152] Detected a new leader: (id='679')\nI0919 15:42:20.007297 13007 group.cpp:706] Trying to get '/mesos/json.info_0000000679' in ZooKeeper\nI0919 15:42:20.008503 13007 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.196:5050) is detected\nI0919 15:42:20.008587 13007 slave.cpp:895] New master detected at master@10.142.55.196:5050\nI0919 15:42:20.008610 13007 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:42:20.008703 13007 slave.cpp:927] Detecting new master\nI0919 15:42:20.008750 13007 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:43:16.387984 13005 slave.cpp:4591] Current disk usage 72.41%. Max allowed age: 1.231162010606794days\nI0919 15:43:20.081272 13005 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:43:20.081374 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:43:26.855154 13005 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:43:26.855315 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:43:26.855159 13010 process.cpp:2105] Failed to shutdown socket with fd 12: Transport endpoint is not connected\nI0919 15:43:32.020196 13002 detector.cpp:152] Detected a new leader: (id='682')\nI0919 15:43:32.020300 13002 group.cpp:706] Trying to get '/mesos/json.info_0000000682' in ZooKeeper\nI0919 15:43:32.022203 13002 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.202:5050) is detected\nI0919 15:43:32.022302 13002 slave.cpp:895] New master detected at master@10.142.55.202:5050\nI0919 15:43:32.022328 13002 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:43:32.022382 13002 slave.cpp:927] Detecting new master\nI0919 15:43:32.022423 13002 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:44:16.389369 13003 slave.cpp:4591] Current disk usage 72.41%. Max allowed age: 1.231119184877789days\nI0919 15:44:32.535347 13003 slave.cpp:3732] master@10.142.55.202:5050 exited\nW0919 15:44:32.535522 13003 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:44:42.005375 13002 detector.cpp:152] Detected a new leader: (id='684')\nI0919 15:44:42.005496 13002 group.cpp:706] Trying to get '/mesos/json.info_0000000684' in ZooKeeper\nI0919 15:44:42.006367 13002 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.190:5050) is detected\nI0919 15:44:42.006492 13002 slave.cpp:895] New master detected at master@10.142.55.190:5050\nI0919 15:44:42.006597 13002 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:44:42.006675 13002 slave.cpp:927] Detecting new master\nI0919 15:44:42.006577 13008 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:45:16.400794 13006 slave.cpp:4591] Current disk usage 72.48%. Max allowed age: 1.226390000804074days\nI0919 15:45:42.354790 13005 slave.cpp:3732] master@10.142.55.190:5050 exited\nW0919 15:45:42.354857 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:45:54.020563 13002 detector.cpp:152] Detected a new leader: (id='687')\nI0919 15:45:54.020756 13002 group.cpp:706] Trying to get '/mesos/json.info_0000000687' in ZooKeeper\nI0919 15:45:54.023296 13002 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.196:5050) is detected\nI0919 15:45:54.023455 13002 slave.cpp:895] New master detected at master@10.142.55.196:5050\nI0919 15:45:54.023558 13002 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:45:54.023526 13008 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:45:54.023669 13002 slave.cpp:927] Detecting new master\nI0919 15:46:16.402402 13003 slave.cpp:4591] Current disk usage 72.53%. Max allowed age: 1.223205601954942days\nI0919 15:46:54.075505 13007 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:46:54.075592 13007 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:46:56.098012 13010 process.cpp:2105] Failed to shutdown socket with fd 14: Transport endpoint is not connected\nI0919 15:46:56.098016 13007 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:46:56.098253 13007 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:46:56.462254 13010 process.cpp:2105] Failed to shutdown socket with fd 14: Transport endpoint is not connected\nI0919 15:46:56.462260 13005 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:46:56.462540 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:47:02.005637 13009 detector.cpp:152] Detected a new leader: (id='688')\nI0919 15:47:02.005765 13009 group.cpp:706] Trying to get '/mesos/json.info_0000000688' in ZooKeeper\nI0919 15:47:02.006853 13009 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.202:5050) is detected\nI0919 15:47:02.006959 13009 slave.cpp:895] New master detected at master@10.142.55.202:5050\nI0919 15:47:02.006986 13009 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:47:02.007025 13009 slave.cpp:927] Detecting new master\nI0919 15:47:02.007061 13009 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:47:16.406669 13008 slave.cpp:4591] Current disk usage 72.53%. Max allowed age: 1.223184189090440days\nI0919 15:48:02.950891 13005 slave.cpp:3732] master@10.142.55.202:5050 exited\nW0919 15:48:02.950994 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:48:12.006634 13005 detector.cpp:152] Detected a new leader: (id='690')\nI0919 15:48:12.006817 13003 group.cpp:706] Trying to get '/mesos/json.info_0000000690' in ZooKeeper\nI0919 15:48:12.007987 13003 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.190:5050) is detected\nI0919 15:48:12.008126 13003 slave.cpp:895] New master detected at master@10.142.55.190:5050\nI0919 15:48:12.008210 13003 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:48:12.008280 13003 slave.cpp:927] Detecting new master\nI0919 15:48:12.008191 13008 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:48:16.409266 13003 slave.cpp:4591] Current disk usage 72.54%. Max allowed age: 1.222480623542604days\nI0919 15:49:12.379010 13009 slave.cpp:3732] master@10.142.55.190:5050 exited\nW0919 15:49:12.379149 13009 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:49:12.379233 13010 process.cpp:2105] Failed to shutdown socket with fd 12: Transport endpoint is not connected\nI0919 15:49:16.413767 13007 slave.cpp:4591] Current disk usage 72.64%. Max allowed age: 1.215032005677465days\nI0919 15:49:24.016290 13007 detector.cpp:152] Detected a new leader: (id='693')\nI0919 15:49:24.016417 13007 group.cpp:706] Trying to get '/mesos/json.info_0000000693' in ZooKeeper\nI0919 15:49:24.018273 13007 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.196:5050) is detected\nI0919 15:49:24.018437 13007 slave.cpp:895] New master detected at master@10.142.55.196:5050\nI0919 15:49:24.018523 13007 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:49:24.018604 13007 slave.cpp:927] Detecting new master\nI0919 15:49:24.018496 13008 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:50:16.416391 13008 slave.cpp:4591] Current disk usage 72.64%. Max allowed age: 1.215016710774248days\nI0919 15:50:24.065268 13003 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:50:24.065342 13003 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:50:24.485752 13004 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:50:24.485839 13004 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:50:24.485977 13010 process.cpp:2105] Failed to shutdown socket with fd 14: Transport endpoint is not connected\nI0919 15:50:28.343647 13003 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:50:28.343719 13003 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:50:28.343819 13010 process.cpp:2105] Failed to shutdown socket with fd 14: Transport endpoint is not connected\nI0919 15:50:31.545099 13005 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:50:31.545171 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:50:31.545284 13010 process.cpp:2105] Failed to shutdown socket with fd 14: Transport endpoint is not connected\nI0919 15:50:32.007096 13008 detector.cpp:152] Detected a new leader: (id='694')\nI0919 15:50:32.007195 13008 group.cpp:706] Trying to get '/mesos/json.info_0000000694' in ZooKeeper\nI0919 15:50:32.009881 13008 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.202:5050) is detected\nI0919 15:50:32.009970 13008 slave.cpp:895] New master detected at master@10.142.55.202:5050\nI0919 15:50:32.009994 13008 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:50:32.010030 13008 slave.cpp:927] Detecting new master\nI0919 15:50:32.010079 13008 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:51:16.417846 13006 slave.cpp:4591] Current disk usage 72.64%. Max allowed age: 1.214964708103322days\nI0919 15:51:32.560317 13003 slave.cpp:3732] master@10.142.55.202:5050 exited\nW0919 15:51:32.560410 13003 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:51:42.005147 13009 detector.cpp:152] Detected a new leader: (id='696')\nI0919 15:51:42.005265 13009 group.cpp:706] Trying to get '/mesos/json.info_0000000696' in ZooKeeper\nI0919 15:51:42.006824 13009 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.190:5050) is detected\nI0919 15:51:42.006904 13009 slave.cpp:895] New master detected at master@10.142.55.190:5050\nI0919 15:51:42.006928 13009 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:51:42.006963 13009 slave.cpp:927] Detecting new master\nI0919 15:51:42.006999 13009 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:52:16.419373 13003 slave.cpp:4591] Current disk usage 72.71%. Max allowed age: 1.209981628636250days\nI0919 15:52:42.336305 13002 slave.cpp:3732] master@10.142.55.190:5050 exited\nW0919 15:52:42.336426 13002 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:52:54.005267 13005 detector.cpp:152] Detected a new leader: (id='699')\nI0919 15:52:54.005408 13005 group.cpp:706] Trying to get '/mesos/json.info_0000000699' in ZooKeeper\nI0919 15:52:54.006206 13005 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.196:5050) is detected\nI0919 15:52:54.006285 13005 slave.cpp:895] New master detected at master@10.142.55.196:5050\nI0919 15:52:54.006309 13005 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:52:54.006398 13005 slave.cpp:927] Detecting new master\nI0919 15:52:54.006451 13005 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:53:16.420258 13005 slave.cpp:4591] Current disk usage 72.76%. Max allowed age: 1.206748286096840days\nI0919 15:53:54.071012 13005 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:53:54.071143 13005 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:54:01.105780 13002 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:54:01.105854 13002 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:54:01.105970 13010 process.cpp:2105] Failed to shutdown socket with fd 15: Transport endpoint is not connected\nI0919 15:54:05.733837 13007 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:54:05.733932 13007 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nE0919 15:54:05.734071 13010 process.cpp:2105] Failed to shutdown socket with fd 15: Transport endpoint is not connected\nE0919 15:54:05.818560 13010 process.cpp:2105] Failed to shutdown socket with fd 15: Transport endpoint is not connected\nI0919 15:54:05.818583 13003 slave.cpp:3732] master@10.142.55.196:5050 exited\nW0919 15:54:05.818758 13003 slave.cpp:3737] Master disconnected! Waiting for a new master to be elected\nI0919 15:54:06.004385 13009 detector.cpp:152] Detected a new leader: (id='700')\nI0919 15:54:06.004494 13009 group.cpp:706] Trying to get '/mesos/json.info_0000000700' in ZooKeeper\nI0919 15:54:06.005511 13009 zookeeper.cpp:259] A new leading master (UPID=master@10.142.55.202:5050) is detected\nI0919 15:54:06.005586 13009 slave.cpp:895] New master detected at master@10.142.55.202:5050\nI0919 15:54:06.005609 13009 slave.cpp:916] No credentials provided. Attempting to register without authentication\nI0919 15:54:06.005676 13009 slave.cpp:927] Detecting new master\nI0919 15:54:06.005720 13009 status_update_manager.cpp:174] Pausing sending status updates\nI0919 15:54:16.423193 13002 slave.cpp:4591] Current disk usage 72.76%. Max allowed age: 1.206699342406551days\n</code></pre>\n", "is_answered": true, "title": "mesos-master can not found mesos-slave, and elect a new leader in a short interval", "last_edit_date": 1474509240, "tags": ["linux", "installation", "apache-zookeeper", "mesos", "mesosphere"], "view_count": 535, "accepted_answer_id": 39629076, "last_activity_date": 1474509240, "answers": [{"body": "<p>Thanks to <a href=\"https://issues.apache.org/jira/browse/MESOS-6205\" rel=\"nofollow\">Joseph Wu</a> to help me solve the problem, detail:</p>\n\n<p>There are two repeating log messages that tell you (indirectly) that something is wrong:</p>\n\n<blockquote>\n  <p>I0919 15:55:08.178272 13280 replica.cpp:673] Replica in VOTING status received a broadcasted recover request from (14)@10.142.55.202:5050</p>\n</blockquote>\n\n<p>This message means that you've started this master before, with the same work directory. It has some sort of persistent state in its work directory.</p>\n\n<p>This log message tells you that there are two masters you have not started before:</p>\n\n<blockquote>\n  <p>I0919 15:55:16.018023 13282 consensus.cpp:360] Aborting implicit promise request because 2 ignores received</p>\n</blockquote>\n\n<p>The masters will refuse to start because there is less than a quorum of masters with the persistent state. If the masters were to start, you would have potential data loss. This is the expected behavior, as Mesos errs on the side of caution. </p>\n\n<hr>\n\n<p>If I need a fresh mesos cluster, I need clean work directory of the master.\nBut the problem is not on <code>10.142.55.202</code> as Joseph Wu says. I clear all the word_dir, and get out of this problem.</p>\n\n<p>How to clean the work dir:</p>\n\n<ol>\n<li><p>find mesos-master work dir</p>\n\n<pre><code>$ cat /etc/mesos-master/work_dir\n/var/lib/mesos\n</code></pre></li>\n<li><p>remove it</p>\n\n<pre><code>$ rm -rf /var/lib/mesos\n</code></pre></li>\n</ol>\n", "answer_id": 39629076, "last_activity_date": 1474509156, "creation_date": 1474509156, "score": 1, "owner": {"user_id": 1637673, "profile_image": "https://www.gravatar.com/avatar/102059d423f2265e737117ce0947e7ee?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3255, "link": "https://stackoverflow.com/users/1637673/mithril", "accept_rate": 62, "display_name": "Mithril"}, "is_accepted": true, "question_id": 39565150}], "score": 1, "link": "https://stackoverflow.com/questions/39565150/mesos-master-can-not-found-mesos-slave-and-elect-a-new-leader-in-a-short-interv", "answer_count": 1, "owner": {"user_id": 1637673, "profile_image": "https://www.gravatar.com/avatar/102059d423f2265e737117ce0947e7ee?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3255, "link": "https://stackoverflow.com/users/1637673/mithril", "accept_rate": 62, "display_name": "Mithril"}, "creation_date": 1474257624, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39565150}{"body": "<p>I'm trying to run a Cassandra docker image on Mesos / DCOS. I know I can install Cassandra from the Universe but I need it as a docker image.  When I deploy it using the config below, I get the error in the Debug:\nState     TASK_FAILED\nMessage   Container exited with status 137</p>\n\n<p>Marathon JSON</p>\n\n<p><code>{\n  \"id\": \"cassandra\",\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"cassandra:3.9\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"hostPort\": 9042,\n          \"containerPort\": 9042,\n          \"servicePort\": 9042,\n          \"labels\": {\n            \"VIP_0\": \"172.17.0.2:9042\"\n          }\n        }\n      ],\n      \"forcePullImage\": true\n    }\n  },\n  \"instances\": 1,\n  \"cpus\": 1,\n  \"mem\": 1028\n}\n</code></p>\n", "is_answered": false, "tags": ["docker", "mesos", "marathon", "mesosphere"], "title": "Unable to run cassandra docker on Mesos", "last_activity_date": 1487127070, "answer_count": 0, "creation_date": 1487127070, "score": 0, "link": "https://stackoverflow.com/questions/42239843/unable-to-run-cassandra-docker-on-mesos", "owner": {"user_id": 5327086, "profile_image": "https://www.gravatar.com/avatar/7da3e0464eb2cde1eef7387ab766051e?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 25, "link": "https://stackoverflow.com/users/5327086/adoyt", "accept_rate": 29, "display_name": "Adoyt"}, "view_count": 50, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 42239843}{"body": "<p>I am going to set up a kafka cluster on apache mesos.\nI follow the instruction at <a href=\"https://github.com/mesos/kafka\" rel=\"nofollow\">kafka-mesos on github</a>. I installed a mesos cluster (using <a href=\"https://open.mesosphere.com/getting-started/datacenter/install/\" rel=\"nofollow\">Mesosphere</a> without Marathon) with 3 nodes each with 2 CPUs and 4GB memory. I tested the cluster with hello world examples successfully.</p>\n\n<p>I can run kafka-mesos scheduler on it and can add brokers to it.\nBut when i want to start the broker, an memory limit issued appear.</p>\n\n<pre><code>broker-191-.... TASK_FAILED slave:#c3-S1 reason:REASON_MEMORY_LIMIT\n</code></pre>\n\n<p>Although, the cluster has 12GB memory, but broker just need 3GB memory with 1GB heap. (I test it with various configuration from 512M till 3GB, but not worked)</p>\n\n<p>What is the problem? and what is the solution?</p>\n\n<p>the complete story is here:</p>\n\n<pre><code>2015-10-17 17:39:24,748 [Jetty-17] INFO  ly.stealth.mesos.kafka.HttpServer$  - handling - http://192.168.11.191:7000/api/broker/start\n2015-10-17 17:39:28,202 [Thread-605] INFO  ly.stealth.mesos.kafka.Scheduler$  - [resourceOffers]\nmesos-2#O1160 cpus:2.00 mem:4098.00 disk:9869.00 ports:[31000..32000]\nmesos-3#O1161 cpus:2.00 mem:4098.00 disk:9869.00 ports:[31000..32000]\nmesos-1#O1162 cpus:2.00 mem:4098.00 disk:9869.00 ports:[31000..32000]\n2015-10-17 17:39:28,204 [Thread-605] INFO  ly.stealth.mesos.kafka.Scheduler$  - Starting broker 191: launching task broker-191-0abe9e57-b0fb-4d87-a1b4-529acb111940 by offer mesos-2#O1160\nbroker-191-0abe9e57-b0fb-4d87-a1b4-529acb111940 slave:#c6-S3 cpus:1.00 mem:3096.00 ports:[31000..31000] data:defaults=broker.id\\=191\\,log.dirs\\=kafka-logs\\,port\\=31000\\,zookeeper.connect\\=192.168.11.191:2181\\\\\\,192.168.11.192:2181\\\\\\,192.168.11.193:2181\\,host.name\\=mesos-2\\,log.retention.bytes\\=10737418240,broker={\"stickiness\" : {\"period\" : \"10m\"\\, \"stopTime\" : \"2015-10-17 13:43:29.278\"}\\, \"id\" : \"191\"\\, \"mem\" : 3096\\, \"cpus\" : 1.0\\, \"heap\" : 1024\\, \"failover\" : {\"delay\" : \"1m\"\\, \"maxDelay\" : \"10m\"}\\, \"active\" : true}\n2015-10-17 17:39:28,417 [Thread-606] INFO  ly.stealth.mesos.kafka.Scheduler$  - [statusUpdate] broker-191-0abe9e57-b0fb-4d87-a1b4-529acb111940 TASK_FAILED slave:#c6-S3 reason:REASON_MEMORY_LIMIT\n2015-10-17 17:39:28,418 [Thread-606] INFO  ly.stealth.mesos.kafka.Scheduler$  - Broker 191 failed 1, waiting 1m, next start ~ 2015-10-17 17:40:28+03\n2015-10-17 17:39:29,202 [Thread-607] INFO  ly.stealth.mesos.kafka.Scheduler$  - [resourceOffers]\n</code></pre>\n\n<p>I found the following in Mesos master log:</p>\n\n<pre><code>...validation.cpp:422] Executor broker-191-... for task broker-191-... uses less CPUs (None) than the minimum required (0.01). Please update your executor, as this will be mandatory in future releases.\n...validation.cpp:434] Executor broker-191-... for task broker-191-... uses less memory (None) than the minimum required (32MB). Please update your executor, as this will be mandatory in future releases.\n</code></pre>\n\n<p>but i set the CPU and MEM for brokers via broker add (update):</p>\n\n<pre><code>broker updated:\nid: 191\nactive: false\nstate: stopped\nresources: cpus:1.00, mem:2048, heap:1024, port:auto\nfailover: delay:1m, max-delay:10m\nstickiness: period:10m, expires:2015-10-19 11:15:53+03\n</code></pre>\n", "is_answered": true, "tags": ["apache-kafka", "mesos", "mesosphere"], "last_edit_date": 1445241493, "title": "Mesos Kafka task failed memory limit", "last_activity_date": 1445241493, "answer_count": 1, "creation_date": 1445091930, "score": 1, "link": "https://stackoverflow.com/questions/33187684/mesos-kafka-task-failed-memory-limit", "answers": [{"body": "<p>The executor doesn't get the heap setting just the broker. I opened an issue for this <a href=\"https://github.com/mesos/kafka/issues/137\" rel=\"nofollow\">https://github.com/mesos/kafka/issues/137</a>. Please increase the mem until a patch is available.</p>\n\n<p>This hasn't been a problem seen I suspect because the mem gets set as a larger value (the size of your data set you don't want to hit disk from when reading) so there is page cache for max efficiencies <a href=\"http://kafka.apache.org/documentation.html#maximizingefficiency\" rel=\"nofollow\">http://kafka.apache.org/documentation.html#maximizingefficiency</a></p>\n", "answer_id": 33205576, "last_activity_date": 1445220675, "creation_date": 1445220675, "score": 2, "owner": {"user_id": 5461070, "profile_image": "https://lh6.googleusercontent.com/-gsJ6WJl-BHw/AAAAAAAAAAI/AAAAAAAAAA0/yhk08FYZo5g/photo.jpg?sz=128", "user_type": "registered", "reputation": 21, "link": "https://stackoverflow.com/users/5461070/joe-stein", "display_name": "Joe Stein"}, "is_accepted": false, "question_id": 33187684}], "owner": {"user_id": 2527458, "profile_image": "https://i.stack.imgur.com/fYtXY.jpg?s=128&g=1", "user_type": "registered", "reputation": 237, "link": "https://stackoverflow.com/users/2527458/majid-hajibaba", "accept_rate": 40, "display_name": "majid hajibaba"}, "view_count": 328, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 9}, "question_id": 33187684}{"body": "<p>We have multiple kinds of applications running on the same Mesos-Marathon cluster. The applications can be classified into very loosely coupled categories and can almost run separately. They are running on the same cluster considering the easiness to provision, maintenance of the cluster, re-use of CI/CD pipelines etc. \nHowever, is there a mechanism to statically partition the number of slaves in the cluster so that a group of these applications are provisioned on a set of slaves and the other group on another set.</p>\n", "is_answered": true, "tags": ["mesos", "marathon", "dcos"], "title": "Statically partitioning the slaves in a mesos marathon cluster", "last_activity_date": 1491407806, "answer_count": 1, "creation_date": 1491345106, "score": 3, "link": "https://stackoverflow.com/questions/43218792/statically-partitioning-the-slaves-in-a-mesos-marathon-cluster", "answers": [{"body": "<p>You could use Mesos custom <a href=\"https://mesos.apache.org/documentation/latest/attributes-resources/\" rel=\"nofollow noreferrer\">attributes</a> for that which in turn get used by Marathon via constraints.</p>\n\n<p>From the <a href=\"https://github.com/mesosphere/marathon/blob/master/docs/docs/constraints.md\" rel=\"nofollow noreferrer\">Marathon documentation on constraints</a>:</p>\n\n<blockquote>\n  <p>Constraints control where apps run to allow optimizing for either\n  fault tolerance (by spreading a task out on multiple nodes) or\n  locality (by running all of an applications tasks on the same node).\n  Constraints have three parts: a field name, an operator, and an\n  optional parameter. The field can be the hostname of the agent node or\n  any attribute of the agent node.</p>\n</blockquote>\n", "answer_id": 43236120, "last_activity_date": 1491407806, "creation_date": 1491407806, "score": 2, "owner": {"user_id": 91282, "profile_image": "https://www.gravatar.com/avatar/5ae09a7b73edd93a4ec40a5c1b29e728?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 25632, "link": "https://stackoverflow.com/users/91282/till", "accept_rate": 100, "display_name": "Till"}, "is_accepted": false, "question_id": 43218792}], "owner": {"user_id": 793465, "profile_image": "https://www.gravatar.com/avatar/49fd14ca8858e6b4e8119c585ef8a6b4?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 891, "link": "https://stackoverflow.com/users/793465/phelodas", "accept_rate": 55, "display_name": "Phelodas"}, "view_count": 49, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 43218792}{"body": "<p>We're using a slightly modified community mesosphere cluster. This has mesos-dns installed - so we can resolve master.mesos, and x.marathon.mesos, no problem.\nThe question is which name we should use to access the Cassandra database (whether with cqlsh or with another application)?</p>\n\n<p>I've found the following in the documentation: cassandra-dcos-node.cassandra.dcos.mesos (<a href=\"https://docs.mesosphere.com/services/cassandra/\" rel=\"nofollow\">https://docs.mesosphere.com/services/cassandra/</a>) but what if we change the cluster name (to say, \"foo\")? Which bit gets modified?  I've played around with all combos, but haven't worked it out.</p>\n", "is_answered": true, "tags": ["dns", "mesos", "mesosphere"], "title": "What's the service name mesos-dns provides to access Cassandra when using the Cassandra-mesos framework?", "last_activity_date": 1436904755, "answer_count": 2, "creation_date": 1436869174, "score": 3, "link": "https://stackoverflow.com/questions/31403882/whats-the-service-name-mesos-dns-provides-to-access-cassandra-when-using-the-ca", "answers": [{"body": "<p>The default DNS name for the cassandra server provided by cassandra-mesos framework is <code>cassandra.dcos.node</code>.  that is prepended according to the mesos-dns spec to the service <code>cassandra</code> and then to the domain <code>dcos.mesos</code> to form <code>cassandra-dcos-node.cassandra.dcos.mesos</code>.   </p>\n\n<p>If you are still unclear, the way to confirm the services name is to:</p>\n\n<ol>\n<li>ssh into the server with mesos-dns (I'll assume it is the mesos-master)</li>\n<li>follow the dns service:  <code>journalctl -u mesos-dns -f</code></li>\n<li>register a cassandra-mesos service</li>\n</ol>\n\n<p><strong>you are looking for an A record entry similar to:</strong></p>\n\n<pre><code>Jul 14 13:43:09 ip-10-0-7-2.us-west-2.compute.internal mesos-dns[1331]: VERY VERBOSE: 2015/07/14 13:43:09 generator.go:364: [A]        cassandra-dcos-node.cassandra.dcos.mesos.: 10.0.1.171\n</code></pre>\n", "answer_id": 31408709, "last_activity_date": 1436883209, "creation_date": 1436882059, "score": 1, "owner": {"user_id": 1375187, "profile_image": "https://www.gravatar.com/avatar/54ce5c4133119bd3791bd23f2cc2f582?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 219, "link": "https://stackoverflow.com/users/1375187/ken", "display_name": "Ken"}, "is_accepted": false, "last_edit_date": 1436883209, "question_id": 31403882}, {"body": "<p>In the case of Cassandra running on DCOS (which the docs refer to) the Cluster name is <code>dcos</code>. The framework name registered with Mesos is <code>cassandra.dcos</code>.  The task name for a running Cassandra server is <code>cassandra.dcos.node</code>, </p>\n\n<p>If you were to change the cluster name to \"foo\", the framework name would now be <code>cassandra.foo</code> and the server task names would now be <code>cassandra.foo.node</code>.</p>\n\n<p>To access your \"foo\" Cassandra cluster you would use <code>cassandra-foo-node.cassandra.foo.mesos</code>.</p>\n\n<h3>Now an explanation of how:</h3>\n\n<p>The DNS names that are created by mesos-dns follow a specific schema, all of which can be found in the official documentation[1].</p>\n\n<p>To summarize the documentation here, mesos-dns creates a DNS name with the following format: <code>taskName.frameworkName.mesos</code>. </p>\n\n<p>In the case of Cassandra the task name is <code>cassandra.dcos.node</code> which mesos-dns turns into <code>cassandra-dcos-node</code> since it doesn't all <code>.</code> in task names.  The framework name <code>cassandra.dcos</code> is allowed to have <code>.</code> in it so that stays the same. And mesos is the default value for TLD.</p>\n\n<p>When we put it altogether this is <code>cassandra-dcos-node.cassandra.dcos.mesos</code>.  </p>\n\n<p>The original intent was to have a name of <code>node.dcos.cassandra.mesos</code> but due to time constraints and a misunderstanding of how mesos-dns worked, this is what we're left with.  Hopefully it can be cleaned up in the future.</p>\n\n<p>[1] <a href=\"http://mesosphere.github.io/mesos-dns/docs/naming.html\" rel=\"nofollow\">http://mesosphere.github.io/mesos-dns/docs/naming.html</a></p>\n", "answer_id": 31416376, "last_activity_date": 1436904755, "creation_date": 1436904755, "score": 3, "owner": {"user_id": 4607350, "profile_image": "https://lh3.googleusercontent.com/-HkhCOYc7b4g/AAAAAAAAAAI/AAAAAAAAHXs/OiYKUyob39Q/photo.jpg?sz=128", "user_type": "registered", "reputation": 129, "link": "https://stackoverflow.com/users/4607350/ben-whitehead", "display_name": "Ben Whitehead"}, "is_accepted": false, "question_id": 31403882}], "owner": {"user_id": 4763282, "profile_image": "https://www.gravatar.com/avatar/94e702f4ba85a5a5f528ea44fad44681?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 116, "link": "https://stackoverflow.com/users/4763282/elise-huard", "display_name": "Elise Huard"}, "view_count": 530, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31403882}{"body": "<p>I am facing the problem to add/change attributes of the slave machines in the DCOS environment. </p>\n\n<p>After changing attributes in </p>\n\n<blockquote>\n  <p>vi /var/lib/dcos/mesos-slave-common </p>\n</blockquote>\n\n<pre><code>MESOS_ATTRIBUTES=TYPE:DB;DB_TYPE:MONGO;\n</code></pre>\n\n<p>file, it not immediately getting updated in the cluster. </p>\n\n<p>I have to run the following commands </p>\n\n<blockquote>\n  <p>systemctl stop dcos-mesos-slave</p>\n  \n  <p>rm -f /var/lib/mesos/slave/meta/\u00adslaves/latest</p>\n  \n  <p>systemctl start dcos-mesos-slave</p>\n</blockquote>\n\n<p>This means essentially I have to restart the service in the slave. </p>\n\n<p>And the slave is down for at least 1 hour, </p>\n\n<p>Is there any other way achieve this?</p>\n", "is_answered": false, "tags": ["mesos", "marathon", "mesosphere", "dcos"], "title": "how to change the DCOS attributes without restarting slave?", "last_activity_date": 1493460843, "answer_count": 1, "creation_date": 1488087441, "score": 0, "link": "https://stackoverflow.com/questions/42465131/how-to-change-the-dcos-attributes-without-restarting-slave", "answers": [{"body": "<p>As variant we are using some hack, we create /var/lib/dcos/mesos-slave-common file and \"froze\" it by changing access right, like:</p>\n\n<pre><code>echo \"MESOS_ATTRIBUTES=TYPE:DB;DB_TYPE:MONGO;\" | sudo tee /var/lib/dcos/mesos-slave-common\nsudo chmod -w /var/lib/dcos/mesos-slave-common\n# And after that you can execute node installation. Ugly, but that is working :) \nsudo dcos_install.sh slave \n</code></pre>\n", "answer_id": 43694364, "last_activity_date": 1493460843, "creation_date": 1493460843, "score": 0, "owner": {"user_id": 2210612, "profile_image": "https://i.stack.imgur.com/lr42r.jpg?s=128&g=1", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/2210612/vasyaod", "display_name": "vasyaod"}, "is_accepted": false, "question_id": 42465131}], "owner": {"user_id": 1124447, "profile_image": "https://www.gravatar.com/avatar/38565246d552f18c291145ff05c373d0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 522, "link": "https://stackoverflow.com/users/1124447/vimal-prakash", "accept_rate": 48, "display_name": "vimal prakash"}, "view_count": 357, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 42465131}{"body": "<p>Recently I've discovered such a thing as a Apache Mesos.</p>\n\n<p>It all looks amazingly in all that demos and examples. I could easily imagine how one would run for stateless jobs - that fits to the whole idea naturally.</p>\n\n<p>Bot how to deal with long running jobs that are stateful?</p>\n\n<p>Say, I have a cluster that consists of N machines (and that is scheduled via Marathon). And I want to run a postgresql server there.</p>\n\n<p>That's it - at first I don't even want it to be highly available, but just simply a single job (actually Dockerized) that hosts a postgresql server.</p>\n\n<p>1- How would one organize it? Constraint a server to a particular cluster node? Use some distributed FS?</p>\n\n<p>2- DRBD, MooseFS, GlusterFS, NFS, CephFS, which one of those play well with Mesos and services like postgres? (I'm thinking here on the possibility that Mesos/marathon could relocate the service if goes down)</p>\n\n<p>3- Please tell if my approach is wrong in terms of philosophy (DFS for data servers and some kind of switchover for servers like postgres on the top of Mesos)</p>\n\n<p><sub><sup>Question largely copied from <a href=\"https://softwareengineering.stackexchange.com/questions/247068/persistent-storage-for-apache-mesos\">Persistent storage for Apache Mesos</a>, asked by <a href=\"https://softwareengineering.stackexchange.com/users/18348/zerkms\">zerkms</a> on <a href=\"https://softwareengineering.stackexchange.com/\">Programmers Stack Exchange</a>.</sup></sub></p>\n", "is_answered": true, "title": "Persistent storage for Apache Mesos", "last_edit_date": 1491982281, "tags": ["postgresql", "distributed-computing", "mesos", "mesosphere"], "view_count": 7589, "accepted_answer_id": 28493909, "last_activity_date": 1436811731, "answers": [{"body": "<p>Excellent question. Here are a few upcoming features in Mesos to improve support for stateful services, and corresponding current workarounds.</p>\n\n<ol>\n<li><a href=\"https://issues.apache.org/jira/browse/MESOS-1554\">Persistent volumes</a> (0.23): When launching a task, you can create a volume that exists outside of the task's sandbox and will persist on the node even after the task dies/completes. When the task exits, its resources -- including the persistent volume --  can be offered back to the framework, so that the framework can launch the same task again, launch a recovery task, or launch a new task that consumes the previous task's output as its input.\n\n<ul>\n<li>Current workaround: Persist your state in some known location outside the sandbox, and have your tasks try to recover it manually. Maybe persist it in a distributed filesystem/database, so that it can be accessed from any node.</li>\n</ul></li>\n<li><a href=\"https://issues.apache.org/jira/browse/MESOS-1587\">Disk</a> <a href=\"https://issues.apache.org/jira/browse/MESOS-1588\">Isolation</a> (0.22): Enforce disk quota limits on sandboxes as well as persistent volumes. This ensures that your storage-heavy framework won't be able to clog up the disk and prevent other tasks from running.\n\n<ul>\n<li>Current workaround: Monitor disk usage out of band, and run periodic cleanup jobs.</li>\n</ul></li>\n<li><a href=\"https://issues.apache.org/jira/browse/MESOS-2018\">Dynamic Reservations</a> (0.23): Upon launching a task, you can reserve the resources your task uses (including persistent volumes) to guarantee that they are offered back to you upon task exit, instead of going to whichever framework is furthest below its fair share.\n\n<ul>\n<li>Current workaround: Use the slave's <code>--resources</code> flag to statically reserve resources for your framework upon slave startup.</li>\n</ul></li>\n</ol>\n\n<p>As for your specific use case and questions:</p>\n\n<p>1a) <em>How would one organize it?</em> You could do this with Marathon, perhaps creating a separate Marathon instance for your stateful services, so that you can create static reservations for the 'stateful' role, such that only the stateful Marathon will be guaranteed those resources.</p>\n\n<p>1b) <em>Constraint a server to a particular cluster node?</em> You can do this easily in Marathon, constraining an application to a specific hostname, or any node with a specific attribute value (e.g. NFS_Access=true). See <a href=\"https://mesosphere.github.io/marathon/docs/constraints.html\">Marathon Constraints</a>. If you only wanted to run your tasks on a specific set of nodes, you would only need to create the static reservations on those nodes. And if you need discoverability of those nodes, you should check out <a href=\"https://github.com/mesosphere/mesos-dns\">Mesos-DNS</a> and/or <a href=\"https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html\">Marathon's HAProxy integration</a>.</p>\n\n<p>1c) <em>Use some distributed FS?</em> The data replication provided by many distributed filesystems would guarantee that your data can survive the failure of any single node. Persisting to a DFS would also provide more flexibility in where you can schedule your tasks, although at the cost of the difference in latency between network and local disk. Mesos has built-in support for fetching binaries from HDFS uris, and many customers use HDFS for passing executor binaries, config files, and input data to the slaves where their tasks will run.</p>\n\n<p>2) <em>DRBD, MooseFS, GlusterFS, NFS, CephFS?</em> I've heard of customers using CephFS, HDFS, and MapRFS with Mesos. NFS would seem an easy fit too. It really doesn't matter to Mesos what you use as long as your task knows how to access it from whatever node where it's placed. </p>\n\n<p>Hope that helps!</p>\n", "answer_id": 28493909, "last_activity_date": 1436811731, "creation_date": 1423809698, "score": 43, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": true, "last_edit_date": 1436811731, "question_id": 28368751}], "score": 32, "link": "https://stackoverflow.com/questions/28368751/persistent-storage-for-apache-mesos", "answer_count": 1, "owner": {"user_id": 829928, "profile_image": "https://www.gravatar.com/avatar/8f2a2dbbd68def108e07d81b32f1df53?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1334, "link": "https://stackoverflow.com/users/829928/carlos-castellanos", "accept_rate": 83, "display_name": "Carlos Castellanos"}, "creation_date": 1423235379, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 28368751}{"body": "<p>I would like to write and run a Mesos framework with Python, so I need mesos.native module.</p>\n\n<p>On Ubuntu:</p>\n\n<p>I can build mesos from source code. I tried to easy_install all the generated egg files but none of them made it possible for Python to import mesos.native.</p>\n\n<p>I also tried to download the egg from <a href=\"http://downloads.mesosphere.io/master/ubuntu/14.04/mesos-0.20.1-py2.7-linux-x86_64.egg\" rel=\"nofollow\">http://downloads.mesosphere.io/master/ubuntu/14.04/mesos-0.20.1-py2.7-linux-x86_64.egg</a> and easy_install it, which didn't work as well.</p>\n\n<p>On Max OS:</p>\n\n<p>Got some problem building the mesos source code because of <a href=\"https://issues.apache.org/jira/browse/MESOS-799\" rel=\"nofollow\">the issue</a>. So I am wondering whether there is an easy way to install the Python module without building the source code.</p>\n\n<p>BTW, why don't they make the mesos.native pip-installable like mesos.interface?</p>\n", "is_answered": true, "title": "How to install mesos.native python module in Mac OS and Ubuntu", "tags": ["python", "mesos", "mesosphere"], "last_activity_date": 1471846429, "accepted_answer_id": 39072413, "creation_date": 1471820243, "answers": [{"body": "<p>Problem solved: <a href=\"https://github.com/RobinDong/mesos-python-examples/blob/master/calculate_pi/pi_run\" rel=\"nofollow\">https://github.com/RobinDong/mesos-python-examples/blob/master/calculate_pi/pi_run</a></p>\n\n<p>I just need to set PYTHONPATH as that in the file and run python. Mesos.native can be successfully loaded.</p>\n", "answer_id": 39072413, "last_activity_date": 1471846429, "creation_date": 1471846429, "score": 0, "owner": {"user_id": 2595935, "profile_image": "https://www.gravatar.com/avatar/a22d69896720e425ec5b29d1f466c998?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1377, "link": "https://stackoverflow.com/users/2595935/fake", "accept_rate": 92, "display_name": "Fake"}, "is_accepted": true, "question_id": 39069553}], "score": 0, "link": "https://stackoverflow.com/questions/39069553/how-to-install-mesos-native-python-module-in-mac-os-and-ubuntu", "answer_count": 1, "owner": {"user_id": 2595935, "profile_image": "https://www.gravatar.com/avatar/a22d69896720e425ec5b29d1f466c998?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1377, "link": "https://stackoverflow.com/users/2595935/fake", "accept_rate": 92, "display_name": "Fake"}, "view_count": 368, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39069553}{"body": "<p>I'm running a jenkins server on my DC/OS, and also got a private registry in the same DC. </p>\n\n<p>the private registry does not have any ssl certificate and to push images from my mac I used the following command</p>\n\n<blockquote>\n  <p>ocker-machine ssh default \"echo $'EXTRA_ARGS=\\\"--insecure-registry \\\"' | sudo tee -a /var/lib/boot2docker/profile &amp;&amp; sudo /etc/init.d/docker restart\"</p>\n</blockquote>\n\n<p>so it worked fine.</p>\n\n<p>on jenkins I tried to set the DOCKER_OPTS see <a href=\"https://docs.docker.com/registry/insecure/\" rel=\"nofollow noreferrer\">https://docs.docker.com/registry/insecure/</a></p>\n\n<p>but then I figured that the build is actually running on an agent, so how do I configure the jenkins worker to trust my private registry?</p>\n", "is_answered": true, "title": "Jenkins issue with docker push to private repo", "tags": ["jenkins", "docker-registry", "dcos"], "last_activity_date": 1478713246, "accepted_answer_id": 40494534, "creation_date": 1478601418, "answers": [{"body": "<p>If you installed the Jenkins from the Mesosphere Universe, then the default Jenkins agent container uses docker-in-docker. </p>\n\n<p>See the DC/OS Jenkins service guide for how to configure docker run parameters to add environment variables: <a href=\"https://docs.mesosphere.com/1.8/usage/service-guides/jenkins/advanced-configuration/\" rel=\"nofollow noreferrer\">https://docs.mesosphere.com/1.8/usage/service-guides/jenkins/advanced-configuration/</a></p>\n", "answer_id": 40494534, "last_activity_date": 1478713246, "creation_date": 1478631708, "score": 1, "owner": {"user_id": 760185, "profile_image": "https://i.stack.imgur.com/5227F.jpg?s=128&g=1", "user_type": "registered", "reputation": 1733, "link": "https://stackoverflow.com/users/760185/karlkfi", "display_name": "KarlKFI"}, "is_accepted": true, "last_edit_date": 1478713246, "question_id": 40484729}], "score": 1, "link": "https://stackoverflow.com/questions/40484729/jenkins-issue-with-docker-push-to-private-repo", "answer_count": 1, "owner": {"user_id": 67505, "profile_image": "https://www.gravatar.com/avatar/094c0ec476b95ed7619d6a4cb918da78?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 9919, "link": "https://stackoverflow.com/users/67505/chen-kinnrot", "accept_rate": 71, "display_name": "Chen Kinnrot"}, "view_count": 239, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40484729}{"body": "<p>Unfortunately I face problems with deployment to Marathon.</p>\n\n<p>I do <code>curl -X PUT -H 'Content-Type: application/json' -i http://marathon_url/v2/apps/lookout -d@lookout.json</code></p>\n\n<p>And receive response:</p>\n\n<pre><code>HTTP/1.1 100 Continue\n\nHTTP/1.1 200 OK\nConnection: close\nServer: Jetty(8.y.z-SNAPSHOT)\n</code></pre>\n\n<p>That's it. No <code>deploymentId</code> returned in response.\nSometimes it needs to do around 10 <code>curl</code> to get an app deployed.</p>\n\n<p>Sometimes I receive <code>deploymentId</code>, but anyway nothing changed in Marathon UI.</p>\n\n<p><strong>Marathon version: 0.9.2</strong></p>\n\n<p>Does anybody have the same problem?</p>\n", "is_answered": true, "tags": ["deployment", "mesosphere", "marathon"], "title": "Marathon doesn't deploy an app via PUT /v2/apps/{appId}", "last_activity_date": 1441457781, "answer_count": 1, "creation_date": 1441199548, "score": 0, "link": "https://stackoverflow.com/questions/32354177/marathon-doesnt-deploy-an-app-via-put-v2-apps-appid", "answers": [{"body": "<p><code>PUT</code> is for changing the config of an already deployed app. Use <a href=\"https://mesosphere.github.io/marathon/docs/rest-api.html#post-v2-apps\" rel=\"nofollow\">POST</a> to deploy an app.</p>\n", "answer_id": 32413308, "last_activity_date": 1441457781, "creation_date": 1441457781, "score": 1, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 32354177}], "owner": {"user_id": 1023876, "profile_image": "https://www.gravatar.com/avatar/e0135ac69dd8ad56c9cdea4c1f742bb5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 232, "link": "https://stackoverflow.com/users/1023876/pavel", "accept_rate": 60, "display_name": "Pavel"}, "view_count": 177, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32354177}{"body": "<p>i would like to understand the concept of weights for different roles in mesos and where to specify that. I have used --weights parameter while starting the mesos-master. But it didn't work. I want to know like if for a particular role, if we give weight as 2.0, how does the resource allocation change compared to default weight of 1. </p>\n", "is_answered": false, "tags": ["mesos", "mesosphere"], "last_edit_date": 1484856186, "title": "how to specify weights for different roles in apache mesos", "last_activity_date": 1484856186, "answer_count": 0, "creation_date": 1484855299, "score": 0, "link": "https://stackoverflow.com/questions/41750403/how-to-specify-weights-for-different-roles-in-apache-mesos", "owner": {"user_id": 5003970, "profile_image": "https://www.gravatar.com/avatar/f644389a1ef05582c6b26343c2aa48f8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 105, "link": "https://stackoverflow.com/users/5003970/midhun-mathew-sunny", "accept_rate": 65, "display_name": "Midhun Mathew Sunny"}, "view_count": 43, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 4}, "question_id": 41750403}{"is_answered": false, "tags": ["apache-kafka"], "last_edit_date": 1482189377, "title": "DCos Kafka Certificate error", "last_activity_date": 1482189377, "answer_count": 0, "creation_date": 1482187864, "score": 1, "link": "https://stackoverflow.com/questions/41232279/dcos-kafka-certificate-error", "owner": {"user_id": 7318455, "profile_image": "https://www.gravatar.com/avatar/029d2ce62878efc5cd5ddedcc3fb7d43?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/7318455/mahipal", "display_name": "mahipal"}, "view_count": 8, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41232279}{"body": "<p>I am unable to run rabbitmq using marathon/mesos framework. I have tried it with rabbitmq images available in docker hub as well as custom build rabbitmmq docker image. In the mesos slave log I see the following error:</p>\n\n<p>E0222 12:38:37.225500 15984 slave.cpp:2344] Failed to update resources for container c02b0067-89c1-4fc1-80b0-0f653b909777 of executor rabbitmq.9ebfc76f-ba61-11e4-85c9-56847afe9799 running task rabbitmq.9ebfc76f-ba61-11e4-85c9-56847afe9799 on status update for terminal task, destroying container: Failed to determine cgroup for the 'cpu' subsystem: Failed to read /proc/13197/cgroup: Failed to open file '/proc/13197/cgroup': No such file or directory</p>\n\n<p>On googling I could find one hit as follows\n<a href=\"https://github.com/mesosphere/marathon/issues/632\" rel=\"nofollow\">https://github.com/mesosphere/marathon/issues/632</a></p>\n\n<p>Not sure if this is the issue even I am facing. Anyone tried running rabbitmq using marathon/mesos/docker?</p>\n", "is_answered": true, "tags": ["docker", "mesos", "mesosphere", "marathon"], "title": "Unable to run rabbitmq using marathon mesos", "last_activity_date": 1444414829, "answer_count": 2, "creation_date": 1424589806, "score": 0, "link": "https://stackoverflow.com/questions/28655516/unable-to-run-rabbitmq-using-marathon-mesos", "answers": [{"body": "<p>Looks like the process went away (likely crashed) before the container was set up. You should check <code>stdout</code> and <code>stderr</code> to see what happened, and fix the root issue.</p>\n", "answer_id": 29088184, "last_activity_date": 1426545263, "creation_date": 1426545263, "score": 2, "owner": {"user_id": 4488486, "profile_image": "https://lh5.googleusercontent.com/-B_euLGuvgb4/AAAAAAAAAAI/AAAAAAAAUMI/XbYweAvxML0/photo.jpg?sz=128", "user_type": "registered", "reputation": 169, "link": "https://stackoverflow.com/users/4488486/brenden-matthews", "display_name": "Brenden Matthews"}, "is_accepted": false, "question_id": 28655516}, {"body": "<p>\"cmd\": \"\", is the like'y culprit. I'd look at couchbase docker containers for a few clues on how to get it working. </p>\n", "answer_id": 33044823, "last_activity_date": 1444414829, "creation_date": 1444414829, "score": -1, "owner": {"user_id": 5428851, "profile_image": "https://www.gravatar.com/avatar/ccc6857f1603987d3ebb0985b3e60a7c?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1, "link": "https://stackoverflow.com/users/5428851/michaeld", "display_name": "Michaeld"}, "is_accepted": false, "question_id": 28655516}], "owner": {"user_id": 1507003, "profile_image": "https://www.gravatar.com/avatar/df818458a14756eb70203e20b7295524?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 443, "link": "https://stackoverflow.com/users/1507003/ashishjain", "accept_rate": 67, "display_name": "ashishjain"}, "view_count": 671, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 28655516}{"body": "<p>I recently enabled cgroups/cpu isolation on my Mesos cluster. I've been running some stress tests (like starting some cpu-bound programs and seeing if a cpu-burst program can jump in and claim its cpu allocation), and it looks like Mesos is slicing the cpu correctly. However, I've seen some posts claiming it's dangerous for cpu-bound programs to take all idle cpu.</p>\n\n<p>I'm trying to understand exactly what the dangers of soft-limiting cpu are. Is the problem that a critical task may not be able use its full cpu allocation immediately? What are some situations that soft-limits on cpu would cause problems? The alternative to my current setup is CFS scheduling, but my programs tend to be idle most of the time.</p>\n\n<p>I use Marathon and Chronos (latest stable versions) to schedule tasks on my Mesos cluster (also the latest stable version). </p>\n", "is_answered": false, "tags": ["cpu", "mesos", "isolation", "dcos"], "title": "Mesos cpu soft-limit dangers?", "last_activity_date": 1483567249, "answer_count": 0, "creation_date": 1483567249, "score": 1, "link": "https://stackoverflow.com/questions/41473954/mesos-cpu-soft-limit-dangers", "owner": {"user_id": 6731830, "profile_image": "https://www.gravatar.com/avatar/a7e3da0bb36caf8f6ad1a87e3f19ce00?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 6, "link": "https://stackoverflow.com/users/6731830/distuser11", "display_name": "distUser11"}, "view_count": 36, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41473954}{"body": "<pre><code>{\n\"id\": \"sparkslave\",\n\"instances\": 1,\n\"cpus\": 1,\n\"mem\": 512,\n\"constraints\": [[\"hostname\", \"UNIQUE\"]],\n\"cmd\": \"/root/spark-1.5.0/sbin/start-slave.sh spark://sparkmaster.marathon.mesos:7077 &amp;&amp; tail -f /var/log/messages\"\n}\n</code></pre>\n\n<p>shouldn't sparkmaster.marathon.mesos resolve and connect to the IP where sparkmaster is running?</p>\n\n<p>sparkmaster is another application being run through Marathon.</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "marathon"], "last_edit_date": 1466284159, "title": "Cant connect to an app using Mesos-DNS", "last_activity_date": 1466486755, "answer_count": 1, "creation_date": 1444040039, "score": 0, "link": "https://stackoverflow.com/questions/32946086/cant-connect-to-an-app-using-mesos-dns", "answers": [{"body": "<p>When using <code>mesos-dns</code>, you should add your <code>mesos-dns</code> host ip to <code>/etc/resolv.conf</code>, so that your dns request can be handled by <code>mesos-dns</code></p>\n", "answer_id": 37935953, "last_activity_date": 1466486755, "creation_date": 1466485428, "score": 0, "owner": {"user_id": 6318890, "profile_image": "https://i.stack.imgur.com/PmQ25.jpg?s=128&g=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/6318890/night", "display_name": "Night"}, "is_accepted": false, "last_edit_date": 1466486755, "question_id": 32946086}], "owner": {"user_id": 3690397, "profile_image": "https://i.stack.imgur.com/Pe9bM.jpg?s=128&g=1", "user_type": "registered", "reputation": 69, "link": "https://stackoverflow.com/users/3690397/208rishabh", "accept_rate": 17, "display_name": "208rishabh"}, "view_count": 50, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 32946086}{"body": "<p>I created a DCOS setup on AWS using <a href=\"https://s3.amazonaws.com/downloads.mesosphere.io/dcos/stable/cloudformation/single-master.cloudformation.json\" rel=\"nofollow\" title=\"default config\">default config</a></p>\n\n<p>I add two kafka brokers using CLI </p>\n\n<pre><code>(DCOS) PS C:\\DCOS&gt; dcos kafka broker list\nbrokers:\n  id: 1\n  active: false\n  state: stopped\n  resources: cpus:2.00, mem:8192, heap:1024, port:auto\n  failover: delay:1m, max-delay:10m\n  stickiness: period:10m, expires:2016-03-22 15:58:51-04\n</code></pre>\n\n<p>When I start broker I see that offer from master was declined</p>\n\n<pre><code>I0322 20:56:38.954476  1316 master.cpp:5350] Sending 2 offers to framework d8c03032-ebab-4c88-80cb-e2de92e3c4c4-0001 (kafka) at scheduler-fff6da19-e31e-4518-864e-2dfcdc31a5d2@10.0.3.104:53766\nI0322 20:56:38.966846  1320 master.cpp:3673] Processing DECLINE call for offers: [ d8c03032-ebab-4c88-80cb-e2de92e3c4c4-O7389 ] for framework d8c03032-ebab-4c88-80cb-e2de92e3c4c4-0001 (kafka) at scheduler-fff6da19-e31e-4518-864e-2dfcdc31a5d2@10.0.3.104:53766\nI0322 20:56:38.967591  1319 master.cpp:3673] Processing DECLINE call for offers: [ d8c03032-ebab-4c88-80cb-e2de92e3c4c4-O7390 ] for framework d8c03032-ebab-4c88-80cb-e2de92e3c4c4-0001 (kafka) at scheduler-fff6da19-e31e-4518-864e-2dfcdc31a5d2@10.0.3.104:53766\nI0322 20:56:40.043771  1318 http.cpp:512] HTTP GET for /master/state-summary from 10.0.6.116:60000 with User-Agent='python-requests/2.6.0 CPython/3.4.2 Linux/4.1.7-coreos-r1'\n</code></pre>\n\n<p>I'm not able to find any relevant logs on the slaves to see what is going on.\n/var/log/mesos has some files with no relevant info. As per the doc I should see syslogs in /var/log/messages but I don't see that file. The default config provisions CoreOS. I tried <strong>journalctl</strong> command but didn't find anything there too. Not sure how to debug this.</p>\n", "is_answered": false, "tags": ["amazon-web-services", "apache-kafka", "mesos", "mesosphere", "dcos"], "last_edit_date": 1458724070, "title": "Mesos DCOS offer declined on AWS", "last_activity_date": 1458724070, "answer_count": 0, "creation_date": 1458681030, "score": 2, "link": "https://stackoverflow.com/questions/36165276/mesos-dcos-offer-declined-on-aws", "owner": {"user_id": 3349257, "profile_image": "https://www.gravatar.com/avatar/f37b803a3616d628a6ec3ff4e646cf70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 287, "link": "https://stackoverflow.com/users/3349257/cheeko", "accept_rate": 78, "display_name": "Cheeko"}, "view_count": 263, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 36165276}{"body": "<p>I have 6 machines mesos cluster (3 masters and 3 slaves), I acces to mesos User interface 172.16.8.211:5050 and it works correctly and redirect to the leader if it is not. Then If I access to marathon User interface 172.16.8.211:8080 it works correctly. Summing before configuring and executing the consul-cluster marathon works well.</p>\n\n<p>My problem is when I configure and run a consul cluster with 3 servers that are the mesos masters and 3 clients that are the mesos slaves. If I execute consul members it is fine, all the members alive and working together.\nBut now if I try to access to marathon User interface I can't, and I access to mesos User interface and I go to 'Frameworks' and does not appear marathon Framework. </p>\n\n<pre><code>ikerlan@client3:~$ consul members\nNode     Address            Status  Type    Build  Protocol  DC\nclient3  172.16.8.216:8301  alive   client  0.5.2  2         nyc2\nclient2  172.16.8.215:8301  alive   client  0.5.2  2         nyc2\nserver2  172.16.8.212:8301  alive   server  0.5.2  2         nyc2\nserver3  172.16.8.213:8301  alive   server  0.5.2  2         nyc2\nclient1  172.16.8.214:8301  alive   client  0.5.2  2         nyc2\nserver1  172.16.8.211:8301  alive   server  0.5.2  2         nyc2\n</code></pre>\n\n<p>In Slaves tab of mesos I could see the next:\n<a href=\"https://i.stack.imgur.com/WzJA6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WzJA6.png\" alt=\"Mesos-Slave-Tab\"></a></p>\n\n<p>-Mesos version: 0.27.0\n-Marathon version: 0.15.1</p>\n\n<p>I have the next file logs, where would appear something related with this issue?</p>\n\n<p><a href=\"https://i.stack.imgur.com/7PaWW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7PaWW.png\" alt=\"Mesos logs image\"></a></p>\n\n<p>What could be the problem?</p>\n", "is_answered": true, "title": "Marathon stop working when consul starts", "last_edit_date": 1455289312, "tags": ["mesos", "mesosphere", "marathon", "consul"], "view_count": 99, "accepted_answer_id": 35411618, "last_activity_date": 1473856877, "answers": [{"body": "<p><strong>Solution:</strong></p>\n\n<p>I have see in the marathon logs <code>'/var/log/syslog'</code> that the problem is a problem of DNS. So I try to add the IPs of the other hosts of the cluster to the file  <code>/etc/hosts</code>. And it resolv the problem, now it works perfectly.</p>\n", "answer_id": 35411618, "last_activity_date": 1455545568, "creation_date": 1455545568, "score": 1, "owner": {"user_id": 5621509, "profile_image": "https://www.gravatar.com/avatar/2ade806eb7a16154fb3d627a687383d4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 662, "link": "https://stackoverflow.com/users/5621509/asier-gomez", "accept_rate": 98, "display_name": "Asier Gomez"}, "is_accepted": true, "question_id": 35364782}, {"body": "<p>You can add all the cluster hosts to the zookeeper config file, it would work</p>\n", "answer_id": 39490712, "last_activity_date": 1473856877, "creation_date": 1473856877, "score": 1, "owner": {"user_id": 6830900, "profile_image": "https://graph.facebook.com/1251128013/picture?type=large", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6830900/asier-gomez-akasuso", "display_name": "Asier Gomez Akasuso"}, "is_accepted": false, "question_id": 35364782}], "score": 3, "link": "https://stackoverflow.com/questions/35364782/marathon-stop-working-when-consul-starts", "answer_count": 2, "owner": {"user_id": 5621509, "profile_image": "https://www.gravatar.com/avatar/2ade806eb7a16154fb3d627a687383d4?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 662, "link": "https://stackoverflow.com/users/5621509/asier-gomez", "accept_rate": 98, "display_name": "Asier Gomez"}, "creation_date": 1455286601, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 35364782}{"body": "<p>I am running cassandra on mesos. Here I have two tasks running on mesos agent, one is cassandra task itself and second is restore data task. When I directly ssh into mesos agent and run restore data command (sstableloader), it completes within 2 minutes but when same command is invoked in restore data task container (mesos containerizer), it takes about 8 hours. I have allocated 12 cpus, 4 gb of ram and disk to that task out. I need to understand where is this containerizer property creating a bottleneck and how can I resolve it.</p>\n\n<p>I have set stream throughput and compaction throughput 300 MB/s.</p>\n\n<p>One theory, I have is the port restore task is using to communicate with cassandra task may be an issue.</p>\n", "is_answered": false, "tags": ["cassandra", "mesos", "mesosphere"], "title": "mesos containerizer task are too slow", "last_activity_date": 1474391407, "answer_count": 0, "creation_date": 1474391407, "score": 0, "link": "https://stackoverflow.com/questions/39600048/mesos-containerizer-task-are-too-slow", "owner": {"user_id": 1726183, "profile_image": "https://www.gravatar.com/avatar/e052c9c68ad2978015d389b4c00513f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 674, "link": "https://stackoverflow.com/users/1726183/varun-gupta", "accept_rate": 55, "display_name": "Varun Gupta"}, "view_count": 64, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 39600048}{"is_answered": false, "tags": ["azure", "cassandra", "dcos"], "last_edit_date": 1484072614, "title": "Cassandra deployment fails on Azure DCOS", "last_activity_date": 1484146802, "answer_count": 0, "creation_date": 1482311419, "score": 2, "link": "https://stackoverflow.com/questions/41258931/cassandra-deployment-fails-on-azure-dcos", "owner": {"user_id": 6670354, "profile_image": "https://www.gravatar.com/avatar/77a39eb5e65cfa7eb814b040a01b86a3?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 11, "link": "https://stackoverflow.com/users/6670354/zarinius", "display_name": "zarinius"}, "view_count": 112, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 2}, "question_id": 41258931}{"body": "<p>Running Spark 1.4.1 on a Mesos cluster using GCE.  I can get Spark up and running, but cannot access the UI for either Mesos or Spark.</p>\n\n<p>I have tried:</p>\n\n<ul>\n<li>MesosMasterExternalIP:4040</li>\n<li>MesosMasterExternalIP:5050</li>\n<li>MesosMasterExternalIP:7070</li>\n<li>MesosMasterExternalIP:7077</li>\n</ul>\n\n<p>I also tried stopping Spark, ran\n     \"ps ax | grep spark-shell\" \nand killed all processes, restarted Spark.  No success.</p>\n\n<p>I was trying to follow the instructions in <a href=\"http://ceteri.blogspot.com/2014/09/spark-atop-mesos-on-google-cloud.html\" rel=\"nofollow\">Paco Nathan's post</a> Section 5, but keep getting a \"This webpage is not available\" error when ever I try to get to the UI via my laptop browser. (Chrome on ubuntu 14.04)</p>\n\n<p>Any suggestions on how to proceed?</p>\n", "is_answered": false, "tags": ["apache-spark", "google-compute-engine", "google-cloud-platform", "mesosphere"], "last_edit_date": 1441028386, "title": "How to access GCE Mesos Spark UI", "last_activity_date": 1441028386, "answer_count": 0, "creation_date": 1441016948, "score": 0, "link": "https://stackoverflow.com/questions/32309172/how-to-access-gce-mesos-spark-ui", "owner": {"user_id": 1955720, "profile_image": "https://www.gravatar.com/avatar/6af8482c7db54924a35d1148515b964f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 374, "link": "https://stackoverflow.com/users/1955720/thom-rogers", "accept_rate": 56, "display_name": "Thom Rogers"}, "view_count": 74, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32309172}{"body": "<p>I'm using dcos installed via Azure ACS and installed hdfs and spark via dcos tool with default options.</p>\n\n<p>Creating a SparkStreamingContext gives:</p>\n\n<pre><code>16/07/22 01:51:04 WARN DFSUtil: Namenode for hdfs remains unresolved for ID nn1. Check your hdfs-site.xml file to ensure namenodes are configured properly. \n16/07/22 01:51:04 WARN DFSUtil: Namenode for hdfs remains unresolved for ID nn2. Check your hdfs-site.xml file to ensure namenodes are configured properly.\nException in thread \"main\" java.lang.IllegalArgumentException:\njava.net.UnknownHostException: namenode1.hdfs.mesos\n</code></pre>\n\n<p>I expect I have to redeploy the spark package with <code>dcos package install</code> with \u2013options= but can't figure out what the <code>hdfs.config-url</code> should be. The <a href=\"https://docs.mesosphere.com/1.7/usage/service-guides/spark/install/#hdfs\" rel=\"nofollow\">https://docs.mesosphere.com/1.7/usage/service-guides/spark/install/#hdfs</a> docs seem out of date.</p>\n", "is_answered": true, "title": "new Spark StreamingContext failes with hdfs errors", "tags": ["apache-spark", "hdfs", "mesosphere", "dcos"], "last_activity_date": 1470401475, "accepted_answer_id": 38774903, "creation_date": 1469220962, "answers": [{"body": "<p>Yes, it is out of date.  We'll fix that.</p>\n\n<p>DC/OS HDFS now serves its config on <a href=\"http://hdfs.marathon.mesos:[port]/v1/connect\" rel=\"nofollow\">http://hdfs.marathon.mesos:[port]/v1/connect</a></p>\n", "answer_id": 38774903, "last_activity_date": 1470335528, "creation_date": 1470335528, "score": 1, "owner": {"user_id": 514187, "profile_image": "https://www.gravatar.com/avatar/ae96ef1fd1f1d8e7470df5bbdcf62411?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 328, "link": "https://stackoverflow.com/users/514187/michael-gummelt", "accept_rate": 14, "display_name": "Michael Gummelt"}, "is_accepted": true, "question_id": 38535095}], "score": 0, "link": "https://stackoverflow.com/questions/38535095/new-spark-streamingcontext-failes-with-hdfs-errors", "answer_count": 1, "owner": {"user_id": 7223, "profile_image": "https://www.gravatar.com/avatar/3ba7e831b71e59f6904d09a47f1973b6?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 663, "link": "https://stackoverflow.com/users/7223/navicore", "accept_rate": 87, "display_name": "navicore"}, "view_count": 89, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 38535095}{"body": "<p>I'm trying to setup multiple different websites on a single cluster of servers (DC/OS). These servers are load balanced via ELB and the websites are spread out across the servers (each website has it's own port that stays the same on all the servers). What I want to do is something like:</p>\n\n<pre><code>example.com -&gt; [elb public dns]:8080  \nexample2.com -&gt; [elb public dns]: 9000\n</code></pre>\n\n<p>I found a way to do this via multiple application ELBs. I can essentially listen on port 80 on multiple different ELBs, each ELB for a specific website. These ELBs are then directed to the proper \"target group\". However, I'm not sure if this is a good solution since I need to pay for multiple ELBs just for routing my requests from DNS -> IP:PORT. Is there a better way to do this on AWS?</p>\n", "is_answered": true, "title": "How to go from a DNS name to a IP:PORT on AWS?", "last_edit_date": 1475829690, "tags": ["amazon-web-services", "dns", "port", "dcos"], "view_count": 63, "accepted_answer_id": 39913032, "last_activity_date": 1475829690, "answers": [{"body": "<p>Yes, in DC/OS there is Marathon-LB (MLB) available as a Universe package. MLB is a HAProxy-based load balancer that can be configured exactly in the way you need it, see the section 'Virtual hosts' in the <a href=\"https://dcos.io/docs/1.8/usage/service-discovery/marathon-lb/usage/\" rel=\"nofollow\">Marathon-LB docs</a>.</p>\n", "answer_id": 39913032, "last_activity_date": 1475829656, "creation_date": 1475829656, "score": 2, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": true, "question_id": 39911355}], "score": 1, "link": "https://stackoverflow.com/questions/39911355/how-to-go-from-a-dns-name-to-a-ipport-on-aws", "answer_count": 1, "owner": {"user_id": 3457620, "profile_image": "https://www.gravatar.com/avatar/fffca4dadd9fde38ccac76d578f6c781?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 160, "link": "https://stackoverflow.com/users/3457620/asuna", "accept_rate": 79, "display_name": "asuna"}, "creation_date": 1475823912, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 39911355}{"body": "<p>I missed to update the cluster name (cluster_name) in my boot node's genconf/config.yaml before deploying the DC/OS cluster.  I was wondering if there's a configuration/properties file in the nodes (or using dcos-cli or in etcd) that I need to change to update the cluster name string (that appears on the DC/OS UI).  'appreciate any help.</p>\n\n<pre><code>version: DC/OS 1.8 \nnodes running on CoreOS \nsize: 3 masters and 11 agents\n</code></pre>\n", "is_answered": false, "tags": ["mesosphere", "dcos"], "title": "DC/OS: modifying Cluster name post installation", "last_activity_date": 1500852737, "answer_count": 1, "creation_date": 1500421788, "score": 1, "link": "https://stackoverflow.com/questions/45178812/dc-os-modifying-cluster-name-post-installation", "answers": [{"body": "<p>The cluster name that appears on the DC/OS interface is extracted from the Mesos cluster name. According to this configuration generation file it's possible to change the name of <a href=\"https://github.com/dcos/dcos/blob/1.8/gen/dcos-config.yaml#L238\" rel=\"nofollow noreferrer\">the environment variable</a>. Obviously you're going to have to restart the Mesos master one by one.</p>\n\n<p><strong>Important note</strong>: I have not had the possibility to test it, if you are in a production environment I highly recommend you not to do.</p>\n", "answer_id": 45270804, "last_activity_date": 1500852737, "creation_date": 1500852737, "score": 0, "owner": {"user_id": 1644234, "profile_image": "https://www.gravatar.com/avatar/fe0024beef236fa12b1ede5091828d43?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 20, "link": "https://stackoverflow.com/users/1644234/jmparraguez", "display_name": "jmparraguez"}, "is_accepted": false, "question_id": 45178812}], "owner": {"user_id": 1476019, "profile_image": "https://www.gravatar.com/avatar/c7eeca9812d07b54a16274113f76abad?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 861, "link": "https://stackoverflow.com/users/1476019/dharmi", "display_name": "Dharmi"}, "view_count": 26, "_params_": {"filter": "_ba", "body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45178812}{"body": "<p>Here is what I am trying to do,</p>\n\n<p>I have deployed my distributed application on Mesos. Mesos provides machine resource management capability. Application Scheduler gets offers depending on allocation policies and availability of resources. Application Scheduler\ndepending on the need of resources for the particular task accepts/rejects offers. </p>\n\n<p>My application task fetches data from data source and stores it such that it could be used by a subsequent task. </p>\n\n<p>Now, next task needs to be run in the same container so that stored data could be used and in some cases, the new connection need to be created or existing connection needs to be used to get more information/data.</p>\n\n<p>An application has a limitation that it could create max 10 connections with the data source. </p>\n\n<p>So, when my scheduler decides where to run next task, I want it to access data location information and availability of connection on that particular node and its state.</p>\n\n<p>To achieve this I need to maintain this information somewhere and connections could also have states like offline, connected, In-use etc. </p>\n\n<p>So, I need to implement distributed state machine to achieve this. \nSo my question is how could we achieve this in Mesos?</p>\n\n<p>Do I have to use Cluster Manager like Apache Helix to handle distributed resources like these using distributed state machines?</p>\n", "is_answered": false, "tags": ["mesos", "mesosphere", "helix"], "last_edit_date": 1491223444, "title": "How do we manage distributed resources like queue, lock, data store along with machine resources using Apache Mesos?", "last_activity_date": 1491223444, "answer_count": 0, "creation_date": 1490855972, "score": 0, "link": "https://stackoverflow.com/questions/43110333/how-do-we-manage-distributed-resources-like-queue-lock-data-store-along-with-m", "owner": {"user_id": 1266150, "profile_image": "https://www.gravatar.com/avatar/7732616c0735b113af792c141346dafc?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 63, "link": "https://stackoverflow.com/users/1266150/amar-gajbhiye", "accept_rate": 75, "display_name": "Amar Gajbhiye"}, "view_count": 66, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 3}, "question_id": 43110333}{"is_answered": true, "tags": ["arangodb", "dcos"], "title": "DCOS unable to install &amp; run ArangoDB", "last_activity_date": 1472799048, "answer_count": 1, "creation_date": 1472735302, "score": 0, "link": "https://stackoverflow.com/questions/39272385/dcos-unable-to-install-run-arangodb", "accepted_answer_id": 39286006, "owner": {"user_id": 2256892, "profile_image": "https://www.gravatar.com/avatar/5f69c301234079ca927fb7a7fcef461f?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 90, "link": "https://stackoverflow.com/users/2256892/keyurm", "accept_rate": 80, "display_name": "KeyurM"}, "view_count": 127, "_params_": {"body": true, "intitle": "dcos", "site": "stackoverflow.com", "comments": "false", "page": 3}, "question_id": 39272385}{"body": "<p>I just investigate DC/OS, I find that DC/OS has three roles:master, slave, slave_public, I want to deploy a cluster which can host  master, slave or slave_public roles on one host, but currently I can't do that. </p>\n\n<p>I want to know that why can't put them on one host when designed. If I do that, could I get some suggestions?</p>\n\n<p>I just have the idea. If I can't do, I'll quit using DCOS, I'll use mesos and marathon.</p>\n\n<p>Is there someone has the idea with me? I look forward to the reply.</p>\n", "is_answered": true, "tags": ["master", "slave", "dcos"], "last_edit_date": 1477433335, "title": "DC/OS has three roles, they are master, slave, slave_public, why can't put them on one host?", "last_activity_date": 1477433335, "answer_count": 2, "creation_date": 1477383888, "score": 1, "link": "https://stackoverflow.com/questions/40234947/dc-os-has-three-roles-they-are-master-slave-slave-public-why-cant-put-them", "answers": [{"body": "<p>This is by design, and things are actually being worked on to re-enforce that an machine is <a href=\"https://github.com/dcos/dcos/pull/303\" rel=\"nofollow\">installed with only one role</a> because things break with more than one.</p>\n\n<p>If you're trying to demo / experiment with DC/OS and you only have one machine, you can use Virtual Machines or Docker to partition that one machine into multiple machines / parts which you can install DC/OS on. <a href=\"https://github.com/dcos/dcos-vagrant\" rel=\"nofollow\">dcos-vagrant</a> and <a href=\"https://github.com/dcos/dcos-docker\" rel=\"nofollow\">dcos-docker</a> can help you there.</p>\n\n<p>As far as installing though, the configuration for each of the three roles is incompatible with one another. The \"master\" role causes a whole bunch of pieces of software to be started / installed on a host (Mesos-DNS, Mesos master, marathon, exhibitor, zookeeper, 3dt, adminrouter, rexray, spartan, navstar among others) which listen on various ports. The \"slave\" role causes a machine to have a mesos-agent (mesos renamed mesos-slave to mesos-agent, hence the disconnect) configured and started on the agent. The mesos-agent is configured to control / most ports greater than 1024 to tasks which are launched by mesos frameworks on the agent. Several of those ports are used by services which are run on masters, resulting in odd conflicts and hard to fix bad behavior.</p>\n\n<p>In the case of running the \"slave\" and \"slave_public\" on the same host, those two conflict more directly, because both of them cause mesos-agent to be run on the host, with slightly different configuration. Both the mesos-agent (the one configured with the \"slave\" role and the one with the \"slave_public\" role are configured to listen on port 5051. Only one of them can use it though, so you end up with one of the agents being non-functional.</p>\n", "answer_id": 40250020, "last_activity_date": 1477430838, "creation_date": 1477430838, "score": 1, "owner": {"user_id": 2803594, "profile_image": "https://www.gravatar.com/avatar/b63e00c0b20b57650d77a1b6beb43ead?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 56, "link": "https://stackoverflow.com/users/2803594/firebird347", "display_name": "Firebird347"}, "is_accepted": false, "question_id": 40234947}, {"body": "<p>DC/OS only supports running a node as either a master or an agent(slave). You are correct that Mesos does not have this limitation. But DC/OS is more than just a Mesos/Marathon. To enable all the additional features of DC/OS there are various components built around Mesos and Marathon. At times these components behave differently whether they are running on a master or an agent and at other times the components that exist on a master may or may not exist on an agent or vice versa. So running a master and an agent on the same node would lead to conflicts/issues. </p>\n\n<p>If you are looking to run a small development setup before scaling the solution out to a bigger distributed system <a href=\"https://github.com/dcos/dcos-vagrant\" rel=\"nofollow\">DC/OS Vagrant</a> might be a good starting point.</p>\n", "answer_id": 40250268, "last_activity_date": 1477431961, "creation_date": 1477431961, "score": 0, "owner": {"user_id": 4851450, "profile_image": "https://www.gravatar.com/avatar/a08b58c81d6fd180debbb083d162c17c?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 46, "link": "https://stackoverflow.com/users/4851450/surdy", "display_name": "surdy"}, "is_accepted": false, "question_id": 40234947}], "owner": {"user_id": 6112290, "profile_image": "https://www.gravatar.com/avatar/d62bd9e40dce93263c8d7cf556026cb8?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/6112290/%e5%bc%a0%e9%a3%9e%e5%bb%ba", "display_name": "\u5f20\u98de\u5efa"}, "view_count": 323, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 6}, "question_id": 40234947}{"body": "<p>We have this scenario.</p>\n\n<p>We have 3/3 master/slave arch for Mesos.</p>\n\n<p>Each sleeve is identical, 4GB RAM and 4 Core CPUs.</p>\n\n<p>We have started 10 marathon Apps with 1core CPU and 1GB RAM. We started the containers, but not utilizing them, as per the system it's saying 97% CPU is free.</p>\n\n<p>Now, we are trying to start an another container with a 3Core CPU and 2GB RAM. </p>\n\n<p>Unfortunately, we are not able to start the container, as per the Mesos logs, it's saying that marathon has declined the offer, but all slave nodes are not doing anything. Marathon apps stayed in Deployment state itself.</p>\n\n<p>If mesos is not able to allocate resources to the marathon app (If containers are not utilizing the resources), then what's the use of Docker integration here.</p>\n\n<p>As per my understanding:</p>\n\n<p>Once an offer is accepted by marathon app, even if docker is not using that resource, mesos is thinking like that resources are already utilizing by the app. But if the container is not utilizing any resources, mesos need to collect the available resources and allocate to next marathon application.</p>\n\n<p>Instead of that once an offer is assigned to marathon App, Mesos is subtracting the allocated resources from the total resources.</p>\n\n<p>We are not fully utilizing the Docker features in Mesos/Marathon.</p>\n\n<p>Let me know any suggestions and answers.</p>\n\n<p>Thank you</p>\n", "is_answered": true, "tags": ["docker", "containers", "mesos", "mesosphere", "marathon"], "last_edit_date": 1440432950, "title": "Limitations in Mesos and Marathon Regarding Docker", "last_activity_date": 1440442965, "answer_count": 2, "creation_date": 1440430770, "score": 0, "link": "https://stackoverflow.com/questions/32186323/limitations-in-mesos-and-marathon-regarding-docker", "answers": [{"body": "<p>Mesos tracks \"allocation\" and not the actual usage. If your app is not doing anything, it doesn't mean it won't do anything in the next moment. That means, if your app requested 1 CPU, this CPU is reserved for the app.</p>\n\n<p>Now, if you don't want to precisely estimate resources your app is using, you may want to look at <a href=\"https://stackoverflow.com/questions/32186323/limitations-in-mesos-and-marathon-regarding-docker\">oversubscription in Mesos</a>. You must keep in mind though, that once oversubscribed resources are requested by the app, for which these resources have been allocated, apps using oversubscribed resources may be terminated.</p>\n", "answer_id": 32189680, "last_activity_date": 1440442614, "creation_date": 1440442614, "score": 2, "owner": {"user_id": 4871583, "profile_image": "https://i.stack.imgur.com/psLys.jpg?s=128&g=1", "user_type": "registered", "reputation": 849, "link": "https://stackoverflow.com/users/4871583/rukletsov", "display_name": "rukletsov"}, "is_accepted": false, "last_edit_date": 1495540358, "question_id": 32186323}, {"body": "<p>Mesos/Marathon actually considers the allocated 10*(1GB + 1CPU), because that is the max your app(s) is allowed to use.\nAnd so yes your understanding is correct. </p>\n\n<p>In my opinion you have at least 2 options</p>\n\n<ol>\n<li>Assign less resources to your tasks.</li>\n<li>There is actually an interesting new feature which seems to fit your use case: <a href=\"https://github.com/apache/mesos/blob/master/docs/oversubscription.md\" rel=\"nofollow\">oversubscription</a> which basically tries to utilize this difference between allocated and actual used resources.</li>\n</ol>\n", "answer_id": 32189791, "last_activity_date": 1440442965, "creation_date": 1440442965, "score": 1, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 32186323}], "owner": {"user_id": 5193610, "profile_image": "https://graph.facebook.com/702352349868685/picture?type=large", "user_type": "registered", "reputation": 131, "link": "https://stackoverflow.com/users/5193610/rajiv-reddy", "accept_rate": 0, "display_name": "Rajiv Reddy"}, "view_count": 1214, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 10}, "question_id": 32186323}{"body": "<p>I'm trying to start a spark streaming job on mesos using the DCOS cli.\nI'm able to start the job. My program expects a config file to be passed as cli parameter. How do I achieve this with <strong>dcos spark run --submit-args</strong>?</p>\n\n<p>I tried --files <a href=\"http://server/path/to//file\" rel=\"nofollow\">http://server/path/to//file</a> hoping it will download files but that didn't work. Driver starts but fails because config file is missing.</p>\n\n<p>I also tried to roll up the jar and config file as tar and submitted it. I can see in Mesos logs that the tar was fetched and untar. Both config and jar file are seen in the working directory. But job fails with ClassNotFoundException. I suspect something was not right about how spark-submit was started.</p>\n\n<pre><code>dcos spark run --submit-args=\"--supervise --deploy-mode cluster --class package.name.classname http://file-server:8000/Streaming.tar.gz Streaming.conf\"\n</code></pre>\n\n<p>Any hint on how to proceed? Also, in which log file can I see the underlying spark-submit command used by DCOS?</p>\n", "is_answered": true, "title": "Spark submit using mesos dcos cli", "tags": ["mesos", "mesosphere", "marathon", "dcos"], "last_activity_date": 1459809748, "accepted_answer_id": 36406478, "creation_date": 1459392665, "answers": [{"body": "<p><code>Streaming.conf</code> is just a string that will be passed to your driver.  Your driver must be able to see it.  The easiest way to do this is to place it in an accessible location, the specify that you want it downloaded to the sandbox via <code>spark.mesos.uris</code> [1].  You could alternately write your application to support reading from a remote location, and just pass the location on the CLI.</p>\n\n<p><code>--files</code> is used to place files at the executors, but you're trying to pass a file to the driver, so that won't work.</p>\n\n<p>[1] <a href=\"http://spark.apache.org/docs/latest/running-on-mesos.html\" rel=\"nofollow\">http://spark.apache.org/docs/latest/running-on-mesos.html</a></p>\n\n<p>Michael Gummelt<br>\nMesosphere</p>\n", "answer_id": 36339600, "last_activity_date": 1459444202, "creation_date": 1459444202, "score": 2, "owner": {"user_id": 514187, "profile_image": "https://www.gravatar.com/avatar/ae96ef1fd1f1d8e7470df5bbdcf62411?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 328, "link": "https://stackoverflow.com/users/514187/michael-gummelt", "accept_rate": 14, "display_name": "Michael Gummelt"}, "is_accepted": false, "question_id": 36323287}, {"body": "<p>Here is the example of a command you should launch in order to make it work:</p>\n\n<p><code>dcos spark run --submit-args='--conf spark.mesos.uris=https://s3-us-west-2.amazonaws.com/andrey-so-36323287/pi.conf --class JavaSparkPiConf https://s3-us-west-2.amazonaws.com/andrey-so-36323287/sparkPi_without_config_file.jar /mnt/mesos/sandbox/pi.conf'</code></p>\n\n<p>Where</p>\n\n<blockquote>\n  <p><code>--conf spark.mesos.uris=...</code> A comma-separated list of URIs to be downloaded to the sandbox when driver or executor is launched by Mesos. This applies to both coarse-grained and fine-grained mode.</p>\n  \n  <p><code>/mnt/mesos/sandbox/pi.conf</code> A path to the downloaded file which your main class receives as a 0th parameter (see the code snippet below). <code>/mnt/mesos/sandbox/</code> is a standard path inside a container which is mapped to a corespondent mesos-task sandbox.</p>\n</blockquote>\n\n<pre class=\"lang-java prettyprint-override\"><code>public final class JavaSparkPiConf {\n\n  public static void main(String[] args) throws Exception {\n    SparkConf sparkConf = new SparkConf().setAppName(\"JavaSparkPi\");\n    JavaSparkContext jsc = new JavaSparkContext(sparkConf);\n\n    Scanner scanner = new Scanner(new FileInputStream(args[0]));\n    int slices;\n    if (scanner.hasNextInt()) {\n      slices = scanner.nextInt();\n    } else {\n      slices = 2;\n    }\n    int n = 100000 * slices;\n    List&lt;Integer&gt; l = new ArrayList&lt;&gt;(n);\n    for (int i = 0; i &lt; n; i++) {\n      l.add(i);\n    }\n\n    JavaRDD&lt;Integer&gt; dataSet = jsc.parallelize(l, slices);\n\n    int count = dataSet.map(new Function&lt;Integer, Integer&gt;() {\n      @Override\n      public Integer call(Integer integer) {\n        double x = Math.random() * 2 - 1;\n        double y = Math.random() * 2 - 1;\n        return (x * x + y * y &lt; 1) ? 1 : 0;\n      }\n    }).reduce(new Function2&lt;Integer, Integer, Integer&gt;() {\n      @Override\n      public Integer call(Integer integer, Integer integer2) {\n        return integer + integer2;\n      }\n    });\n\n    System.out.println(\"Pi is roughly \" + 4.0 * count / n);\n\n    jsc.stop();\n  }\n}\n</code></pre>\n", "answer_id": 36406478, "last_activity_date": 1459809748, "creation_date": 1459782846, "score": 3, "owner": {"user_id": 3052074, "profile_image": "https://www.gravatar.com/avatar/619c2a3b094423dd741dc8eb161836f0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 330, "link": "https://stackoverflow.com/users/3052074/andrey-dyatlov", "display_name": "Andrey Dyatlov"}, "is_accepted": true, "last_edit_date": 1459809748, "question_id": 36323287}], "score": 3, "link": "https://stackoverflow.com/questions/36323287/spark-submit-using-mesos-dcos-cli", "answer_count": 2, "owner": {"user_id": 3349257, "profile_image": "https://www.gravatar.com/avatar/f37b803a3616d628a6ec3ff4e646cf70?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 287, "link": "https://stackoverflow.com/users/3349257/cheeko", "accept_rate": 78, "display_name": "Cheeko"}, "view_count": 724, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 36323287}{"body": "<p>I am using DC/OS 1.8 community edition , 3 Master and 4 slaves. </p>\n\n<p>I deployed one marathon and run one service (tomcat), with VIP_0 of /testservice:8080</p>\n\n<p>Problem I facing , I am not able to access the newly created marathon's service by its URL.</p>\n\n<blockquote>\n  <p>ex : curl testservice.testmarathon.l4lb.thisdcos.directory:8080</p>\n</blockquote>\n\n<p>This curl not working only in one slave machine, others it works fine. and it is happening only for the newly deployed marathon , the old marathon services working fine. </p>\n\n<p>To DC/OS Team , </p>\n\n<p>I am planing to use DC/OS community edition for my production then migrate to Commercial one. Now I am so much scared to go with DC/OS. </p>\n", "is_answered": false, "tags": ["mesosphere", "dcos"], "title": "DC/OS service discovery fails from one particular node", "last_activity_date": 1495550911, "answer_count": 0, "creation_date": 1495452854, "score": 0, "link": "https://stackoverflow.com/questions/44111840/dc-os-service-discovery-fails-from-one-particular-node", "owner": {"user_id": 1124447, "profile_image": "https://www.gravatar.com/avatar/38565246d552f18c291145ff05c373d0?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 522, "link": "https://stackoverflow.com/users/1124447/vimal-prakash", "accept_rate": 48, "display_name": "vimal prakash"}, "view_count": 28, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 44111840}{"body": "<p>I am following <a href=\"https://github.com/mesos/hadoop\" rel=\"nofollow\">https://github.com/mesos/hadoop</a></p>\n\n<pre><code>On Linux:\n\n$ MESOS_NATIVE_JAVA_LIBRARY=/path/to/libmesos.so hadoop jobtracker\n</code></pre>\n\n<p>This gives an error of:</p>\n\n<blockquote>\n  <p>DEPRECATED: Use of this script to execute mapred command is\n  deprecated. Instead use the mapred command for it.</p>\n  \n  <p>Sorry, the jobtracker command is no longer supported. You may find\n  similar functionality with the \"yarn\" shell command. Usage: mapred\n  [--config confdir] COMMAND\n         where COMMAND is one of:   pipes                run a Pipes job   job                  manipulate MapReduce jobs   queue<br>\n  get information regarding JobQueues   classpath            prints the\n  class path needed for running\n                         mapreduce subcommands   historyserver        run job history servers as a standalone daemon   distcp \n   copy file or directories recursively   archive -archiveName\n  NAME -p  *  create a hadoop archive   hsadmin \n  job history server admin interface</p>\n  \n  <p>Most commands print help when invoked w/o parameters.</p>\n</blockquote>\n\n<p>While executing the downloaded hadoop binary yields:</p>\n\n<pre><code>~/hadoop-2.5.0-cdh5.2.0 # MESOS_NATIVE_JAVA_LIBRARY=/usr/lib/libmesos.so ./bin/hadoop jobtracker\nError: Could not find or load main class   org.apache.hadoop.mapred.JobTracker\n</code></pre>\n\n<p>What am i missing?</p>\n\n<p>CLASSPATH before execution:</p>\n\n<pre><code>root@mesos-master3 ~/hadoop-2.5.0-cdh5.2.0 # MESOS_NATIVE_JAVA_LIBRARY=/usr/lib/libmesos.so ./bin/hadoop jobtracker\n/root/hadoop-2.5.0-cdh5.2.0/bin-mapreduce1/../etc/hadoop:/usr/lib/tools.jar:/root/hadoop-2.5.0-cdh5.2.0/bin-mapreduce1/../share/hadoop/mapreduce1/hadoop-core-2.5.0-mr1-cdh5.2.0.jar:/root/hadoop-2.5.0-cdh5.2.0/bin-mapreduce1/../lib/*.jar:/root/hadoop-2.5.0-cdh5.2.0/bin-mapreduce1/../lib/jsp-2.1/*.jar:/root/hadoop-2.5.0-cdh5.2.0/bin-mapreduce1/../etc/hadoop:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/common/lib/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/common/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/hdfs:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/hdfs/lib/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/hdfs/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/yarn/lib/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/yarn/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/mapreduce:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/mapreduce/lib/*:/root/hadoop-2.5.0-cdh5.2.0/share/hadoop/mapreduce/*\nError: Could not find or load main class org.apache.hadoop.mapred.JobTracker\n</code></pre>\n", "is_answered": false, "tags": ["java", "linux", "hadoop", "mesos", "mesosphere"], "last_edit_date": 1432300907, "title": "mesos hadoop org.apache.hadoop.mapred.JobTracker not starting", "last_activity_date": 1456990528, "answer_count": 1, "creation_date": 1432299727, "score": 0, "link": "https://stackoverflow.com/questions/30397436/mesos-hadoop-org-apache-hadoop-mapred-jobtracker-not-starting", "answers": [{"body": "<p>Modern versions of Hadoop (2.4+) enable YARN/MapReduce2 by default, so the older MRv1 JobTracker/TaskTracker commands won't work out of the box. You'll either have to change your config to enable MRv1 (set <code>HADOOP_HOME</code> and <code>HADOOP_CONF_DIR</code> to point to the MR1 directories) or switch to YARN on Mesos via Myriad: <a href=\"https://github.com/mesos/myriad\" rel=\"nofollow\">https://github.com/mesos/myriad</a></p>\n", "answer_id": 31134071, "last_activity_date": 1435655418, "creation_date": 1435655418, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 30397436}], "owner": {"user_id": 1160840, "profile_image": "https://www.gravatar.com/avatar/8bacc6ec0fd4d84ec3482be576e2a661?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 45, "link": "https://stackoverflow.com/users/1160840/strzelecki-maciek", "accept_rate": 75, "display_name": "strzelecki.maciek"}, "view_count": 259, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 30397436}{"is_answered": false, "tags": ["cloud", "devops", "mesos", "marathon", "mesosphere"], "last_edit_date": 1499883774, "title": "Mesosphere slave goes down after a day. And Hadoop error is introduced", "last_activity_date": 1499883774, "answer_count": 0, "creation_date": 1499880607, "score": 0, "link": "https://stackoverflow.com/questions/45064171/mesosphere-slave-goes-down-after-a-day-and-hadoop-error-is-introduced", "owner": {"user_id": 7188364, "profile_image": "https://www.gravatar.com/avatar/a3b288540196f7eb3d914a9e5f95fc06?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 13, "link": "https://stackoverflow.com/users/7188364/nachiket-joshi", "display_name": "Nachiket Joshi"}, "view_count": 23, "_params_": {"body": true, "intitle": "mesosphere", "site": "stackoverflow.com", "comments": "false"}, "question_id": 45064171}{"body": "<p>I want to run a simple spark program, but i am  restricted by some errors.\nMy Environment is:\nCentOS:<strong>6.6</strong>\nJava: <strong>1.7.0_51</strong>\nScala: <strong>2.10.4</strong>\nSpark: <strong>spark-1.4.0-bin-hadoop2.6</strong>\nMesos: <strong>0.22.1</strong></p>\n\n<p>All are installed and nodes are up.Now i have one Mesos master and Mesos slave node. My spark properties are below:</p>\n\n<pre><code>spark.app.id            20150624-185838-2885789888-5050-1291-0005\nspark.app.name          Spark shell\nspark.driver.host   192.168.1.172\nspark.driver.memory 512m\nspark.driver.port   46428\nspark.executor.id   driver\nspark.executor.memory   512m\nspark.executor.uri  http://192.168.1.172:8080/spark-1.4.0-bin-hadoop2.6.tgz\nspark.externalBlockStore.folderName spark-91aafe3b-01a8-4c86-ac3b-999e278807c5\nspark.fileserver.uri    http://192.168.1.172:51240\nspark.jars  \nspark.master            mesos://zk://192.168.1.172:2181/mesos\nspark.mesos.coarse  true\nspark.repl.class.uri    http://192.168.1.172:51600\nspark.scheduler.mode    FIFO\n</code></pre>\n\n<p>Now when I started spark, it comes to scala prompt(scala>).\nAfter that I am getting following error: mesos task 1 is now TASK_FAILED, blacklisting mesos slave value due to too many failures is Spark installed on it\nHow to resolve this.</p>\n", "is_answered": true, "tags": ["apache-spark", "mesos", "mesosphere"], "title": "Running a simple Spark script on Mesos with Zookeeper", "last_activity_date": 1455974189, "answer_count": 2, "creation_date": 1435155831, "score": 0, "link": "https://stackoverflow.com/questions/31029236/running-a-simple-spark-script-on-mesos-with-zookeeper", "answers": [{"body": "<p>Could you check the mesos slave logs/ task information for more output on why the task failed. You could have a look at :5050.</p>\n\n<p>Probably unrelated question: Do you actually have zookeeper:</p>\n\n<pre><code>spark.master mesos://zk://192.168.1.172:2181/mesos\n</code></pre>\n\n<p>running (as you mentioned you only have one master)? </p>\n", "answer_id": 31042369, "last_activity_date": 1455974095, "creation_date": 1435212236, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "last_edit_date": 1455974095, "question_id": 31029236}, {"body": "<p>With only 900MB and <code>spark.driver.memory = 512m</code>, you will be able to launch the scheduler/REPL, but you won't have enough memory for <code>spark.executor.memory = 512m</code>, so any tasks will fail. Either increasing your VM memory size or reducing the driver/executor memory requirements will help you get around these memory limits.</p>\n", "answer_id": 31133085, "last_activity_date": 1455974189, "creation_date": 1435652371, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "last_edit_date": 1455974189, "question_id": 31029236}], "owner": {"user_id": 3374023, "profile_image": "https://www.gravatar.com/avatar/d0a08c35396d4edb7641de001c19ab80?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 16, "link": "https://stackoverflow.com/users/3374023/user3374023", "display_name": "user3374023"}, "view_count": 710, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 31029236}{"body": "<p>I've just written an Ansible playbook that deploys DC/OS with their CloudFormation template as shown here:<br>\n<a href=\"https://docs.mesosphere.com/1.8/administration/installing/cloud/aws/\" rel=\"nofollow\">https://docs.mesosphere.com/1.8/administration/installing/cloud/aws/</a><br>\nAnd it works fine!  </p>\n\n<p>Now I'm trying to connect on DC/OS with Ansible to deploy stuff on it, but of course I need to login first.<br>\nThe way I know to create the first account is to visit with a browser the DC/OS page.</p>\n\n<p>But I want to create this first account programmatically for Ansible, how can I do so?</p>\n\n<p>Cheers </p>\n", "is_answered": true, "title": "Ansible DC/OS deployment", "last_edit_date": 1473395635, "tags": ["mesos", "dcos"], "view_count": 422, "accepted_answer_id": 39531532, "last_activity_date": 1474028890, "answers": [{"body": "<p>Open Source DC/OS currently uses dcos-oauth</p>\n\n<p>The easiest way to automatically create a user is to create the relevant ZNode in ZooKeeper (/dcos/users/). Hopefully Ansible has a plugin to do this.</p>\n\n<p>Relevant code here:</p>\n\n<p><a href=\"https://github.com/dcos/dcos-oauth/blob/master/dcos-oauth/login.go#L100\" rel=\"nofollow\">https://github.com/dcos/dcos-oauth/blob/master/dcos-oauth/login.go#L100</a></p>\n\n<p>This being said, we're planning to open source parts of our Identity and Access Management service in the 1.10 release (available towards the end of 2016 or early 2017), at which point open DC/OS will get a REST API to do this automation.</p>\n", "answer_id": 39531532, "last_activity_date": 1474028890, "creation_date": 1474028890, "score": 1, "owner": {"user_id": 2033554, "profile_image": "https://www.gravatar.com/avatar/fa3279b202e9a85f7d90a0422bca4489?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 26, "link": "https://stackoverflow.com/users/2033554/fullung", "display_name": "fullung"}, "is_accepted": true, "question_id": 39395317}], "score": 1, "link": "https://stackoverflow.com/questions/39395317/ansible-dc-os-deployment", "answer_count": 1, "owner": {"user_id": 599728, "profile_image": "https://i.stack.imgur.com/1aQMn.jpg?s=128&g=1", "user_type": "registered", "reputation": 1515, "link": "https://stackoverflow.com/users/599728/joan", "accept_rate": 58, "display_name": "Joan"}, "creation_date": 1473349690, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 7}, "question_id": 39395317}{"body": "<p>I have a private Docker registry that is accessible at <a href=\"https://docker.somedomain.com\" rel=\"nofollow\">https://docker.somedomain.com</a> (over standard port 443 not 5000).  My infrastructure includes a set up of Mesosphere, which have docker containerizer enabled.  I'm am trying to deploy a specific container to a Mesos slave via Marathon; however, this always fails with Mesos failing the task almost immediately with no data in stderr and stdout of that sandbox.  </p>\n\n<p>I tried deploying from an image from the standard Docker Registry and it appears to work fine.  I'm having trouble figuring out what is wrong.  My private Docker registry does not require password authentication (turned off for debugging this), AND if I shell into the Meso's slave instance, and sudo su as root, I can run a 'docker pull docker.somedomain.com/services/myapp' successfully every time.</p>\n\n<p>Here is my Marathon post data for starting the task:</p>\n\n<pre><code>{\n  \"id\": \"myapp\",\n  \"cpus\": 0.5,\n  \"mem\": 64.0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"docker.somedomain.com/services/myapp:2\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        { \"containerPort\": 7000, \"hostPort\": 0, \"servicePort\": 0, \"protocol\": \"tcp\" }\n      ]\n    },\n    \"volumes\": [\n      {\n        \"containerPath\": \"application.yml\",\n        \"hostPath\": \"/var/myapp/application.yml\",\n        \"mode\": \"RO\"\n      }\n    ]\n  },\n  \"healthChecks\": [\n    {\n      \"protocol\": \"HTTP\",\n      \"portIndex\": 0,\n      \"path\": \"/\",\n      \"gracePeriodSeconds\": 5,\n      \"intervalSeconds\": 20,\n      \"maxConsecutiveFailures\": 3\n    }\n  ]\n}   \n</code></pre>\n\n<p>I've been stuck on this for almost a day now, everything I've tried seems to be yielding the same result.  Any insights on this would be much appreciated.</p>\n\n<p>My versions: \nMesos: 0.22.1\nMarathon: 0.8.2\nDocker: 1.6.2 </p>\n", "is_answered": true, "tags": ["docker", "mesos", "docker-registry", "mesosphere", "marathon"], "title": "Mesos cannot deploy container from private Docker registry", "last_activity_date": 1435329095, "answer_count": 3, "creation_date": 1435256531, "score": 2, "link": "https://stackoverflow.com/questions/31057910/mesos-cannot-deploy-container-from-private-docker-registry", "answers": [{"body": "<p>If it is a problem between Marathon and the registry, the answer should be in the http logs of your registry. If Marathon connects, there will be an entry. And the Mesos master log should contain a clue as well.</p>\n\n<p>It doesn't really sound like a problem between Marathon and Registry though. Are you sure you have 'docker,mesos' in /etc/mesos-slave/containerizers?</p>\n", "answer_id": 31068672, "last_activity_date": 1435308102, "creation_date": 1435308102, "score": 0, "owner": {"user_id": 4277731, "profile_image": "https://www.gravatar.com/avatar/ad48f508ec67c999941685b945abb5a7?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 31, "link": "https://stackoverflow.com/users/4277731/thijs-schnitger", "display_name": "Thijs Schnitger"}, "is_accepted": false, "question_id": 31057910}, {"body": "<p>Did you --despite having no authentification-- try to follow <a href=\"https://mesosphere.github.io/marathon/docs/native-docker.html\" rel=\"nofollow\">Using a Private Docker Repository</a>?</p>\n\n<blockquote>\n  <p>To supply credentials to pull from a private repository, add a .dockercfg to the uris field of your app. The $HOME environment variable will then be set to the same value as $MESOS_SANDBOX so Docker can automatically pick up the config file.</p>\n</blockquote>\n", "answer_id": 31071937, "last_activity_date": 1435317707, "creation_date": 1435317707, "score": 0, "owner": {"user_id": 1373454, "profile_image": "https://i.stack.imgur.com/rJSGo.jpg?s=128&g=1", "user_type": "registered", "reputation": 2021, "link": "https://stackoverflow.com/users/1373454/js84", "accept_rate": 75, "display_name": "js84"}, "is_accepted": false, "question_id": 31057910}, {"body": "<p>So this turns out to be an issue with volumes</p>\n\n<pre><code>\"volumes\": [\n      {\n        \"containerPath\": \"/application.yml\",\n        \"hostPath\": \"/var/myapp/application.yml\",\n        \"mode\": \"RO\"\n      }\n    ]\n</code></pre>\n\n<p>Using the root path of the container of the root path may be legal in docker, but Mesos appears not to handle this behavior.  Modifying the containerPath to a non-root path resolves this, i.e</p>\n\n<pre><code>\"volumes\": [\n      {\n        \"containerPath\": \"/var\",\n        \"hostPath\": \"/var/myapp\",\n        \"mode\": \"RW\"\n      }\n    ]\n</code></pre>\n", "answer_id": 31075844, "last_activity_date": 1435329095, "creation_date": 1435329095, "score": 2, "owner": {"user_id": 695624, "profile_image": "https://www.gravatar.com/avatar/5cf03a8436d5207df2946238fb26df2a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 73, "link": "https://stackoverflow.com/users/695624/user695624", "accept_rate": 20, "display_name": "user695624"}, "is_accepted": false, "question_id": 31057910}], "owner": {"user_id": 695624, "profile_image": "https://www.gravatar.com/avatar/5cf03a8436d5207df2946238fb26df2a?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 73, "link": "https://stackoverflow.com/users/695624/user695624", "accept_rate": 20, "display_name": "user695624"}, "view_count": 1324, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 11}, "question_id": 31057910}{"body": "<p>I have to integrate HDP with Mesos. I don't want to do it with cloudbreak, because it's not a mature project. Is there any other ways you can integrate HDP with Mesos ?</p>\n", "is_answered": false, "tags": ["hadoop", "bigdata", "mesos", "hortonworks-data-platform", "dcos"], "title": "Integration of Hortonworks HDP with Mesos", "last_activity_date": 1465402545, "answer_count": 1, "creation_date": 1465380767, "score": 0, "link": "https://stackoverflow.com/questions/37699575/integration-of-hortonworks-hdp-with-mesos", "answers": [{"body": "<p>See Apache Myriad (incubating) at <a href=\"http://myriad.incubator.apache.org/\" rel=\"nofollow\">http://myriad.incubator.apache.org/</a></p>\n", "answer_id": 37707779, "last_activity_date": 1465402545, "creation_date": 1465402545, "score": 0, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 37699575}], "owner": {"user_id": 2583343, "profile_image": "https://www.gravatar.com/avatar/00cc218a21189ccab2bde125c91c21bd?s=128&d=identicon&r=PG&f=1", "user_type": "registered", "reputation": 528, "link": "https://stackoverflow.com/users/2583343/vishnu-nair", "accept_rate": 50, "display_name": "Vishnu Nair"}, "view_count": 243, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 37699575}{"body": "<p>Some guidance required for building mesosphere solution on Amazon EC2 servers. </p>\n\n<p>For the staging state of my application I was thinking of launching a master and a slave on a single instance plus another slave on a different instance. Plus marathon and chronos frameworks on top of mesos master node. </p>\n\n<p>Marathon should be responsible for running http server on the same instance, which should serve as an access layer to the mesosphere API's. </p>\n\n<p>Chronos will be used to run 1000s of very simple bash script (execution time about 1-5sec) each. (in this part not sure if aggregation of jobs is needed) </p>\n\n<ol>\n<li><p>Should I run chronos via marathon, or just launch it as the service on my master node? Is there any difference? </p></li>\n<li><p>Any guidance/advice on the current architecture design? </p></li>\n<li><p>Is there a official support from Amazon to run mesosphere in amazon cloud? </p></li>\n</ol>\n", "is_answered": true, "title": "Mesos Chronos cluster design solution on EC2 instaces", "tags": ["amazon-web-services", "design", "amazon-ec2", "mesos", "mesosphere"], "last_activity_date": 1454257106, "accepted_answer_id": 35116075, "creation_date": 1453908147, "answers": [{"body": "<p>You can run a single master mesos cluster only on two hosts but it will not be HA so there is no need to run two instances of anything except the mesos-slave.</p>\n\n<p>If you really only want to use two hosts and use mesos I would recommend the following setup:</p>\n\n<p>Host1:  </p>\n\n<ul>\n<li>zookeeper</li>\n<li>mesos-master</li>\n<li>mesos-slave</li>\n<li>marathon</li>\n<li>chronos</li>\n</ul>\n\n<p>Host2:</p>\n\n<ul>\n<li>mesos-slave</li>\n</ul>\n\n<p>You need to configure the quorum number to 1 and run the cluster like that (no master election can happend that way, if Host1 dies, all processes stop executing). In practice you could run two instances of zookeeper and mesos-master (I saw a working setup like that) but in theory the leader election might screw up things because of the quorum setup of only 2 zookeeper nodes. My advice is to use at least 3 host (each host running a zookeeper, mesos-master, mesos-slave, marathon and chronos, new host's only need to run mesos-slave). This way you can manage with a host down.</p>\n\n<p>If you really want to stick to the two host setup I already gave my advice, ask if I haven't answered something.</p>\n\n<p>Also I don't know any official amazon support for mesos.</p>\n", "answer_id": 35116075, "last_activity_date": 1454257106, "creation_date": 1454257106, "score": 0, "owner": {"user_id": 1668665, "profile_image": "https://www.gravatar.com/avatar/8f0c2f6f79872479b9ebd1040e681efa?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 66, "link": "https://stackoverflow.com/users/1668665/salaander", "display_name": "Salaander"}, "is_accepted": true, "question_id": 35041272}], "score": 0, "link": "https://stackoverflow.com/questions/35041272/mesos-chronos-cluster-design-solution-on-ec2-instaces", "answer_count": 1, "owner": {"user_id": 1597656, "profile_image": "https://www.gravatar.com/avatar/22f0d3352b38fd97b8d86992c5dde179?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1600, "link": "https://stackoverflow.com/users/1597656/yerken", "accept_rate": 80, "display_name": "Yerken"}, "view_count": 90, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 8}, "question_id": 35041272}{"body": "<p>I am running a storm cluster on AWS. But I want the storm cluster to expand automatically when the need comes. I figured out mesos is something like that. But I do not have much knowledge about mesos and its deployment on AWS.</p>\n\n<p>Can mesos on AWS automatically increase the parallelism of my topology tasks by launching new instances and shutting them down when not necessary? If it can, how do we configure mesos for the same. </p>\n", "is_answered": true, "tags": ["amazon-web-services", "amazon-ec2", "apache-storm", "mesos", "mesosphere"], "last_edit_date": 1428642767, "title": "Strom on Mesos in AWS", "last_activity_date": 1429766099, "answer_count": 2, "creation_date": 1428496413, "score": 2, "link": "https://stackoverflow.com/questions/29514751/strom-on-mesos-in-aws", "answers": [{"body": "<p>Yes, you're heading in the right direction. However I'd suggest to use <a href=\"https://mesosphere.github.io/marathon/\" rel=\"nofollow\">Marathon</a> rather than the low-level Mesos API.</p>\n\n<p>See for example the GitHub repo <a href=\"https://github.com/obaidsalikeen/storm-marathon\" rel=\"nofollow\">obaidsalikeen/storm-marathon</a>, which is particularly well done in terms of completeness and documentation richness.</p>\n", "answer_id": 29574422, "last_activity_date": 1428729714, "creation_date": 1428729714, "score": 0, "owner": {"user_id": 396567, "profile_image": "https://www.gravatar.com/avatar/5c3807aaaf0ffefe6c75e3dbbb8588b5?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 3455, "link": "https://stackoverflow.com/users/396567/michael-hausenblas", "accept_rate": 80, "display_name": "Michael Hausenblas"}, "is_accepted": false, "question_id": 29514751}, {"body": "<p>Mesos does not directly handle autoscaling itself, but allows frameworks running on top of it to receive new resource offers and react to them by launching new task instances. I haven't used it personally, but you could try the Storm-Mesos framework for running Storm on Mesos: <a href=\"https://github.com/mesos/storm\" rel=\"nofollow\">https://github.com/mesos/storm</a></p>\n\n<p>Once you have Storm running on Mesos, ready to launch new instances as resources come available, you're ready to autoscale within the existing cluster's capacity. You'll probably want to take advantage of Amazon's Auto-Scaling Groups (ASGs) to scale up the number of Mesos nodes based on your need. As the ASG scales up more Mesos nodes, the resources from those nodes will be automatically offered to the Storm-Mesos framework, which can launch more Storm instances.</p>\n", "answer_id": 29814269, "last_activity_date": 1429766099, "creation_date": 1429766099, "score": 1, "owner": {"user_id": 4056606, "profile_image": "https://i.stack.imgur.com/Zb6Mv.png?s=128&g=1", "user_type": "registered", "reputation": 3882, "link": "https://stackoverflow.com/users/4056606/adam", "display_name": "Adam"}, "is_accepted": false, "question_id": 29514751}], "owner": {"user_id": 2366051, "profile_image": "https://www.gravatar.com/avatar/da3882c798fd179efe8a7d253ab6c919?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 115, "link": "https://stackoverflow.com/users/2366051/bhargav-sarvepalli", "accept_rate": 14, "display_name": "Bhargav Sarvepalli"}, "view_count": 178, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 12}, "question_id": 29514751}{"body": "<p>I have DCOS installed behind a firewall where there is no internet access.  I want to be able to install packages into the cluster (e.g. Kafka) and so I have built a local universe, using the instructions <a href=\"https://docs.mesosphere.com/1.9/installing/custom/deploying-a-local-dcos-universe/\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>When I build the local universe (from a computer with internet access and by cloning the universe repo on <a href=\"https://github.com/mesosphere/universe\" rel=\"nofollow noreferrer\">Github</a>), I see the script causes the downloading of resources (URL resources defined in the <code>resource.json</code> file as well as docker images).  The process creates a file that I am able to upload to the DCOS cluster as a local universe.</p>\n\n<p>However, when I try to install packages into the DCOS cluster from this local universe, not all of them install.  The ones that fail seem to rely on docker images, and I see an error message in the mess logs that looks like:</p>\n\n<pre><code>Container xxx for executor yyy of framework zzz failed to start. Failed to perform 'curl': curl: 96) Could not resolve host: registry-1.docker.io\n</code></pre>\n\n<p>The cluster appears to be trying to reach the Docker registry, which of course it can't, as it's behind the corporate firewall.  This appears to relate to <a href=\"https://issues.apache.org/jira/browse/MESOS-6810\" rel=\"nofollow noreferrer\">MESOS-6810</a>, which simply says that the mesos cluster should be run with <code>--docker-registry</code> pointing to a local docker registry.  I have yet to reinstall the DCOS cluster from scratch with the <code>[cluster_docker_registry_url][4]</code> installation config option pointing to a local docker registry.</p>\n\n<p>My question is why does the build process for a local universe download docker images when the installation process for a package then tries to download docker images too? The packages I want to have available to be installed inside the cluster result in a local universe of 9 GB. I'm trying to understand under what circumstances DCOS will attempt to contact hosts outside the cluster.</p>\n", "is_answered": false, "tags": ["docker", "mesos", "mesosphere", "dcos"], "title": "How does a DCOS local universe handle docker resources used by packages?", "last_activity_date": 1493498123, "answer_count": 0, "creation_date": 1493498123, "score": 0, "link": "https://stackoverflow.com/questions/43700220/how-does-a-dcos-local-universe-handle-docker-resources-used-by-packages", "owner": {"user_id": 272023, "profile_image": "https://www.gravatar.com/avatar/25dbc4a263833e5a5b36f5394cfc1d01?s=128&d=identicon&r=PG", "user_type": "registered", "reputation": 1708, "link": "https://stackoverflow.com/users/272023/john", "accept_rate": 66, "display_name": "John"}, "view_count": 45, "_params_": {"body": "false", "tagged": "mesosphere", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 2}, "question_id": 43700220}{"body": "<p>When I want use</p>\n\n<pre><code>\"constraints\": [[\"hostname\", \"CLUSTER\", \"192.168.18.6(1|2)\"]]\n</code></pre>\n\n<p>or</p>\n\n<pre><code>\"constraints\": [[\"hostname\", \"CLUSTER\", \"DCOS-S-0(1|2)\"]] \n</code></pre>\n\n<p>In Marathon app name \"/zaslepki/4maxpl\" has all the time Waiting status</p>\n\n<p>So I try use attribute - I execute:</p>\n\n<pre><code>[root@DCOS-S-00 etc]# systemctl stop dcos-mesos-slave-public.service\n[root@DCOS-S-00 etc]# mesos-slave --work_dir=/var/lib/mesos/slave --attributes=DC:DL01 --master=zk://192.168.18.51:2181,192.168.18.51:2181,192.168.18.53:2181/mesos\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nI1229 13:16:19.800616 24537 main.cpp:243] Build: 2016-11-07 21:31:04 by \nI1229 13:16:19.800720 24537 main.cpp:244] Version: 1.0.1\nI1229 13:16:19.800726 24537 main.cpp:251] Git SHA: d5746045ac740d5f28f238dc55ec95c89d2b7cd9\nI1229 13:16:19.807195 24537 systemd.cpp:237] systemd version `219` detected\nI1229 13:16:19.807232 24537 main.cpp:342] Inializing systemd state\nI1229 13:16:19.820071 24537 systemd.cpp:325] Started systemd slice `mesos_executors.slice`\nI1229 13:16:19.821051 24537 containerizer.cpp:196] Using isolation: posix/cpu,posix/mem,filesystem/posix,network/cni\nI1229 13:16:19.825422 24537 linux_launcher.cpp:101] Using /sys/fs/cgroup/freezer as the freezer hierarchy for the Linux launcher\nI1229 13:16:19.826690 24537 main.cpp:434] Starting Mesos agent\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@726: Client environment:zookeeper.version=zookeeper C client 3.4.8\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@730: Client environment:host.name=DCOS-S-00\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@737: Client environment:os.name=Linux\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@738: Client environment:os.arch=3.10.0-514.2.2.el7.x86_64\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@739: Client environment:os.version=#1 SMP Tue Dec 6 23:06:41 UTC 2016\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@747: Client environment:user.name=root\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@755: Client environment:user.home=/root\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@log_env@767: Client environment:user.dir=/opt/mesosphere/etc\n2016-12-29 13:16:19,827:24537(0x7f8ecae60700):ZOO_INFO@zookeeper_init@800: Initiating client connection, host=192.168.18.51:2181,192.168.18.51:2181,192.168.18.53:2181 sessionTimeout=10000 watcher=0x7f8ed221a030 sessionId=0 sessionPasswd=&lt;null&gt; context=0x7f8ebc001ee0 flags=0\nI1229 13:16:19.828233 24537 slave.cpp:198] Agent started on 1)@192.168.18.60:5051\n2016-12-29 13:16:19,828:24537(0x7f8ec8c49700):ZOO_INFO@check_events@1728: initiated connection to server [192.168.18.51:2181]\nI1229 13:16:19.828263 24537 slave.cpp:199] Flags at startup: --appc_simple_discovery_uri_prefix=\"http://\" --appc_store_dir=\"/tmp/mesos/store/appc\" --attributes=\"DC:DL01\" --authenticate_http_readonly=\"false\" --authenticate_http_readwrite=\"false\" --authenticatee=\"crammd5\" --authentication_backoff_factor=\"1secs\" --authorizer=\"local\" --cgroups_cpu_enable_pids_and_tids_count=\"false\" --cgroups_enable_cfs=\"false\" --cgroups_hierarchy=\"/sys/fs/cgroup\" --cgroups_limit_swap=\"false\" --cgroups_root=\"mesos\" --container_disk_watch_interval=\"15secs\" --containerizers=\"mesos\" --default_role=\"*\" --disk_watch_interval=\"1mins\" --docker=\"docker\" --docker_kill_orphans=\"true\" --docker_registry=\"https://registry-1.docker.io\" --docker_remove_delay=\"6hrs\" --docker_socket=\"/var/run/docker.sock\" --docker_stop_timeout=\"0ns\" --docker_store_dir=\"/tmp/mesos/store/docker\" --docker_volume_checkpoint_dir=\"/var/run/mesos/isolators/docker/volume\" --enforce_container_disk_quota=\"false\" --executor_registration_timeout=\"1mins\" --executor_shutdown_grace_period=\"5secs\" --fetcher_cache_dir=\"/tmp/mesos/fetch\" --fetcher_cache_size=\"2GB\" --frameworks_home=\"\" --gc_delay=\"1weeks\" --gc_disk_headroom=\"0.1\" --hadoop_home=\"\" --help=\"false\" --hostname_lookup=\"true\" --http_authenticators=\"basic\" --http_command_executor=\"false\" --image_provisioner_backend=\"copy\" --initialize_driver_logging=\"true\" --ip_discovery_command=\"/opt/mesosphere/bin/detect_ip\" --isolation=\"posix/cpu,posix/mem\" --launcher_dir=\"/opt/mesosphere/packages/mesos--253f5cb0a96e2e3574293ddfecf5c63358527377/libexec/mesos\" --logbufsecs=\"0\" --logging_level=\"INFO\" --master=\"zk://192.168.18.51:2181,192.168.18.51:2181,192.168.18.53:2181/mesos\" --oversubscribed_resources_interval=\"15secs\" --perf_duration=\"10secs\" --perf_interval=\"1mins\" --port=\"5051\" --qos_correction_interval_min=\"0ns\" --quiet=\"false\" --recover=\"reconnect\" --recovery_timeout=\"15mins\" --registration_backoff_factor=\"1secs\" --revocable_cpu_low_priority=\"true\" --sandbox_directory=\"/mnt/mesos/sandbox\" --strict=\"true\" --switch_user=\"true\" --systemd_enable_support=\"true\" --systemd_runtime_directory=\"/run/systemd/system\" --version=\"false\" --work_dir=\"/var/lib/mesos/slave\"\nI1229 13:16:19.829263 24537 slave.cpp:519] Agent resources: cpus(*):8; mem(*):6541; disk(*):36019; ports(*):[31000-32000]\nI1229 13:16:19.829306 24537 slave.cpp:527] Agent attributes: [ DC=DL01 ]\nI1229 13:16:19.829319 24537 slave.cpp:532] Agent hostname: DCOS-S-00\n2016-12-29 13:16:19,832:24537(0x7f8ec8c49700):ZOO_INFO@check_events@1775: session establishment complete on server [192.168.18.51:2181], sessionId=0x1593f6a1ef20fce, negotiated timeout=10000\nI1229 13:16:19.832623 24548 state.cpp:57] Recovering state from '/var/lib/mesos/slave/meta'\nI1229 13:16:19.832695 24547 group.cpp:349] Group process (group(1)@192.168.18.60:5051) connected to ZooKeeper\nI1229 13:16:19.832723 24547 group.cpp:837] Syncing group operations: queue size (joins, cancels, datas) = (0, 0, 0)\nI1229 13:16:19.832736 24547 group.cpp:427] Trying to create path '/mesos' in ZooKeeper\nI1229 13:16:19.834234 24547 detector.cpp:152] Detected a new leader: (id='70')\nI1229 13:16:19.834319 24547 group.cpp:706] Trying to get '/mesos/json.info_0000000070' in ZooKeeper\nI1229 13:16:19.835002 24547 zookeeper.cpp:259] A new leading master (UPID=master@192.168.18.53:5050) is detected\nFailed to perform recovery: Incompatible agent info detected.\n------------------------------------------------------------\nOld agent info:\nhostname: \"192.168.18.60\"\nresources {\n  name: \"ports\"\n  type: RANGES\n  ranges {\n    range {\n      begin: 1\n      end: 21\n    }\n    range {\n      begin: 23\n      end: 5050\n    }\n    range {\n      begin: 5052\n      end: 32000\n    }\n  }\n  role: \"slave_public\"\n}\nresources {\n  name: \"disk\"\n  type: SCALAR\n  scalar {\n    value: 37284\n  }\n  role: \"slave_public\"\n}\nresources {\n  name: \"cpus\"\n  type: SCALAR\n  scalar {\n    value: 8\n  }\n  role: \"slave_public\"\n}\nresources {\n  name: \"mem\"\n  type: SCALAR\n  scalar {\n    value: 6541\n  }\n  role: \"slave_public\"\n}\nattributes {\n  name: \"public_ip\"\n  type: TEXT\n  text {\n    value: \"true\"\n  }\n}\nid {\n  value: \"8bc3d621-ed8a-4641-88c1-7a7163668263-S9\"\n}\ncheckpoint: true\nport: 5051\n\n------------------------------------------------------------\nNew agent info:\nhostname: \"DCOS-S-00\"\nresources {\n  name: \"cpus\"\n  type: SCALAR\n  scalar {\n    value: 8\n  }\n  role: \"*\"\n}\nresources {\n  name: \"mem\"\n  type: SCALAR\n  scalar {\n    value: 6541\n  }\n  role: \"*\"\n}\nresources {\n  name: \"disk\"\n  type: SCALAR\n  scalar {\n    value: 36019\n  }\n  role: \"*\"\n}\nresources {\n  name: \"ports\"\n  type: RANGES\n  ranges {\n    range {\n      begin: 31000\n      end: 32000\n    }\n  }\n  role: \"*\"\n}\nattributes {\n  name: \"DC\"\n  type: TEXT\n  text {\n    value: \"DL01\"\n  }\n}\nid {\n  value: \"8bc3d621-ed8a-4641-88c1-7a7163668263-S9\"\n}\ncheckpoint: true\nport: 5051\n\n------------------------------------------------------------\nTo remedy this do as follows:\nStep 1: rm -f /var/lib/mesos/slave/meta/slaves/latest\n        This ensures agent doesn't recover old live executors.\nStep 2: Restart the agent.\n[root@DCOS-S-00 etc]# rm -f /var/lib/mesos/slave/meta/slaves/latest\n[root@DCOS-S-00 etc]# systemctl start dcos-mesos-slave-public.service\n</code></pre>\n\n<p>and I use in .json application configuration file</p>\n\n<pre><code>\"constraints\": [[\"DC\", \"CLUSTER\", \"DL01\"]]\n</code></pre>\n\n<p>Status application is Waiting.....</p>\n\n<p>This is my .json file aplication \"/zaslepki/4maxpl\"</p>\n\n<pre><code>{\n  \"id\": \"/zaslepki/4maxpl\",\n  \"cmd\": null,\n  \"cpus\": 0.5,\n  \"mem\": 256,\n  \"disk\": 0,\n  \"instances\": 2,\n  \"constraints\": [[\"hostname\", \"CLUSTER\", \"DCOS-S-0(3|4)\"]],\n  \"acceptedResourceRoles\": [\n    \"slave_public\"\n  ],\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"volumes\": [],\n    \"docker\": {\n      \"image\": \"arekmax/4maxpl\",\n      \"network\": \"BRIDGE\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 80,\n          \"hostPort\": 0,\n          \"servicePort\": 10015,\n          \"protocol\": \"tcp\",\n          \"labels\": {}\n        }\n      ],\n      \"privileged\": false,\n      \"parameters\": [],\n      \"forcePullImage\": false\n    }\n  },\n  \"healthChecks\": [\n    {\n      \"path\": \"/\",\n      \"protocol\": \"HTTP\",\n      \"portIndex\": 0,\n      \"gracePeriodSeconds\": 300,\n      \"intervalSeconds\": 30,\n      \"timeoutSeconds\": 10,\n      \"maxConsecutiveFailures\": 2,\n      \"ignoreHttp1xx\": false\n    }\n  ],\n  \"labels\": {\n    \"HAPROXY_GROUP\": \"external\"\n  },\n  \"portDefinitions\": [\n    {\n      \"port\": 10015,\n      \"protocol\": \"tcp\",\n      \"labels\": {}\n    }\n  ]\n}\n</code></pre>\n\n<p>What I do wrong? I find that same problem <a href=\"https://groups.google.com/forum/#!topic/marathon-framework/zZOQg0vrgXM\" rel=\"nofollow noreferrer\">link</a> but there problem was fixed by use </p>\n\n<p>constraints: [[\"DC\", \"CLUSTER\", \"DL01\"]]</p>\n", "is_answered": true, "tags": ["constraints", "hostname", "marathon", "dcos"], "last_edit_date": 1483103990, "title": "DC/OS Marathon constraints hostname list", "last_activity_date": 1483103990, "answer_count": 1, "creation_date": 1482938081, "score": 2, "link": "https://stackoverflow.com/questions/41364821/dc-os-marathon-constraints-hostname-list", "answers": [{"body": "<p>You've got a clue in a log:</p>\n\n<blockquote>\n  <p>Invalid attribute key:value pair 'DL01'</p>\n</blockquote>\n\n<p>Change your attribute to key:value pair e.g., <code>DC:DL01</code> and it should work. Probably you will need to clean metadata directory because you are changing Agent configuration.</p>\n\n<p>Cluster operator doesnt work with multiple values. You need to pass regular expression so your it should looks like this</p>\n\n<pre><code>\"constraints\": [[\"hostname\", \"LIKE\", \"192.168.18.6(1|2)\"]]\n</code></pre>\n", "answer_id": 41365075, "last_activity_date": 1483025019, "creation_date": 1482938998, "score": 2, "owner": {"user_id": 1387612, "profile_image": "https://i.stack.imgur.com/j3ybF.png?s=128&g=1", "user_type": "registered", "reputation": 3770, "link": "https://stackoverflow.com/users/1387612/janisz", "display_name": "janisz"}, "is_accepted": false, "last_edit_date": 1483025019, "question_id": 41364821}], "owner": {"user_id": 6464173, "profile_image": "https://lh4.googleusercontent.com/-ysDEIwtaQ4w/AAAAAAAAAAI/AAAAAAAAA90/TDjOH69Mf8k/photo.jpg?sz=128", "user_type": "registered", "reputation": 29, "link": "https://stackoverflow.com/users/6464173/arek", "accept_rate": 0, "display_name": "Arek"}, "view_count": 563, "_params_": {"body": "false", "tagged": "dcos", "site": "stackoverflow.com", "comments": "false", "filter": "_ba", "page": 5}, "question_id": 41364821}